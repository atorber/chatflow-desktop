{
    "response": {
      "statusCode": 200,
      "body": {
        "apiVersion": "kubeflow.org/v1",
        "items": [
          {
            "apiVersion": "kubeflow.org/v1",
            "kind": "PyTorchJob",
            "metadata": {
              "annotations": {
                "aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": "",
                "aijob.cce.baidubce.com/timeline": "[{\"conditionType\":\"Created\",\"time\":1721652110},{\"conditionType\":\"Scheduled\",\"time\":1721652111},{\"conditionType\":\"Running\",\"time\":1721652144},{\"conditionType\":\"Failed\",\"time\":1721652265}]"
              },
              "creationTimestamp": "2024-07-22T12:41:50Z",
              "generation": 2,
              "managedFields": [
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        ".": {},
                        "f:aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": {},
                        "f:aijob.cce.baidubce.com/timeline": {}
                      }
                    },
                    "f:spec": {
                      "f:pytorchReplicaSpecs": {
                        "f:Master": {
                          "f:template": {
                            "f:metadata": {},
                            "f:spec": {
                              "f:containers": {}
                            }
                          }
                        }
                      },
                      "f:runPolicy": {
                        ".": {},
                        "f:cleanPodPolicy": {}
                      }
                    }
                  },
                  "manager": "controller",
                  "operation": "Update",
                  "time": "2024-07-22T12:41:50Z"
                },
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:spec": {
                      ".": {},
                      "f:pytorchReplicaSpecs": {
                        ".": {},
                        "f:Master": {
                          ".": {},
                          "f:replicas": {},
                          "f:restartPolicy": {},
                          "f:template": {
                            ".": {},
                            "f:spec": {
                              ".": {},
                              "f:schedulerName": {},
                              "f:terminationGracePeriodSeconds": {},
                              "f:volumes": {}
                            }
                          }
                        }
                      }
                    }
                  },
                  "manager": "kubectl-create",
                  "operation": "Update",
                  "time": "2024-07-22T12:41:50Z"
                },
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:status": {
                      ".": {},
                      "f:completionTime": {},
                      "f:conditions": {},
                      "f:lastReconcileTime": {},
                      "f:replicaStatuses": {
                        ".": {},
                        "f:Master": {
                          ".": {},
                          "f:failed": {},
                          "f:selector": {}
                        }
                      },
                      "f:startTime": {}
                    }
                  },
                  "manager": "manager",
                  "operation": "Update",
                  "time": "2024-07-22T12:44:25Z"
                }
              ],
              "name": "agile-aiak-training-llm-pengxiangyu-1721652109",
              "namespace": "default",
              "resourceVersion": "2376292738",
              "uid": "0f0fbd78-3cd4-41f3-84ed-153f615d57fd"
            },
            "spec": {
              "pytorchReplicaSpecs": {
                "Master": {
                  "replicas": 1,
                  "restartPolicy": "Never",
                  "template": {
                    "metadata": {},
                    "spec": {
                      "containers": [
                        {
                          "command": [
                            "/bin/bash",
                            "-c",
                            "\n#! /bin/bash\nset -euo pipefail\nmkdir -p /workspace/logs\n\necho \"开始下载 aiak_training_llm\"\ncd /workspace && rm -rf AIAK-Training-LLM\nwget https://cce-ai-datasets.bj.bcebos.com/hac_test/AIAK-Training-LLM/develop/20240722_1721651386/AIAK-Training-LLM.tar.gz\ntar -zxvf AIAK-Training-LLM.tar.gz\necho \"下载完成 aiak_training_llm\"\n\ncd /workspace/AIAK-Training-LLM/ci/tests/scripts\nextra_param=\"--node_nums 1                              --gpu_nums 8                              --models baichuan2-13b baichuan2-7b llama-2-7b llama-3-8b qwen-7b                              --tasks check_correctness_task check_precess_data_task                              --ckpt_loss_diff 0.01                              --timeout 7200\"\nif [[ \"false\" == \"true\" ]]; then\n    extra_param=\"$extra_param --use_nccl\"\nfi\ncommand=\"python3 main.py $extra_param\"\necho \"任务开始执行: $command\"\neval $command"
                          ],
                          "env": [
                            {
                              "name": "TRAIN_DATA_DIR",
                              "value": "/mnt/pfs/leoli"
                            },
                            {
                              "name": "CUDA_DEVICE_MAX_CONNECTIONS",
                              "value": "1"
                            },
                            {
                              "name": "NCCL_DEBUG",
                              "value": "INFO"
                            },
                            {
                              "name": "timeout",
                              "value": "7200"
                            },
                            {
                              "name": "BOS_SYNC_MEGATRON_SCRIPTS_ADDR"
                            }
                          ],
                          "image": "registry.baidubce.com/hac-aiacc/aiak-training-llm:ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_dev_20240722_203000_encrypt",
                          "imagePullPolicy": "Always",
                          "name": "pytorch",
                          "ports": [
                            {
                              "containerPort": 23456,
                              "name": "pytorchjob-port",
                              "protocol": "TCP"
                            }
                          ],
                          "resources": {
                            "limits": {
                              "baidu.com/a800_80g_cgpu": "8"
                            }
                          },
                          "securityContext": {
                            "capabilities": {
                              "add": [
                                "IPC_LOCK"
                              ]
                            }
                          },
                          "volumeMounts": [
                            {
                              "mountPath": "/mnt/pfs",
                              "name": "pfs"
                            },
                            {
                              "mountPath": "/dev/shm",
                              "name": "cache-volume"
                            }
                          ]
                        }
                      ],
                      "schedulerName": "volcano",
                      "terminationGracePeriodSeconds": 10,
                      "volumes": [
                        {
                          "name": "pfs",
                          "persistentVolumeClaim": {
                            "claimName": "pvc-pfs"
                          }
                        },
                        {
                          "emptyDir": {
                            "medium": "Memory"
                          },
                          "name": "cache-volume"
                        }
                      ]
                    }
                  }
                }
              },
              "runPolicy": {
                "cleanPodPolicy": "None"
              }
            },
            "status": {
              "completionTime": "2024-07-22T12:44:25Z",
              "conditions": [
                {
                  "lastTransitionTime": "2024-07-22T12:41:50Z",
                  "lastUpdateTime": "2024-07-22T12:41:50Z",
                  "message": "PyTorchJob agile-aiak-training-llm-pengxiangyu-1721652109 is created.",
                  "reason": "PyTorchJobCreated",
                  "status": "True",
                  "type": "Created"
                },
                {
                  "lastTransitionTime": "2024-07-22T12:42:24Z",
                  "lastUpdateTime": "2024-07-22T12:42:24Z",
                  "message": "PyTorchJob agile-aiak-training-llm-pengxiangyu-1721652109 is running.",
                  "reason": "JobRunning",
                  "status": "False",
                  "type": "Running"
                },
                {
                  "lastTransitionTime": "2024-07-22T12:44:25Z",
                  "lastUpdateTime": "2024-07-22T12:44:25Z",
                  "message": "PyTorchJob agile-aiak-training-llm-pengxiangyu-1721652109 is failed because 1 Master replica(s) failed.",
                  "reason": "JobFailed",
                  "status": "True",
                  "type": "Failed"
                }
              ],
              "lastReconcileTime": "2024-07-22T12:41:50Z",
              "replicaStatuses": {
                "Master": {
                  "failed": 1,
                  "selector": "training.kubeflow.org/job-name=agile-aiak-training-llm-pengxiangyu-1721652109,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=master"
                }
              },
              "startTime": "2024-07-22T12:41:50Z"
            }
          },
          {
            "apiVersion": "kubeflow.org/v1",
            "kind": "PyTorchJob",
            "metadata": {
              "annotations": {
                "aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": "",
                "aijob.cce.baidubce.com/timeline": "[{\"conditionType\":\"Created\",\"time\":1721615725},{\"conditionType\":\"Scheduled\",\"time\":1721615728},{\"conditionType\":\"Running\",\"time\":1721615738}]",
                "kubectl.kubernetes.io/last-applied-configuration": "{\"apiVersion\":\"kubeflow.org/v1\",\"kind\":\"PyTorchJob\",\"metadata\":{\"annotations\":{},\"name\":\"baidu5-task-for-8gpu\",\"namespace\":\"default\"},\"spec\":{\"pytorchReplicaSpecs\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"template\":{\"metadata\":null,\"spec\":{\"containers\":[{\"command\":[\"bash\",\"/workspace/Megatron-LM/examples/launch.sh\"],\"env\":[{\"name\":\"CUDA_DEVICE_MAX_CONNECTIONS\",\"value\":\"1\"},{\"name\":\"NCCL_DEBUG\",\"value\":\"INFO\"},{\"name\":\"NCCL_IB_DISABLE\",\"value\":\"0\"},{\"name\":\"MASTER\",\"value\":\"1\"}],\"image\":\"registry.baidubce.com/cce-ai-native/aiak-megatron:ubuntu22.04-cu12.2-torch2.1.0-py310_v1.2.4.2\",\"imagePullPolicy\":\"Always\",\"name\":\"pytorch\",\"resources\":{\"limits\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1}},\"securityContext\":{\"capabilities\":{\"add\":[\"IPC_LOCK\"]}},\"volumeMounts\":[{\"mountPath\":\"/dev/shm\",\"name\":\"cache-volume\"},{\"mountPath\":\"/tmp\",\"name\":\"tmp-volume\"},{\"mountPath\":\"/workspace/Megatron-LM/examples/launch.sh\",\"name\":\"config-volume\",\"subPath\":\"launch.sh\"},{\"mountPath\":\"/mnt/cluster\",\"name\":\"data\"}]}],\"schedulerName\":\"volcano\",\"volumes\":[{\"emptyDir\":{\"medium\":\"Memory\"},\"name\":\"cache-volume\"},{\"emptyDir\":{\"medium\":\"Memory\"},\"name\":\"tmp-volume\"},{\"configMap\":{\"name\":\"baidu5-task-for-8gpu\"},\"name\":\"config-volume\"},{\"name\":\"data\",\"persistentVolumeClaim\":{\"claimName\":\"pvc-pfs\"}}]}}}}}}\n"
              },
              "creationTimestamp": "2024-07-22T02:35:25Z",
              "generation": 2,
              "managedFields": [
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        "f:aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": {},
                        "f:aijob.cce.baidubce.com/timeline": {}
                      }
                    },
                    "f:spec": {
                      "f:pytorchReplicaSpecs": {
                        "f:Master": {
                          "f:template": {
                            "f:metadata": {},
                            "f:spec": {
                              "f:containers": {}
                            }
                          }
                        }
                      },
                      "f:runPolicy": {
                        ".": {},
                        "f:cleanPodPolicy": {}
                      }
                    }
                  },
                  "manager": "controller",
                  "operation": "Update",
                  "time": "2024-07-22T02:35:25Z"
                },
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        ".": {},
                        "f:kubectl.kubernetes.io/last-applied-configuration": {}
                      }
                    },
                    "f:spec": {
                      ".": {},
                      "f:pytorchReplicaSpecs": {
                        ".": {},
                        "f:Master": {
                          ".": {},
                          "f:replicas": {},
                          "f:restartPolicy": {},
                          "f:template": {
                            ".": {},
                            "f:spec": {
                              ".": {},
                              "f:schedulerName": {},
                              "f:volumes": {}
                            }
                          }
                        }
                      }
                    }
                  },
                  "manager": "kubectl-client-side-apply",
                  "operation": "Update",
                  "time": "2024-07-22T02:35:25Z"
                },
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:status": {
                      ".": {},
                      "f:conditions": {},
                      "f:lastReconcileTime": {},
                      "f:replicaStatuses": {
                        ".": {},
                        "f:Master": {
                          ".": {},
                          "f:active": {},
                          "f:selector": {}
                        }
                      },
                      "f:startTime": {}
                    }
                  },
                  "manager": "manager",
                  "operation": "Update",
                  "time": "2024-07-22T02:35:38Z"
                }
              ],
              "name": "baidu5-task-for-8gpu",
              "namespace": "default",
              "resourceVersion": "2375802662",
              "uid": "6caf9759-c42b-4e01-8838-bfea936f46a4"
            },
            "spec": {
              "pytorchReplicaSpecs": {
                "Master": {
                  "replicas": 1,
                  "restartPolicy": "Never",
                  "template": {
                    "metadata": {},
                    "spec": {
                      "containers": [
                        {
                          "command": [
                            "bash",
                            "/workspace/Megatron-LM/examples/launch.sh"
                          ],
                          "env": [
                            {
                              "name": "CUDA_DEVICE_MAX_CONNECTIONS",
                              "value": "1"
                            },
                            {
                              "name": "NCCL_DEBUG",
                              "value": "INFO"
                            },
                            {
                              "name": "NCCL_IB_DISABLE",
                              "value": "0"
                            },
                            {
                              "name": "MASTER",
                              "value": "1"
                            }
                          ],
                          "image": "registry.baidubce.com/cce-ai-native/aiak-megatron:ubuntu22.04-cu12.2-torch2.1.0-py310_v1.2.4.2",
                          "imagePullPolicy": "Always",
                          "name": "pytorch",
                          "ports": [
                            {
                              "containerPort": 23456,
                              "name": "pytorchjob-port",
                              "protocol": "TCP"
                            }
                          ],
                          "resources": {
                            "limits": {
                              "baidu.com/a800_80g_cgpu": "8",
                              "rdma/hca": "1"
                            }
                          },
                          "securityContext": {
                            "capabilities": {
                              "add": [
                                "IPC_LOCK"
                              ]
                            }
                          },
                          "volumeMounts": [
                            {
                              "mountPath": "/dev/shm",
                              "name": "cache-volume"
                            },
                            {
                              "mountPath": "/tmp",
                              "name": "tmp-volume"
                            },
                            {
                              "mountPath": "/workspace/Megatron-LM/examples/launch.sh",
                              "name": "config-volume",
                              "subPath": "launch.sh"
                            },
                            {
                              "mountPath": "/mnt/cluster",
                              "name": "data"
                            }
                          ]
                        }
                      ],
                      "schedulerName": "volcano",
                      "volumes": [
                        {
                          "emptyDir": {
                            "medium": "Memory"
                          },
                          "name": "cache-volume"
                        },
                        {
                          "emptyDir": {
                            "medium": "Memory"
                          },
                          "name": "tmp-volume"
                        },
                        {
                          "configMap": {
                            "name": "baidu5-task-for-8gpu"
                          },
                          "name": "config-volume"
                        },
                        {
                          "name": "data",
                          "persistentVolumeClaim": {
                            "claimName": "pvc-pfs"
                          }
                        }
                      ]
                    }
                  }
                }
              },
              "runPolicy": {
                "cleanPodPolicy": "None"
              }
            },
            "status": {
              "conditions": [
                {
                  "lastTransitionTime": "2024-07-22T02:35:25Z",
                  "lastUpdateTime": "2024-07-22T02:35:25Z",
                  "message": "PyTorchJob baidu5-task-for-8gpu is created.",
                  "reason": "PyTorchJobCreated",
                  "status": "True",
                  "type": "Created"
                },
                {
                  "lastTransitionTime": "2024-07-22T02:35:38Z",
                  "lastUpdateTime": "2024-07-22T02:35:38Z",
                  "message": "PyTorchJob baidu5-task-for-8gpu is running.",
                  "reason": "JobRunning",
                  "status": "True",
                  "type": "Running"
                }
              ],
              "lastReconcileTime": "2024-07-22T02:35:26Z",
              "replicaStatuses": {
                "Master": {
                  "active": 1,
                  "selector": "training.kubeflow.org/job-name=baidu5-task-for-8gpu,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=master"
                }
              },
              "startTime": "2024-07-22T02:35:27Z"
            }
          },
          {
            "apiVersion": "kubeflow.org/v1",
            "kind": "PyTorchJob",
            "metadata": {
              "annotations": {
                "aijob.cce.baidubce.com/fault-tolerance-enabled": "true",
                "aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": "",
                "aijob.cce.baidubce.com/timeline": "[{\"conditionType\":\"Created\",\"time\":1721653657}]",
                "kubectl.kubernetes.io/last-applied-configuration": "{\"apiVersion\":\"kubeflow.org/v1\",\"kind\":\"PyTorchJob\",\"metadata\":{\"annotations\":{},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"name\":\"changtao02-llama2-70b-448\",\"namespace\":\"default\"},\"spec\":{\"pytorchReplicaSpecs\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"template\":{\"metadata\":{\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"}},\"spec\":{\"containers\":[{\"command\":[\"bash\",\"/workspace/Megatron-LM/examples/launch.sh\"],\"env\":[{\"name\":\"CUDA_DEVICE_MAX_CONNECTIONS\",\"value\":\"1\"},{\"name\":\"NCCL_DEBUG\",\"value\":\"INFO\"},{\"name\":\"NCCL_IB_DISABLE\",\"value\":\"0\"},{\"name\":\"MASTER\",\"value\":\"1\"}],\"image\":\"registry.baidubce.com/hac-aiacc/aiak-training-llm:ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_dev_20240718_204220\",\"imagePullPolicy\":\"Always\",\"name\":\"pytorch\",\"resources\":{\"limits\":{\"nvidia.com/gpu\":8,\"rdma/hca\":1}},\"securityContext\":{\"capabilities\":{\"add\":[\"IPC_LOCK\"]}},\"volumeMounts\":[{\"mountPath\":\"/dev/shm\",\"name\":\"cache-volume\"},{\"mountPath\":\"/workspace/Megatron-LM/examples/launch.sh\",\"name\":\"config-volume\",\"subPath\":\"launch.sh\"},{\"mountPath\":\"/mnt/cluster\",\"name\":\"data\"}]}],\"hostNetwork\":true,\"schedulerName\":\"volcano\",\"volumes\":[{\"emptyDir\":{\"medium\":\"Memory\"},\"name\":\"cache-volume\"},{\"configMap\":{\"name\":\"launch-changtao02-cm-pytorch-llama2-70b-1\"},\"name\":\"config-volume\"},{\"name\":\"data\",\"persistentVolumeClaim\":{\"claimName\":\"pvc-pfs\"}}]}}},\"Worker\":{\"replicas\":3,\"restartPolicy\":\"Never\",\"template\":{\"spec\":{\"containers\":[{\"command\":[\"bash\",\"/workspace/Megatron-LM/examples/launch.sh\"],\"env\":[{\"name\":\"CUDA_DEVICE_MAX_CONNECTIONS\",\"value\":\"1\"},{\"name\":\"NCCL_DEBUG\",\"value\":\"INFO\"},{\"name\":\"NCCL_IB_DISABLE\",\"value\":\"0\"}],\"image\":\"registry.baidubce.com/hac-aiacc/aiak-training-llm:ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_dev_20240718_204220\",\"imagePullPolicy\":\"Always\",\"name\":\"pytorch\",\"resources\":{\"limits\":{\"nvidia.com/gpu\":8,\"rdma/hca\":1}},\"securityContext\":{\"capabilities\":{\"add\":[\"IPC_LOCK\"]}},\"volumeMounts\":[{\"mountPath\":\"/dev/shm\",\"name\":\"cache-volume\"},{\"mountPath\":\"/workspace/Megatron-LM/examples/launch.sh\",\"name\":\"config-volume\",\"subPath\":\"launch.sh\"},{\"mountPath\":\"/mnt/cluster\",\"name\":\"data\"}]}],\"schedulerName\":\"volcano\",\"volumes\":[{\"emptyDir\":{\"medium\":\"Memory\"},\"name\":\"cache-volume\"},{\"configMap\":{\"name\":\"launch-changtao02-cm-pytorch-llama2-70b-1\"},\"name\":\"config-volume\"},{\"name\":\"data\",\"persistentVolumeClaim\":{\"claimName\":\"pvc-pfs\"}}]}}}}}}\n"
              },
              "creationTimestamp": "2024-07-22T13:07:37Z",
              "generation": 2,
              "labels": {
                "aijob.cce.baidubce.com/create-from-aihcp": "true"
              },
              "managedFields": [
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        "f:aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": {},
                        "f:aijob.cce.baidubce.com/timeline": {}
                      }
                    }
                  },
                  "manager": "controller",
                  "operation": "Update",
                  "time": "2024-07-22T13:07:37Z"
                },
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        ".": {},
                        "f:kubectl.kubernetes.io/last-applied-configuration": {}
                      },
                      "f:labels": {
                        ".": {},
                        "f:aijob.cce.baidubce.com/create-from-aihcp": {}
                      }
                    },
                    "f:spec": {
                      ".": {},
                      "f:pytorchReplicaSpecs": {
                        ".": {},
                        "f:Master": {
                          ".": {},
                          "f:replicas": {},
                          "f:restartPolicy": {},
                          "f:template": {
                            ".": {},
                            "f:metadata": {
                              ".": {},
                              "f:labels": {
                                ".": {},
                                "f:aijob.cce.baidubce.com/create-from-aihcp": {}
                              }
                            },
                            "f:spec": {
                              ".": {},
                              "f:hostNetwork": {},
                              "f:schedulerName": {},
                              "f:volumes": {}
                            }
                          }
                        },
                        "f:Worker": {
                          ".": {},
                          "f:replicas": {},
                          "f:restartPolicy": {},
                          "f:template": {
                            ".": {},
                            "f:spec": {
                              ".": {},
                              "f:schedulerName": {},
                              "f:volumes": {}
                            }
                          }
                        }
                      }
                    }
                  },
                  "manager": "kubectl-client-side-apply",
                  "operation": "Update",
                  "time": "2024-07-22T13:07:37Z"
                },
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {}
                      }
                    },
                    "f:spec": {
                      "f:pytorchReplicaSpecs": {
                        "f:Master": {
                          "f:template": {
                            "f:spec": {
                              "f:containers": {}
                            }
                          }
                        },
                        "f:Worker": {
                          "f:template": {
                            "f:metadata": {},
                            "f:spec": {
                              "f:containers": {}
                            }
                          }
                        }
                      },
                      "f:runPolicy": {
                        ".": {},
                        "f:cleanPodPolicy": {}
                      }
                    },
                    "f:status": {
                      ".": {},
                      "f:conditions": {},
                      "f:lastReconcileTime": {},
                      "f:replicaStatuses": {
                        ".": {},
                        "f:Master": {
                          ".": {},
                          "f:selector": {}
                        },
                        "f:Worker": {
                          ".": {},
                          "f:selector": {}
                        }
                      },
                      "f:startTime": {}
                    }
                  },
                  "manager": "manager",
                  "operation": "Update",
                  "time": "2024-07-22T13:07:37Z"
                }
              ],
              "name": "changtao02-llama2-70b-448",
              "namespace": "default",
              "resourceVersion": "2376311041",
              "uid": "e7917ae4-92b9-42f9-a1ba-2e53d98e392f"
            },
            "spec": {
              "pytorchReplicaSpecs": {
                "Master": {
                  "replicas": 1,
                  "restartPolicy": "Never",
                  "template": {
                    "metadata": {
                      "labels": {
                        "aijob.cce.baidubce.com/create-from-aihcp": "true"
                      }
                    },
                    "spec": {
                      "containers": [
                        {
                          "command": [
                            "bash",
                            "/workspace/Megatron-LM/examples/launch.sh"
                          ],
                          "env": [
                            {
                              "name": "CUDA_DEVICE_MAX_CONNECTIONS",
                              "value": "1"
                            },
                            {
                              "name": "NCCL_DEBUG",
                              "value": "INFO"
                            },
                            {
                              "name": "NCCL_IB_DISABLE",
                              "value": "0"
                            },
                            {
                              "name": "MASTER",
                              "value": "1"
                            }
                          ],
                          "image": "registry.baidubce.com/hac-aiacc/aiak-training-llm:ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_dev_20240718_204220",
                          "imagePullPolicy": "Always",
                          "name": "pytorch",
                          "ports": [
                            {
                              "containerPort": 23456,
                              "name": "pytorchjob-port",
                              "protocol": "TCP"
                            }
                          ],
                          "resources": {
                            "limits": {
                              "nvidia.com/gpu": "8",
                              "rdma/hca": "1"
                            }
                          },
                          "securityContext": {
                            "capabilities": {
                              "add": [
                                "IPC_LOCK"
                              ]
                            }
                          },
                          "volumeMounts": [
                            {
                              "mountPath": "/dev/shm",
                              "name": "cache-volume"
                            },
                            {
                              "mountPath": "/workspace/Megatron-LM/examples/launch.sh",
                              "name": "config-volume",
                              "subPath": "launch.sh"
                            },
                            {
                              "mountPath": "/mnt/cluster",
                              "name": "data"
                            }
                          ]
                        }
                      ],
                      "hostNetwork": true,
                      "schedulerName": "volcano",
                      "volumes": [
                        {
                          "emptyDir": {
                            "medium": "Memory"
                          },
                          "name": "cache-volume"
                        },
                        {
                          "configMap": {
                            "name": "launch-changtao02-cm-pytorch-llama2-70b-1"
                          },
                          "name": "config-volume"
                        },
                        {
                          "name": "data",
                          "persistentVolumeClaim": {
                            "claimName": "pvc-pfs"
                          }
                        }
                      ]
                    }
                  }
                },
                "Worker": {
                  "replicas": 3,
                  "restartPolicy": "Never",
                  "template": {
                    "metadata": {},
                    "spec": {
                      "containers": [
                        {
                          "command": [
                            "bash",
                            "/workspace/Megatron-LM/examples/launch.sh"
                          ],
                          "env": [
                            {
                              "name": "CUDA_DEVICE_MAX_CONNECTIONS",
                              "value": "1"
                            },
                            {
                              "name": "NCCL_DEBUG",
                              "value": "INFO"
                            },
                            {
                              "name": "NCCL_IB_DISABLE",
                              "value": "0"
                            }
                          ],
                          "image": "registry.baidubce.com/hac-aiacc/aiak-training-llm:ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_dev_20240718_204220",
                          "imagePullPolicy": "Always",
                          "name": "pytorch",
                          "ports": [
                            {
                              "containerPort": 23456,
                              "name": "pytorchjob-port",
                              "protocol": "TCP"
                            }
                          ],
                          "resources": {
                            "limits": {
                              "nvidia.com/gpu": "8",
                              "rdma/hca": "1"
                            }
                          },
                          "securityContext": {
                            "capabilities": {
                              "add": [
                                "IPC_LOCK"
                              ]
                            }
                          },
                          "volumeMounts": [
                            {
                              "mountPath": "/dev/shm",
                              "name": "cache-volume"
                            },
                            {
                              "mountPath": "/workspace/Megatron-LM/examples/launch.sh",
                              "name": "config-volume",
                              "subPath": "launch.sh"
                            },
                            {
                              "mountPath": "/mnt/cluster",
                              "name": "data"
                            }
                          ]
                        }
                      ],
                      "schedulerName": "volcano",
                      "volumes": [
                        {
                          "emptyDir": {
                            "medium": "Memory"
                          },
                          "name": "cache-volume"
                        },
                        {
                          "configMap": {
                            "name": "launch-changtao02-cm-pytorch-llama2-70b-1"
                          },
                          "name": "config-volume"
                        },
                        {
                          "name": "data",
                          "persistentVolumeClaim": {
                            "claimName": "pvc-pfs"
                          }
                        }
                      ]
                    }
                  }
                }
              },
              "runPolicy": {
                "cleanPodPolicy": "None"
              }
            },
            "status": {
              "conditions": [
                {
                  "lastTransitionTime": "2024-07-22T13:07:37Z",
                  "lastUpdateTime": "2024-07-22T13:07:37Z",
                  "message": "PyTorchJob changtao02-llama2-70b-448 is created.",
                  "reason": "PyTorchJobCreated",
                  "status": "True",
                  "type": "Created"
                }
              ],
              "lastReconcileTime": "2024-07-22T13:07:37Z",
              "replicaStatuses": {
                "Master": {
                  "selector": "training.kubeflow.org/job-name=changtao02-llama2-70b-448,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=master"
                },
                "Worker": {
                  "selector": "training.kubeflow.org/job-name=changtao02-llama2-70b-448,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=worker"
                }
              },
              "startTime": "2024-07-22T13:07:38Z"
            }
          },
          {
            "apiVersion": "kubeflow.org/v1",
            "kind": "PyTorchJob",
            "metadata": {
              "annotations": {
                "aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": "",
                "aijob.cce.baidubce.com/timeline": "[{\"conditionType\":\"Created\",\"time\":1721129463},{\"conditionType\":\"Scheduled\",\"time\":1721129465},{\"conditionType\":\"Running\",\"time\":1721129468},{\"conditionType\":\"Succeeded\",\"time\":1721475093}]",
                "kubectl.kubernetes.io/last-applied-configuration": "{\"apiVersion\":\"kubeflow.org/v1\",\"kind\":\"PyTorchJob\",\"metadata\":{\"annotations\":{},\"name\":\"changtao02-megatron-cpu-sleep-lj\",\"namespace\":\"default\"},\"spec\":{\"pytorchReplicaSpecs\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"template\":{\"metadata\":null,\"spec\":{\"containers\":[{\"command\":[\"bash\",\"-c\",\"sleep 4d\"],\"image\":\"registry.baidubce.com/cce-ai-native/aiak-megatron:multi-accelerators-20240608\",\"imagePullPolicy\":\"Always\",\"name\":\"pytorch\",\"volumeMounts\":[{\"mountPath\":\"/dev/shm\",\"name\":\"cache-volume\"},{\"mountPath\":\"/workspace/Megatron-LM/examples/launch.sh\",\"name\":\"config-volume\",\"subPath\":\"launch.sh\"},{\"mountPath\":\"/mnt/cluster\",\"name\":\"data\"}]}],\"schedulerName\":\"volcano\",\"volumes\":[{\"emptyDir\":{\"medium\":\"Memory\"},\"name\":\"cache-volume\"},{\"configMap\":{\"name\":\"changtao02-cpu-sleep\"},\"name\":\"config-volume\"},{\"name\":\"data\",\"persistentVolumeClaim\":{\"claimName\":\"pvc-pfs\"}}]}}}}}}\n"
              },
              "creationTimestamp": "2024-07-16T11:31:03Z",
              "generation": 5,
              "managedFields": [
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        "f:aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": {},
                        "f:aijob.cce.baidubce.com/timeline": {}
                      }
                    },
                    "f:spec": {
                      "f:pytorchReplicaSpecs": {
                        "f:Master": {
                          "f:template": {
                            "f:metadata": {},
                            "f:spec": {
                              "f:containers": {}
                            }
                          }
                        }
                      },
                      "f:runPolicy": {
                        ".": {},
                        "f:cleanPodPolicy": {}
                      }
                    }
                  },
                  "manager": "controller",
                  "operation": "Update",
                  "time": "2024-07-16T11:31:16Z"
                },
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        ".": {},
                        "f:kubectl.kubernetes.io/last-applied-configuration": {}
                      }
                    },
                    "f:spec": {
                      ".": {},
                      "f:pytorchReplicaSpecs": {
                        ".": {},
                        "f:Master": {
                          ".": {},
                          "f:replicas": {},
                          "f:restartPolicy": {},
                          "f:template": {
                            ".": {},
                            "f:spec": {
                              ".": {},
                              "f:schedulerName": {},
                              "f:volumes": {}
                            }
                          }
                        }
                      }
                    }
                  },
                  "manager": "kubectl-client-side-apply",
                  "operation": "Update",
                  "time": "2024-07-16T11:31:16Z"
                },
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:status": {
                      ".": {},
                      "f:completionTime": {},
                      "f:conditions": {},
                      "f:lastReconcileTime": {},
                      "f:replicaStatuses": {
                        ".": {},
                        "f:Master": {
                          ".": {},
                          "f:selector": {},
                          "f:succeeded": {}
                        }
                      },
                      "f:startTime": {}
                    }
                  },
                  "manager": "manager",
                  "operation": "Update",
                  "time": "2024-07-20T11:31:33Z"
                }
              ],
              "name": "changtao02-megatron-cpu-sleep-lj",
              "namespace": "default",
              "resourceVersion": "2373966056",
              "uid": "dcc732fc-9bc9-4e50-8708-d221e4df63d5"
            },
            "spec": {
              "pytorchReplicaSpecs": {
                "Master": {
                  "replicas": 1,
                  "restartPolicy": "Never",
                  "template": {
                    "metadata": {},
                    "spec": {
                      "containers": [
                        {
                          "command": [
                            "bash",
                            "-c",
                            "sleep 4d"
                          ],
                          "image": "registry.baidubce.com/cce-ai-native/aiak-megatron:multi-accelerators-20240608",
                          "imagePullPolicy": "Always",
                          "name": "pytorch",
                          "ports": [
                            {
                              "containerPort": 23456,
                              "name": "pytorchjob-port",
                              "protocol": "TCP"
                            }
                          ],
                          "resources": {},
                          "volumeMounts": [
                            {
                              "mountPath": "/dev/shm",
                              "name": "cache-volume"
                            },
                            {
                              "mountPath": "/workspace/Megatron-LM/examples/launch.sh",
                              "name": "config-volume",
                              "subPath": "launch.sh"
                            },
                            {
                              "mountPath": "/mnt/cluster",
                              "name": "data"
                            }
                          ]
                        }
                      ],
                      "schedulerName": "volcano",
                      "volumes": [
                        {
                          "emptyDir": {
                            "medium": "Memory"
                          },
                          "name": "cache-volume"
                        },
                        {
                          "configMap": {
                            "name": "changtao02-cpu-sleep"
                          },
                          "name": "config-volume"
                        },
                        {
                          "name": "data",
                          "persistentVolumeClaim": {
                            "claimName": "pvc-pfs"
                          }
                        }
                      ]
                    }
                  }
                }
              },
              "runPolicy": {
                "cleanPodPolicy": "None"
              }
            },
            "status": {
              "completionTime": "2024-07-20T11:31:33Z",
              "conditions": [
                {
                  "lastTransitionTime": "2024-07-16T11:31:03Z",
                  "lastUpdateTime": "2024-07-16T11:31:03Z",
                  "message": "PyTorchJob changtao02-megatron-cpu-sleep-lj is created.",
                  "reason": "PyTorchJobCreated",
                  "status": "True",
                  "type": "Created"
                },
                {
                  "lastTransitionTime": "2024-07-16T11:31:08Z",
                  "lastUpdateTime": "2024-07-16T11:31:08Z",
                  "message": "PyTorchJob changtao02-megatron-cpu-sleep-lj is running.",
                  "reason": "JobRunning",
                  "status": "False",
                  "type": "Running"
                },
                {
                  "lastTransitionTime": "2024-07-20T11:31:33Z",
                  "lastUpdateTime": "2024-07-20T11:31:33Z",
                  "message": "PyTorchJob changtao02-megatron-cpu-sleep-lj is successfully completed.",
                  "reason": "JobSucceeded",
                  "status": "True",
                  "type": "Succeeded"
                }
              ],
              "lastReconcileTime": "2024-07-16T11:31:03Z",
              "replicaStatuses": {
                "Master": {
                  "selector": "training.kubeflow.org/job-name=changtao02-megatron-cpu-sleep-lj,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=master",
                  "succeeded": 1
                }
              },
              "startTime": "2024-07-16T11:31:04Z"
            }
          },
          {
            "apiVersion": "kubeflow.org/v1",
            "kind": "PyTorchJob",
            "metadata": {
              "annotations": {
                "aijob.cce.baidubce.com/barrier-finish": "d0f023d4-59a0-495f-a478-f42104ab5ec5",
                "aijob.cce.baidubce.com/fault-tolerance-enabled": "true",
                "aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": "",
                "aijob.cce.baidubce.com/internal-fault-tolerance-time": "2024-07-18T13:22:29.815441541Z",
                "aijob.cce.baidubce.com/timeline": "[{\"conditionType\":\"Created\",\"time\":1721306309},{\"conditionType\":\"Scheduled\",\"time\":1721308393},{\"conditionType\":\"Running\",\"time\":1721308739},{\"conditionType\":\"Abnormal\",\"time\":1721308949},{\"conditionType\":\"Failed\",\"time\":1721309552}]",
                "kubectl.kubernetes.io/last-applied-configuration": "{\"apiVersion\":\"kubeflow.org/v1\",\"kind\":\"PyTorchJob\",\"metadata\":{\"annotations\":{},\"name\":\"changtao02-megatron-llama3-70b-tp4-pp4\",\"namespace\":\"default\"},\"spec\":{\"pytorchReplicaSpecs\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"template\":{\"metadata\":null,\"spec\":{\"containers\":[{\"command\":[\"bash\",\"/workspace/Megatron-LM/examples/launch.sh\"],\"env\":[{\"name\":\"CUDA_DEVICE_MAX_CONNECTIONS\",\"value\":\"1\"},{\"name\":\"NCCL_IB_DISABLE\",\"value\":\"0\"},{\"name\":\"MASTER\",\"value\":\"1\"}],\"image\":\"registry.baidubce.com/cce-ai-native/aiak-megatron:multi-accelerators-20240608\",\"imagePullPolicy\":\"Always\",\"name\":\"pytorch\",\"resources\":{\"limits\":{\"nvidia.com/gpu\":8,\"rdma/hca\":1}},\"securityContext\":{\"capabilities\":{\"add\":[\"IPC_LOCK\"]}},\"volumeMounts\":[{\"mountPath\":\"/dev/shm\",\"name\":\"cache-volume\"},{\"mountPath\":\"/workspace/Megatron-LM/examples/launch.sh\",\"name\":\"config-volume\",\"subPath\":\"launch.sh\"},{\"mountPath\":\"/mnt/cluster\",\"name\":\"data\"}]}],\"schedulerName\":\"volcano\",\"volumes\":[{\"emptyDir\":{\"medium\":\"Memory\"},\"name\":\"cache-volume\"},{\"configMap\":{\"name\":\"launch-cm-llama3-70b-tp4-pp4\"},\"name\":\"config-volume\"},{\"name\":\"data\",\"persistentVolumeClaim\":{\"claimName\":\"pvc-pfs\"}}]}}},\"Worker\":{\"replicas\":3,\"restartPolicy\":\"Never\",\"template\":{\"spec\":{\"containers\":[{\"command\":[\"bash\",\"/workspace/Megatron-LM/examples/launch.sh\"],\"env\":[{\"name\":\"CUDA_DEVICE_MAX_CONNECTIONS\",\"value\":\"1\"},{\"name\":\"NCCL_IB_DISABLE\",\"value\":\"0\"}],\"image\":\"registry.baidubce.com/cce-ai-native/aiak-megatron:multi-accelerators-20240608\",\"imagePullPolicy\":\"Always\",\"name\":\"pytorch\",\"resources\":{\"limits\":{\"nvidia.com/gpu\":8,\"rdma/hca\":1}},\"securityContext\":{\"capabilities\":{\"add\":[\"IPC_LOCK\"]}},\"volumeMounts\":[{\"mountPath\":\"/dev/shm\",\"name\":\"cache-volume\"},{\"mountPath\":\"/workspace/Megatron-LM/examples/launch.sh\",\"name\":\"config-volume\",\"subPath\":\"launch.sh\"},{\"mountPath\":\"/mnt/cluster\",\"name\":\"data\"}]}],\"schedulerName\":\"volcano\",\"volumes\":[{\"emptyDir\":{\"medium\":\"Memory\"},\"name\":\"cache-volume\"},{\"configMap\":{\"name\":\"launch-cm-llama3-70b-tp4-pp4\"},\"name\":\"config-volume\"},{\"name\":\"data\",\"persistentVolumeClaim\":{\"claimName\":\"pvc-pfs\"}}]}}}}}}\n"
              },
              "creationTimestamp": "2024-07-18T12:38:29Z",
              "generation": 3,
              "managedFields": [
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        "f:aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": {},
                        "f:aijob.cce.baidubce.com/timeline": {}
                      }
                    }
                  },
                  "manager": "controller",
                  "operation": "Update",
                  "time": "2024-07-18T12:38:29Z"
                },
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        ".": {},
                        "f:kubectl.kubernetes.io/last-applied-configuration": {}
                      }
                    },
                    "f:spec": {
                      ".": {},
                      "f:pytorchReplicaSpecs": {
                        ".": {},
                        "f:Master": {
                          ".": {},
                          "f:replicas": {},
                          "f:restartPolicy": {},
                          "f:template": {
                            ".": {},
                            "f:spec": {
                              ".": {},
                              "f:schedulerName": {}
                            }
                          }
                        },
                        "f:Worker": {
                          ".": {},
                          "f:replicas": {},
                          "f:restartPolicy": {},
                          "f:template": {
                            ".": {},
                            "f:spec": {
                              ".": {},
                              "f:schedulerName": {}
                            }
                          }
                        }
                      }
                    }
                  },
                  "manager": "kubectl-client-side-apply",
                  "operation": "Update",
                  "time": "2024-07-18T12:38:29Z"
                },
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        "f:aijob.cce.baidubce.com/barrier-finish": {}
                      }
                    }
                  },
                  "manager": "jobbarrier",
                  "operation": "Update",
                  "time": "2024-07-18T13:18:56Z"
                },
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                        "f:aijob.cce.baidubce.com/internal-fault-tolerance-time": {}
                      }
                    },
                    "f:spec": {
                      "f:pytorchReplicaSpecs": {
                        "f:Master": {
                          "f:template": {
                            "f:metadata": {
                              ".": {},
                              "f:annotations": {
                                ".": {},
                                "f:prometheus.io/path": {},
                                "f:prometheus.io/port": {},
                                "f:prometheus.io/scrape": {}
                              }
                            },
                            "f:spec": {
                              "f:containers": {},
                              "f:serviceAccountName": {},
                              "f:shareProcessNamespace": {},
                              "f:volumes": {}
                            }
                          }
                        },
                        "f:Worker": {
                          "f:template": {
                            "f:metadata": {
                              ".": {},
                              "f:annotations": {
                                ".": {},
                                "f:prometheus.io/path": {},
                                "f:prometheus.io/port": {},
                                "f:prometheus.io/scrape": {}
                              }
                            },
                            "f:spec": {
                              "f:containers": {},
                              "f:serviceAccountName": {},
                              "f:shareProcessNamespace": {},
                              "f:volumes": {}
                            }
                          }
                        }
                      },
                      "f:runPolicy": {
                        ".": {},
                        "f:cleanPodPolicy": {}
                      }
                    },
                    "f:status": {
                      ".": {},
                      "f:completionTime": {},
                      "f:conditions": {},
                      "f:lastReconcileTime": {},
                      "f:replicaStatuses": {
                        ".": {},
                        "f:Master": {
                          ".": {},
                          "f:failed": {},
                          "f:selector": {}
                        },
                        "f:Worker": {
                          ".": {},
                          "f:failed": {},
                          "f:selector": {}
                        }
                      },
                      "f:startTime": {}
                    }
                  },
                  "manager": "manager",
                  "operation": "Update",
                  "time": "2024-07-18T13:32:32Z"
                }
              ],
              "name": "changtao02-megatron-llama3-70b-tp4-pp4",
              "namespace": "default",
              "resourceVersion": "2371781262",
              "uid": "bd0f44ca-e715-4565-8bce-4e26051cf5b5"
            },
            "spec": {
              "pytorchReplicaSpecs": {
                "Master": {
                  "replicas": 1,
                  "restartPolicy": "Never",
                  "template": {
                    "metadata": {
                      "annotations": {
                        "prometheus.io/path": "/metrics",
                        "prometheus.io/port": "9101",
                        "prometheus.io/scrape": "true"
                      }
                    },
                    "spec": {
                      "containers": [
                        {
                          "command": [
                            "bash",
                            "/workspace/Megatron-LM/examples/launch.sh"
                          ],
                          "env": [
                            {
                              "name": "CUDA_DEVICE_MAX_CONNECTIONS",
                              "value": "1"
                            },
                            {
                              "name": "NCCL_IB_DISABLE",
                              "value": "0"
                            },
                            {
                              "name": "MASTER",
                              "value": "1"
                            },
                            {
                              "name": "BCCL_BUS_BW_CALCULATE_MODE",
                              "value": "Agg"
                            },
                            {
                              "name": "BCCL_PROFILING_FILE",
                              "value": "/var/bccl/logs/busbw.cal.%h.%p"
                            }
                          ],
                          "image": "registry.baidubce.com/cce-ai-native/aiak-megatron:multi-accelerators-20240608",
                          "imagePullPolicy": "Always",
                          "name": "pytorch",
                          "ports": [
                            {
                              "containerPort": 23456,
                              "name": "pytorchjob-port",
                              "protocol": "TCP"
                            }
                          ],
                          "resources": {
                            "limits": {
                              "nvidia.com/gpu": "8",
                              "rdma/hca": "1"
                            }
                          },
                          "securityContext": {
                            "capabilities": {
                              "add": [
                                "IPC_LOCK"
                              ]
                            }
                          },
                          "volumeMounts": [
                            {
                              "mountPath": "/dev/shm",
                              "name": "cache-volume"
                            },
                            {
                              "mountPath": "/workspace/Megatron-LM/examples/launch.sh",
                              "name": "config-volume",
                              "subPath": "launch.sh"
                            },
                            {
                              "mountPath": "/mnt/cluster",
                              "name": "data"
                            },
                            {
                              "mountPath": "/var/bccl/logs",
                              "name": "bccl-logs-volume"
                            }
                          ]
                        },
                        {
                          "env": [
                            {
                              "name": "POD_NAME",
                              "valueFrom": {
                                "fieldRef": {
                                  "apiVersion": "v1",
                                  "fieldPath": "metadata.name"
                                }
                              }
                            },
                            {
                              "name": "POD_UID",
                              "valueFrom": {
                                "fieldRef": {
                                  "apiVersion": "v1",
                                  "fieldPath": "metadata.uid"
                                }
                              }
                            },
                            {
                              "name": "POD_NAMESPACE",
                              "valueFrom": {
                                "fieldRef": {
                                  "apiVersion": "v1",
                                  "fieldPath": "metadata.namespace"
                                }
                              }
                            },
                            {
                              "name": "NODE_NAME",
                              "valueFrom": {
                                "fieldRef": {
                                  "apiVersion": "v1",
                                  "fieldPath": "spec.nodeName"
                                }
                              }
                            },
                            {
                              "name": "JOB_NAME",
                              "value": "changtao02-megatron-llama3-70b-tp4-pp4"
                            },
                            {
                              "name": "NODE_IP",
                              "valueFrom": {
                                "fieldRef": {
                                  "apiVersion": "v1",
                                  "fieldPath": "status.hostIP"
                                }
                              }
                            },
                            {
                              "name": "GPUS_PER_NODE",
                              "value": "8"
                            },
                            {
                              "name": "ENABLE_ELASTIC",
                              "value": "9"
                            },
                            {
                              "name": "BCCL_LOG_DIR",
                              "value": "/var/bccl/logs"
                            },
                            {
                              "name": "EXPORTER_PORT",
                              "value": "9101"
                            },
                            {
                              "name": "EXPORTER_INTERVAL",
                              "value": "60"
                            },
                            {
                              "name": "EXPORTER_PATH",
                              "value": "/metrics"
                            },
                            {
                              "name": "BCCL_BUS_BW_CALCULATE_MODE",
                              "value": "Agg"
                            },
                            {
                              "name": "BCCL_PROFILING_FILE",
                              "value": "/var/bccl/logs/busbw.cal.%h.%p"
                            }
                          ],
                          "image": "registry.baidubce.com/cce-plugin-dev/ftagent:v1.6.21",
                          "imagePullPolicy": "Always",
                          "name": "ftagent",
                          "ports": [
                            {
                              "containerPort": 9101,
                              "name": "exporter",
                              "protocol": "TCP"
                            }
                          ],
                          "resources": {},
                          "securityContext": {
                            "capabilities": {
                              "add": [
                                "IPC_LOCK"
                              ]
                            }
                          },
                          "volumeMounts": [
                            {
                              "mountPath": "/var/log/pods",
                              "name": "pod-log-volume"
                            },
                            {
                              "mountPath": "/home/cce",
                              "name": "container-log-volume"
                            },
                            {
                              "mountPath": "/var/bccl/logs",
                              "name": "bccl-logs-volume"
                            }
                          ]
                        }
                      ],
                      "schedulerName": "volcano",
                      "serviceAccountName": "ftagent-sa",
                      "shareProcessNamespace": true,
                      "volumes": [
                        {
                          "emptyDir": {
                            "medium": "Memory"
                          },
                          "name": "cache-volume"
                        },
                        {
                          "configMap": {
                            "name": "launch-cm-llama3-70b-tp4-pp4"
                          },
                          "name": "config-volume"
                        },
                        {
                          "name": "data",
                          "persistentVolumeClaim": {
                            "claimName": "pvc-pfs"
                          }
                        },
                        {
                          "emptyDir": {},
                          "name": "bccl-logs-volume"
                        },
                        {
                          "hostPath": {
                            "path": "/var/log/pods",
                            "type": "DirectoryOrCreate"
                          },
                          "name": "pod-log-volume"
                        },
                        {
                          "hostPath": {
                            "path": "/home/cce",
                            "type": "DirectoryOrCreate"
                          },
                          "name": "container-log-volume"
                        }
                      ]
                    }
                  }
                },
                "Worker": {
                  "replicas": 3,
                  "restartPolicy": "Never",
                  "template": {
                    "metadata": {
                      "annotations": {
                        "prometheus.io/path": "/metrics",
                        "prometheus.io/port": "9101",
                        "prometheus.io/scrape": "true"
                      }
                    },
                    "spec": {
                      "containers": [
                        {
                          "command": [
                            "bash",
                            "/workspace/Megatron-LM/examples/launch.sh"
                          ],
                          "env": [
                            {
                              "name": "CUDA_DEVICE_MAX_CONNECTIONS",
                              "value": "1"
                            },
                            {
                              "name": "NCCL_IB_DISABLE",
                              "value": "0"
                            },
                            {
                              "name": "BCCL_BUS_BW_CALCULATE_MODE",
                              "value": "Agg"
                            },
                            {
                              "name": "BCCL_PROFILING_FILE",
                              "value": "/var/bccl/logs/busbw.cal.%h.%p"
                            }
                          ],
                          "image": "registry.baidubce.com/cce-ai-native/aiak-megatron:multi-accelerators-20240608",
                          "imagePullPolicy": "Always",
                          "name": "pytorch",
                          "ports": [
                            {
                              "containerPort": 23456,
                              "name": "pytorchjob-port",
                              "protocol": "TCP"
                            }
                          ],
                          "resources": {
                            "limits": {
                              "nvidia.com/gpu": "8",
                              "rdma/hca": "1"
                            }
                          },
                          "securityContext": {
                            "capabilities": {
                              "add": [
                                "IPC_LOCK"
                              ]
                            }
                          },
                          "volumeMounts": [
                            {
                              "mountPath": "/dev/shm",
                              "name": "cache-volume"
                            },
                            {
                              "mountPath": "/workspace/Megatron-LM/examples/launch.sh",
                              "name": "config-volume",
                              "subPath": "launch.sh"
                            },
                            {
                              "mountPath": "/mnt/cluster",
                              "name": "data"
                            },
                            {
                              "mountPath": "/var/bccl/logs",
                              "name": "bccl-logs-volume"
                            }
                          ]
                        },
                        {
                          "env": [
                            {
                              "name": "POD_NAME",
                              "valueFrom": {
                                "fieldRef": {
                                  "apiVersion": "v1",
                                  "fieldPath": "metadata.name"
                                }
                              }
                            },
                            {
                              "name": "POD_UID",
                              "valueFrom": {
                                "fieldRef": {
                                  "apiVersion": "v1",
                                  "fieldPath": "metadata.uid"
                                }
                              }
                            },
                            {
                              "name": "POD_NAMESPACE",
                              "valueFrom": {
                                "fieldRef": {
                                  "apiVersion": "v1",
                                  "fieldPath": "metadata.namespace"
                                }
                              }
                            },
                            {
                              "name": "NODE_NAME",
                              "valueFrom": {
                                "fieldRef": {
                                  "apiVersion": "v1",
                                  "fieldPath": "spec.nodeName"
                                }
                              }
                            },
                            {
                              "name": "JOB_NAME",
                              "value": "changtao02-megatron-llama3-70b-tp4-pp4"
                            },
                            {
                              "name": "NODE_IP",
                              "valueFrom": {
                                "fieldRef": {
                                  "apiVersion": "v1",
                                  "fieldPath": "status.hostIP"
                                }
                              }
                            },
                            {
                              "name": "GPUS_PER_NODE",
                              "value": "8"
                            },
                            {
                              "name": "ENABLE_ELASTIC",
                              "value": "9"
                            },
                            {
                              "name": "BCCL_LOG_DIR",
                              "value": "/var/bccl/logs"
                            },
                            {
                              "name": "EXPORTER_PORT",
                              "value": "9101"
                            },
                            {
                              "name": "EXPORTER_INTERVAL",
                              "value": "60"
                            },
                            {
                              "name": "EXPORTER_PATH",
                              "value": "/metrics"
                            },
                            {
                              "name": "BCCL_BUS_BW_CALCULATE_MODE",
                              "value": "Agg"
                            },
                            {
                              "name": "BCCL_PROFILING_FILE",
                              "value": "/var/bccl/logs/busbw.cal.%h.%p"
                            }
                          ],
                          "image": "registry.baidubce.com/cce-plugin-dev/ftagent:v1.6.21",
                          "imagePullPolicy": "Always",
                          "name": "ftagent",
                          "ports": [
                            {
                              "containerPort": 9101,
                              "name": "exporter",
                              "protocol": "TCP"
                            }
                          ],
                          "resources": {},
                          "securityContext": {
                            "capabilities": {
                              "add": [
                                "IPC_LOCK"
                              ]
                            }
                          },
                          "volumeMounts": [
                            {
                              "mountPath": "/var/log/pods",
                              "name": "pod-log-volume"
                            },
                            {
                              "mountPath": "/home/cce",
                              "name": "container-log-volume"
                            },
                            {
                              "mountPath": "/var/bccl/logs",
                              "name": "bccl-logs-volume"
                            }
                          ]
                        }
                      ],
                      "schedulerName": "volcano",
                      "serviceAccountName": "ftagent-sa",
                      "shareProcessNamespace": true,
                      "volumes": [
                        {
                          "emptyDir": {
                            "medium": "Memory"
                          },
                          "name": "cache-volume"
                        },
                        {
                          "configMap": {
                            "name": "launch-cm-llama3-70b-tp4-pp4"
                          },
                          "name": "config-volume"
                        },
                        {
                          "name": "data",
                          "persistentVolumeClaim": {
                            "claimName": "pvc-pfs"
                          }
                        },
                        {
                          "emptyDir": {},
                          "name": "bccl-logs-volume"
                        },
                        {
                          "hostPath": {
                            "path": "/var/log/pods",
                            "type": "DirectoryOrCreate"
                          },
                          "name": "pod-log-volume"
                        },
                        {
                          "hostPath": {
                            "path": "/home/cce",
                            "type": "DirectoryOrCreate"
                          },
                          "name": "container-log-volume"
                        }
                      ]
                    }
                  }
                }
              },
              "runPolicy": {
                "cleanPodPolicy": "None"
              }
            },
            "status": {
              "completionTime": "2024-07-18T13:32:32Z",
              "conditions": [
                {
                  "lastTransitionTime": "2024-07-18T12:38:29Z",
                  "lastUpdateTime": "2024-07-18T12:38:29Z",
                  "message": "PyTorchJob changtao02-megatron-llama3-70b-tp4-pp4 is created.",
                  "reason": "PyTorchJobCreated",
                  "status": "True",
                  "type": "Created"
                },
                {
                  "lastTransitionTime": "2024-07-18T13:18:59Z",
                  "lastUpdateTime": "2024-07-18T13:18:59Z",
                  "message": "PyTorchJob changtao02-megatron-llama3-70b-tp4-pp4 is running.",
                  "reason": "JobRunning",
                  "status": "False",
                  "type": "Running"
                },
                {
                  "lastTransitionTime": "2024-07-18T13:32:32Z",
                  "lastUpdateTime": "2024-07-18T13:32:32Z",
                  "message": "PyTorchJob changtao02-megatron-llama3-70b-tp4-pp4 is failed because 1 Master replica(s) failed.",
                  "reason": "JobFailed",
                  "status": "True",
                  "type": "Failed"
                }
              ],
              "lastReconcileTime": "2024-07-18T12:38:29Z",
              "replicaStatuses": {
                "Master": {
                  "failed": 1,
                  "selector": "training.kubeflow.org/job-name=changtao02-megatron-llama3-70b-tp4-pp4,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=master"
                },
                "Worker": {
                  "failed": 3,
                  "selector": "training.kubeflow.org/job-name=changtao02-megatron-llama3-70b-tp4-pp4,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=worker"
                }
              },
              "startTime": "2024-07-18T12:38:30Z"
            }
          },
          {
            "apiVersion": "kubeflow.org/v1",
            "kind": "PyTorchJob",
            "metadata": {
              "annotations": {
                "aijob.cce.baidubce.com/barrier-finish": "57675ff2-cc51-47e9-856b-e674a7e15ce4",
                "aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": "",
                "aijob.cce.baidubce.com/timeline": "[{\"conditionType\":\"Created\",\"time\":1721299165},{\"conditionType\":\"Scheduled\",\"time\":1721299167},{\"conditionType\":\"Running\",\"time\":1721299180},{\"conditionType\":\"Succeeded\",\"time\":1721299361}]",
                "kubectl.kubernetes.io/last-applied-configuration": "{\"apiVersion\":\"kubeflow.org/v1\",\"kind\":\"PyTorchJob\",\"metadata\":{\"annotations\":{},\"name\":\"changtao02-megatron-llama3-layer20-debug-lj\",\"namespace\":\"default\"},\"spec\":{\"pytorchReplicaSpecs\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"template\":{\"metadata\":null,\"spec\":{\"containers\":[{\"command\":[\"bash\",\"/workspace/Megatron-LM/examples/launch.sh\"],\"env\":[{\"name\":\"CUDA_DEVICE_MAX_CONNECTIONS\",\"value\":\"1\"},{\"name\":\"NCCL_IB_DISABLE\",\"value\":\"0\"},{\"name\":\"MASTER\",\"value\":\"1\"}],\"image\":\"registry.baidubce.com/cce-ai-native/aiak-megatron:multi-accelerators-20240608\",\"imagePullPolicy\":\"Always\",\"name\":\"pytorch\",\"resources\":{\"limits\":{\"nvidia.com/gpu\":8,\"rdma/hca\":1}},\"securityContext\":{\"capabilities\":{\"add\":[\"IPC_LOCK\"]}},\"volumeMounts\":[{\"mountPath\":\"/dev/shm\",\"name\":\"cache-volume\"},{\"mountPath\":\"/workspace/Megatron-LM/examples/launch.sh\",\"name\":\"config-volume\",\"subPath\":\"launch.sh\"},{\"mountPath\":\"/mnt/cluster\",\"name\":\"data\"}]}],\"schedulerName\":\"volcano\",\"volumes\":[{\"emptyDir\":{\"medium\":\"Memory\"},\"name\":\"cache-volume\"},{\"configMap\":{\"name\":\"changtao02-llama3-layer20-debug\"},\"name\":\"config-volume\"},{\"name\":\"data\",\"persistentVolumeClaim\":{\"claimName\":\"pvc-pfs\"}}]}}},\"Worker\":{\"replicas\":0,\"restartPolicy\":\"Never\",\"template\":{\"spec\":{\"containers\":[{\"command\":[\"bash\",\"/workspace/Megatron-LM/examples/launch.sh\"],\"env\":[{\"name\":\"CUDA_DEVICE_MAX_CONNECTIONS\",\"value\":\"1\"},{\"name\":\"NCCL_IB_DISABLE\",\"value\":\"0\"}],\"image\":\"registry.baidubce.com/cce-ai-native/aiak-megatron:multi-accelerators-20240608\",\"imagePullPolicy\":\"Always\",\"name\":\"pytorch\",\"resources\":{\"limits\":{\"nvidia.com/gpu\":8,\"rdma/hca\":1}},\"securityContext\":{\"capabilities\":{\"add\":[\"IPC_LOCK\"]}},\"volumeMounts\":[{\"mountPath\":\"/dev/shm\",\"name\":\"cache-volume\"},{\"mountPath\":\"/workspace/Megatron-LM/examples/launch.sh\",\"name\":\"config-volume\",\"subPath\":\"launch.sh\"},{\"mountPath\":\"/mnt/cluster\",\"name\":\"data\"}]}],\"schedulerName\":\"volcano\",\"volumes\":[{\"emptyDir\":{\"medium\":\"Memory\"},\"name\":\"cache-volume\"},{\"configMap\":{\"name\":\"changtao02-llama3-layer20-debug\"},\"name\":\"config-volume\"},{\"name\":\"data\",\"persistentVolumeClaim\":{\"claimName\":\"pvc-pfs\"}}]}}}}}}\n"
              },
              "creationTimestamp": "2024-07-18T10:39:25Z",
              "generation": 2,
              "managedFields": [
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        "f:aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": {},
                        "f:aijob.cce.baidubce.com/timeline": {}
                      }
                    },
                    "f:spec": {
                      "f:pytorchReplicaSpecs": {
                        "f:Master": {
                          "f:template": {
                            "f:metadata": {},
                            "f:spec": {
                              "f:containers": {}
                            }
                          }
                        },
                        "f:Worker": {
                          "f:template": {
                            "f:metadata": {},
                            "f:spec": {
                              "f:containers": {}
                            }
                          }
                        }
                      },
                      "f:runPolicy": {
                        ".": {},
                        "f:cleanPodPolicy": {}
                      }
                    }
                  },
                  "manager": "controller",
                  "operation": "Update",
                  "time": "2024-07-18T10:39:25Z"
                },
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        ".": {},
                        "f:kubectl.kubernetes.io/last-applied-configuration": {}
                      }
                    },
                    "f:spec": {
                      ".": {},
                      "f:pytorchReplicaSpecs": {
                        ".": {},
                        "f:Master": {
                          ".": {},
                          "f:replicas": {},
                          "f:restartPolicy": {},
                          "f:template": {
                            ".": {},
                            "f:spec": {
                              ".": {},
                              "f:schedulerName": {},
                              "f:volumes": {}
                            }
                          }
                        },
                        "f:Worker": {
                          ".": {},
                          "f:replicas": {},
                          "f:restartPolicy": {},
                          "f:template": {
                            ".": {},
                            "f:spec": {
                              ".": {},
                              "f:schedulerName": {},
                              "f:volumes": {}
                            }
                          }
                        }
                      }
                    }
                  },
                  "manager": "kubectl-client-side-apply",
                  "operation": "Update",
                  "time": "2024-07-18T10:39:25Z"
                },
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        "f:aijob.cce.baidubce.com/barrier-finish": {}
                      }
                    }
                  },
                  "manager": "jobbarrier",
                  "operation": "Update",
                  "time": "2024-07-18T10:39:37Z"
                },
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:status": {
                      ".": {},
                      "f:completionTime": {},
                      "f:conditions": {},
                      "f:lastReconcileTime": {},
                      "f:replicaStatuses": {
                        ".": {},
                        "f:Master": {
                          ".": {},
                          "f:selector": {},
                          "f:succeeded": {}
                        },
                        "f:Worker": {
                          ".": {},
                          "f:selector": {}
                        }
                      },
                      "f:startTime": {}
                    }
                  },
                  "manager": "manager",
                  "operation": "Update",
                  "time": "2024-07-18T10:42:41Z"
                }
              ],
              "name": "changtao02-megatron-llama3-layer20-debug-lj",
              "namespace": "default",
              "resourceVersion": "2371637326",
              "uid": "202c61cb-a030-41b5-93b1-8bbdc12f30be"
            },
            "spec": {
              "pytorchReplicaSpecs": {
                "Master": {
                  "replicas": 1,
                  "restartPolicy": "Never",
                  "template": {
                    "metadata": {},
                    "spec": {
                      "containers": [
                        {
                          "command": [
                            "bash",
                            "/workspace/Megatron-LM/examples/launch.sh"
                          ],
                          "env": [
                            {
                              "name": "CUDA_DEVICE_MAX_CONNECTIONS",
                              "value": "1"
                            },
                            {
                              "name": "NCCL_IB_DISABLE",
                              "value": "0"
                            },
                            {
                              "name": "MASTER",
                              "value": "1"
                            }
                          ],
                          "image": "registry.baidubce.com/cce-ai-native/aiak-megatron:multi-accelerators-20240608",
                          "imagePullPolicy": "Always",
                          "name": "pytorch",
                          "ports": [
                            {
                              "containerPort": 23456,
                              "name": "pytorchjob-port",
                              "protocol": "TCP"
                            }
                          ],
                          "resources": {
                            "limits": {
                              "nvidia.com/gpu": "8",
                              "rdma/hca": "1"
                            }
                          },
                          "securityContext": {
                            "capabilities": {
                              "add": [
                                "IPC_LOCK"
                              ]
                            }
                          },
                          "volumeMounts": [
                            {
                              "mountPath": "/dev/shm",
                              "name": "cache-volume"
                            },
                            {
                              "mountPath": "/workspace/Megatron-LM/examples/launch.sh",
                              "name": "config-volume",
                              "subPath": "launch.sh"
                            },
                            {
                              "mountPath": "/mnt/cluster",
                              "name": "data"
                            }
                          ]
                        }
                      ],
                      "schedulerName": "volcano",
                      "volumes": [
                        {
                          "emptyDir": {
                            "medium": "Memory"
                          },
                          "name": "cache-volume"
                        },
                        {
                          "configMap": {
                            "name": "changtao02-llama3-layer20-debug"
                          },
                          "name": "config-volume"
                        },
                        {
                          "name": "data",
                          "persistentVolumeClaim": {
                            "claimName": "pvc-pfs"
                          }
                        }
                      ]
                    }
                  }
                },
                "Worker": {
                  "replicas": 0,
                  "restartPolicy": "Never",
                  "template": {
                    "metadata": {},
                    "spec": {
                      "containers": [
                        {
                          "command": [
                            "bash",
                            "/workspace/Megatron-LM/examples/launch.sh"
                          ],
                          "env": [
                            {
                              "name": "CUDA_DEVICE_MAX_CONNECTIONS",
                              "value": "1"
                            },
                            {
                              "name": "NCCL_IB_DISABLE",
                              "value": "0"
                            }
                          ],
                          "image": "registry.baidubce.com/cce-ai-native/aiak-megatron:multi-accelerators-20240608",
                          "imagePullPolicy": "Always",
                          "name": "pytorch",
                          "ports": [
                            {
                              "containerPort": 23456,
                              "name": "pytorchjob-port",
                              "protocol": "TCP"
                            }
                          ],
                          "resources": {
                            "limits": {
                              "nvidia.com/gpu": "8",
                              "rdma/hca": "1"
                            }
                          },
                          "securityContext": {
                            "capabilities": {
                              "add": [
                                "IPC_LOCK"
                              ]
                            }
                          },
                          "volumeMounts": [
                            {
                              "mountPath": "/dev/shm",
                              "name": "cache-volume"
                            },
                            {
                              "mountPath": "/workspace/Megatron-LM/examples/launch.sh",
                              "name": "config-volume",
                              "subPath": "launch.sh"
                            },
                            {
                              "mountPath": "/mnt/cluster",
                              "name": "data"
                            }
                          ]
                        }
                      ],
                      "schedulerName": "volcano",
                      "volumes": [
                        {
                          "emptyDir": {
                            "medium": "Memory"
                          },
                          "name": "cache-volume"
                        },
                        {
                          "configMap": {
                            "name": "changtao02-llama3-layer20-debug"
                          },
                          "name": "config-volume"
                        },
                        {
                          "name": "data",
                          "persistentVolumeClaim": {
                            "claimName": "pvc-pfs"
                          }
                        }
                      ]
                    }
                  }
                }
              },
              "runPolicy": {
                "cleanPodPolicy": "None"
              }
            },
            "status": {
              "completionTime": "2024-07-18T10:42:41Z",
              "conditions": [
                {
                  "lastTransitionTime": "2024-07-18T10:39:25Z",
                  "lastUpdateTime": "2024-07-18T10:39:25Z",
                  "message": "PyTorchJob changtao02-megatron-llama3-layer20-debug-lj is created.",
                  "reason": "PyTorchJobCreated",
                  "status": "True",
                  "type": "Created"
                },
                {
                  "lastTransitionTime": "2024-07-18T10:39:40Z",
                  "lastUpdateTime": "2024-07-18T10:39:40Z",
                  "message": "PyTorchJob changtao02-megatron-llama3-layer20-debug-lj is running.",
                  "reason": "JobRunning",
                  "status": "False",
                  "type": "Running"
                },
                {
                  "lastTransitionTime": "2024-07-18T10:42:41Z",
                  "lastUpdateTime": "2024-07-18T10:42:41Z",
                  "message": "PyTorchJob changtao02-megatron-llama3-layer20-debug-lj is successfully completed.",
                  "reason": "JobSucceeded",
                  "status": "True",
                  "type": "Succeeded"
                }
              ],
              "lastReconcileTime": "2024-07-18T10:39:26Z",
              "replicaStatuses": {
                "Master": {
                  "selector": "training.kubeflow.org/job-name=changtao02-megatron-llama3-layer20-debug-lj,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=master",
                  "succeeded": 1
                },
                "Worker": {
                  "selector": "training.kubeflow.org/job-name=changtao02-megatron-llama3-layer20-debug-lj,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=worker"
                }
              },
              "startTime": "2024-07-18T10:39:26Z"
            }
          },
          {
            "apiVersion": "kubeflow.org/v1",
            "kind": "PyTorchJob",
            "metadata": {
              "annotations": {
                "aijob.cce.baidubce.com/barrier-finish": "513c1989-e194-41eb-b1c1-5279a79337a0",
                "aijob.cce.baidubce.com/fault-tolerance-enabled": "true",
                "aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": "",
                "aijob.cce.baidubce.com/openapi-jobid": "pytorch-5f188c2b-a851-4ea8-a62e-dd0b61b8f1e6",
                "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
                "aijob.cce.baidubce.com/raw-request": "{\"name\":\"deepspeed-zhuxiang\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"normal\",\"oversell\":false,\"faultTolerance\":true,\"command\":\" source /root/anaconda3/etc/profile.d/conda.sh\\n    conda activate llama-factory\\n\\n    ROOT_DIR=/workspace/LLaMA-Factory/\\n\\n    CHECKPOINT_LOAD_PATH=/mnt/cluster/ppl/Qwen-14B-Chat\\n    CHECKPOINT_SAVE_PATH=/mnt/cluster/ppl/Qwen-14B-Chat_saved\\n    DEEPSPEED_CONFIG=$ROOT_DIR/examples/deepspeed/ds_z3_offload_config.json\\n\\n    GPUS_PER_NODE=8\\n\\n    is_master=${MASTER-\\\"0\\\"}\\n    if [[ $is_master -eq 1 ]];then\\n      DISTRIBUTED_ARGS=\\\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $HOSTNAME --master_port $MASTER_PORT\\\"\\n    else\\n      DISTRIBUTED_ARGS=\\\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $MASTER_ADDR --master_port $MASTER_PORT\\\"\\n    fi\\n\\n    QWEN_14B_ARGS=\\\"--model_name_or_path $CHECKPOINT_LOAD_PATH \\\\\\n        --stage sft \\\\\\n        --do_train \\\\\\n        --dataset alpaca_en_demo \\\\\\n        --template qwen \\\\\\n        --finetuning_type lora \\\\\\n        --lora_target all \\\\\\n        --overwrite_output_dir \\\\\\n        --dataset_dir $ROOT_DIR/data \\\\\\n        --output_dir $CHECKPOINT_SAVE_PATH \\\\\\n        --preprocessing_num_workers 90 \\\\\\n        --dataloader_num_workers 90 \\\\\\n        --per_device_train_batch_size 1 \\\\\\n        --gradient_accumulation_steps 8 \\\\\\n        --cutoff_len 2048 \\\\\\n        --max_length 2048 \\\\\\n        --deepspeed $DEEPSPEED_CONFIG \\\\\\n        --logging_first_step \\\\\\n        --logging_steps 10 \\\\\\n        --save_strategy steps \\\\\\n        --save_steps 40 \\\\\\n        --num_train_epochs 2.0 \\\\\\n        --lr_scheduler_type cosine \\\\\\n        --learning_rate 1e-5 \\\\\\n        --plot_loss \\\\\\n        --bf16 \\\\\\n        --rope_scaling linear \\\\\\n        --flash_attn auto \\\\\\n        --shift_attn \\\\\\n        --ddp_find_unused_parameters False \\\\\\n        --push_to_hub False\\\"\\n\\n    PYTHONPATH=$ROOT_DIR:$PYTHONPATH \\\\\\n        torchrun $DISTRIBUTED_ARGS \\\\\\n        $ROOT_DIR/src/train.py \\\\\\n        $QWEN_14B_ARGS\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":true,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/cce-ai-native/aiak-algo\",\"tag\":\"0.1\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"deepspeed-zhuxiang\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/deepspeed-zhuxiang/output/training_logs\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"},\"Worker\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/cce-ai-native/aiak-algo\",\"tag\":\"0.1\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"deepspeed-zhuxiang\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/deepspeed-zhuxiang/output/training_logs\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":true,\"logPath\":\"/mnt/cluster/deepspeed-zhuxiang/output/training_logs\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":true,\"isCopyJob\":false,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
                "aijob.cce.baidubce.com/timeline": "[{\"conditionType\":\"Created\",\"time\":1721569996},{\"conditionType\":\"Scheduled\",\"time\":1721569998},{\"conditionType\":\"Running\",\"time\":1721571406},{\"conditionType\":\"Succeeded\",\"time\":1721571826}]",
                "scheduling.k8s.io/job-enable-oversell": "false",
                "tensorboard-gc": "true"
              },
              "creationTimestamp": "2024-07-21T13:53:16Z",
              "generation": 2,
              "labels": {
                "aijob.cce.baidubce.com/ai-user-id": "b89c433a0e884615a4c878ca24e2686e",
                "aijob.cce.baidubce.com/ai-user-name": "zhuxiang05",
                "aijob.cce.baidubce.com/create-from-aihcp": "true",
                "aijob.cce.baidubce.com/openapi-jobid": "pytorch-5f188c2b-a851-4ea8-a62e-dd0b61b8f1e6"
              },
              "managedFields": [
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        ".": {},
                        "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                        "f:aijob.cce.baidubce.com/openapi-jobid": {},
                        "f:aijob.cce.baidubce.com/pfs-id": {},
                        "f:aijob.cce.baidubce.com/raw-request": {},
                        "f:scheduling.k8s.io/job-enable-oversell": {}
                      },
                      "f:labels": {
                        ".": {},
                        "f:aijob.cce.baidubce.com/ai-user-id": {},
                        "f:aijob.cce.baidubce.com/ai-user-name": {},
                        "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                        "f:aijob.cce.baidubce.com/openapi-jobid": {}
                      }
                    },
                    "f:spec": {
                      ".": {},
                      "f:pytorchReplicaSpecs": {
                        ".": {},
                        "f:Master": {
                          ".": {},
                          "f:replicas": {},
                          "f:restartPolicy": {},
                          "f:template": {
                            ".": {},
                            "f:metadata": {
                              ".": {},
                              "f:annotations": {
                                ".": {},
                                "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                                "f:aijob.cce.baidubce.com/openapi-jobid": {},
                                "f:aijob.cce.baidubce.com/pfs-id": {},
                                "f:aijob.cce.baidubce.com/raw-request": {},
                                "f:scheduling.k8s.io/job-enable-oversell": {}
                              },
                              "f:labels": {
                                ".": {},
                                "f:aijob.cce.baidubce.com/ai-user-id": {},
                                "f:aijob.cce.baidubce.com/ai-user-name": {},
                                "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                                "f:aijob.cce.baidubce.com/openapi-jobid": {}
                              }
                            },
                            "f:spec": {
                              ".": {},
                              "f:dnsPolicy": {},
                              "f:hostNetwork": {},
                              "f:schedulerName": {},
                              "f:volumes": {}
                            }
                          }
                        },
                        "f:Worker": {
                          ".": {},
                          "f:replicas": {},
                          "f:restartPolicy": {},
                          "f:template": {
                            ".": {},
                            "f:metadata": {
                              ".": {},
                              "f:annotations": {
                                ".": {},
                                "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                                "f:aijob.cce.baidubce.com/openapi-jobid": {},
                                "f:aijob.cce.baidubce.com/pfs-id": {},
                                "f:aijob.cce.baidubce.com/raw-request": {},
                                "f:scheduling.k8s.io/job-enable-oversell": {}
                              },
                              "f:labels": {
                                ".": {},
                                "f:aijob.cce.baidubce.com/ai-user-id": {},
                                "f:aijob.cce.baidubce.com/ai-user-name": {},
                                "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                                "f:aijob.cce.baidubce.com/openapi-jobid": {}
                              }
                            },
                            "f:spec": {
                              ".": {},
                              "f:dnsPolicy": {},
                              "f:hostNetwork": {},
                              "f:schedulerName": {},
                              "f:volumes": {}
                            }
                          }
                        }
                      },
                      "f:runPolicy": {
                        ".": {},
                        "f:schedulingPolicy": {
                          ".": {},
                          "f:priorityClass": {},
                          "f:queue": {}
                        }
                      }
                    }
                  },
                  "manager": "cce-ai-service",
                  "operation": "Update",
                  "time": "2024-07-21T13:53:16Z"
                },
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        "f:aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": {},
                        "f:aijob.cce.baidubce.com/timeline": {}
                      }
                    },
                    "f:spec": {
                      "f:pytorchReplicaSpecs": {
                        "f:Master": {
                          "f:template": {
                            "f:spec": {
                              "f:containers": {}
                            }
                          }
                        },
                        "f:Worker": {
                          "f:template": {
                            "f:spec": {
                              "f:containers": {}
                            }
                          }
                        }
                      },
                      "f:runPolicy": {
                        "f:cleanPodPolicy": {}
                      }
                    }
                  },
                  "manager": "controller",
                  "operation": "Update",
                  "time": "2024-07-21T13:53:16Z"
                },
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        "f:aijob.cce.baidubce.com/barrier-finish": {}
                      }
                    }
                  },
                  "manager": "jobbarrier",
                  "operation": "Update",
                  "time": "2024-07-21T14:16:37Z"
                },
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        "f:tensorboard-gc": {}
                      }
                    },
                    "f:status": {
                      ".": {},
                      "f:completionTime": {},
                      "f:conditions": {},
                      "f:lastReconcileTime": {},
                      "f:replicaStatuses": {
                        ".": {},
                        "f:Master": {
                          ".": {},
                          "f:selector": {},
                          "f:succeeded": {}
                        },
                        "f:Worker": {
                          ".": {},
                          "f:selector": {},
                          "f:succeeded": {}
                        }
                      },
                      "f:startTime": {}
                    }
                  },
                  "manager": "manager",
                  "operation": "Update",
                  "time": "2024-07-22T13:53:34Z"
                }
              ],
              "name": "deepspeed-zhuxiang",
              "namespace": "default",
              "resourceVersion": "2376353037",
              "uid": "9905b1d3-aa53-4500-a38f-85d4e54a3523"
            },
            "spec": {
              "pytorchReplicaSpecs": {
                "Master": {
                  "replicas": 1,
                  "restartPolicy": "Never",
                  "template": {
                    "metadata": {
                      "annotations": {
                        "aijob.cce.baidubce.com/fault-tolerance-enabled": "true",
                        "aijob.cce.baidubce.com/openapi-jobid": "pytorch-5f188c2b-a851-4ea8-a62e-dd0b61b8f1e6",
                        "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
                        "aijob.cce.baidubce.com/raw-request": "{\"name\":\"deepspeed-zhuxiang\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"normal\",\"oversell\":false,\"faultTolerance\":true,\"command\":\" source /root/anaconda3/etc/profile.d/conda.sh\\n    conda activate llama-factory\\n\\n    ROOT_DIR=/workspace/LLaMA-Factory/\\n\\n    CHECKPOINT_LOAD_PATH=/mnt/cluster/ppl/Qwen-14B-Chat\\n    CHECKPOINT_SAVE_PATH=/mnt/cluster/ppl/Qwen-14B-Chat_saved\\n    DEEPSPEED_CONFIG=$ROOT_DIR/examples/deepspeed/ds_z3_offload_config.json\\n\\n    GPUS_PER_NODE=8\\n\\n    is_master=${MASTER-\\\"0\\\"}\\n    if [[ $is_master -eq 1 ]];then\\n      DISTRIBUTED_ARGS=\\\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $HOSTNAME --master_port $MASTER_PORT\\\"\\n    else\\n      DISTRIBUTED_ARGS=\\\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $MASTER_ADDR --master_port $MASTER_PORT\\\"\\n    fi\\n\\n    QWEN_14B_ARGS=\\\"--model_name_or_path $CHECKPOINT_LOAD_PATH \\\\\\n        --stage sft \\\\\\n        --do_train \\\\\\n        --dataset alpaca_en_demo \\\\\\n        --template qwen \\\\\\n        --finetuning_type lora \\\\\\n        --lora_target all \\\\\\n        --overwrite_output_dir \\\\\\n        --dataset_dir $ROOT_DIR/data \\\\\\n        --output_dir $CHECKPOINT_SAVE_PATH \\\\\\n        --preprocessing_num_workers 90 \\\\\\n        --dataloader_num_workers 90 \\\\\\n        --per_device_train_batch_size 1 \\\\\\n        --gradient_accumulation_steps 8 \\\\\\n        --cutoff_len 2048 \\\\\\n        --max_length 2048 \\\\\\n        --deepspeed $DEEPSPEED_CONFIG \\\\\\n        --logging_first_step \\\\\\n        --logging_steps 10 \\\\\\n        --save_strategy steps \\\\\\n        --save_steps 40 \\\\\\n        --num_train_epochs 2.0 \\\\\\n        --lr_scheduler_type cosine \\\\\\n        --learning_rate 1e-5 \\\\\\n        --plot_loss \\\\\\n        --bf16 \\\\\\n        --rope_scaling linear \\\\\\n        --flash_attn auto \\\\\\n        --shift_attn \\\\\\n        --ddp_find_unused_parameters False \\\\\\n        --push_to_hub False\\\"\\n\\n    PYTHONPATH=$ROOT_DIR:$PYTHONPATH \\\\\\n        torchrun $DISTRIBUTED_ARGS \\\\\\n        $ROOT_DIR/src/train.py \\\\\\n        $QWEN_14B_ARGS\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":true,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/cce-ai-native/aiak-algo\",\"tag\":\"0.1\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"deepspeed-zhuxiang\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/deepspeed-zhuxiang/output/training_logs\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"},\"Worker\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/cce-ai-native/aiak-algo\",\"tag\":\"0.1\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"deepspeed-zhuxiang\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/deepspeed-zhuxiang/output/training_logs\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":true,\"logPath\":\"/mnt/cluster/deepspeed-zhuxiang/output/training_logs\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":true,\"isCopyJob\":false,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
                        "scheduling.k8s.io/job-enable-oversell": "false"
                      },
                      "labels": {
                        "aijob.cce.baidubce.com/ai-user-id": "b89c433a0e884615a4c878ca24e2686e",
                        "aijob.cce.baidubce.com/ai-user-name": "zhuxiang05",
                        "aijob.cce.baidubce.com/create-from-aihcp": "true",
                        "aijob.cce.baidubce.com/openapi-jobid": "pytorch-5f188c2b-a851-4ea8-a62e-dd0b61b8f1e6"
                      }
                    },
                    "spec": {
                      "containers": [
                        {
                          "command": [
                            "/bin/bash",
                            "-c",
                            " source /root/anaconda3/etc/profile.d/conda.sh\n    conda activate llama-factory\n\n    ROOT_DIR=/workspace/LLaMA-Factory/\n\n    CHECKPOINT_LOAD_PATH=/mnt/cluster/ppl/Qwen-14B-Chat\n    CHECKPOINT_SAVE_PATH=/mnt/cluster/ppl/Qwen-14B-Chat_saved\n    DEEPSPEED_CONFIG=$ROOT_DIR/examples/deepspeed/ds_z3_offload_config.json\n\n    GPUS_PER_NODE=8\n\n    is_master=${MASTER-\"0\"}\n    if [[ $is_master -eq 1 ]];then\n      DISTRIBUTED_ARGS=\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $HOSTNAME --master_port $MASTER_PORT\"\n    else\n      DISTRIBUTED_ARGS=\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $MASTER_ADDR --master_port $MASTER_PORT\"\n    fi\n\n    QWEN_14B_ARGS=\"--model_name_or_path $CHECKPOINT_LOAD_PATH \\\n        --stage sft \\\n        --do_train \\\n        --dataset alpaca_en_demo \\\n        --template qwen \\\n        --finetuning_type lora \\\n        --lora_target all \\\n        --overwrite_output_dir \\\n        --dataset_dir $ROOT_DIR/data \\\n        --output_dir $CHECKPOINT_SAVE_PATH \\\n        --preprocessing_num_workers 90 \\\n        --dataloader_num_workers 90 \\\n        --per_device_train_batch_size 1 \\\n        --gradient_accumulation_steps 8 \\\n        --cutoff_len 2048 \\\n        --max_length 2048 \\\n        --deepspeed $DEEPSPEED_CONFIG \\\n        --logging_first_step \\\n        --logging_steps 10 \\\n        --save_strategy steps \\\n        --save_steps 40 \\\n        --num_train_epochs 2.0 \\\n        --lr_scheduler_type cosine \\\n        --learning_rate 1e-5 \\\n        --plot_loss \\\n        --bf16 \\\n        --rope_scaling linear \\\n        --flash_attn auto \\\n        --shift_attn \\\n        --ddp_find_unused_parameters False \\\n        --push_to_hub False\"\n\n    PYTHONPATH=$ROOT_DIR:$PYTHONPATH \\\n        torchrun $DISTRIBUTED_ARGS \\\n        $ROOT_DIR/src/train.py \\\n        $QWEN_14B_ARGS"
                          ],
                          "env": [
                            {
                              "name": "AIHC_TENSORBOARD_LOG_PATH",
                              "value": "/mnt/cluster/deepspeed-zhuxiang/output/training_logs"
                            },
                            {
                              "name": "AIHC_JOB_NAME",
                              "value": "deepspeed-zhuxiang"
                            },
                            {
                              "name": "NCCL_IB_DISABLE",
                              "value": "0"
                            }
                          ],
                          "image": "registry.baidubce.com/cce-ai-native/aiak-algo:0.1",
                          "imagePullPolicy": "Always",
                          "name": "pytorch",
                          "ports": [
                            {
                              "containerPort": 23456,
                              "name": "pytorchjob-port",
                              "protocol": "TCP"
                            }
                          ],
                          "resources": {
                            "limits": {
                              "baidu.com/a800_80g_cgpu": "8",
                              "rdma/hca": "1"
                            },
                            "requests": {
                              "baidu.com/a800_80g_cgpu": "8",
                              "rdma/hca": "1"
                            }
                          },
                          "securityContext": {
                            "capabilities": {
                              "add": [
                                "IPC_LOCK"
                              ]
                            }
                          },
                          "volumeMounts": [
                            {
                              "mountPath": "/dev/shm",
                              "name": "devshm"
                            },
                            {
                              "mountPath": "/mnt/cluster",
                              "name": "pvc-pfs"
                            }
                          ]
                        }
                      ],
                      "dnsPolicy": "ClusterFirstWithHostNet",
                      "hostNetwork": true,
                      "schedulerName": "volcano",
                      "volumes": [
                        {
                          "emptyDir": {
                            "medium": "Memory",
                            "sizeLimit": "10Gi"
                          },
                          "name": "devshm"
                        },
                        {
                          "name": "pvc-pfs",
                          "persistentVolumeClaim": {
                            "claimName": "pvc-pfs"
                          }
                        }
                      ]
                    }
                  }
                },
                "Worker": {
                  "replicas": 1,
                  "restartPolicy": "Never",
                  "template": {
                    "metadata": {
                      "annotations": {
                        "aijob.cce.baidubce.com/fault-tolerance-enabled": "true",
                        "aijob.cce.baidubce.com/openapi-jobid": "pytorch-5f188c2b-a851-4ea8-a62e-dd0b61b8f1e6",
                        "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
                        "aijob.cce.baidubce.com/raw-request": "{\"name\":\"deepspeed-zhuxiang\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"normal\",\"oversell\":false,\"faultTolerance\":true,\"command\":\" source /root/anaconda3/etc/profile.d/conda.sh\\n    conda activate llama-factory\\n\\n    ROOT_DIR=/workspace/LLaMA-Factory/\\n\\n    CHECKPOINT_LOAD_PATH=/mnt/cluster/ppl/Qwen-14B-Chat\\n    CHECKPOINT_SAVE_PATH=/mnt/cluster/ppl/Qwen-14B-Chat_saved\\n    DEEPSPEED_CONFIG=$ROOT_DIR/examples/deepspeed/ds_z3_offload_config.json\\n\\n    GPUS_PER_NODE=8\\n\\n    is_master=${MASTER-\\\"0\\\"}\\n    if [[ $is_master -eq 1 ]];then\\n      DISTRIBUTED_ARGS=\\\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $HOSTNAME --master_port $MASTER_PORT\\\"\\n    else\\n      DISTRIBUTED_ARGS=\\\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $MASTER_ADDR --master_port $MASTER_PORT\\\"\\n    fi\\n\\n    QWEN_14B_ARGS=\\\"--model_name_or_path $CHECKPOINT_LOAD_PATH \\\\\\n        --stage sft \\\\\\n        --do_train \\\\\\n        --dataset alpaca_en_demo \\\\\\n        --template qwen \\\\\\n        --finetuning_type lora \\\\\\n        --lora_target all \\\\\\n        --overwrite_output_dir \\\\\\n        --dataset_dir $ROOT_DIR/data \\\\\\n        --output_dir $CHECKPOINT_SAVE_PATH \\\\\\n        --preprocessing_num_workers 90 \\\\\\n        --dataloader_num_workers 90 \\\\\\n        --per_device_train_batch_size 1 \\\\\\n        --gradient_accumulation_steps 8 \\\\\\n        --cutoff_len 2048 \\\\\\n        --max_length 2048 \\\\\\n        --deepspeed $DEEPSPEED_CONFIG \\\\\\n        --logging_first_step \\\\\\n        --logging_steps 10 \\\\\\n        --save_strategy steps \\\\\\n        --save_steps 40 \\\\\\n        --num_train_epochs 2.0 \\\\\\n        --lr_scheduler_type cosine \\\\\\n        --learning_rate 1e-5 \\\\\\n        --plot_loss \\\\\\n        --bf16 \\\\\\n        --rope_scaling linear \\\\\\n        --flash_attn auto \\\\\\n        --shift_attn \\\\\\n        --ddp_find_unused_parameters False \\\\\\n        --push_to_hub False\\\"\\n\\n    PYTHONPATH=$ROOT_DIR:$PYTHONPATH \\\\\\n        torchrun $DISTRIBUTED_ARGS \\\\\\n        $ROOT_DIR/src/train.py \\\\\\n        $QWEN_14B_ARGS\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":true,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/cce-ai-native/aiak-algo\",\"tag\":\"0.1\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"deepspeed-zhuxiang\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/deepspeed-zhuxiang/output/training_logs\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"},\"Worker\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/cce-ai-native/aiak-algo\",\"tag\":\"0.1\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"deepspeed-zhuxiang\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/deepspeed-zhuxiang/output/training_logs\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":true,\"logPath\":\"/mnt/cluster/deepspeed-zhuxiang/output/training_logs\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":true,\"isCopyJob\":false,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
                        "scheduling.k8s.io/job-enable-oversell": "false"
                      },
                      "labels": {
                        "aijob.cce.baidubce.com/ai-user-id": "b89c433a0e884615a4c878ca24e2686e",
                        "aijob.cce.baidubce.com/ai-user-name": "zhuxiang05",
                        "aijob.cce.baidubce.com/create-from-aihcp": "true",
                        "aijob.cce.baidubce.com/openapi-jobid": "pytorch-5f188c2b-a851-4ea8-a62e-dd0b61b8f1e6"
                      }
                    },
                    "spec": {
                      "containers": [
                        {
                          "command": [
                            "/bin/bash",
                            "-c",
                            " source /root/anaconda3/etc/profile.d/conda.sh\n    conda activate llama-factory\n\n    ROOT_DIR=/workspace/LLaMA-Factory/\n\n    CHECKPOINT_LOAD_PATH=/mnt/cluster/ppl/Qwen-14B-Chat\n    CHECKPOINT_SAVE_PATH=/mnt/cluster/ppl/Qwen-14B-Chat_saved\n    DEEPSPEED_CONFIG=$ROOT_DIR/examples/deepspeed/ds_z3_offload_config.json\n\n    GPUS_PER_NODE=8\n\n    is_master=${MASTER-\"0\"}\n    if [[ $is_master -eq 1 ]];then\n      DISTRIBUTED_ARGS=\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $HOSTNAME --master_port $MASTER_PORT\"\n    else\n      DISTRIBUTED_ARGS=\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $MASTER_ADDR --master_port $MASTER_PORT\"\n    fi\n\n    QWEN_14B_ARGS=\"--model_name_or_path $CHECKPOINT_LOAD_PATH \\\n        --stage sft \\\n        --do_train \\\n        --dataset alpaca_en_demo \\\n        --template qwen \\\n        --finetuning_type lora \\\n        --lora_target all \\\n        --overwrite_output_dir \\\n        --dataset_dir $ROOT_DIR/data \\\n        --output_dir $CHECKPOINT_SAVE_PATH \\\n        --preprocessing_num_workers 90 \\\n        --dataloader_num_workers 90 \\\n        --per_device_train_batch_size 1 \\\n        --gradient_accumulation_steps 8 \\\n        --cutoff_len 2048 \\\n        --max_length 2048 \\\n        --deepspeed $DEEPSPEED_CONFIG \\\n        --logging_first_step \\\n        --logging_steps 10 \\\n        --save_strategy steps \\\n        --save_steps 40 \\\n        --num_train_epochs 2.0 \\\n        --lr_scheduler_type cosine \\\n        --learning_rate 1e-5 \\\n        --plot_loss \\\n        --bf16 \\\n        --rope_scaling linear \\\n        --flash_attn auto \\\n        --shift_attn \\\n        --ddp_find_unused_parameters False \\\n        --push_to_hub False\"\n\n    PYTHONPATH=$ROOT_DIR:$PYTHONPATH \\\n        torchrun $DISTRIBUTED_ARGS \\\n        $ROOT_DIR/src/train.py \\\n        $QWEN_14B_ARGS"
                          ],
                          "env": [
                            {
                              "name": "AIHC_TENSORBOARD_LOG_PATH",
                              "value": "/mnt/cluster/deepspeed-zhuxiang/output/training_logs"
                            },
                            {
                              "name": "AIHC_JOB_NAME",
                              "value": "deepspeed-zhuxiang"
                            },
                            {
                              "name": "NCCL_IB_DISABLE",
                              "value": "0"
                            }
                          ],
                          "image": "registry.baidubce.com/cce-ai-native/aiak-algo:0.1",
                          "imagePullPolicy": "Always",
                          "name": "pytorch",
                          "ports": [
                            {
                              "containerPort": 23456,
                              "name": "pytorchjob-port",
                              "protocol": "TCP"
                            }
                          ],
                          "resources": {
                            "limits": {
                              "baidu.com/a800_80g_cgpu": "8",
                              "rdma/hca": "1"
                            },
                            "requests": {
                              "baidu.com/a800_80g_cgpu": "8",
                              "rdma/hca": "1"
                            }
                          },
                          "securityContext": {
                            "capabilities": {
                              "add": [
                                "IPC_LOCK"
                              ]
                            }
                          },
                          "volumeMounts": [
                            {
                              "mountPath": "/dev/shm",
                              "name": "devshm"
                            },
                            {
                              "mountPath": "/mnt/cluster",
                              "name": "pvc-pfs"
                            }
                          ]
                        }
                      ],
                      "dnsPolicy": "ClusterFirstWithHostNet",
                      "hostNetwork": true,
                      "schedulerName": "volcano",
                      "volumes": [
                        {
                          "emptyDir": {
                            "medium": "Memory",
                            "sizeLimit": "10Gi"
                          },
                          "name": "devshm"
                        },
                        {
                          "name": "pvc-pfs",
                          "persistentVolumeClaim": {
                            "claimName": "pvc-pfs"
                          }
                        }
                      ]
                    }
                  }
                }
              },
              "runPolicy": {
                "cleanPodPolicy": "None",
                "schedulingPolicy": {
                  "priorityClass": "normal",
                  "queue": "default"
                }
              }
            },
            "status": {
              "completionTime": "2024-07-21T14:23:46Z",
              "conditions": [
                {
                  "lastTransitionTime": "2024-07-21T13:53:16Z",
                  "lastUpdateTime": "2024-07-21T13:53:16Z",
                  "message": "PyTorchJob deepspeed-zhuxiang is created.",
                  "reason": "PyTorchJobCreated",
                  "status": "True",
                  "type": "Created"
                },
                {
                  "lastTransitionTime": "2024-07-21T14:16:46Z",
                  "lastUpdateTime": "2024-07-21T14:16:46Z",
                  "message": "PyTorchJob deepspeed-zhuxiang is running.",
                  "reason": "JobRunning",
                  "status": "False",
                  "type": "Running"
                },
                {
                  "lastTransitionTime": "2024-07-21T14:23:46Z",
                  "lastUpdateTime": "2024-07-21T14:23:46Z",
                  "message": "PyTorchJob deepspeed-zhuxiang is successfully completed.",
                  "reason": "JobSucceeded",
                  "status": "True",
                  "type": "Succeeded"
                }
              ],
              "lastReconcileTime": "2024-07-21T14:23:46Z",
              "replicaStatuses": {
                "Master": {
                  "selector": "training.kubeflow.org/job-name=deepspeed-zhuxiang,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=master",
                  "succeeded": 1
                },
                "Worker": {
                  "selector": "training.kubeflow.org/job-name=deepspeed-zhuxiang,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=worker",
                  "succeeded": 1
                }
              },
              "startTime": "2024-07-21T13:53:17Z"
            }
          },
          {
            "apiVersion": "kubeflow.org/v1",
            "kind": "PyTorchJob",
            "metadata": {
              "annotations": {
                "aijob.cce.baidubce.com/barrier-finish": "fc10caac-df62-4783-9710-e515765b632c",
                "aijob.cce.baidubce.com/fault-tolerance-enabled": "false",
                "aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": "",
                "aijob.cce.baidubce.com/openapi-jobid": "pytorch-f6085dc4-cc6e-4dc3-a524-881a8b4e172e",
                "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
                "aijob.cce.baidubce.com/raw-request": "{\"name\":\"deepspeed-zhuxiang-1\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"normal\",\"oversell\":false,\"faultTolerance\":false,\"command\":\" source /root/anaconda3/etc/profile.d/conda.sh\\n    conda activate llama-factory\\n\\n    ROOT_DIR=/workspace/LLaMA-Factory/\\n\\n    CHECKPOINT_LOAD_PATH=/mnt/cluster/ppl/Qwen-14B-Chat\\n    CHECKPOINT_SAVE_PATH=/mnt/cluster/ppl/Qwen-14B-Chat_saved_zhuxiang\\n    DEEPSPEED_CONFIG=$ROOT_DIR/examples/deepspeed/ds_z3_offload_config.json\\n\\n    GPUS_PER_NODE=8\\n\\n    is_master=${MASTER-\\\"0\\\"}\\n    if [[ $is_master -eq 1 ]];then\\n      DISTRIBUTED_ARGS=\\\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $HOSTNAME --master_port $MASTER_PORT\\\"\\n    else\\n      DISTRIBUTED_ARGS=\\\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $MASTER_ADDR --master_port $MASTER_PORT\\\"\\n    fi\\n\\n    QWEN_14B_ARGS=\\\"--model_name_or_path $CHECKPOINT_LOAD_PATH \\\\\\n        --stage sft \\\\\\n        --do_train \\\\\\n        --dataset alpaca_en_demo \\\\\\n        --template qwen \\\\\\n        --finetuning_type lora \\\\\\n        --lora_target all \\\\\\n        --overwrite_output_dir \\\\\\n        --dataset_dir $ROOT_DIR/data \\\\\\n        --output_dir $CHECKPOINT_SAVE_PATH \\\\\\n        --preprocessing_num_workers 90 \\\\\\n        --dataloader_num_workers 90 \\\\\\n        --per_device_train_batch_size 1 \\\\\\n        --gradient_accumulation_steps 8 \\\\\\n        --cutoff_len 2048 \\\\\\n        --max_length 2048 \\\\\\n        --deepspeed $DEEPSPEED_CONFIG \\\\\\n        --logging_first_step \\\\\\n        --logging_steps 10 \\\\\\n        --save_strategy steps \\\\\\n        --save_steps 40 \\\\\\n        --num_train_epochs 2.0 \\\\\\n        --lr_scheduler_type cosine \\\\\\n        --learning_rate 1e-5 \\\\\\n        --plot_loss \\\\\\n        --bf16 \\\\\\n        --rope_scaling linear \\\\\\n        --flash_attn auto \\\\\\n        --shift_attn \\\\\\n        --ddp_find_unused_parameters False \\\\\\n        --push_to_hub False\\\"\\n\\n    PYTHONPATH=$ROOT_DIR:$PYTHONPATH \\\\\\n        torchrun $DISTRIBUTED_ARGS \\\\\\n        $ROOT_DIR/src/train.py \\\\\\n        $QWEN_14B_ARGS\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":true,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/cce-ai-native/aiak-algo\",\"tag\":\"0.1\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"deepspeed-zhuxiang-1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"},\"Worker\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/cce-ai-native/aiak-algo\",\"tag\":\"0.1\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"deepspeed-zhuxiang-1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":false,\"logPath\":\"\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":true,\"isCopyJob\":true,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
                "aijob.cce.baidubce.com/timeline": "[{\"conditionType\":\"Created\",\"time\":1721573623},{\"conditionType\":\"Scheduled\",\"time\":1721573624},{\"conditionType\":\"Running\",\"time\":1721573641},{\"conditionType\":\"Succeeded\",\"time\":1721574002}]",
                "scheduling.k8s.io/job-enable-oversell": "false"
              },
              "creationTimestamp": "2024-07-21T14:53:43Z",
              "generation": 2,
              "labels": {
                "aijob.cce.baidubce.com/ai-user-id": "b89c433a0e884615a4c878ca24e2686e",
                "aijob.cce.baidubce.com/ai-user-name": "zhuxiang05",
                "aijob.cce.baidubce.com/create-from-aihcp": "true",
                "aijob.cce.baidubce.com/openapi-jobid": "pytorch-f6085dc4-cc6e-4dc3-a524-881a8b4e172e"
              },
              "managedFields": [
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        ".": {},
                        "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                        "f:aijob.cce.baidubce.com/openapi-jobid": {},
                        "f:aijob.cce.baidubce.com/pfs-id": {},
                        "f:aijob.cce.baidubce.com/raw-request": {},
                        "f:scheduling.k8s.io/job-enable-oversell": {}
                      },
                      "f:labels": {
                        ".": {},
                        "f:aijob.cce.baidubce.com/ai-user-id": {},
                        "f:aijob.cce.baidubce.com/ai-user-name": {},
                        "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                        "f:aijob.cce.baidubce.com/openapi-jobid": {}
                      }
                    },
                    "f:spec": {
                      ".": {},
                      "f:pytorchReplicaSpecs": {
                        ".": {},
                        "f:Master": {
                          ".": {},
                          "f:replicas": {},
                          "f:restartPolicy": {},
                          "f:template": {
                            ".": {},
                            "f:metadata": {
                              ".": {},
                              "f:annotations": {
                                ".": {},
                                "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                                "f:aijob.cce.baidubce.com/openapi-jobid": {},
                                "f:aijob.cce.baidubce.com/pfs-id": {},
                                "f:aijob.cce.baidubce.com/raw-request": {},
                                "f:scheduling.k8s.io/job-enable-oversell": {}
                              },
                              "f:labels": {
                                ".": {},
                                "f:aijob.cce.baidubce.com/ai-user-id": {},
                                "f:aijob.cce.baidubce.com/ai-user-name": {},
                                "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                                "f:aijob.cce.baidubce.com/openapi-jobid": {}
                              }
                            },
                            "f:spec": {
                              ".": {},
                              "f:dnsPolicy": {},
                              "f:hostNetwork": {},
                              "f:schedulerName": {},
                              "f:volumes": {}
                            }
                          }
                        },
                        "f:Worker": {
                          ".": {},
                          "f:replicas": {},
                          "f:restartPolicy": {},
                          "f:template": {
                            ".": {},
                            "f:metadata": {
                              ".": {},
                              "f:annotations": {
                                ".": {},
                                "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                                "f:aijob.cce.baidubce.com/openapi-jobid": {},
                                "f:aijob.cce.baidubce.com/pfs-id": {},
                                "f:aijob.cce.baidubce.com/raw-request": {},
                                "f:scheduling.k8s.io/job-enable-oversell": {}
                              },
                              "f:labels": {
                                ".": {},
                                "f:aijob.cce.baidubce.com/ai-user-id": {},
                                "f:aijob.cce.baidubce.com/ai-user-name": {},
                                "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                                "f:aijob.cce.baidubce.com/openapi-jobid": {}
                              }
                            },
                            "f:spec": {
                              ".": {},
                              "f:dnsPolicy": {},
                              "f:hostNetwork": {},
                              "f:schedulerName": {},
                              "f:volumes": {}
                            }
                          }
                        }
                      },
                      "f:runPolicy": {
                        ".": {},
                        "f:schedulingPolicy": {
                          ".": {},
                          "f:priorityClass": {},
                          "f:queue": {}
                        }
                      }
                    }
                  },
                  "manager": "cce-ai-service",
                  "operation": "Update",
                  "time": "2024-07-21T14:53:43Z"
                },
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        "f:aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": {},
                        "f:aijob.cce.baidubce.com/timeline": {}
                      }
                    },
                    "f:spec": {
                      "f:pytorchReplicaSpecs": {
                        "f:Master": {
                          "f:template": {
                            "f:spec": {
                              "f:containers": {}
                            }
                          }
                        },
                        "f:Worker": {
                          "f:template": {
                            "f:spec": {
                              "f:containers": {}
                            }
                          }
                        }
                      },
                      "f:runPolicy": {
                        "f:cleanPodPolicy": {}
                      }
                    }
                  },
                  "manager": "controller",
                  "operation": "Update",
                  "time": "2024-07-21T14:53:43Z"
                },
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        "f:aijob.cce.baidubce.com/barrier-finish": {}
                      }
                    }
                  },
                  "manager": "jobbarrier",
                  "operation": "Update",
                  "time": "2024-07-21T14:53:57Z"
                },
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:status": {
                      ".": {},
                      "f:completionTime": {},
                      "f:conditions": {},
                      "f:lastReconcileTime": {},
                      "f:replicaStatuses": {
                        ".": {},
                        "f:Master": {
                          ".": {},
                          "f:selector": {},
                          "f:succeeded": {}
                        },
                        "f:Worker": {
                          ".": {},
                          "f:succeeded": {}
                        }
                      },
                      "f:startTime": {}
                    }
                  },
                  "manager": "manager",
                  "operation": "Update",
                  "time": "2024-07-21T15:00:02Z"
                }
              ],
              "name": "deepspeed-zhuxiang-1",
              "namespace": "default",
              "resourceVersion": "2375255404",
              "uid": "2e3133fc-7f1a-4457-bd90-4b791fc806f8"
            },
            "spec": {
              "pytorchReplicaSpecs": {
                "Master": {
                  "replicas": 1,
                  "restartPolicy": "Never",
                  "template": {
                    "metadata": {
                      "annotations": {
                        "aijob.cce.baidubce.com/fault-tolerance-enabled": "false",
                        "aijob.cce.baidubce.com/openapi-jobid": "pytorch-f6085dc4-cc6e-4dc3-a524-881a8b4e172e",
                        "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
                        "aijob.cce.baidubce.com/raw-request": "{\"name\":\"deepspeed-zhuxiang-1\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"normal\",\"oversell\":false,\"faultTolerance\":false,\"command\":\" source /root/anaconda3/etc/profile.d/conda.sh\\n    conda activate llama-factory\\n\\n    ROOT_DIR=/workspace/LLaMA-Factory/\\n\\n    CHECKPOINT_LOAD_PATH=/mnt/cluster/ppl/Qwen-14B-Chat\\n    CHECKPOINT_SAVE_PATH=/mnt/cluster/ppl/Qwen-14B-Chat_saved_zhuxiang\\n    DEEPSPEED_CONFIG=$ROOT_DIR/examples/deepspeed/ds_z3_offload_config.json\\n\\n    GPUS_PER_NODE=8\\n\\n    is_master=${MASTER-\\\"0\\\"}\\n    if [[ $is_master -eq 1 ]];then\\n      DISTRIBUTED_ARGS=\\\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $HOSTNAME --master_port $MASTER_PORT\\\"\\n    else\\n      DISTRIBUTED_ARGS=\\\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $MASTER_ADDR --master_port $MASTER_PORT\\\"\\n    fi\\n\\n    QWEN_14B_ARGS=\\\"--model_name_or_path $CHECKPOINT_LOAD_PATH \\\\\\n        --stage sft \\\\\\n        --do_train \\\\\\n        --dataset alpaca_en_demo \\\\\\n        --template qwen \\\\\\n        --finetuning_type lora \\\\\\n        --lora_target all \\\\\\n        --overwrite_output_dir \\\\\\n        --dataset_dir $ROOT_DIR/data \\\\\\n        --output_dir $CHECKPOINT_SAVE_PATH \\\\\\n        --preprocessing_num_workers 90 \\\\\\n        --dataloader_num_workers 90 \\\\\\n        --per_device_train_batch_size 1 \\\\\\n        --gradient_accumulation_steps 8 \\\\\\n        --cutoff_len 2048 \\\\\\n        --max_length 2048 \\\\\\n        --deepspeed $DEEPSPEED_CONFIG \\\\\\n        --logging_first_step \\\\\\n        --logging_steps 10 \\\\\\n        --save_strategy steps \\\\\\n        --save_steps 40 \\\\\\n        --num_train_epochs 2.0 \\\\\\n        --lr_scheduler_type cosine \\\\\\n        --learning_rate 1e-5 \\\\\\n        --plot_loss \\\\\\n        --bf16 \\\\\\n        --rope_scaling linear \\\\\\n        --flash_attn auto \\\\\\n        --shift_attn \\\\\\n        --ddp_find_unused_parameters False \\\\\\n        --push_to_hub False\\\"\\n\\n    PYTHONPATH=$ROOT_DIR:$PYTHONPATH \\\\\\n        torchrun $DISTRIBUTED_ARGS \\\\\\n        $ROOT_DIR/src/train.py \\\\\\n        $QWEN_14B_ARGS\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":true,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/cce-ai-native/aiak-algo\",\"tag\":\"0.1\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"deepspeed-zhuxiang-1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"},\"Worker\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/cce-ai-native/aiak-algo\",\"tag\":\"0.1\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"deepspeed-zhuxiang-1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":false,\"logPath\":\"\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":true,\"isCopyJob\":true,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
                        "scheduling.k8s.io/job-enable-oversell": "false"
                      },
                      "labels": {
                        "aijob.cce.baidubce.com/ai-user-id": "b89c433a0e884615a4c878ca24e2686e",
                        "aijob.cce.baidubce.com/ai-user-name": "zhuxiang05",
                        "aijob.cce.baidubce.com/create-from-aihcp": "true",
                        "aijob.cce.baidubce.com/openapi-jobid": "pytorch-f6085dc4-cc6e-4dc3-a524-881a8b4e172e"
                      }
                    },
                    "spec": {
                      "containers": [
                        {
                          "command": [
                            "/bin/bash",
                            "-c",
                            " source /root/anaconda3/etc/profile.d/conda.sh\n    conda activate llama-factory\n\n    ROOT_DIR=/workspace/LLaMA-Factory/\n\n    CHECKPOINT_LOAD_PATH=/mnt/cluster/ppl/Qwen-14B-Chat\n    CHECKPOINT_SAVE_PATH=/mnt/cluster/ppl/Qwen-14B-Chat_saved_zhuxiang\n    DEEPSPEED_CONFIG=$ROOT_DIR/examples/deepspeed/ds_z3_offload_config.json\n\n    GPUS_PER_NODE=8\n\n    is_master=${MASTER-\"0\"}\n    if [[ $is_master -eq 1 ]];then\n      DISTRIBUTED_ARGS=\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $HOSTNAME --master_port $MASTER_PORT\"\n    else\n      DISTRIBUTED_ARGS=\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $MASTER_ADDR --master_port $MASTER_PORT\"\n    fi\n\n    QWEN_14B_ARGS=\"--model_name_or_path $CHECKPOINT_LOAD_PATH \\\n        --stage sft \\\n        --do_train \\\n        --dataset alpaca_en_demo \\\n        --template qwen \\\n        --finetuning_type lora \\\n        --lora_target all \\\n        --overwrite_output_dir \\\n        --dataset_dir $ROOT_DIR/data \\\n        --output_dir $CHECKPOINT_SAVE_PATH \\\n        --preprocessing_num_workers 90 \\\n        --dataloader_num_workers 90 \\\n        --per_device_train_batch_size 1 \\\n        --gradient_accumulation_steps 8 \\\n        --cutoff_len 2048 \\\n        --max_length 2048 \\\n        --deepspeed $DEEPSPEED_CONFIG \\\n        --logging_first_step \\\n        --logging_steps 10 \\\n        --save_strategy steps \\\n        --save_steps 40 \\\n        --num_train_epochs 2.0 \\\n        --lr_scheduler_type cosine \\\n        --learning_rate 1e-5 \\\n        --plot_loss \\\n        --bf16 \\\n        --rope_scaling linear \\\n        --flash_attn auto \\\n        --shift_attn \\\n        --ddp_find_unused_parameters False \\\n        --push_to_hub False\"\n\n    PYTHONPATH=$ROOT_DIR:$PYTHONPATH \\\n        torchrun $DISTRIBUTED_ARGS \\\n        $ROOT_DIR/src/train.py \\\n        $QWEN_14B_ARGS"
                          ],
                          "env": [
                            {
                              "name": "AIHC_JOB_NAME",
                              "value": "deepspeed-zhuxiang-1"
                            },
                            {
                              "name": "NCCL_IB_DISABLE",
                              "value": "0"
                            }
                          ],
                          "image": "registry.baidubce.com/cce-ai-native/aiak-algo:0.1",
                          "imagePullPolicy": "Always",
                          "name": "pytorch",
                          "ports": [
                            {
                              "containerPort": 23456,
                              "name": "pytorchjob-port",
                              "protocol": "TCP"
                            }
                          ],
                          "resources": {
                            "limits": {
                              "baidu.com/a800_80g_cgpu": "8",
                              "rdma/hca": "1"
                            },
                            "requests": {
                              "baidu.com/a800_80g_cgpu": "8",
                              "rdma/hca": "1"
                            }
                          },
                          "securityContext": {
                            "capabilities": {
                              "add": [
                                "IPC_LOCK"
                              ]
                            }
                          },
                          "volumeMounts": [
                            {
                              "mountPath": "/dev/shm",
                              "name": "devshm"
                            },
                            {
                              "mountPath": "/mnt/cluster",
                              "name": "pvc-pfs"
                            }
                          ]
                        }
                      ],
                      "dnsPolicy": "ClusterFirstWithHostNet",
                      "hostNetwork": true,
                      "schedulerName": "volcano",
                      "volumes": [
                        {
                          "emptyDir": {
                            "medium": "Memory",
                            "sizeLimit": "10Gi"
                          },
                          "name": "devshm"
                        },
                        {
                          "name": "pvc-pfs",
                          "persistentVolumeClaim": {
                            "claimName": "pvc-pfs"
                          }
                        }
                      ]
                    }
                  }
                },
                "Worker": {
                  "replicas": 1,
                  "restartPolicy": "Never",
                  "template": {
                    "metadata": {
                      "annotations": {
                        "aijob.cce.baidubce.com/fault-tolerance-enabled": "false",
                        "aijob.cce.baidubce.com/openapi-jobid": "pytorch-f6085dc4-cc6e-4dc3-a524-881a8b4e172e",
                        "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
                        "aijob.cce.baidubce.com/raw-request": "{\"name\":\"deepspeed-zhuxiang-1\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"normal\",\"oversell\":false,\"faultTolerance\":false,\"command\":\" source /root/anaconda3/etc/profile.d/conda.sh\\n    conda activate llama-factory\\n\\n    ROOT_DIR=/workspace/LLaMA-Factory/\\n\\n    CHECKPOINT_LOAD_PATH=/mnt/cluster/ppl/Qwen-14B-Chat\\n    CHECKPOINT_SAVE_PATH=/mnt/cluster/ppl/Qwen-14B-Chat_saved_zhuxiang\\n    DEEPSPEED_CONFIG=$ROOT_DIR/examples/deepspeed/ds_z3_offload_config.json\\n\\n    GPUS_PER_NODE=8\\n\\n    is_master=${MASTER-\\\"0\\\"}\\n    if [[ $is_master -eq 1 ]];then\\n      DISTRIBUTED_ARGS=\\\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $HOSTNAME --master_port $MASTER_PORT\\\"\\n    else\\n      DISTRIBUTED_ARGS=\\\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $MASTER_ADDR --master_port $MASTER_PORT\\\"\\n    fi\\n\\n    QWEN_14B_ARGS=\\\"--model_name_or_path $CHECKPOINT_LOAD_PATH \\\\\\n        --stage sft \\\\\\n        --do_train \\\\\\n        --dataset alpaca_en_demo \\\\\\n        --template qwen \\\\\\n        --finetuning_type lora \\\\\\n        --lora_target all \\\\\\n        --overwrite_output_dir \\\\\\n        --dataset_dir $ROOT_DIR/data \\\\\\n        --output_dir $CHECKPOINT_SAVE_PATH \\\\\\n        --preprocessing_num_workers 90 \\\\\\n        --dataloader_num_workers 90 \\\\\\n        --per_device_train_batch_size 1 \\\\\\n        --gradient_accumulation_steps 8 \\\\\\n        --cutoff_len 2048 \\\\\\n        --max_length 2048 \\\\\\n        --deepspeed $DEEPSPEED_CONFIG \\\\\\n        --logging_first_step \\\\\\n        --logging_steps 10 \\\\\\n        --save_strategy steps \\\\\\n        --save_steps 40 \\\\\\n        --num_train_epochs 2.0 \\\\\\n        --lr_scheduler_type cosine \\\\\\n        --learning_rate 1e-5 \\\\\\n        --plot_loss \\\\\\n        --bf16 \\\\\\n        --rope_scaling linear \\\\\\n        --flash_attn auto \\\\\\n        --shift_attn \\\\\\n        --ddp_find_unused_parameters False \\\\\\n        --push_to_hub False\\\"\\n\\n    PYTHONPATH=$ROOT_DIR:$PYTHONPATH \\\\\\n        torchrun $DISTRIBUTED_ARGS \\\\\\n        $ROOT_DIR/src/train.py \\\\\\n        $QWEN_14B_ARGS\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":true,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/cce-ai-native/aiak-algo\",\"tag\":\"0.1\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"deepspeed-zhuxiang-1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"},\"Worker\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/cce-ai-native/aiak-algo\",\"tag\":\"0.1\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"deepspeed-zhuxiang-1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":false,\"logPath\":\"\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":true,\"isCopyJob\":true,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
                        "scheduling.k8s.io/job-enable-oversell": "false"
                      },
                      "labels": {
                        "aijob.cce.baidubce.com/ai-user-id": "b89c433a0e884615a4c878ca24e2686e",
                        "aijob.cce.baidubce.com/ai-user-name": "zhuxiang05",
                        "aijob.cce.baidubce.com/create-from-aihcp": "true",
                        "aijob.cce.baidubce.com/openapi-jobid": "pytorch-f6085dc4-cc6e-4dc3-a524-881a8b4e172e"
                      }
                    },
                    "spec": {
                      "containers": [
                        {
                          "command": [
                            "/bin/bash",
                            "-c",
                            " source /root/anaconda3/etc/profile.d/conda.sh\n    conda activate llama-factory\n\n    ROOT_DIR=/workspace/LLaMA-Factory/\n\n    CHECKPOINT_LOAD_PATH=/mnt/cluster/ppl/Qwen-14B-Chat\n    CHECKPOINT_SAVE_PATH=/mnt/cluster/ppl/Qwen-14B-Chat_saved_zhuxiang\n    DEEPSPEED_CONFIG=$ROOT_DIR/examples/deepspeed/ds_z3_offload_config.json\n\n    GPUS_PER_NODE=8\n\n    is_master=${MASTER-\"0\"}\n    if [[ $is_master -eq 1 ]];then\n      DISTRIBUTED_ARGS=\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $HOSTNAME --master_port $MASTER_PORT\"\n    else\n      DISTRIBUTED_ARGS=\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $MASTER_ADDR --master_port $MASTER_PORT\"\n    fi\n\n    QWEN_14B_ARGS=\"--model_name_or_path $CHECKPOINT_LOAD_PATH \\\n        --stage sft \\\n        --do_train \\\n        --dataset alpaca_en_demo \\\n        --template qwen \\\n        --finetuning_type lora \\\n        --lora_target all \\\n        --overwrite_output_dir \\\n        --dataset_dir $ROOT_DIR/data \\\n        --output_dir $CHECKPOINT_SAVE_PATH \\\n        --preprocessing_num_workers 90 \\\n        --dataloader_num_workers 90 \\\n        --per_device_train_batch_size 1 \\\n        --gradient_accumulation_steps 8 \\\n        --cutoff_len 2048 \\\n        --max_length 2048 \\\n        --deepspeed $DEEPSPEED_CONFIG \\\n        --logging_first_step \\\n        --logging_steps 10 \\\n        --save_strategy steps \\\n        --save_steps 40 \\\n        --num_train_epochs 2.0 \\\n        --lr_scheduler_type cosine \\\n        --learning_rate 1e-5 \\\n        --plot_loss \\\n        --bf16 \\\n        --rope_scaling linear \\\n        --flash_attn auto \\\n        --shift_attn \\\n        --ddp_find_unused_parameters False \\\n        --push_to_hub False\"\n\n    PYTHONPATH=$ROOT_DIR:$PYTHONPATH \\\n        torchrun $DISTRIBUTED_ARGS \\\n        $ROOT_DIR/src/train.py \\\n        $QWEN_14B_ARGS"
                          ],
                          "env": [
                            {
                              "name": "AIHC_JOB_NAME",
                              "value": "deepspeed-zhuxiang-1"
                            },
                            {
                              "name": "NCCL_IB_DISABLE",
                              "value": "0"
                            }
                          ],
                          "image": "registry.baidubce.com/cce-ai-native/aiak-algo:0.1",
                          "imagePullPolicy": "Always",
                          "name": "pytorch",
                          "ports": [
                            {
                              "containerPort": 23456,
                              "name": "pytorchjob-port",
                              "protocol": "TCP"
                            }
                          ],
                          "resources": {
                            "limits": {
                              "baidu.com/a800_80g_cgpu": "8",
                              "rdma/hca": "1"
                            },
                            "requests": {
                              "baidu.com/a800_80g_cgpu": "8",
                              "rdma/hca": "1"
                            }
                          },
                          "securityContext": {
                            "capabilities": {
                              "add": [
                                "IPC_LOCK"
                              ]
                            }
                          },
                          "volumeMounts": [
                            {
                              "mountPath": "/dev/shm",
                              "name": "devshm"
                            },
                            {
                              "mountPath": "/mnt/cluster",
                              "name": "pvc-pfs"
                            }
                          ]
                        }
                      ],
                      "dnsPolicy": "ClusterFirstWithHostNet",
                      "hostNetwork": true,
                      "schedulerName": "volcano",
                      "volumes": [
                        {
                          "emptyDir": {
                            "medium": "Memory",
                            "sizeLimit": "10Gi"
                          },
                          "name": "devshm"
                        },
                        {
                          "name": "pvc-pfs",
                          "persistentVolumeClaim": {
                            "claimName": "pvc-pfs"
                          }
                        }
                      ]
                    }
                  }
                }
              },
              "runPolicy": {
                "cleanPodPolicy": "None",
                "schedulingPolicy": {
                  "priorityClass": "normal",
                  "queue": "default"
                }
              }
            },
            "status": {
              "completionTime": "2024-07-21T15:00:02Z",
              "conditions": [
                {
                  "lastTransitionTime": "2024-07-21T14:53:43Z",
                  "lastUpdateTime": "2024-07-21T14:53:43Z",
                  "message": "PyTorchJob deepspeed-zhuxiang-1 is created.",
                  "reason": "PyTorchJobCreated",
                  "status": "True",
                  "type": "Created"
                },
                {
                  "lastTransitionTime": "2024-07-21T14:54:01Z",
                  "lastUpdateTime": "2024-07-21T14:54:01Z",
                  "message": "PyTorchJob deepspeed-zhuxiang-1 is running.",
                  "reason": "JobRunning",
                  "status": "False",
                  "type": "Running"
                },
                {
                  "lastTransitionTime": "2024-07-21T15:00:02Z",
                  "lastUpdateTime": "2024-07-21T15:00:02Z",
                  "message": "PyTorchJob deepspeed-zhuxiang-1 is successfully completed.",
                  "reason": "JobSucceeded",
                  "status": "True",
                  "type": "Succeeded"
                }
              ],
              "lastReconcileTime": "2024-07-21T14:53:43Z",
              "replicaStatuses": {
                "Master": {
                  "selector": "training.kubeflow.org/job-name=deepspeed-zhuxiang-1,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=master",
                  "succeeded": 1
                },
                "Worker": {
                  "succeeded": 1
                }
              },
              "startTime": "2024-07-21T14:53:43Z"
            }
          },
          {
            "apiVersion": "kubeflow.org/v1",
            "kind": "PyTorchJob",
            "metadata": {
              "annotations": {
                "aijob.cce.baidubce.com/barrier-finish": "61dd5907-b076-4163-9f14-b5076bd48803",
                "aijob.cce.baidubce.com/fault-tolerance-enabled": "true",
                "aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": "",
                "aijob.cce.baidubce.com/internal-fault-tolerance-time": "2024-07-21T15:08:09.245321773Z",
                "aijob.cce.baidubce.com/openapi-jobid": "pytorch-17fe505f-168e-4c2e-951d-20c1f8792a1f",
                "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
                "aijob.cce.baidubce.com/raw-request": "{\"name\":\"deepspeed-zhuxiang-2\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"normal\",\"oversell\":false,\"faultTolerance\":true,\"command\":\" source /root/anaconda3/etc/profile.d/conda.sh\\n    conda activate llama-factory\\n\\n    ROOT_DIR=/workspace/LLaMA-Factory/\\n\\n    CHECKPOINT_LOAD_PATH=/mnt/cluster/ppl/Qwen-14B-Chat\\n    CHECKPOINT_SAVE_PATH=/mnt/cluster/ppl/Qwen-14B-Chat_saved_zhuxiang_1\\n    DEEPSPEED_CONFIG=$ROOT_DIR/examples/deepspeed/ds_z3_offload_config.json\\n\\n    GPUS_PER_NODE=8\\n\\n    is_master=${MASTER-\\\"0\\\"}\\n    if [[ $is_master -eq 1 ]];then\\n      DISTRIBUTED_ARGS=\\\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $HOSTNAME --master_port $MASTER_PORT\\\"\\n    else\\n      DISTRIBUTED_ARGS=\\\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $MASTER_ADDR --master_port $MASTER_PORT\\\"\\n    fi\\n\\n    QWEN_14B_ARGS=\\\"--model_name_or_path $CHECKPOINT_LOAD_PATH \\\\\\n        --stage sft \\\\\\n        --do_train \\\\\\n        --dataset alpaca_en_demo \\\\\\n        --template qwen \\\\\\n        --finetuning_type sft \\\\\\n        --overwrite_output_dir \\\\\\n        --dataset_dir $ROOT_DIR/data \\\\\\n        --output_dir $CHECKPOINT_SAVE_PATH \\\\\\n        --preprocessing_num_workers 90 \\\\\\n        --dataloader_num_workers 90 \\\\\\n        --per_device_train_batch_size 1 \\\\\\n        --gradient_accumulation_steps 8 \\\\\\n        --cutoff_len 2048 \\\\\\n        --max_length 2048 \\\\\\n        --deepspeed $DEEPSPEED_CONFIG \\\\\\n        --logging_first_step \\\\\\n        --logging_steps 10 \\\\\\n        --save_strategy steps \\\\\\n        --save_steps 40 \\\\\\n        --num_train_epochs 2.0 \\\\\\n        --lr_scheduler_type cosine \\\\\\n        --learning_rate 1e-5 \\\\\\n        --plot_loss \\\\\\n        --bf16 \\\\\\n        --rope_scaling linear \\\\\\n        --flash_attn auto \\\\\\n        --shift_attn \\\\\\n        --ddp_find_unused_parameters False \\\\\\n        --push_to_hub False\\\"\\n\\n    PYTHONPATH=$ROOT_DIR:$PYTHONPATH \\\\\\n        torchrun $DISTRIBUTED_ARGS \\\\\\n        $ROOT_DIR/src/train.py \\\\\\n        $QWEN_14B_ARGS\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":true,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/cce-ai-native/aiak-algo\",\"tag\":\"0.1\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"deepspeed-zhuxiang-2\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"},\"Worker\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/cce-ai-native/aiak-algo\",\"tag\":\"0.1\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"deepspeed-zhuxiang-2\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":false,\"logPath\":\"\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":true,\"isCopyJob\":true,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
                "aijob.cce.baidubce.com/timeline": "[{\"conditionType\":\"Created\",\"time\":1721574440},{\"conditionType\":\"Scheduled\",\"time\":1721574442},{\"conditionType\":\"Running\",\"time\":1721574458},{\"conditionType\":\"Abnormal\",\"time\":1721574489},{\"conditionType\":\"Failed\",\"time\":1721575092}]",
                "scheduling.k8s.io/job-enable-oversell": "false"
              },
              "creationTimestamp": "2024-07-21T15:07:20Z",
              "generation": 3,
              "labels": {
                "aijob.cce.baidubce.com/ai-user-id": "b89c433a0e884615a4c878ca24e2686e",
                "aijob.cce.baidubce.com/ai-user-name": "zhuxiang05",
                "aijob.cce.baidubce.com/create-from-aihcp": "true",
                "aijob.cce.baidubce.com/openapi-jobid": "pytorch-17fe505f-168e-4c2e-951d-20c1f8792a1f"
              },
              "managedFields": [
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        ".": {},
                        "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                        "f:aijob.cce.baidubce.com/openapi-jobid": {},
                        "f:aijob.cce.baidubce.com/pfs-id": {},
                        "f:aijob.cce.baidubce.com/raw-request": {},
                        "f:scheduling.k8s.io/job-enable-oversell": {}
                      },
                      "f:labels": {
                        ".": {},
                        "f:aijob.cce.baidubce.com/ai-user-id": {},
                        "f:aijob.cce.baidubce.com/ai-user-name": {},
                        "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                        "f:aijob.cce.baidubce.com/openapi-jobid": {}
                      }
                    },
                    "f:spec": {
                      ".": {},
                      "f:pytorchReplicaSpecs": {
                        ".": {},
                        "f:Master": {
                          ".": {},
                          "f:replicas": {},
                          "f:restartPolicy": {},
                          "f:template": {
                            ".": {},
                            "f:metadata": {
                              ".": {},
                              "f:annotations": {
                                ".": {},
                                "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                                "f:aijob.cce.baidubce.com/openapi-jobid": {},
                                "f:aijob.cce.baidubce.com/pfs-id": {},
                                "f:aijob.cce.baidubce.com/raw-request": {},
                                "f:scheduling.k8s.io/job-enable-oversell": {}
                              },
                              "f:labels": {
                                ".": {},
                                "f:aijob.cce.baidubce.com/ai-user-id": {},
                                "f:aijob.cce.baidubce.com/ai-user-name": {},
                                "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                                "f:aijob.cce.baidubce.com/openapi-jobid": {}
                              }
                            },
                            "f:spec": {
                              ".": {},
                              "f:dnsPolicy": {},
                              "f:hostNetwork": {},
                              "f:schedulerName": {}
                            }
                          }
                        },
                        "f:Worker": {
                          ".": {},
                          "f:replicas": {},
                          "f:restartPolicy": {},
                          "f:template": {
                            ".": {},
                            "f:metadata": {
                              ".": {},
                              "f:annotations": {
                                ".": {},
                                "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                                "f:aijob.cce.baidubce.com/openapi-jobid": {},
                                "f:aijob.cce.baidubce.com/pfs-id": {},
                                "f:aijob.cce.baidubce.com/raw-request": {},
                                "f:scheduling.k8s.io/job-enable-oversell": {}
                              },
                              "f:labels": {
                                ".": {},
                                "f:aijob.cce.baidubce.com/ai-user-id": {},
                                "f:aijob.cce.baidubce.com/ai-user-name": {},
                                "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                                "f:aijob.cce.baidubce.com/openapi-jobid": {}
                              }
                            },
                            "f:spec": {
                              ".": {},
                              "f:dnsPolicy": {},
                              "f:hostNetwork": {},
                              "f:schedulerName": {}
                            }
                          }
                        }
                      },
                      "f:runPolicy": {
                        ".": {},
                        "f:schedulingPolicy": {
                          ".": {},
                          "f:priorityClass": {},
                          "f:queue": {}
                        }
                      }
                    }
                  },
                  "manager": "cce-ai-service",
                  "operation": "Update",
                  "time": "2024-07-21T15:07:20Z"
                },
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        "f:aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": {},
                        "f:aijob.cce.baidubce.com/timeline": {}
                      }
                    },
                    "f:spec": {
                      "f:runPolicy": {
                        "f:cleanPodPolicy": {}
                      }
                    }
                  },
                  "manager": "controller",
                  "operation": "Update",
                  "time": "2024-07-21T15:07:20Z"
                },
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        "f:aijob.cce.baidubce.com/barrier-finish": {}
                      }
                    }
                  },
                  "manager": "jobbarrier",
                  "operation": "Update",
                  "time": "2024-07-21T15:07:35Z"
                },
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        "f:aijob.cce.baidubce.com/internal-fault-tolerance-time": {}
                      }
                    },
                    "f:spec": {
                      "f:pytorchReplicaSpecs": {
                        "f:Master": {
                          "f:template": {
                            "f:metadata": {
                              "f:annotations": {
                                "f:prometheus.io/path": {},
                                "f:prometheus.io/port": {},
                                "f:prometheus.io/scrape": {}
                              }
                            },
                            "f:spec": {
                              "f:containers": {},
                              "f:serviceAccountName": {},
                              "f:shareProcessNamespace": {},
                              "f:volumes": {}
                            }
                          }
                        },
                        "f:Worker": {
                          "f:template": {
                            "f:metadata": {
                              "f:annotations": {
                                "f:prometheus.io/path": {},
                                "f:prometheus.io/port": {},
                                "f:prometheus.io/scrape": {}
                              }
                            },
                            "f:spec": {
                              "f:containers": {},
                              "f:serviceAccountName": {},
                              "f:shareProcessNamespace": {},
                              "f:volumes": {}
                            }
                          }
                        }
                      }
                    },
                    "f:status": {
                      ".": {},
                      "f:completionTime": {},
                      "f:conditions": {},
                      "f:lastReconcileTime": {},
                      "f:replicaStatuses": {
                        ".": {},
                        "f:Master": {
                          ".": {},
                          "f:failed": {},
                          "f:selector": {}
                        },
                        "f:Worker": {
                          ".": {},
                          "f:failed": {}
                        }
                      },
                      "f:startTime": {}
                    }
                  },
                  "manager": "manager",
                  "operation": "Update",
                  "time": "2024-07-21T15:18:12Z"
                }
              ],
              "name": "deepspeed-zhuxiang-2",
              "namespace": "default",
              "resourceVersion": "2375269930",
              "uid": "cf938174-8fcc-4c7f-a7ef-8418b2d7f967"
            },
            "spec": {
              "pytorchReplicaSpecs": {
                "Master": {
                  "replicas": 1,
                  "restartPolicy": "Never",
                  "template": {
                    "metadata": {
                      "annotations": {
                        "aijob.cce.baidubce.com/fault-tolerance-enabled": "true",
                        "aijob.cce.baidubce.com/openapi-jobid": "pytorch-17fe505f-168e-4c2e-951d-20c1f8792a1f",
                        "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
                        "aijob.cce.baidubce.com/raw-request": "{\"name\":\"deepspeed-zhuxiang-2\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"normal\",\"oversell\":false,\"faultTolerance\":true,\"command\":\" source /root/anaconda3/etc/profile.d/conda.sh\\n    conda activate llama-factory\\n\\n    ROOT_DIR=/workspace/LLaMA-Factory/\\n\\n    CHECKPOINT_LOAD_PATH=/mnt/cluster/ppl/Qwen-14B-Chat\\n    CHECKPOINT_SAVE_PATH=/mnt/cluster/ppl/Qwen-14B-Chat_saved_zhuxiang_1\\n    DEEPSPEED_CONFIG=$ROOT_DIR/examples/deepspeed/ds_z3_offload_config.json\\n\\n    GPUS_PER_NODE=8\\n\\n    is_master=${MASTER-\\\"0\\\"}\\n    if [[ $is_master -eq 1 ]];then\\n      DISTRIBUTED_ARGS=\\\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $HOSTNAME --master_port $MASTER_PORT\\\"\\n    else\\n      DISTRIBUTED_ARGS=\\\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $MASTER_ADDR --master_port $MASTER_PORT\\\"\\n    fi\\n\\n    QWEN_14B_ARGS=\\\"--model_name_or_path $CHECKPOINT_LOAD_PATH \\\\\\n        --stage sft \\\\\\n        --do_train \\\\\\n        --dataset alpaca_en_demo \\\\\\n        --template qwen \\\\\\n        --finetuning_type sft \\\\\\n        --overwrite_output_dir \\\\\\n        --dataset_dir $ROOT_DIR/data \\\\\\n        --output_dir $CHECKPOINT_SAVE_PATH \\\\\\n        --preprocessing_num_workers 90 \\\\\\n        --dataloader_num_workers 90 \\\\\\n        --per_device_train_batch_size 1 \\\\\\n        --gradient_accumulation_steps 8 \\\\\\n        --cutoff_len 2048 \\\\\\n        --max_length 2048 \\\\\\n        --deepspeed $DEEPSPEED_CONFIG \\\\\\n        --logging_first_step \\\\\\n        --logging_steps 10 \\\\\\n        --save_strategy steps \\\\\\n        --save_steps 40 \\\\\\n        --num_train_epochs 2.0 \\\\\\n        --lr_scheduler_type cosine \\\\\\n        --learning_rate 1e-5 \\\\\\n        --plot_loss \\\\\\n        --bf16 \\\\\\n        --rope_scaling linear \\\\\\n        --flash_attn auto \\\\\\n        --shift_attn \\\\\\n        --ddp_find_unused_parameters False \\\\\\n        --push_to_hub False\\\"\\n\\n    PYTHONPATH=$ROOT_DIR:$PYTHONPATH \\\\\\n        torchrun $DISTRIBUTED_ARGS \\\\\\n        $ROOT_DIR/src/train.py \\\\\\n        $QWEN_14B_ARGS\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":true,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/cce-ai-native/aiak-algo\",\"tag\":\"0.1\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"deepspeed-zhuxiang-2\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"},\"Worker\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/cce-ai-native/aiak-algo\",\"tag\":\"0.1\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"deepspeed-zhuxiang-2\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":false,\"logPath\":\"\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":true,\"isCopyJob\":true,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
                        "prometheus.io/path": "/metrics",
                        "prometheus.io/port": "9101",
                        "prometheus.io/scrape": "true",
                        "scheduling.k8s.io/job-enable-oversell": "false"
                      },
                      "labels": {
                        "aijob.cce.baidubce.com/ai-user-id": "b89c433a0e884615a4c878ca24e2686e",
                        "aijob.cce.baidubce.com/ai-user-name": "zhuxiang05",
                        "aijob.cce.baidubce.com/create-from-aihcp": "true",
                        "aijob.cce.baidubce.com/openapi-jobid": "pytorch-17fe505f-168e-4c2e-951d-20c1f8792a1f"
                      }
                    },
                    "spec": {
                      "containers": [
                        {
                          "command": [
                            "/bin/bash",
                            "-c",
                            " source /root/anaconda3/etc/profile.d/conda.sh\n    conda activate llama-factory\n\n    ROOT_DIR=/workspace/LLaMA-Factory/\n\n    CHECKPOINT_LOAD_PATH=/mnt/cluster/ppl/Qwen-14B-Chat\n    CHECKPOINT_SAVE_PATH=/mnt/cluster/ppl/Qwen-14B-Chat_saved_zhuxiang_1\n    DEEPSPEED_CONFIG=$ROOT_DIR/examples/deepspeed/ds_z3_offload_config.json\n\n    GPUS_PER_NODE=8\n\n    is_master=${MASTER-\"0\"}\n    if [[ $is_master -eq 1 ]];then\n      DISTRIBUTED_ARGS=\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $HOSTNAME --master_port $MASTER_PORT\"\n    else\n      DISTRIBUTED_ARGS=\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $MASTER_ADDR --master_port $MASTER_PORT\"\n    fi\n\n    QWEN_14B_ARGS=\"--model_name_or_path $CHECKPOINT_LOAD_PATH \\\n        --stage sft \\\n        --do_train \\\n        --dataset alpaca_en_demo \\\n        --template qwen \\\n        --finetuning_type sft \\\n        --overwrite_output_dir \\\n        --dataset_dir $ROOT_DIR/data \\\n        --output_dir $CHECKPOINT_SAVE_PATH \\\n        --preprocessing_num_workers 90 \\\n        --dataloader_num_workers 90 \\\n        --per_device_train_batch_size 1 \\\n        --gradient_accumulation_steps 8 \\\n        --cutoff_len 2048 \\\n        --max_length 2048 \\\n        --deepspeed $DEEPSPEED_CONFIG \\\n        --logging_first_step \\\n        --logging_steps 10 \\\n        --save_strategy steps \\\n        --save_steps 40 \\\n        --num_train_epochs 2.0 \\\n        --lr_scheduler_type cosine \\\n        --learning_rate 1e-5 \\\n        --plot_loss \\\n        --bf16 \\\n        --rope_scaling linear \\\n        --flash_attn auto \\\n        --shift_attn \\\n        --ddp_find_unused_parameters False \\\n        --push_to_hub False\"\n\n    PYTHONPATH=$ROOT_DIR:$PYTHONPATH \\\n        torchrun $DISTRIBUTED_ARGS \\\n        $ROOT_DIR/src/train.py \\\n        $QWEN_14B_ARGS"
                          ],
                          "env": [
                            {
                              "name": "AIHC_JOB_NAME",
                              "value": "deepspeed-zhuxiang-2"
                            },
                            {
                              "name": "NCCL_IB_DISABLE",
                              "value": "0"
                            },
                            {
                              "name": "BCCL_BUS_BW_CALCULATE_MODE",
                              "value": "Agg"
                            },
                            {
                              "name": "BCCL_PROFILING_FILE",
                              "value": "/var/bccl/logs/busbw.cal.%h.%p"
                            }
                          ],
                          "image": "registry.baidubce.com/cce-ai-native/aiak-algo:0.1",
                          "imagePullPolicy": "Always",
                          "name": "pytorch",
                          "ports": [
                            {
                              "containerPort": 23456,
                              "name": "pytorchjob-port",
                              "protocol": "TCP"
                            }
                          ],
                          "resources": {
                            "limits": {
                              "baidu.com/a800_80g_cgpu": "8",
                              "rdma/hca": "1"
                            },
                            "requests": {
                              "baidu.com/a800_80g_cgpu": "8",
                              "rdma/hca": "1"
                            }
                          },
                          "securityContext": {
                            "capabilities": {
                              "add": [
                                "IPC_LOCK"
                              ]
                            }
                          },
                          "volumeMounts": [
                            {
                              "mountPath": "/dev/shm",
                              "name": "devshm"
                            },
                            {
                              "mountPath": "/mnt/cluster",
                              "name": "pvc-pfs"
                            },
                            {
                              "mountPath": "/var/bccl/logs",
                              "name": "bccl-logs-volume"
                            }
                          ]
                        },
                        {
                          "env": [
                            {
                              "name": "POD_NAME",
                              "valueFrom": {
                                "fieldRef": {
                                  "apiVersion": "v1",
                                  "fieldPath": "metadata.name"
                                }
                              }
                            },
                            {
                              "name": "POD_UID",
                              "valueFrom": {
                                "fieldRef": {
                                  "apiVersion": "v1",
                                  "fieldPath": "metadata.uid"
                                }
                              }
                            },
                            {
                              "name": "POD_NAMESPACE",
                              "valueFrom": {
                                "fieldRef": {
                                  "apiVersion": "v1",
                                  "fieldPath": "metadata.namespace"
                                }
                              }
                            },
                            {
                              "name": "NODE_NAME",
                              "valueFrom": {
                                "fieldRef": {
                                  "apiVersion": "v1",
                                  "fieldPath": "spec.nodeName"
                                }
                              }
                            },
                            {
                              "name": "JOB_NAME",
                              "value": "deepspeed-zhuxiang-2"
                            },
                            {
                              "name": "NODE_IP",
                              "valueFrom": {
                                "fieldRef": {
                                  "apiVersion": "v1",
                                  "fieldPath": "status.hostIP"
                                }
                              }
                            },
                            {
                              "name": "GPUS_PER_NODE",
                              "value": "8"
                            },
                            {
                              "name": "ENABLE_ELASTIC",
                              "value": "9"
                            },
                            {
                              "name": "BCCL_LOG_DIR",
                              "value": "/var/bccl/logs"
                            },
                            {
                              "name": "EXPORTER_PORT",
                              "value": "9101"
                            },
                            {
                              "name": "EXPORTER_INTERVAL",
                              "value": "60"
                            },
                            {
                              "name": "EXPORTER_PATH",
                              "value": "/metrics"
                            },
                            {
                              "name": "BCCL_BUS_BW_CALCULATE_MODE",
                              "value": "Agg"
                            },
                            {
                              "name": "BCCL_PROFILING_FILE",
                              "value": "/var/bccl/logs/busbw.cal.%h.%p"
                            }
                          ],
                          "image": "registry.baidubce.com/cce-plugin-dev/ftagent:v1.6.21",
                          "imagePullPolicy": "Always",
                          "name": "ftagent",
                          "ports": [
                            {
                              "containerPort": 9101,
                              "name": "exporter",
                              "protocol": "TCP"
                            }
                          ],
                          "resources": {},
                          "securityContext": {
                            "capabilities": {
                              "add": [
                                "IPC_LOCK"
                              ]
                            }
                          },
                          "volumeMounts": [
                            {
                              "mountPath": "/var/log/pods",
                              "name": "pod-log-volume"
                            },
                            {
                              "mountPath": "/home/cce",
                              "name": "container-log-volume"
                            },
                            {
                              "mountPath": "/var/bccl/logs",
                              "name": "bccl-logs-volume"
                            }
                          ]
                        }
                      ],
                      "dnsPolicy": "ClusterFirstWithHostNet",
                      "hostNetwork": true,
                      "schedulerName": "volcano",
                      "serviceAccountName": "ftagent-sa",
                      "shareProcessNamespace": true,
                      "volumes": [
                        {
                          "emptyDir": {
                            "medium": "Memory",
                            "sizeLimit": "10Gi"
                          },
                          "name": "devshm"
                        },
                        {
                          "name": "pvc-pfs",
                          "persistentVolumeClaim": {
                            "claimName": "pvc-pfs"
                          }
                        },
                        {
                          "emptyDir": {},
                          "name": "bccl-logs-volume"
                        },
                        {
                          "hostPath": {
                            "path": "/var/log/pods",
                            "type": "DirectoryOrCreate"
                          },
                          "name": "pod-log-volume"
                        },
                        {
                          "hostPath": {
                            "path": "/home/cce",
                            "type": "DirectoryOrCreate"
                          },
                          "name": "container-log-volume"
                        }
                      ]
                    }
                  }
                },
                "Worker": {
                  "replicas": 1,
                  "restartPolicy": "Never",
                  "template": {
                    "metadata": {
                      "annotations": {
                        "aijob.cce.baidubce.com/fault-tolerance-enabled": "true",
                        "aijob.cce.baidubce.com/openapi-jobid": "pytorch-17fe505f-168e-4c2e-951d-20c1f8792a1f",
                        "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
                        "aijob.cce.baidubce.com/raw-request": "{\"name\":\"deepspeed-zhuxiang-2\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"normal\",\"oversell\":false,\"faultTolerance\":true,\"command\":\" source /root/anaconda3/etc/profile.d/conda.sh\\n    conda activate llama-factory\\n\\n    ROOT_DIR=/workspace/LLaMA-Factory/\\n\\n    CHECKPOINT_LOAD_PATH=/mnt/cluster/ppl/Qwen-14B-Chat\\n    CHECKPOINT_SAVE_PATH=/mnt/cluster/ppl/Qwen-14B-Chat_saved_zhuxiang_1\\n    DEEPSPEED_CONFIG=$ROOT_DIR/examples/deepspeed/ds_z3_offload_config.json\\n\\n    GPUS_PER_NODE=8\\n\\n    is_master=${MASTER-\\\"0\\\"}\\n    if [[ $is_master -eq 1 ]];then\\n      DISTRIBUTED_ARGS=\\\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $HOSTNAME --master_port $MASTER_PORT\\\"\\n    else\\n      DISTRIBUTED_ARGS=\\\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $MASTER_ADDR --master_port $MASTER_PORT\\\"\\n    fi\\n\\n    QWEN_14B_ARGS=\\\"--model_name_or_path $CHECKPOINT_LOAD_PATH \\\\\\n        --stage sft \\\\\\n        --do_train \\\\\\n        --dataset alpaca_en_demo \\\\\\n        --template qwen \\\\\\n        --finetuning_type sft \\\\\\n        --overwrite_output_dir \\\\\\n        --dataset_dir $ROOT_DIR/data \\\\\\n        --output_dir $CHECKPOINT_SAVE_PATH \\\\\\n        --preprocessing_num_workers 90 \\\\\\n        --dataloader_num_workers 90 \\\\\\n        --per_device_train_batch_size 1 \\\\\\n        --gradient_accumulation_steps 8 \\\\\\n        --cutoff_len 2048 \\\\\\n        --max_length 2048 \\\\\\n        --deepspeed $DEEPSPEED_CONFIG \\\\\\n        --logging_first_step \\\\\\n        --logging_steps 10 \\\\\\n        --save_strategy steps \\\\\\n        --save_steps 40 \\\\\\n        --num_train_epochs 2.0 \\\\\\n        --lr_scheduler_type cosine \\\\\\n        --learning_rate 1e-5 \\\\\\n        --plot_loss \\\\\\n        --bf16 \\\\\\n        --rope_scaling linear \\\\\\n        --flash_attn auto \\\\\\n        --shift_attn \\\\\\n        --ddp_find_unused_parameters False \\\\\\n        --push_to_hub False\\\"\\n\\n    PYTHONPATH=$ROOT_DIR:$PYTHONPATH \\\\\\n        torchrun $DISTRIBUTED_ARGS \\\\\\n        $ROOT_DIR/src/train.py \\\\\\n        $QWEN_14B_ARGS\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":true,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/cce-ai-native/aiak-algo\",\"tag\":\"0.1\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"deepspeed-zhuxiang-2\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"},\"Worker\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/cce-ai-native/aiak-algo\",\"tag\":\"0.1\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"deepspeed-zhuxiang-2\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":false,\"logPath\":\"\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":true,\"isCopyJob\":true,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
                        "prometheus.io/path": "/metrics",
                        "prometheus.io/port": "9101",
                        "prometheus.io/scrape": "true",
                        "scheduling.k8s.io/job-enable-oversell": "false"
                      },
                      "labels": {
                        "aijob.cce.baidubce.com/ai-user-id": "b89c433a0e884615a4c878ca24e2686e",
                        "aijob.cce.baidubce.com/ai-user-name": "zhuxiang05",
                        "aijob.cce.baidubce.com/create-from-aihcp": "true",
                        "aijob.cce.baidubce.com/openapi-jobid": "pytorch-17fe505f-168e-4c2e-951d-20c1f8792a1f"
                      }
                    },
                    "spec": {
                      "containers": [
                        {
                          "command": [
                            "/bin/bash",
                            "-c",
                            " source /root/anaconda3/etc/profile.d/conda.sh\n    conda activate llama-factory\n\n    ROOT_DIR=/workspace/LLaMA-Factory/\n\n    CHECKPOINT_LOAD_PATH=/mnt/cluster/ppl/Qwen-14B-Chat\n    CHECKPOINT_SAVE_PATH=/mnt/cluster/ppl/Qwen-14B-Chat_saved_zhuxiang_1\n    DEEPSPEED_CONFIG=$ROOT_DIR/examples/deepspeed/ds_z3_offload_config.json\n\n    GPUS_PER_NODE=8\n\n    is_master=${MASTER-\"0\"}\n    if [[ $is_master -eq 1 ]];then\n      DISTRIBUTED_ARGS=\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $HOSTNAME --master_port $MASTER_PORT\"\n    else\n      DISTRIBUTED_ARGS=\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $MASTER_ADDR --master_port $MASTER_PORT\"\n    fi\n\n    QWEN_14B_ARGS=\"--model_name_or_path $CHECKPOINT_LOAD_PATH \\\n        --stage sft \\\n        --do_train \\\n        --dataset alpaca_en_demo \\\n        --template qwen \\\n        --finetuning_type sft \\\n        --overwrite_output_dir \\\n        --dataset_dir $ROOT_DIR/data \\\n        --output_dir $CHECKPOINT_SAVE_PATH \\\n        --preprocessing_num_workers 90 \\\n        --dataloader_num_workers 90 \\\n        --per_device_train_batch_size 1 \\\n        --gradient_accumulation_steps 8 \\\n        --cutoff_len 2048 \\\n        --max_length 2048 \\\n        --deepspeed $DEEPSPEED_CONFIG \\\n        --logging_first_step \\\n        --logging_steps 10 \\\n        --save_strategy steps \\\n        --save_steps 40 \\\n        --num_train_epochs 2.0 \\\n        --lr_scheduler_type cosine \\\n        --learning_rate 1e-5 \\\n        --plot_loss \\\n        --bf16 \\\n        --rope_scaling linear \\\n        --flash_attn auto \\\n        --shift_attn \\\n        --ddp_find_unused_parameters False \\\n        --push_to_hub False\"\n\n    PYTHONPATH=$ROOT_DIR:$PYTHONPATH \\\n        torchrun $DISTRIBUTED_ARGS \\\n        $ROOT_DIR/src/train.py \\\n        $QWEN_14B_ARGS"
                          ],
                          "env": [
                            {
                              "name": "AIHC_JOB_NAME",
                              "value": "deepspeed-zhuxiang-2"
                            },
                            {
                              "name": "NCCL_IB_DISABLE",
                              "value": "0"
                            },
                            {
                              "name": "BCCL_BUS_BW_CALCULATE_MODE",
                              "value": "Agg"
                            },
                            {
                              "name": "BCCL_PROFILING_FILE",
                              "value": "/var/bccl/logs/busbw.cal.%h.%p"
                            }
                          ],
                          "image": "registry.baidubce.com/cce-ai-native/aiak-algo:0.1",
                          "imagePullPolicy": "Always",
                          "name": "pytorch",
                          "ports": [
                            {
                              "containerPort": 23456,
                              "name": "pytorchjob-port",
                              "protocol": "TCP"
                            }
                          ],
                          "resources": {
                            "limits": {
                              "baidu.com/a800_80g_cgpu": "8",
                              "rdma/hca": "1"
                            },
                            "requests": {
                              "baidu.com/a800_80g_cgpu": "8",
                              "rdma/hca": "1"
                            }
                          },
                          "securityContext": {
                            "capabilities": {
                              "add": [
                                "IPC_LOCK"
                              ]
                            }
                          },
                          "volumeMounts": [
                            {
                              "mountPath": "/dev/shm",
                              "name": "devshm"
                            },
                            {
                              "mountPath": "/mnt/cluster",
                              "name": "pvc-pfs"
                            },
                            {
                              "mountPath": "/var/bccl/logs",
                              "name": "bccl-logs-volume"
                            }
                          ]
                        },
                        {
                          "env": [
                            {
                              "name": "POD_NAME",
                              "valueFrom": {
                                "fieldRef": {
                                  "apiVersion": "v1",
                                  "fieldPath": "metadata.name"
                                }
                              }
                            },
                            {
                              "name": "POD_UID",
                              "valueFrom": {
                                "fieldRef": {
                                  "apiVersion": "v1",
                                  "fieldPath": "metadata.uid"
                                }
                              }
                            },
                            {
                              "name": "POD_NAMESPACE",
                              "valueFrom": {
                                "fieldRef": {
                                  "apiVersion": "v1",
                                  "fieldPath": "metadata.namespace"
                                }
                              }
                            },
                            {
                              "name": "NODE_NAME",
                              "valueFrom": {
                                "fieldRef": {
                                  "apiVersion": "v1",
                                  "fieldPath": "spec.nodeName"
                                }
                              }
                            },
                            {
                              "name": "JOB_NAME",
                              "value": "deepspeed-zhuxiang-2"
                            },
                            {
                              "name": "NODE_IP",
                              "valueFrom": {
                                "fieldRef": {
                                  "apiVersion": "v1",
                                  "fieldPath": "status.hostIP"
                                }
                              }
                            },
                            {
                              "name": "GPUS_PER_NODE",
                              "value": "8"
                            },
                            {
                              "name": "ENABLE_ELASTIC",
                              "value": "9"
                            },
                            {
                              "name": "BCCL_LOG_DIR",
                              "value": "/var/bccl/logs"
                            },
                            {
                              "name": "EXPORTER_PORT",
                              "value": "9101"
                            },
                            {
                              "name": "EXPORTER_INTERVAL",
                              "value": "60"
                            },
                            {
                              "name": "EXPORTER_PATH",
                              "value": "/metrics"
                            },
                            {
                              "name": "BCCL_BUS_BW_CALCULATE_MODE",
                              "value": "Agg"
                            },
                            {
                              "name": "BCCL_PROFILING_FILE",
                              "value": "/var/bccl/logs/busbw.cal.%h.%p"
                            }
                          ],
                          "image": "registry.baidubce.com/cce-plugin-dev/ftagent:v1.6.21",
                          "imagePullPolicy": "Always",
                          "name": "ftagent",
                          "ports": [
                            {
                              "containerPort": 9101,
                              "name": "exporter",
                              "protocol": "TCP"
                            }
                          ],
                          "resources": {},
                          "securityContext": {
                            "capabilities": {
                              "add": [
                                "IPC_LOCK"
                              ]
                            }
                          },
                          "volumeMounts": [
                            {
                              "mountPath": "/var/log/pods",
                              "name": "pod-log-volume"
                            },
                            {
                              "mountPath": "/home/cce",
                              "name": "container-log-volume"
                            },
                            {
                              "mountPath": "/var/bccl/logs",
                              "name": "bccl-logs-volume"
                            }
                          ]
                        }
                      ],
                      "dnsPolicy": "ClusterFirstWithHostNet",
                      "hostNetwork": true,
                      "schedulerName": "volcano",
                      "serviceAccountName": "ftagent-sa",
                      "shareProcessNamespace": true,
                      "volumes": [
                        {
                          "emptyDir": {
                            "medium": "Memory",
                            "sizeLimit": "10Gi"
                          },
                          "name": "devshm"
                        },
                        {
                          "name": "pvc-pfs",
                          "persistentVolumeClaim": {
                            "claimName": "pvc-pfs"
                          }
                        },
                        {
                          "emptyDir": {},
                          "name": "bccl-logs-volume"
                        },
                        {
                          "hostPath": {
                            "path": "/var/log/pods",
                            "type": "DirectoryOrCreate"
                          },
                          "name": "pod-log-volume"
                        },
                        {
                          "hostPath": {
                            "path": "/home/cce",
                            "type": "DirectoryOrCreate"
                          },
                          "name": "container-log-volume"
                        }
                      ]
                    }
                  }
                }
              },
              "runPolicy": {
                "cleanPodPolicy": "None",
                "schedulingPolicy": {
                  "priorityClass": "normal",
                  "queue": "default"
                }
              }
            },
            "status": {
              "completionTime": "2024-07-21T15:18:12Z",
              "conditions": [
                {
                  "lastTransitionTime": "2024-07-21T15:07:20Z",
                  "lastUpdateTime": "2024-07-21T15:07:20Z",
                  "message": "PyTorchJob deepspeed-zhuxiang-2 is created.",
                  "reason": "PyTorchJobCreated",
                  "status": "True",
                  "type": "Created"
                },
                {
                  "lastTransitionTime": "2024-07-21T15:07:38Z",
                  "lastUpdateTime": "2024-07-21T15:07:38Z",
                  "message": "PyTorchJob deepspeed-zhuxiang-2 is running.",
                  "reason": "JobRunning",
                  "status": "False",
                  "type": "Running"
                },
                {
                  "lastTransitionTime": "2024-07-21T15:18:12Z",
                  "lastUpdateTime": "2024-07-21T15:18:12Z",
                  "message": "PyTorchJob deepspeed-zhuxiang-2 is failed because 1 Master replica(s) failed.",
                  "reason": "JobFailed",
                  "status": "True",
                  "type": "Failed"
                }
              ],
              "lastReconcileTime": "2024-07-21T15:07:20Z",
              "replicaStatuses": {
                "Master": {
                  "failed": 1,
                  "selector": "training.kubeflow.org/job-name=deepspeed-zhuxiang-2,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=master"
                },
                "Worker": {
                  "failed": 1,
                  "selector": "training.kubeflow.org/job-name=deepspeed-zhuxiang-2,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=worker"
                }
              },
              "startTime": "2024-07-21T15:07:21Z"
            }
          },
          {
            "apiVersion": "kubeflow.org/v1",
            "kind": "PyTorchJob",
            "metadata": {
              "annotations": {
                "aijob.cce.baidubce.com/barrier-finish": "f8bf1e5e-2085-4f24-b6fb-75de43615847",
                "aijob.cce.baidubce.com/fault-tolerance-enabled": "true",
                "aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": "",
                "aijob.cce.baidubce.com/openapi-jobid": "pytorch-78c57221-992e-4086-b890-2e9956d4dd8f",
                "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
                "aijob.cce.baidubce.com/raw-request": "{\"name\":\"deepspeed-zhuxiang-3\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"normal\",\"oversell\":false,\"faultTolerance\":true,\"command\":\" source /root/anaconda3/etc/profile.d/conda.sh\\n    conda activate llama-factory\\n\\n    ROOT_DIR=/workspace/LLaMA-Factory/\\n\\n    CHECKPOINT_LOAD_PATH=/mnt/cluster/ppl/Qwen-14B-Chat\\n    CHECKPOINT_SAVE_PATH=/mnt/cluster/ppl/Qwen-14B-Chat_saved_zhuxiang_2\\n    DEEPSPEED_CONFIG=$ROOT_DIR/examples/deepspeed/ds_z3_offload_config.json\\n\\n    GPUS_PER_NODE=8\\n\\n    is_master=${MASTER-\\\"0\\\"}\\n    if [[ $is_master -eq 1 ]];then\\n      DISTRIBUTED_ARGS=\\\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $HOSTNAME --master_port $MASTER_PORT\\\"\\n    else\\n      DISTRIBUTED_ARGS=\\\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $MASTER_ADDR --master_port $MASTER_PORT\\\"\\n    fi\\n\\n    QWEN_14B_ARGS=\\\"--model_name_or_path $CHECKPOINT_LOAD_PATH \\\\\\n        --stage sft \\\\\\n        --do_train \\\\\\n        --dataset alpaca_en_demo \\\\\\n        --template qwen \\\\\\n        --finetuning_type full \\\\\\n        --overwrite_output_dir \\\\\\n        --dataset_dir $ROOT_DIR/data \\\\\\n        --output_dir $CHECKPOINT_SAVE_PATH \\\\\\n        --preprocessing_num_workers 90 \\\\\\n        --dataloader_num_workers 90 \\\\\\n        --per_device_train_batch_size 1 \\\\\\n        --gradient_accumulation_steps 8 \\\\\\n        --cutoff_len 2048 \\\\\\n        --max_length 2048 \\\\\\n        --deepspeed $DEEPSPEED_CONFIG \\\\\\n        --logging_first_step \\\\\\n        --logging_steps 10 \\\\\\n        --save_strategy steps \\\\\\n        --save_steps 40 \\\\\\n        --num_train_epochs 2.0 \\\\\\n        --lr_scheduler_type cosine \\\\\\n        --learning_rate 1e-5 \\\\\\n        --plot_loss \\\\\\n        --bf16 \\\\\\n        --rope_scaling linear \\\\\\n        --flash_attn auto \\\\\\n        --shift_attn \\\\\\n        --ddp_find_unused_parameters False \\\\\\n        --push_to_hub False\\\"\\n\\n    PYTHONPATH=$ROOT_DIR:$PYTHONPATH \\\\\\n        torchrun $DISTRIBUTED_ARGS \\\\\\n        $ROOT_DIR/src/train.py \\\\\\n        $QWEN_14B_ARGS\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":true,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/cce-ai-native/aiak-algo\",\"tag\":\"0.1\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"deepspeed-zhuxiang-3\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"},\"Worker\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/cce-ai-native/aiak-algo\",\"tag\":\"0.1\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"deepspeed-zhuxiang-3\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":false,\"logPath\":\"\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":true,\"isCopyJob\":true,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
                "aijob.cce.baidubce.com/timeline": "[{\"conditionType\":\"Created\",\"time\":1721574643},{\"conditionType\":\"Scheduled\",\"time\":1721574645},{\"conditionType\":\"Running\",\"time\":1721574661},{\"conditionType\":\"Succeeded\",\"time\":1721575112}]",
                "scheduling.k8s.io/job-enable-oversell": "false"
              },
              "creationTimestamp": "2024-07-21T15:10:43Z",
              "generation": 2,
              "labels": {
                "aijob.cce.baidubce.com/ai-user-id": "b89c433a0e884615a4c878ca24e2686e",
                "aijob.cce.baidubce.com/ai-user-name": "zhuxiang05",
                "aijob.cce.baidubce.com/create-from-aihcp": "true",
                "aijob.cce.baidubce.com/openapi-jobid": "pytorch-78c57221-992e-4086-b890-2e9956d4dd8f"
              },
              "managedFields": [
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        ".": {},
                        "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                        "f:aijob.cce.baidubce.com/openapi-jobid": {},
                        "f:aijob.cce.baidubce.com/pfs-id": {},
                        "f:aijob.cce.baidubce.com/raw-request": {},
                        "f:scheduling.k8s.io/job-enable-oversell": {}
                      },
                      "f:labels": {
                        ".": {},
                        "f:aijob.cce.baidubce.com/ai-user-id": {},
                        "f:aijob.cce.baidubce.com/ai-user-name": {},
                        "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                        "f:aijob.cce.baidubce.com/openapi-jobid": {}
                      }
                    },
                    "f:spec": {
                      ".": {},
                      "f:pytorchReplicaSpecs": {
                        ".": {},
                        "f:Master": {
                          ".": {},
                          "f:replicas": {},
                          "f:restartPolicy": {},
                          "f:template": {
                            ".": {},
                            "f:metadata": {
                              ".": {},
                              "f:annotations": {
                                ".": {},
                                "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                                "f:aijob.cce.baidubce.com/openapi-jobid": {},
                                "f:aijob.cce.baidubce.com/pfs-id": {},
                                "f:aijob.cce.baidubce.com/raw-request": {},
                                "f:scheduling.k8s.io/job-enable-oversell": {}
                              },
                              "f:labels": {
                                ".": {},
                                "f:aijob.cce.baidubce.com/ai-user-id": {},
                                "f:aijob.cce.baidubce.com/ai-user-name": {},
                                "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                                "f:aijob.cce.baidubce.com/openapi-jobid": {}
                              }
                            },
                            "f:spec": {
                              ".": {},
                              "f:dnsPolicy": {},
                              "f:hostNetwork": {},
                              "f:schedulerName": {},
                              "f:volumes": {}
                            }
                          }
                        },
                        "f:Worker": {
                          ".": {},
                          "f:replicas": {},
                          "f:restartPolicy": {},
                          "f:template": {
                            ".": {},
                            "f:metadata": {
                              ".": {},
                              "f:annotations": {
                                ".": {},
                                "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                                "f:aijob.cce.baidubce.com/openapi-jobid": {},
                                "f:aijob.cce.baidubce.com/pfs-id": {},
                                "f:aijob.cce.baidubce.com/raw-request": {},
                                "f:scheduling.k8s.io/job-enable-oversell": {}
                              },
                              "f:labels": {
                                ".": {},
                                "f:aijob.cce.baidubce.com/ai-user-id": {},
                                "f:aijob.cce.baidubce.com/ai-user-name": {},
                                "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                                "f:aijob.cce.baidubce.com/openapi-jobid": {}
                              }
                            },
                            "f:spec": {
                              ".": {},
                              "f:dnsPolicy": {},
                              "f:hostNetwork": {},
                              "f:schedulerName": {},
                              "f:volumes": {}
                            }
                          }
                        }
                      },
                      "f:runPolicy": {
                        ".": {},
                        "f:schedulingPolicy": {
                          ".": {},
                          "f:priorityClass": {},
                          "f:queue": {}
                        }
                      }
                    }
                  },
                  "manager": "cce-ai-service",
                  "operation": "Update",
                  "time": "2024-07-21T15:10:43Z"
                },
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        "f:aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": {},
                        "f:aijob.cce.baidubce.com/timeline": {}
                      }
                    },
                    "f:spec": {
                      "f:pytorchReplicaSpecs": {
                        "f:Master": {
                          "f:template": {
                            "f:spec": {
                              "f:containers": {}
                            }
                          }
                        },
                        "f:Worker": {
                          "f:template": {
                            "f:spec": {
                              "f:containers": {}
                            }
                          }
                        }
                      },
                      "f:runPolicy": {
                        "f:cleanPodPolicy": {}
                      }
                    }
                  },
                  "manager": "controller",
                  "operation": "Update",
                  "time": "2024-07-21T15:10:43Z"
                },
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        "f:aijob.cce.baidubce.com/barrier-finish": {}
                      }
                    }
                  },
                  "manager": "jobbarrier",
                  "operation": "Update",
                  "time": "2024-07-21T15:10:58Z"
                },
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:status": {
                      ".": {},
                      "f:completionTime": {},
                      "f:conditions": {},
                      "f:lastReconcileTime": {},
                      "f:replicaStatuses": {
                        ".": {},
                        "f:Master": {
                          ".": {},
                          "f:selector": {},
                          "f:succeeded": {}
                        },
                        "f:Worker": {
                          ".": {},
                          "f:succeeded": {}
                        }
                      },
                      "f:startTime": {}
                    }
                  },
                  "manager": "manager",
                  "operation": "Update",
                  "time": "2024-07-21T15:18:32Z"
                }
              ],
              "name": "deepspeed-zhuxiang-3",
              "namespace": "default",
              "resourceVersion": "2375270190",
              "uid": "79f25aa1-63fe-4c7d-bc10-e413306f9e52"
            },
            "spec": {
              "pytorchReplicaSpecs": {
                "Master": {
                  "replicas": 1,
                  "restartPolicy": "Never",
                  "template": {
                    "metadata": {
                      "annotations": {
                        "aijob.cce.baidubce.com/fault-tolerance-enabled": "true",
                        "aijob.cce.baidubce.com/openapi-jobid": "pytorch-78c57221-992e-4086-b890-2e9956d4dd8f",
                        "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
                        "aijob.cce.baidubce.com/raw-request": "{\"name\":\"deepspeed-zhuxiang-3\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"normal\",\"oversell\":false,\"faultTolerance\":true,\"command\":\" source /root/anaconda3/etc/profile.d/conda.sh\\n    conda activate llama-factory\\n\\n    ROOT_DIR=/workspace/LLaMA-Factory/\\n\\n    CHECKPOINT_LOAD_PATH=/mnt/cluster/ppl/Qwen-14B-Chat\\n    CHECKPOINT_SAVE_PATH=/mnt/cluster/ppl/Qwen-14B-Chat_saved_zhuxiang_2\\n    DEEPSPEED_CONFIG=$ROOT_DIR/examples/deepspeed/ds_z3_offload_config.json\\n\\n    GPUS_PER_NODE=8\\n\\n    is_master=${MASTER-\\\"0\\\"}\\n    if [[ $is_master -eq 1 ]];then\\n      DISTRIBUTED_ARGS=\\\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $HOSTNAME --master_port $MASTER_PORT\\\"\\n    else\\n      DISTRIBUTED_ARGS=\\\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $MASTER_ADDR --master_port $MASTER_PORT\\\"\\n    fi\\n\\n    QWEN_14B_ARGS=\\\"--model_name_or_path $CHECKPOINT_LOAD_PATH \\\\\\n        --stage sft \\\\\\n        --do_train \\\\\\n        --dataset alpaca_en_demo \\\\\\n        --template qwen \\\\\\n        --finetuning_type full \\\\\\n        --overwrite_output_dir \\\\\\n        --dataset_dir $ROOT_DIR/data \\\\\\n        --output_dir $CHECKPOINT_SAVE_PATH \\\\\\n        --preprocessing_num_workers 90 \\\\\\n        --dataloader_num_workers 90 \\\\\\n        --per_device_train_batch_size 1 \\\\\\n        --gradient_accumulation_steps 8 \\\\\\n        --cutoff_len 2048 \\\\\\n        --max_length 2048 \\\\\\n        --deepspeed $DEEPSPEED_CONFIG \\\\\\n        --logging_first_step \\\\\\n        --logging_steps 10 \\\\\\n        --save_strategy steps \\\\\\n        --save_steps 40 \\\\\\n        --num_train_epochs 2.0 \\\\\\n        --lr_scheduler_type cosine \\\\\\n        --learning_rate 1e-5 \\\\\\n        --plot_loss \\\\\\n        --bf16 \\\\\\n        --rope_scaling linear \\\\\\n        --flash_attn auto \\\\\\n        --shift_attn \\\\\\n        --ddp_find_unused_parameters False \\\\\\n        --push_to_hub False\\\"\\n\\n    PYTHONPATH=$ROOT_DIR:$PYTHONPATH \\\\\\n        torchrun $DISTRIBUTED_ARGS \\\\\\n        $ROOT_DIR/src/train.py \\\\\\n        $QWEN_14B_ARGS\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":true,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/cce-ai-native/aiak-algo\",\"tag\":\"0.1\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"deepspeed-zhuxiang-3\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"},\"Worker\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/cce-ai-native/aiak-algo\",\"tag\":\"0.1\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"deepspeed-zhuxiang-3\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":false,\"logPath\":\"\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":true,\"isCopyJob\":true,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
                        "scheduling.k8s.io/job-enable-oversell": "false"
                      },
                      "labels": {
                        "aijob.cce.baidubce.com/ai-user-id": "b89c433a0e884615a4c878ca24e2686e",
                        "aijob.cce.baidubce.com/ai-user-name": "zhuxiang05",
                        "aijob.cce.baidubce.com/create-from-aihcp": "true",
                        "aijob.cce.baidubce.com/openapi-jobid": "pytorch-78c57221-992e-4086-b890-2e9956d4dd8f"
                      }
                    },
                    "spec": {
                      "containers": [
                        {
                          "command": [
                            "/bin/bash",
                            "-c",
                            " source /root/anaconda3/etc/profile.d/conda.sh\n    conda activate llama-factory\n\n    ROOT_DIR=/workspace/LLaMA-Factory/\n\n    CHECKPOINT_LOAD_PATH=/mnt/cluster/ppl/Qwen-14B-Chat\n    CHECKPOINT_SAVE_PATH=/mnt/cluster/ppl/Qwen-14B-Chat_saved_zhuxiang_2\n    DEEPSPEED_CONFIG=$ROOT_DIR/examples/deepspeed/ds_z3_offload_config.json\n\n    GPUS_PER_NODE=8\n\n    is_master=${MASTER-\"0\"}\n    if [[ $is_master -eq 1 ]];then\n      DISTRIBUTED_ARGS=\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $HOSTNAME --master_port $MASTER_PORT\"\n    else\n      DISTRIBUTED_ARGS=\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $MASTER_ADDR --master_port $MASTER_PORT\"\n    fi\n\n    QWEN_14B_ARGS=\"--model_name_or_path $CHECKPOINT_LOAD_PATH \\\n        --stage sft \\\n        --do_train \\\n        --dataset alpaca_en_demo \\\n        --template qwen \\\n        --finetuning_type full \\\n        --overwrite_output_dir \\\n        --dataset_dir $ROOT_DIR/data \\\n        --output_dir $CHECKPOINT_SAVE_PATH \\\n        --preprocessing_num_workers 90 \\\n        --dataloader_num_workers 90 \\\n        --per_device_train_batch_size 1 \\\n        --gradient_accumulation_steps 8 \\\n        --cutoff_len 2048 \\\n        --max_length 2048 \\\n        --deepspeed $DEEPSPEED_CONFIG \\\n        --logging_first_step \\\n        --logging_steps 10 \\\n        --save_strategy steps \\\n        --save_steps 40 \\\n        --num_train_epochs 2.0 \\\n        --lr_scheduler_type cosine \\\n        --learning_rate 1e-5 \\\n        --plot_loss \\\n        --bf16 \\\n        --rope_scaling linear \\\n        --flash_attn auto \\\n        --shift_attn \\\n        --ddp_find_unused_parameters False \\\n        --push_to_hub False\"\n\n    PYTHONPATH=$ROOT_DIR:$PYTHONPATH \\\n        torchrun $DISTRIBUTED_ARGS \\\n        $ROOT_DIR/src/train.py \\\n        $QWEN_14B_ARGS"
                          ],
                          "env": [
                            {
                              "name": "NCCL_IB_DISABLE",
                              "value": "0"
                            },
                            {
                              "name": "AIHC_JOB_NAME",
                              "value": "deepspeed-zhuxiang-3"
                            }
                          ],
                          "image": "registry.baidubce.com/cce-ai-native/aiak-algo:0.1",
                          "imagePullPolicy": "Always",
                          "name": "pytorch",
                          "ports": [
                            {
                              "containerPort": 23456,
                              "name": "pytorchjob-port",
                              "protocol": "TCP"
                            }
                          ],
                          "resources": {
                            "limits": {
                              "baidu.com/a800_80g_cgpu": "8",
                              "rdma/hca": "1"
                            },
                            "requests": {
                              "baidu.com/a800_80g_cgpu": "8",
                              "rdma/hca": "1"
                            }
                          },
                          "securityContext": {
                            "capabilities": {
                              "add": [
                                "IPC_LOCK"
                              ]
                            }
                          },
                          "volumeMounts": [
                            {
                              "mountPath": "/dev/shm",
                              "name": "devshm"
                            },
                            {
                              "mountPath": "/mnt/cluster",
                              "name": "pvc-pfs"
                            }
                          ]
                        }
                      ],
                      "dnsPolicy": "ClusterFirstWithHostNet",
                      "hostNetwork": true,
                      "schedulerName": "volcano",
                      "volumes": [
                        {
                          "emptyDir": {
                            "medium": "Memory",
                            "sizeLimit": "10Gi"
                          },
                          "name": "devshm"
                        },
                        {
                          "name": "pvc-pfs",
                          "persistentVolumeClaim": {
                            "claimName": "pvc-pfs"
                          }
                        }
                      ]
                    }
                  }
                },
                "Worker": {
                  "replicas": 1,
                  "restartPolicy": "Never",
                  "template": {
                    "metadata": {
                      "annotations": {
                        "aijob.cce.baidubce.com/fault-tolerance-enabled": "true",
                        "aijob.cce.baidubce.com/openapi-jobid": "pytorch-78c57221-992e-4086-b890-2e9956d4dd8f",
                        "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
                        "aijob.cce.baidubce.com/raw-request": "{\"name\":\"deepspeed-zhuxiang-3\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"normal\",\"oversell\":false,\"faultTolerance\":true,\"command\":\" source /root/anaconda3/etc/profile.d/conda.sh\\n    conda activate llama-factory\\n\\n    ROOT_DIR=/workspace/LLaMA-Factory/\\n\\n    CHECKPOINT_LOAD_PATH=/mnt/cluster/ppl/Qwen-14B-Chat\\n    CHECKPOINT_SAVE_PATH=/mnt/cluster/ppl/Qwen-14B-Chat_saved_zhuxiang_2\\n    DEEPSPEED_CONFIG=$ROOT_DIR/examples/deepspeed/ds_z3_offload_config.json\\n\\n    GPUS_PER_NODE=8\\n\\n    is_master=${MASTER-\\\"0\\\"}\\n    if [[ $is_master -eq 1 ]];then\\n      DISTRIBUTED_ARGS=\\\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $HOSTNAME --master_port $MASTER_PORT\\\"\\n    else\\n      DISTRIBUTED_ARGS=\\\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $MASTER_ADDR --master_port $MASTER_PORT\\\"\\n    fi\\n\\n    QWEN_14B_ARGS=\\\"--model_name_or_path $CHECKPOINT_LOAD_PATH \\\\\\n        --stage sft \\\\\\n        --do_train \\\\\\n        --dataset alpaca_en_demo \\\\\\n        --template qwen \\\\\\n        --finetuning_type full \\\\\\n        --overwrite_output_dir \\\\\\n        --dataset_dir $ROOT_DIR/data \\\\\\n        --output_dir $CHECKPOINT_SAVE_PATH \\\\\\n        --preprocessing_num_workers 90 \\\\\\n        --dataloader_num_workers 90 \\\\\\n        --per_device_train_batch_size 1 \\\\\\n        --gradient_accumulation_steps 8 \\\\\\n        --cutoff_len 2048 \\\\\\n        --max_length 2048 \\\\\\n        --deepspeed $DEEPSPEED_CONFIG \\\\\\n        --logging_first_step \\\\\\n        --logging_steps 10 \\\\\\n        --save_strategy steps \\\\\\n        --save_steps 40 \\\\\\n        --num_train_epochs 2.0 \\\\\\n        --lr_scheduler_type cosine \\\\\\n        --learning_rate 1e-5 \\\\\\n        --plot_loss \\\\\\n        --bf16 \\\\\\n        --rope_scaling linear \\\\\\n        --flash_attn auto \\\\\\n        --shift_attn \\\\\\n        --ddp_find_unused_parameters False \\\\\\n        --push_to_hub False\\\"\\n\\n    PYTHONPATH=$ROOT_DIR:$PYTHONPATH \\\\\\n        torchrun $DISTRIBUTED_ARGS \\\\\\n        $ROOT_DIR/src/train.py \\\\\\n        $QWEN_14B_ARGS\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":true,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/cce-ai-native/aiak-algo\",\"tag\":\"0.1\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"deepspeed-zhuxiang-3\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"},\"Worker\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/cce-ai-native/aiak-algo\",\"tag\":\"0.1\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"deepspeed-zhuxiang-3\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":false,\"logPath\":\"\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":true,\"isCopyJob\":true,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
                        "scheduling.k8s.io/job-enable-oversell": "false"
                      },
                      "labels": {
                        "aijob.cce.baidubce.com/ai-user-id": "b89c433a0e884615a4c878ca24e2686e",
                        "aijob.cce.baidubce.com/ai-user-name": "zhuxiang05",
                        "aijob.cce.baidubce.com/create-from-aihcp": "true",
                        "aijob.cce.baidubce.com/openapi-jobid": "pytorch-78c57221-992e-4086-b890-2e9956d4dd8f"
                      }
                    },
                    "spec": {
                      "containers": [
                        {
                          "command": [
                            "/bin/bash",
                            "-c",
                            " source /root/anaconda3/etc/profile.d/conda.sh\n    conda activate llama-factory\n\n    ROOT_DIR=/workspace/LLaMA-Factory/\n\n    CHECKPOINT_LOAD_PATH=/mnt/cluster/ppl/Qwen-14B-Chat\n    CHECKPOINT_SAVE_PATH=/mnt/cluster/ppl/Qwen-14B-Chat_saved_zhuxiang_2\n    DEEPSPEED_CONFIG=$ROOT_DIR/examples/deepspeed/ds_z3_offload_config.json\n\n    GPUS_PER_NODE=8\n\n    is_master=${MASTER-\"0\"}\n    if [[ $is_master -eq 1 ]];then\n      DISTRIBUTED_ARGS=\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $HOSTNAME --master_port $MASTER_PORT\"\n    else\n      DISTRIBUTED_ARGS=\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $MASTER_ADDR --master_port $MASTER_PORT\"\n    fi\n\n    QWEN_14B_ARGS=\"--model_name_or_path $CHECKPOINT_LOAD_PATH \\\n        --stage sft \\\n        --do_train \\\n        --dataset alpaca_en_demo \\\n        --template qwen \\\n        --finetuning_type full \\\n        --overwrite_output_dir \\\n        --dataset_dir $ROOT_DIR/data \\\n        --output_dir $CHECKPOINT_SAVE_PATH \\\n        --preprocessing_num_workers 90 \\\n        --dataloader_num_workers 90 \\\n        --per_device_train_batch_size 1 \\\n        --gradient_accumulation_steps 8 \\\n        --cutoff_len 2048 \\\n        --max_length 2048 \\\n        --deepspeed $DEEPSPEED_CONFIG \\\n        --logging_first_step \\\n        --logging_steps 10 \\\n        --save_strategy steps \\\n        --save_steps 40 \\\n        --num_train_epochs 2.0 \\\n        --lr_scheduler_type cosine \\\n        --learning_rate 1e-5 \\\n        --plot_loss \\\n        --bf16 \\\n        --rope_scaling linear \\\n        --flash_attn auto \\\n        --shift_attn \\\n        --ddp_find_unused_parameters False \\\n        --push_to_hub False\"\n\n    PYTHONPATH=$ROOT_DIR:$PYTHONPATH \\\n        torchrun $DISTRIBUTED_ARGS \\\n        $ROOT_DIR/src/train.py \\\n        $QWEN_14B_ARGS"
                          ],
                          "env": [
                            {
                              "name": "AIHC_JOB_NAME",
                              "value": "deepspeed-zhuxiang-3"
                            },
                            {
                              "name": "NCCL_IB_DISABLE",
                              "value": "0"
                            }
                          ],
                          "image": "registry.baidubce.com/cce-ai-native/aiak-algo:0.1",
                          "imagePullPolicy": "Always",
                          "name": "pytorch",
                          "ports": [
                            {
                              "containerPort": 23456,
                              "name": "pytorchjob-port",
                              "protocol": "TCP"
                            }
                          ],
                          "resources": {
                            "limits": {
                              "baidu.com/a800_80g_cgpu": "8",
                              "rdma/hca": "1"
                            },
                            "requests": {
                              "baidu.com/a800_80g_cgpu": "8",
                              "rdma/hca": "1"
                            }
                          },
                          "securityContext": {
                            "capabilities": {
                              "add": [
                                "IPC_LOCK"
                              ]
                            }
                          },
                          "volumeMounts": [
                            {
                              "mountPath": "/dev/shm",
                              "name": "devshm"
                            },
                            {
                              "mountPath": "/mnt/cluster",
                              "name": "pvc-pfs"
                            }
                          ]
                        }
                      ],
                      "dnsPolicy": "ClusterFirstWithHostNet",
                      "hostNetwork": true,
                      "schedulerName": "volcano",
                      "volumes": [
                        {
                          "emptyDir": {
                            "medium": "Memory",
                            "sizeLimit": "10Gi"
                          },
                          "name": "devshm"
                        },
                        {
                          "name": "pvc-pfs",
                          "persistentVolumeClaim": {
                            "claimName": "pvc-pfs"
                          }
                        }
                      ]
                    }
                  }
                }
              },
              "runPolicy": {
                "cleanPodPolicy": "None",
                "schedulingPolicy": {
                  "priorityClass": "normal",
                  "queue": "default"
                }
              }
            },
            "status": {
              "completionTime": "2024-07-21T15:18:32Z",
              "conditions": [
                {
                  "lastTransitionTime": "2024-07-21T15:10:43Z",
                  "lastUpdateTime": "2024-07-21T15:10:43Z",
                  "message": "PyTorchJob deepspeed-zhuxiang-3 is created.",
                  "reason": "PyTorchJobCreated",
                  "status": "True",
                  "type": "Created"
                },
                {
                  "lastTransitionTime": "2024-07-21T15:11:01Z",
                  "lastUpdateTime": "2024-07-21T15:11:01Z",
                  "message": "PyTorchJob deepspeed-zhuxiang-3 is running.",
                  "reason": "JobRunning",
                  "status": "False",
                  "type": "Running"
                },
                {
                  "lastTransitionTime": "2024-07-21T15:18:32Z",
                  "lastUpdateTime": "2024-07-21T15:18:32Z",
                  "message": "PyTorchJob deepspeed-zhuxiang-3 is successfully completed.",
                  "reason": "JobSucceeded",
                  "status": "True",
                  "type": "Succeeded"
                }
              ],
              "lastReconcileTime": "2024-07-21T15:10:43Z",
              "replicaStatuses": {
                "Master": {
                  "selector": "training.kubeflow.org/job-name=deepspeed-zhuxiang-3,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=master",
                  "succeeded": 1
                },
                "Worker": {
                  "succeeded": 1
                }
              },
              "startTime": "2024-07-21T15:10:45Z"
            }
          },
          {
            "apiVersion": "kubeflow.org/v1",
            "kind": "PyTorchJob",
            "metadata": {
              "annotations": {
                "aijob.cce.baidubce.com/barrier-finish": "33633217-ff37-4710-a9ba-5cf66782e1df",
                "aijob.cce.baidubce.com/fault-tolerance-enabled": "true",
                "aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": "",
                "aijob.cce.baidubce.com/openapi-jobid": "pytorch-5a4216f3-fc78-46b1-89b3-5bae67f3751a",
                "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
                "aijob.cce.baidubce.com/raw-request": "{\"name\":\"deepspeed-zhuxiang-4\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"normal\",\"oversell\":false,\"faultTolerance\":true,\"command\":\" source /root/anaconda3/etc/profile.d/conda.sh\\n    conda activate llama-factory\\n\\n    ROOT_DIR=/workspace/LLaMA-Factory/\\n\\n    CHECKPOINT_LOAD_PATH=/mnt/cluster/ppl/Qwen-14B-Chat\\n    CHECKPOINT_SAVE_PATH=/mnt/cluster/ppl/Qwen-14B-Chat_saved_zhuxiang_4\\n    DEEPSPEED_CONFIG=$ROOT_DIR/examples/deepspeed/ds_z3_offload_config.json\\n\\n    GPUS_PER_NODE=8\\n\\n    is_master=${MASTER-\\\"0\\\"}\\n    if [[ $is_master -eq 1 ]];then\\n      DISTRIBUTED_ARGS=\\\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $HOSTNAME --master_port $MASTER_PORT\\\"\\n    else\\n      DISTRIBUTED_ARGS=\\\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $MASTER_ADDR --master_port $MASTER_PORT\\\"\\n    fi\\n\\n    QWEN_14B_ARGS=\\\"--model_name_or_path $CHECKPOINT_LOAD_PATH \\\\\\n        --stage sft \\\\\\n        --do_train \\\\\\n        --dataset alpaca_en_demo \\\\\\n        --template qwen \\\\\\n        --finetuning_type lora \\\\\\n        --lora_target all \\\\\\n        --overwrite_output_dir \\\\\\n        --dataset_dir $ROOT_DIR/data \\\\\\n        --output_dir $CHECKPOINT_SAVE_PATH \\\\\\n        --preprocessing_num_workers 90 \\\\\\n        --dataloader_num_workers 90 \\\\\\n        --per_device_train_batch_size 1 \\\\\\n        --gradient_accumulation_steps 8 \\\\\\n        --cutoff_len 2048 \\\\\\n        --max_length 2048 \\\\\\n        --deepspeed $DEEPSPEED_CONFIG \\\\\\n        --logging_first_step \\\\\\n        --logging_steps 10 \\\\\\n        --save_strategy steps \\\\\\n        --save_steps 40 \\\\\\n        --num_train_epochs 2.0 \\\\\\n        --lr_scheduler_type cosine \\\\\\n        --learning_rate 1e-5 \\\\\\n        --plot_loss \\\\\\n        --bf16 \\\\\\n        --rope_scaling linear \\\\\\n        --flash_attn auto \\\\\\n        --shift_attn \\\\\\n        --ddp_find_unused_parameters False \\\\\\n        --push_to_hub False\\\"\\n\\n    PYTHONPATH=$ROOT_DIR:$PYTHONPATH \\\\\\n        torchrun $DISTRIBUTED_ARGS \\\\\\n        $ROOT_DIR/src/train.py \\\\\\n        $QWEN_14B_ARGS\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":true,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/cce-ai-native/aiak-algo\",\"tag\":\"0.1\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"deepspeed-zhuxiang-4\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"},\"Worker\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/cce-ai-native/aiak-algo\",\"tag\":\"0.1\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"deepspeed-zhuxiang-4\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":false,\"logPath\":\"\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":true,\"isCopyJob\":true,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
                "aijob.cce.baidubce.com/timeline": "[{\"conditionType\":\"Created\",\"time\":1721577689},{\"conditionType\":\"Scheduled\",\"time\":1721577690},{\"conditionType\":\"Running\",\"time\":1721577744},{\"conditionType\":\"Succeeded\",\"time\":1721578104}]",
                "scheduling.k8s.io/job-enable-oversell": "false"
              },
              "creationTimestamp": "2024-07-21T16:01:29Z",
              "generation": 2,
              "labels": {
                "aijob.cce.baidubce.com/ai-user-id": "b89c433a0e884615a4c878ca24e2686e",
                "aijob.cce.baidubce.com/ai-user-name": "zhuxiang05",
                "aijob.cce.baidubce.com/create-from-aihcp": "true",
                "aijob.cce.baidubce.com/openapi-jobid": "pytorch-5a4216f3-fc78-46b1-89b3-5bae67f3751a"
              },
              "managedFields": [
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        ".": {},
                        "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                        "f:aijob.cce.baidubce.com/openapi-jobid": {},
                        "f:aijob.cce.baidubce.com/pfs-id": {},
                        "f:aijob.cce.baidubce.com/raw-request": {},
                        "f:scheduling.k8s.io/job-enable-oversell": {}
                      },
                      "f:labels": {
                        ".": {},
                        "f:aijob.cce.baidubce.com/ai-user-id": {},
                        "f:aijob.cce.baidubce.com/ai-user-name": {},
                        "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                        "f:aijob.cce.baidubce.com/openapi-jobid": {}
                      }
                    },
                    "f:spec": {
                      ".": {},
                      "f:pytorchReplicaSpecs": {
                        ".": {},
                        "f:Master": {
                          ".": {},
                          "f:replicas": {},
                          "f:restartPolicy": {},
                          "f:template": {
                            ".": {},
                            "f:metadata": {
                              ".": {},
                              "f:annotations": {
                                ".": {},
                                "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                                "f:aijob.cce.baidubce.com/openapi-jobid": {},
                                "f:aijob.cce.baidubce.com/pfs-id": {},
                                "f:aijob.cce.baidubce.com/raw-request": {},
                                "f:scheduling.k8s.io/job-enable-oversell": {}
                              },
                              "f:labels": {
                                ".": {},
                                "f:aijob.cce.baidubce.com/ai-user-id": {},
                                "f:aijob.cce.baidubce.com/ai-user-name": {},
                                "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                                "f:aijob.cce.baidubce.com/openapi-jobid": {}
                              }
                            },
                            "f:spec": {
                              ".": {},
                              "f:dnsPolicy": {},
                              "f:hostNetwork": {},
                              "f:schedulerName": {},
                              "f:volumes": {}
                            }
                          }
                        },
                        "f:Worker": {
                          ".": {},
                          "f:replicas": {},
                          "f:restartPolicy": {},
                          "f:template": {
                            ".": {},
                            "f:metadata": {
                              ".": {},
                              "f:annotations": {
                                ".": {},
                                "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                                "f:aijob.cce.baidubce.com/openapi-jobid": {},
                                "f:aijob.cce.baidubce.com/pfs-id": {},
                                "f:aijob.cce.baidubce.com/raw-request": {},
                                "f:scheduling.k8s.io/job-enable-oversell": {}
                              },
                              "f:labels": {
                                ".": {},
                                "f:aijob.cce.baidubce.com/ai-user-id": {},
                                "f:aijob.cce.baidubce.com/ai-user-name": {},
                                "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                                "f:aijob.cce.baidubce.com/openapi-jobid": {}
                              }
                            },
                            "f:spec": {
                              ".": {},
                              "f:dnsPolicy": {},
                              "f:hostNetwork": {},
                              "f:schedulerName": {},
                              "f:volumes": {}
                            }
                          }
                        }
                      },
                      "f:runPolicy": {
                        ".": {},
                        "f:schedulingPolicy": {
                          ".": {},
                          "f:priorityClass": {},
                          "f:queue": {}
                        }
                      }
                    }
                  },
                  "manager": "cce-ai-service",
                  "operation": "Update",
                  "time": "2024-07-21T16:01:29Z"
                },
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        "f:aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": {},
                        "f:aijob.cce.baidubce.com/timeline": {}
                      }
                    },
                    "f:spec": {
                      "f:pytorchReplicaSpecs": {
                        "f:Master": {
                          "f:template": {
                            "f:spec": {
                              "f:containers": {}
                            }
                          }
                        },
                        "f:Worker": {
                          "f:template": {
                            "f:spec": {
                              "f:containers": {}
                            }
                          }
                        }
                      },
                      "f:runPolicy": {
                        "f:cleanPodPolicy": {}
                      }
                    }
                  },
                  "manager": "controller",
                  "operation": "Update",
                  "time": "2024-07-21T16:01:29Z"
                },
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        "f:aijob.cce.baidubce.com/barrier-finish": {}
                      }
                    }
                  },
                  "manager": "jobbarrier",
                  "operation": "Update",
                  "time": "2024-07-21T16:02:19Z"
                },
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:status": {
                      ".": {},
                      "f:completionTime": {},
                      "f:conditions": {},
                      "f:lastReconcileTime": {},
                      "f:replicaStatuses": {
                        ".": {},
                        "f:Master": {
                          ".": {},
                          "f:selector": {},
                          "f:succeeded": {}
                        },
                        "f:Worker": {
                          ".": {},
                          "f:succeeded": {}
                        }
                      },
                      "f:startTime": {}
                    }
                  },
                  "manager": "manager",
                  "operation": "Update",
                  "time": "2024-07-21T16:08:24Z"
                }
              ],
              "name": "deepspeed-zhuxiang-4",
              "namespace": "default",
              "resourceVersion": "2375309550",
              "uid": "db613901-bbdb-48da-bed1-d32f817ee964"
            },
            "spec": {
              "pytorchReplicaSpecs": {
                "Master": {
                  "replicas": 1,
                  "restartPolicy": "Never",
                  "template": {
                    "metadata": {
                      "annotations": {
                        "aijob.cce.baidubce.com/fault-tolerance-enabled": "true",
                        "aijob.cce.baidubce.com/openapi-jobid": "pytorch-5a4216f3-fc78-46b1-89b3-5bae67f3751a",
                        "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
                        "aijob.cce.baidubce.com/raw-request": "{\"name\":\"deepspeed-zhuxiang-4\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"normal\",\"oversell\":false,\"faultTolerance\":true,\"command\":\" source /root/anaconda3/etc/profile.d/conda.sh\\n    conda activate llama-factory\\n\\n    ROOT_DIR=/workspace/LLaMA-Factory/\\n\\n    CHECKPOINT_LOAD_PATH=/mnt/cluster/ppl/Qwen-14B-Chat\\n    CHECKPOINT_SAVE_PATH=/mnt/cluster/ppl/Qwen-14B-Chat_saved_zhuxiang_4\\n    DEEPSPEED_CONFIG=$ROOT_DIR/examples/deepspeed/ds_z3_offload_config.json\\n\\n    GPUS_PER_NODE=8\\n\\n    is_master=${MASTER-\\\"0\\\"}\\n    if [[ $is_master -eq 1 ]];then\\n      DISTRIBUTED_ARGS=\\\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $HOSTNAME --master_port $MASTER_PORT\\\"\\n    else\\n      DISTRIBUTED_ARGS=\\\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $MASTER_ADDR --master_port $MASTER_PORT\\\"\\n    fi\\n\\n    QWEN_14B_ARGS=\\\"--model_name_or_path $CHECKPOINT_LOAD_PATH \\\\\\n        --stage sft \\\\\\n        --do_train \\\\\\n        --dataset alpaca_en_demo \\\\\\n        --template qwen \\\\\\n        --finetuning_type lora \\\\\\n        --lora_target all \\\\\\n        --overwrite_output_dir \\\\\\n        --dataset_dir $ROOT_DIR/data \\\\\\n        --output_dir $CHECKPOINT_SAVE_PATH \\\\\\n        --preprocessing_num_workers 90 \\\\\\n        --dataloader_num_workers 90 \\\\\\n        --per_device_train_batch_size 1 \\\\\\n        --gradient_accumulation_steps 8 \\\\\\n        --cutoff_len 2048 \\\\\\n        --max_length 2048 \\\\\\n        --deepspeed $DEEPSPEED_CONFIG \\\\\\n        --logging_first_step \\\\\\n        --logging_steps 10 \\\\\\n        --save_strategy steps \\\\\\n        --save_steps 40 \\\\\\n        --num_train_epochs 2.0 \\\\\\n        --lr_scheduler_type cosine \\\\\\n        --learning_rate 1e-5 \\\\\\n        --plot_loss \\\\\\n        --bf16 \\\\\\n        --rope_scaling linear \\\\\\n        --flash_attn auto \\\\\\n        --shift_attn \\\\\\n        --ddp_find_unused_parameters False \\\\\\n        --push_to_hub False\\\"\\n\\n    PYTHONPATH=$ROOT_DIR:$PYTHONPATH \\\\\\n        torchrun $DISTRIBUTED_ARGS \\\\\\n        $ROOT_DIR/src/train.py \\\\\\n        $QWEN_14B_ARGS\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":true,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/cce-ai-native/aiak-algo\",\"tag\":\"0.1\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"deepspeed-zhuxiang-4\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"},\"Worker\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/cce-ai-native/aiak-algo\",\"tag\":\"0.1\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"deepspeed-zhuxiang-4\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":false,\"logPath\":\"\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":true,\"isCopyJob\":true,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
                        "scheduling.k8s.io/job-enable-oversell": "false"
                      },
                      "labels": {
                        "aijob.cce.baidubce.com/ai-user-id": "b89c433a0e884615a4c878ca24e2686e",
                        "aijob.cce.baidubce.com/ai-user-name": "zhuxiang05",
                        "aijob.cce.baidubce.com/create-from-aihcp": "true",
                        "aijob.cce.baidubce.com/openapi-jobid": "pytorch-5a4216f3-fc78-46b1-89b3-5bae67f3751a"
                      }
                    },
                    "spec": {
                      "containers": [
                        {
                          "command": [
                            "/bin/bash",
                            "-c",
                            " source /root/anaconda3/etc/profile.d/conda.sh\n    conda activate llama-factory\n\n    ROOT_DIR=/workspace/LLaMA-Factory/\n\n    CHECKPOINT_LOAD_PATH=/mnt/cluster/ppl/Qwen-14B-Chat\n    CHECKPOINT_SAVE_PATH=/mnt/cluster/ppl/Qwen-14B-Chat_saved_zhuxiang_4\n    DEEPSPEED_CONFIG=$ROOT_DIR/examples/deepspeed/ds_z3_offload_config.json\n\n    GPUS_PER_NODE=8\n\n    is_master=${MASTER-\"0\"}\n    if [[ $is_master -eq 1 ]];then\n      DISTRIBUTED_ARGS=\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $HOSTNAME --master_port $MASTER_PORT\"\n    else\n      DISTRIBUTED_ARGS=\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $MASTER_ADDR --master_port $MASTER_PORT\"\n    fi\n\n    QWEN_14B_ARGS=\"--model_name_or_path $CHECKPOINT_LOAD_PATH \\\n        --stage sft \\\n        --do_train \\\n        --dataset alpaca_en_demo \\\n        --template qwen \\\n        --finetuning_type lora \\\n        --lora_target all \\\n        --overwrite_output_dir \\\n        --dataset_dir $ROOT_DIR/data \\\n        --output_dir $CHECKPOINT_SAVE_PATH \\\n        --preprocessing_num_workers 90 \\\n        --dataloader_num_workers 90 \\\n        --per_device_train_batch_size 1 \\\n        --gradient_accumulation_steps 8 \\\n        --cutoff_len 2048 \\\n        --max_length 2048 \\\n        --deepspeed $DEEPSPEED_CONFIG \\\n        --logging_first_step \\\n        --logging_steps 10 \\\n        --save_strategy steps \\\n        --save_steps 40 \\\n        --num_train_epochs 2.0 \\\n        --lr_scheduler_type cosine \\\n        --learning_rate 1e-5 \\\n        --plot_loss \\\n        --bf16 \\\n        --rope_scaling linear \\\n        --flash_attn auto \\\n        --shift_attn \\\n        --ddp_find_unused_parameters False \\\n        --push_to_hub False\"\n\n    PYTHONPATH=$ROOT_DIR:$PYTHONPATH \\\n        torchrun $DISTRIBUTED_ARGS \\\n        $ROOT_DIR/src/train.py \\\n        $QWEN_14B_ARGS"
                          ],
                          "env": [
                            {
                              "name": "AIHC_JOB_NAME",
                              "value": "deepspeed-zhuxiang-4"
                            },
                            {
                              "name": "NCCL_IB_DISABLE",
                              "value": "0"
                            }
                          ],
                          "image": "registry.baidubce.com/cce-ai-native/aiak-algo:0.1",
                          "imagePullPolicy": "Always",
                          "name": "pytorch",
                          "ports": [
                            {
                              "containerPort": 23456,
                              "name": "pytorchjob-port",
                              "protocol": "TCP"
                            }
                          ],
                          "resources": {
                            "limits": {
                              "baidu.com/a800_80g_cgpu": "8",
                              "rdma/hca": "1"
                            },
                            "requests": {
                              "baidu.com/a800_80g_cgpu": "8",
                              "rdma/hca": "1"
                            }
                          },
                          "securityContext": {
                            "capabilities": {
                              "add": [
                                "IPC_LOCK"
                              ]
                            }
                          },
                          "volumeMounts": [
                            {
                              "mountPath": "/dev/shm",
                              "name": "devshm"
                            },
                            {
                              "mountPath": "/mnt/cluster",
                              "name": "pvc-pfs"
                            }
                          ]
                        }
                      ],
                      "dnsPolicy": "ClusterFirstWithHostNet",
                      "hostNetwork": true,
                      "schedulerName": "volcano",
                      "volumes": [
                        {
                          "emptyDir": {
                            "medium": "Memory",
                            "sizeLimit": "10Gi"
                          },
                          "name": "devshm"
                        },
                        {
                          "name": "pvc-pfs",
                          "persistentVolumeClaim": {
                            "claimName": "pvc-pfs"
                          }
                        }
                      ]
                    }
                  }
                },
                "Worker": {
                  "replicas": 1,
                  "restartPolicy": "Never",
                  "template": {
                    "metadata": {
                      "annotations": {
                        "aijob.cce.baidubce.com/fault-tolerance-enabled": "true",
                        "aijob.cce.baidubce.com/openapi-jobid": "pytorch-5a4216f3-fc78-46b1-89b3-5bae67f3751a",
                        "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
                        "aijob.cce.baidubce.com/raw-request": "{\"name\":\"deepspeed-zhuxiang-4\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"normal\",\"oversell\":false,\"faultTolerance\":true,\"command\":\" source /root/anaconda3/etc/profile.d/conda.sh\\n    conda activate llama-factory\\n\\n    ROOT_DIR=/workspace/LLaMA-Factory/\\n\\n    CHECKPOINT_LOAD_PATH=/mnt/cluster/ppl/Qwen-14B-Chat\\n    CHECKPOINT_SAVE_PATH=/mnt/cluster/ppl/Qwen-14B-Chat_saved_zhuxiang_4\\n    DEEPSPEED_CONFIG=$ROOT_DIR/examples/deepspeed/ds_z3_offload_config.json\\n\\n    GPUS_PER_NODE=8\\n\\n    is_master=${MASTER-\\\"0\\\"}\\n    if [[ $is_master -eq 1 ]];then\\n      DISTRIBUTED_ARGS=\\\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $HOSTNAME --master_port $MASTER_PORT\\\"\\n    else\\n      DISTRIBUTED_ARGS=\\\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $MASTER_ADDR --master_port $MASTER_PORT\\\"\\n    fi\\n\\n    QWEN_14B_ARGS=\\\"--model_name_or_path $CHECKPOINT_LOAD_PATH \\\\\\n        --stage sft \\\\\\n        --do_train \\\\\\n        --dataset alpaca_en_demo \\\\\\n        --template qwen \\\\\\n        --finetuning_type lora \\\\\\n        --lora_target all \\\\\\n        --overwrite_output_dir \\\\\\n        --dataset_dir $ROOT_DIR/data \\\\\\n        --output_dir $CHECKPOINT_SAVE_PATH \\\\\\n        --preprocessing_num_workers 90 \\\\\\n        --dataloader_num_workers 90 \\\\\\n        --per_device_train_batch_size 1 \\\\\\n        --gradient_accumulation_steps 8 \\\\\\n        --cutoff_len 2048 \\\\\\n        --max_length 2048 \\\\\\n        --deepspeed $DEEPSPEED_CONFIG \\\\\\n        --logging_first_step \\\\\\n        --logging_steps 10 \\\\\\n        --save_strategy steps \\\\\\n        --save_steps 40 \\\\\\n        --num_train_epochs 2.0 \\\\\\n        --lr_scheduler_type cosine \\\\\\n        --learning_rate 1e-5 \\\\\\n        --plot_loss \\\\\\n        --bf16 \\\\\\n        --rope_scaling linear \\\\\\n        --flash_attn auto \\\\\\n        --shift_attn \\\\\\n        --ddp_find_unused_parameters False \\\\\\n        --push_to_hub False\\\"\\n\\n    PYTHONPATH=$ROOT_DIR:$PYTHONPATH \\\\\\n        torchrun $DISTRIBUTED_ARGS \\\\\\n        $ROOT_DIR/src/train.py \\\\\\n        $QWEN_14B_ARGS\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":true,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/cce-ai-native/aiak-algo\",\"tag\":\"0.1\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"deepspeed-zhuxiang-4\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"},\"Worker\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/cce-ai-native/aiak-algo\",\"tag\":\"0.1\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"deepspeed-zhuxiang-4\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":false,\"logPath\":\"\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":true,\"isCopyJob\":true,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
                        "scheduling.k8s.io/job-enable-oversell": "false"
                      },
                      "labels": {
                        "aijob.cce.baidubce.com/ai-user-id": "b89c433a0e884615a4c878ca24e2686e",
                        "aijob.cce.baidubce.com/ai-user-name": "zhuxiang05",
                        "aijob.cce.baidubce.com/create-from-aihcp": "true",
                        "aijob.cce.baidubce.com/openapi-jobid": "pytorch-5a4216f3-fc78-46b1-89b3-5bae67f3751a"
                      }
                    },
                    "spec": {
                      "containers": [
                        {
                          "command": [
                            "/bin/bash",
                            "-c",
                            " source /root/anaconda3/etc/profile.d/conda.sh\n    conda activate llama-factory\n\n    ROOT_DIR=/workspace/LLaMA-Factory/\n\n    CHECKPOINT_LOAD_PATH=/mnt/cluster/ppl/Qwen-14B-Chat\n    CHECKPOINT_SAVE_PATH=/mnt/cluster/ppl/Qwen-14B-Chat_saved_zhuxiang_4\n    DEEPSPEED_CONFIG=$ROOT_DIR/examples/deepspeed/ds_z3_offload_config.json\n\n    GPUS_PER_NODE=8\n\n    is_master=${MASTER-\"0\"}\n    if [[ $is_master -eq 1 ]];then\n      DISTRIBUTED_ARGS=\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $HOSTNAME --master_port $MASTER_PORT\"\n    else\n      DISTRIBUTED_ARGS=\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $MASTER_ADDR --master_port $MASTER_PORT\"\n    fi\n\n    QWEN_14B_ARGS=\"--model_name_or_path $CHECKPOINT_LOAD_PATH \\\n        --stage sft \\\n        --do_train \\\n        --dataset alpaca_en_demo \\\n        --template qwen \\\n        --finetuning_type lora \\\n        --lora_target all \\\n        --overwrite_output_dir \\\n        --dataset_dir $ROOT_DIR/data \\\n        --output_dir $CHECKPOINT_SAVE_PATH \\\n        --preprocessing_num_workers 90 \\\n        --dataloader_num_workers 90 \\\n        --per_device_train_batch_size 1 \\\n        --gradient_accumulation_steps 8 \\\n        --cutoff_len 2048 \\\n        --max_length 2048 \\\n        --deepspeed $DEEPSPEED_CONFIG \\\n        --logging_first_step \\\n        --logging_steps 10 \\\n        --save_strategy steps \\\n        --save_steps 40 \\\n        --num_train_epochs 2.0 \\\n        --lr_scheduler_type cosine \\\n        --learning_rate 1e-5 \\\n        --plot_loss \\\n        --bf16 \\\n        --rope_scaling linear \\\n        --flash_attn auto \\\n        --shift_attn \\\n        --ddp_find_unused_parameters False \\\n        --push_to_hub False\"\n\n    PYTHONPATH=$ROOT_DIR:$PYTHONPATH \\\n        torchrun $DISTRIBUTED_ARGS \\\n        $ROOT_DIR/src/train.py \\\n        $QWEN_14B_ARGS"
                          ],
                          "env": [
                            {
                              "name": "AIHC_JOB_NAME",
                              "value": "deepspeed-zhuxiang-4"
                            },
                            {
                              "name": "NCCL_IB_DISABLE",
                              "value": "0"
                            }
                          ],
                          "image": "registry.baidubce.com/cce-ai-native/aiak-algo:0.1",
                          "imagePullPolicy": "Always",
                          "name": "pytorch",
                          "ports": [
                            {
                              "containerPort": 23456,
                              "name": "pytorchjob-port",
                              "protocol": "TCP"
                            }
                          ],
                          "resources": {
                            "limits": {
                              "baidu.com/a800_80g_cgpu": "8",
                              "rdma/hca": "1"
                            },
                            "requests": {
                              "baidu.com/a800_80g_cgpu": "8",
                              "rdma/hca": "1"
                            }
                          },
                          "securityContext": {
                            "capabilities": {
                              "add": [
                                "IPC_LOCK"
                              ]
                            }
                          },
                          "volumeMounts": [
                            {
                              "mountPath": "/dev/shm",
                              "name": "devshm"
                            },
                            {
                              "mountPath": "/mnt/cluster",
                              "name": "pvc-pfs"
                            }
                          ]
                        }
                      ],
                      "dnsPolicy": "ClusterFirstWithHostNet",
                      "hostNetwork": true,
                      "schedulerName": "volcano",
                      "volumes": [
                        {
                          "emptyDir": {
                            "medium": "Memory",
                            "sizeLimit": "10Gi"
                          },
                          "name": "devshm"
                        },
                        {
                          "name": "pvc-pfs",
                          "persistentVolumeClaim": {
                            "claimName": "pvc-pfs"
                          }
                        }
                      ]
                    }
                  }
                }
              },
              "runPolicy": {
                "cleanPodPolicy": "None",
                "schedulingPolicy": {
                  "priorityClass": "normal",
                  "queue": "default"
                }
              }
            },
            "status": {
              "completionTime": "2024-07-21T16:08:24Z",
              "conditions": [
                {
                  "lastTransitionTime": "2024-07-21T16:01:29Z",
                  "lastUpdateTime": "2024-07-21T16:01:29Z",
                  "message": "PyTorchJob deepspeed-zhuxiang-4 is created.",
                  "reason": "PyTorchJobCreated",
                  "status": "True",
                  "type": "Created"
                },
                {
                  "lastTransitionTime": "2024-07-21T16:02:24Z",
                  "lastUpdateTime": "2024-07-21T16:02:24Z",
                  "message": "PyTorchJob deepspeed-zhuxiang-4 is running.",
                  "reason": "JobRunning",
                  "status": "False",
                  "type": "Running"
                },
                {
                  "lastTransitionTime": "2024-07-21T16:08:24Z",
                  "lastUpdateTime": "2024-07-21T16:08:24Z",
                  "message": "PyTorchJob deepspeed-zhuxiang-4 is successfully completed.",
                  "reason": "JobSucceeded",
                  "status": "True",
                  "type": "Succeeded"
                }
              ],
              "lastReconcileTime": "2024-07-21T16:01:29Z",
              "replicaStatuses": {
                "Master": {
                  "selector": "training.kubeflow.org/job-name=deepspeed-zhuxiang-4,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=master",
                  "succeeded": 1
                },
                "Worker": {
                  "succeeded": 1
                }
              },
              "startTime": "2024-07-21T16:01:29Z"
            }
          },
          {
            "apiVersion": "kubeflow.org/v1",
            "kind": "PyTorchJob",
            "metadata": {
              "annotations": {
                "aijob.cce.baidubce.com/barrier-finish": "7cfa2c4c-680b-4351-815a-0c6f560ae580",
                "aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": "",
                "aijob.cce.baidubce.com/timeline": "[{\"conditionType\":\"Created\",\"time\":1721271291},{\"conditionType\":\"Scheduled\",\"time\":1721271292},{\"conditionType\":\"Running\",\"time\":1721271304},{\"conditionType\":\"Succeeded\",\"time\":1721271664}]",
                "kubectl.kubernetes.io/last-applied-configuration": "{\"apiVersion\":\"kubeflow.org/v1\",\"kind\":\"PyTorchJob\",\"metadata\":{\"annotations\":{},\"name\":\"guoyaning-pytorch-communication-config-test\",\"namespace\":\"default\"},\"spec\":{\"pytorchReplicaSpecs\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"template\":{\"metadata\":null,\"spec\":{\"containers\":[{\"command\":[\"/bin/bash\",\"-c\",\"#! /bin/bash\\npython -m torch.distributed.launch --use_env --nproc_per_node 8 --nnodes 1 --node_rank $RANK --master_addr $MASTER_ADDR --master_port $MASTER_PORT communication.py -n 10 -b 8G -tp 4 -dp 2 -pp 1 -order 1 -d float32 -l debug -interbw 100 -intrabw 200\"],\"env\":[{\"name\":\"NCCL_DEBUG\",\"value\":\"INFO\"},{\"name\":\"NCCL_ALGO\",\"value\":\"RING\"},{\"name\":\"NCCL_IB_DISABLE\",\"value\":\"0\"}],\"image\":\"registry.baidubce.com/cce-ai-native/pytorch:gyn-torch\",\"imagePullPolicy\":\"Always\",\"name\":\"pytorch\",\"resources\":{\"limits\":{\"baidu.com/a800_80g_cgpu\":\"8\",\"rdma/hca\":1},\"requests\":{\"baidu.com/a800_80g_cgpu\":\"8\",\"rdma/hca\":1}},\"securityContext\":{\"capabilities\":{\"add\":[\"IPC_LOCK\"]}},\"volumeMounts\":[{\"mountPath\":\"/dev/shm\",\"name\":\"cache-volume\"}]}],\"schedulerName\":\"volcano\",\"volumes\":[{\"emptyDir\":{\"medium\":\"Memory\"},\"name\":\"cache-volume\"}]}}},\"Worker\":{\"replicas\":0,\"restartPolicy\":\"Never\",\"template\":{\"metadata\":null,\"spec\":{\"containers\":[{\"command\":[\"/bin/bash\",\"-c\",\"#! /bin/bash\\npython -m torch.distributed.launch --use_env --nproc_per_node 8 --nnodes 1 --node_rank $RANK --master_addr $MASTER_ADDR --master_port $MASTER_PORT communication.py -n 10 -b 8G -tp 4 -dp 2 -pp 1 -order 1 -d float32 -l debug -interbw 100 -intrabw 200\"],\"env\":[{\"name\":\"NCCL_DEBUG\",\"value\":\"INFO\"},{\"name\":\"NCCL_ALGO\",\"value\":\"RING\"},{\"name\":\"NCCL_IB_DISABLE\",\"value\":\"0\"}],\"image\":\"registry.baidubce.com/cce-ai-native/pytorch:gyn-torch\",\"imagePullPolicy\":\"Always\",\"name\":\"pytorch\",\"resources\":{\"limits\":{\"baidu.com/a800_80g_cgpu\":\"8\",\"rdma/hca\":1},\"requests\":{\"baidu.com/a800_80g_cgpu\":\"8\",\"rdma/hca\":1}},\"securityContext\":{\"capabilities\":{\"add\":[\"IPC_LOCK\"]}},\"volumeMounts\":[{\"mountPath\":\"/dev/shm\",\"name\":\"cache-volume\"}]}],\"schedulerName\":\"volcano\",\"volumes\":[{\"emptyDir\":{\"medium\":\"Memory\"},\"name\":\"cache-volume\"}]}}}},\"runPolicy\":{\"schedulingPolicy\":{\"queue\":\"default\"}}}}\n"
              },
              "creationTimestamp": "2024-07-18T02:54:51Z",
              "generation": 2,
              "managedFields": [
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        "f:aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": {},
                        "f:aijob.cce.baidubce.com/timeline": {}
                      }
                    },
                    "f:spec": {
                      "f:pytorchReplicaSpecs": {
                        "f:Master": {
                          "f:template": {
                            "f:metadata": {},
                            "f:spec": {
                              "f:containers": {}
                            }
                          }
                        },
                        "f:Worker": {
                          "f:template": {
                            "f:metadata": {},
                            "f:spec": {
                              "f:containers": {}
                            }
                          }
                        }
                      },
                      "f:runPolicy": {
                        "f:cleanPodPolicy": {}
                      }
                    }
                  },
                  "manager": "controller",
                  "operation": "Update",
                  "time": "2024-07-18T02:54:51Z"
                },
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        ".": {},
                        "f:kubectl.kubernetes.io/last-applied-configuration": {}
                      }
                    },
                    "f:spec": {
                      ".": {},
                      "f:pytorchReplicaSpecs": {
                        ".": {},
                        "f:Master": {
                          ".": {},
                          "f:replicas": {},
                          "f:restartPolicy": {},
                          "f:template": {
                            ".": {},
                            "f:spec": {
                              ".": {},
                              "f:schedulerName": {},
                              "f:volumes": {}
                            }
                          }
                        },
                        "f:Worker": {
                          ".": {},
                          "f:replicas": {},
                          "f:restartPolicy": {},
                          "f:template": {
                            ".": {},
                            "f:spec": {
                              ".": {},
                              "f:schedulerName": {},
                              "f:volumes": {}
                            }
                          }
                        }
                      },
                      "f:runPolicy": {
                        ".": {},
                        "f:schedulingPolicy": {
                          ".": {},
                          "f:queue": {}
                        }
                      }
                    }
                  },
                  "manager": "kubectl-client-side-apply",
                  "operation": "Update",
                  "time": "2024-07-18T02:54:51Z"
                },
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        "f:aijob.cce.baidubce.com/barrier-finish": {}
                      }
                    }
                  },
                  "manager": "jobbarrier",
                  "operation": "Update",
                  "time": "2024-07-18T02:55:01Z"
                },
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:status": {
                      ".": {},
                      "f:completionTime": {},
                      "f:conditions": {},
                      "f:lastReconcileTime": {},
                      "f:replicaStatuses": {
                        ".": {},
                        "f:Master": {
                          ".": {},
                          "f:selector": {},
                          "f:succeeded": {}
                        },
                        "f:Worker": {}
                      },
                      "f:startTime": {}
                    }
                  },
                  "manager": "manager",
                  "operation": "Update",
                  "time": "2024-07-18T03:01:04Z"
                }
              ],
              "name": "guoyaning-pytorch-communication-config-test",
              "namespace": "default",
              "resourceVersion": "2371222980",
              "uid": "4601f4a6-70cb-484f-9eea-f976b0b66898"
            },
            "spec": {
              "pytorchReplicaSpecs": {
                "Master": {
                  "replicas": 1,
                  "restartPolicy": "Never",
                  "template": {
                    "metadata": {},
                    "spec": {
                      "containers": [
                        {
                          "command": [
                            "/bin/bash",
                            "-c",
                            "#! /bin/bash\npython -m torch.distributed.launch --use_env --nproc_per_node 8 --nnodes 1 --node_rank $RANK --master_addr $MASTER_ADDR --master_port $MASTER_PORT communication.py -n 10 -b 8G -tp 4 -dp 2 -pp 1 -order 1 -d float32 -l debug -interbw 100 -intrabw 200"
                          ],
                          "env": [
                            {
                              "name": "NCCL_DEBUG",
                              "value": "INFO"
                            },
                            {
                              "name": "NCCL_ALGO",
                              "value": "RING"
                            },
                            {
                              "name": "NCCL_IB_DISABLE",
                              "value": "0"
                            }
                          ],
                          "image": "registry.baidubce.com/cce-ai-native/pytorch:gyn-torch",
                          "imagePullPolicy": "Always",
                          "name": "pytorch",
                          "ports": [
                            {
                              "containerPort": 23456,
                              "name": "pytorchjob-port",
                              "protocol": "TCP"
                            }
                          ],
                          "resources": {
                            "limits": {
                              "baidu.com/a800_80g_cgpu": "8",
                              "rdma/hca": "1"
                            },
                            "requests": {
                              "baidu.com/a800_80g_cgpu": "8",
                              "rdma/hca": "1"
                            }
                          },
                          "securityContext": {
                            "capabilities": {
                              "add": [
                                "IPC_LOCK"
                              ]
                            }
                          },
                          "volumeMounts": [
                            {
                              "mountPath": "/dev/shm",
                              "name": "cache-volume"
                            }
                          ]
                        }
                      ],
                      "schedulerName": "volcano",
                      "volumes": [
                        {
                          "emptyDir": {
                            "medium": "Memory"
                          },
                          "name": "cache-volume"
                        }
                      ]
                    }
                  }
                },
                "Worker": {
                  "replicas": 0,
                  "restartPolicy": "Never",
                  "template": {
                    "metadata": {},
                    "spec": {
                      "containers": [
                        {
                          "command": [
                            "/bin/bash",
                            "-c",
                            "#! /bin/bash\npython -m torch.distributed.launch --use_env --nproc_per_node 8 --nnodes 1 --node_rank $RANK --master_addr $MASTER_ADDR --master_port $MASTER_PORT communication.py -n 10 -b 8G -tp 4 -dp 2 -pp 1 -order 1 -d float32 -l debug -interbw 100 -intrabw 200"
                          ],
                          "env": [
                            {
                              "name": "NCCL_DEBUG",
                              "value": "INFO"
                            },
                            {
                              "name": "NCCL_ALGO",
                              "value": "RING"
                            },
                            {
                              "name": "NCCL_IB_DISABLE",
                              "value": "0"
                            }
                          ],
                          "image": "registry.baidubce.com/cce-ai-native/pytorch:gyn-torch",
                          "imagePullPolicy": "Always",
                          "name": "pytorch",
                          "ports": [
                            {
                              "containerPort": 23456,
                              "name": "pytorchjob-port",
                              "protocol": "TCP"
                            }
                          ],
                          "resources": {
                            "limits": {
                              "baidu.com/a800_80g_cgpu": "8",
                              "rdma/hca": "1"
                            },
                            "requests": {
                              "baidu.com/a800_80g_cgpu": "8",
                              "rdma/hca": "1"
                            }
                          },
                          "securityContext": {
                            "capabilities": {
                              "add": [
                                "IPC_LOCK"
                              ]
                            }
                          },
                          "volumeMounts": [
                            {
                              "mountPath": "/dev/shm",
                              "name": "cache-volume"
                            }
                          ]
                        }
                      ],
                      "schedulerName": "volcano",
                      "volumes": [
                        {
                          "emptyDir": {
                            "medium": "Memory"
                          },
                          "name": "cache-volume"
                        }
                      ]
                    }
                  }
                }
              },
              "runPolicy": {
                "cleanPodPolicy": "None",
                "schedulingPolicy": {
                  "queue": "default"
                }
              }
            },
            "status": {
              "completionTime": "2024-07-18T03:01:04Z",
              "conditions": [
                {
                  "lastTransitionTime": "2024-07-18T02:54:51Z",
                  "lastUpdateTime": "2024-07-18T02:54:51Z",
                  "message": "PyTorchJob guoyaning-pytorch-communication-config-test is created.",
                  "reason": "PyTorchJobCreated",
                  "status": "True",
                  "type": "Created"
                },
                {
                  "lastTransitionTime": "2024-07-18T02:55:04Z",
                  "lastUpdateTime": "2024-07-18T02:55:04Z",
                  "message": "PyTorchJob guoyaning-pytorch-communication-config-test is running.",
                  "reason": "JobRunning",
                  "status": "False",
                  "type": "Running"
                },
                {
                  "lastTransitionTime": "2024-07-18T03:01:04Z",
                  "lastUpdateTime": "2024-07-18T03:01:04Z",
                  "message": "PyTorchJob guoyaning-pytorch-communication-config-test is successfully completed.",
                  "reason": "JobSucceeded",
                  "status": "True",
                  "type": "Succeeded"
                }
              ],
              "lastReconcileTime": "2024-07-18T02:54:51Z",
              "replicaStatuses": {
                "Master": {
                  "selector": "training.kubeflow.org/job-name=guoyaning-pytorch-communication-config-test,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=master",
                  "succeeded": 1
                },
                "Worker": {}
              },
              "startTime": "2024-07-18T02:54:51Z"
            }
          },
          {
            "apiVersion": "kubeflow.org/v1",
            "kind": "PyTorchJob",
            "metadata": {
              "annotations": {
                "aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": "",
                "aijob.cce.baidubce.com/timeline": "[{\"conditionType\":\"Created\",\"time\":1721637753},{\"conditionType\":\"Scheduled\",\"time\":1721637755},{\"conditionType\":\"Running\",\"time\":1721637765}]",
                "kubectl.kubernetes.io/last-applied-configuration": "{\"apiVersion\":\"kubeflow.org/v1\",\"kind\":\"PyTorchJob\",\"metadata\":{\"annotations\":{},\"name\":\"gushilei-72hours-llama2-test2\",\"namespace\":\"default\"},\"spec\":{\"pytorchReplicaSpecs\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"template\":{\"metadata\":null,\"spec\":{\"containers\":[{\"command\":[\"bash\",\"/workspace/launch.sh\"],\"env\":[{\"name\":\"CUDA_DEVICE_MAX_CONNECTIONS\",\"value\":\"1\"},{\"name\":\"NCCL_DEBUG\",\"value\":\"INFO\"},{\"name\":\"NCCL_IB_DISABLE\",\"value\":\"0\"},{\"name\":\"MASTER\",\"value\":\"1\"}],\"image\":\"registry.baidubce.com/cce-ai-native/gsl-deepspeed-sq:05\",\"imagePullPolicy\":\"Always\",\"name\":\"pytorch\",\"resources\":{\"limits\":{\"nvidia.com/gpu\":8,\"rdma/hca\":1}},\"securityContext\":{\"capabilities\":{\"add\":[\"IPC_LOCK\"]}},\"volumeMounts\":[{\"mountPath\":\"/dev/shm\",\"name\":\"cache-volume\"},{\"mountPath\":\"/workspace/launch.sh\",\"name\":\"config-volume\",\"subPath\":\"launch.sh\"},{\"mountPath\":\"/mnt/cluster\",\"name\":\"data\"}]}],\"schedulerName\":\"volcano\",\"volumes\":[{\"emptyDir\":{\"medium\":\"Memory\"},\"name\":\"cache-volume\"},{\"configMap\":{\"name\":\"gsl-launch-cm-7b-test2-d2\"},\"name\":\"config-volume\"},{\"name\":\"data\",\"persistentVolumeClaim\":{\"claimName\":\"pvc-pfs\"}}]}}}}}}\n"
              },
              "creationTimestamp": "2024-07-22T08:42:33Z",
              "generation": 2,
              "managedFields": [
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        "f:aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": {},
                        "f:aijob.cce.baidubce.com/timeline": {}
                      }
                    },
                    "f:spec": {
                      "f:pytorchReplicaSpecs": {
                        "f:Master": {
                          "f:template": {
                            "f:metadata": {},
                            "f:spec": {
                              "f:containers": {}
                            }
                          }
                        }
                      },
                      "f:runPolicy": {
                        ".": {},
                        "f:cleanPodPolicy": {}
                      }
                    }
                  },
                  "manager": "controller",
                  "operation": "Update",
                  "time": "2024-07-22T08:42:33Z"
                },
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        ".": {},
                        "f:kubectl.kubernetes.io/last-applied-configuration": {}
                      }
                    },
                    "f:spec": {
                      ".": {},
                      "f:pytorchReplicaSpecs": {
                        ".": {},
                        "f:Master": {
                          ".": {},
                          "f:replicas": {},
                          "f:restartPolicy": {},
                          "f:template": {
                            ".": {},
                            "f:spec": {
                              ".": {},
                              "f:schedulerName": {},
                              "f:volumes": {}
                            }
                          }
                        }
                      }
                    }
                  },
                  "manager": "kubectl-client-side-apply",
                  "operation": "Update",
                  "time": "2024-07-22T08:42:33Z"
                },
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:status": {
                      ".": {},
                      "f:conditions": {},
                      "f:lastReconcileTime": {},
                      "f:replicaStatuses": {
                        ".": {},
                        "f:Master": {
                          ".": {},
                          "f:active": {},
                          "f:selector": {}
                        }
                      },
                      "f:startTime": {}
                    }
                  },
                  "manager": "manager",
                  "operation": "Update",
                  "time": "2024-07-22T08:42:45Z"
                }
              ],
              "name": "gushilei-72hours-llama2-test2",
              "namespace": "default",
              "resourceVersion": "2376098975",
              "uid": "24515d31-9df9-4ccb-8848-01b7083145d2"
            },
            "spec": {
              "pytorchReplicaSpecs": {
                "Master": {
                  "replicas": 1,
                  "restartPolicy": "Never",
                  "template": {
                    "metadata": {},
                    "spec": {
                      "containers": [
                        {
                          "command": [
                            "bash",
                            "/workspace/launch.sh"
                          ],
                          "env": [
                            {
                              "name": "CUDA_DEVICE_MAX_CONNECTIONS",
                              "value": "1"
                            },
                            {
                              "name": "NCCL_DEBUG",
                              "value": "INFO"
                            },
                            {
                              "name": "NCCL_IB_DISABLE",
                              "value": "0"
                            },
                            {
                              "name": "MASTER",
                              "value": "1"
                            }
                          ],
                          "image": "registry.baidubce.com/cce-ai-native/gsl-deepspeed-sq:05",
                          "imagePullPolicy": "Always",
                          "name": "pytorch",
                          "ports": [
                            {
                              "containerPort": 23456,
                              "name": "pytorchjob-port",
                              "protocol": "TCP"
                            }
                          ],
                          "resources": {
                            "limits": {
                              "nvidia.com/gpu": "8",
                              "rdma/hca": "1"
                            }
                          },
                          "securityContext": {
                            "capabilities": {
                              "add": [
                                "IPC_LOCK"
                              ]
                            }
                          },
                          "volumeMounts": [
                            {
                              "mountPath": "/dev/shm",
                              "name": "cache-volume"
                            },
                            {
                              "mountPath": "/workspace/launch.sh",
                              "name": "config-volume",
                              "subPath": "launch.sh"
                            },
                            {
                              "mountPath": "/mnt/cluster",
                              "name": "data"
                            }
                          ]
                        }
                      ],
                      "schedulerName": "volcano",
                      "volumes": [
                        {
                          "emptyDir": {
                            "medium": "Memory"
                          },
                          "name": "cache-volume"
                        },
                        {
                          "configMap": {
                            "name": "gsl-launch-cm-7b-test2-d2"
                          },
                          "name": "config-volume"
                        },
                        {
                          "name": "data",
                          "persistentVolumeClaim": {
                            "claimName": "pvc-pfs"
                          }
                        }
                      ]
                    }
                  }
                }
              },
              "runPolicy": {
                "cleanPodPolicy": "None"
              }
            },
            "status": {
              "conditions": [
                {
                  "lastTransitionTime": "2024-07-22T08:42:33Z",
                  "lastUpdateTime": "2024-07-22T08:42:33Z",
                  "message": "PyTorchJob gushilei-72hours-llama2-test2 is created.",
                  "reason": "PyTorchJobCreated",
                  "status": "True",
                  "type": "Created"
                },
                {
                  "lastTransitionTime": "2024-07-22T08:42:45Z",
                  "lastUpdateTime": "2024-07-22T08:42:45Z",
                  "message": "PyTorchJob gushilei-72hours-llama2-test2 is running.",
                  "reason": "JobRunning",
                  "status": "True",
                  "type": "Running"
                }
              ],
              "lastReconcileTime": "2024-07-22T08:42:33Z",
              "replicaStatuses": {
                "Master": {
                  "active": 1,
                  "selector": "training.kubeflow.org/job-name=gushilei-72hours-llama2-test2,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=master"
                }
              },
              "startTime": "2024-07-22T08:42:34Z"
            }
          },
          {
            "apiVersion": "kubeflow.org/v1",
            "kind": "PyTorchJob",
            "metadata": {
              "annotations": {
                "aijob.cce.baidubce.com/barrier-finish": "2e07e965-0cfd-41c0-86d0-19d2092780d0",
                "aijob.cce.baidubce.com/fault-tolerance-enabled": "true",
                "aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": "",
                "aijob.cce.baidubce.com/internal-fault-tolerance-time": "2024-07-18T02:17:39.225207493Z",
                "aijob.cce.baidubce.com/openapi-jobid": "pytorch-5961a180-13bb-49a1-8c5d-58ad07e652e4",
                "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
                "aijob.cce.baidubce.com/raw-request": "{\"name\":\"llamatest0718forxiaomi\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"high\",\"oversell\":false,\"faultTolerance\":true,\"command\":\"\\n#! /bin/bash\\n\\nMEGATRON_PATH=${MEGATRON_PATH:-\\\"/workspace/AIAK-Megatron\\\"}\\nAIAK_TRAINING_PATH=${AIAK_TRAINING_PATH:-\\\"/workspace/AIAK-Training-LLM\\\"}\\n\\nDATA_PATH=${DATA_PATH:-\\\"/mnt/cluster/llama2/pile/pile-llama_text_document\\\"}\\nTOKENIZER_PATH=${TOKENIZER_PATH:-\\\"/mnt/cluster/llama2/Llama-2-70b-hf/\\\"}\\n\\nCHECKPOINT_PATH=${CHECKPOINT_PATH:-\\\"/mnt/cluster/llama2/mcore_llama2_70b_tp4_pp4\\\"}\\n\\nTENSORBOARD_PATH=${TENSORBOARD_PATH:-\\\"/mnt/cluster/aiak-training-llm/tensorboard-log/llama2-70b-tp4pp4\\\"}\\n\\nGPUS_PER_NODE=8\\n\\n# Change for multinode config\\nMASTER_ADDR=${MASTER_ADDR:-\\\"localhost\\\"}\\nMASTER_PORT=${MASTER_PORT:-\\\"6000\\\"}\\nNNODES=${WORLD_SIZE:-\\\"1\\\"}\\nNODE_RANK=${RANK:-\\\"0\\\"}\\n\\nDISTRIBUTED_ARGS=(\\n    --nproc_per_node $GPUS_PER_NODE\\n    --nnodes $NNODES\\n    --node_rank $NODE_RANK\\n    --master_addr $MASTER_ADDR\\n    --master_port $MASTER_PORT\\n)\\n\\n# you can setup llama2-70b maunally\\n#MODEL_ARGS=(\\n#    --model-name llama2\\n#    --num-layers 80\\n#    --hidden-size 8192\\n#    --ffn-hidden-size 28672\\n#    --num-attention-heads 64\\n#    --position-embedding-type rope\\n#    --normalization RMSNorm\\n#    --swiglu\\n#    --attention-dropout 0\\n#    --hidden-dropout 0\\n#    --disable-bias-linear\\n#    --untie-embeddings-and-output-weights\\n#    --group-query-attention\\n#    --num-query-groups 8\\n#)\\n\\n# or you can setup llama2-70b by using the following command\\nMODEL_ARGS=(\\n    --model-name llama2-70b # options: llama2-7b, llama2-13b, llama2-70b\\n)\\n\\nDATA_ARGS=(\\n    --tokenizer-type HFTokenizer\\n    --hf-tokenizer-path $TOKENIZER_PATH\\n    --data-path $DATA_PATH\\n    --split 949,50,1\\n)\\n\\nTRAINING_ARGS=(\\n    --training-phase pretrain # options: pretrain, sft\\n    --seq-length 4096\\n    --max-position-embeddings 4096\\n    --init-method-std 0.01\\n    --micro-batch-size 1\\n    --global-batch-size 1024\\n    --lr 0.0002\\n    --min-lr 1.0e-5\\n    --clip-grad 1.0\\n    --weight-decay 0.01\\n    --optimizer adam\\n    --adam-beta1 0.9\\n    --adam-beta2 0.95\\n    --adam-eps 1e-05\\n    --norm-epsilon 1e-6\\n    --train-iters 500000\\n    --lr-decay-iters 500000\\n    --lr-decay-style cosine\\n    --lr-warmup-fraction 0.002\\n    --initial-loss-scale 65536\\n    --fp16\\n    --save-interval 5000\\n    --eval-interval 1000\\n    --eval-iters 10\\n    #--ckpt-step 0\\n    #--no-load-optim\\n    #--no-load-rng\\n)\\n\\nMODEL_PARALLEL_ARGS=(\\n    --tensor-model-parallel-size 4\\n    --pipeline-model-parallel-size 4\\n    --use-distributed-optimizer\\n    --overlap-grad-reduce\\n    --overlap-param-gather\\n    --distributed-backend nccl\\n    --sequence-parallel\\n    #--tp-comm-overlap # require mpi envrionment\\n)\\n\\nLOGGING_ARGS=(\\n    --log-interval 1\\n    --tensorboard-dir ${TENSORBOARD_PATH}\\n    --log-timers-to-tensorboard\\n)\\n\\nif [ -n \\\"${WANDB_API_KEY}\\\" ]; then\\n    LOGGING_ARGS+=(\\n        --wandb-project ${WANDB_PROJECT}\\n        --wandb-exp-name ${WANDB_NAME} \\n    )\\nfi\\n\\nPYTHONPATH=$MEGATRON_PATH:$AIAK_TRAINING_PATH:$PYTHONPATH     torchrun ${DISTRIBUTED_ARGS[@]}     $AIAK_TRAINING_PATH/aiak_training_llm/train.py     ${MODEL_ARGS[@]}     ${DATA_ARGS[@]}     ${TRAINING_ARGS[@]}     ${MODEL_PARALLEL_ARGS[@]}     ${LOGGING_ARGS[@]}\\n\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":true,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi/output/training_logs\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"},\"Worker\":{\"replicas\":3,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi/output/training_logs\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":true,\"logPath\":\"/mnt/cluster/llamatest0718forxiaomi/output/training_logs\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":true,\"isCopyJob\":false,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
                "aijob.cce.baidubce.com/timeline": "[{\"conditionType\":\"Created\",\"time\":1721268630},{\"conditionType\":\"Scheduled\",\"time\":1721268981},{\"conditionType\":\"Running\",\"time\":1721269028},{\"conditionType\":\"Abnormal\",\"time\":1721269059},{\"conditionType\":\"ManualTermination\",\"time\":1721269176}]",
                "job-manager/action": "stop",
                "scheduling.k8s.io/job-enable-oversell": "false",
                "tensorboard-gc": "true"
              },
              "creationTimestamp": "2024-07-18T02:10:30Z",
              "generation": 4,
              "labels": {
                "aijob.cce.baidubce.com/ai-user-id": "b5a24aa26e4d4f55bc3acf68edc4b051",
                "aijob.cce.baidubce.com/ai-user-name": "zhangmuhua",
                "aijob.cce.baidubce.com/create-from-aihcp": "true",
                "aijob.cce.baidubce.com/openapi-jobid": "pytorch-5961a180-13bb-49a1-8c5d-58ad07e652e4"
              },
              "managedFields": [
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        "f:aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": {},
                        "f:aijob.cce.baidubce.com/timeline": {}
                      }
                    },
                    "f:spec": {
                      "f:runPolicy": {
                        "f:cleanPodPolicy": {}
                      }
                    }
                  },
                  "manager": "controller",
                  "operation": "Update",
                  "time": "2024-07-18T02:10:30Z"
                },
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        "f:aijob.cce.baidubce.com/barrier-finish": {}
                      }
                    }
                  },
                  "manager": "jobbarrier",
                  "operation": "Update",
                  "time": "2024-07-18T02:17:04Z"
                },
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        ".": {},
                        "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                        "f:aijob.cce.baidubce.com/openapi-jobid": {},
                        "f:aijob.cce.baidubce.com/pfs-id": {},
                        "f:aijob.cce.baidubce.com/raw-request": {},
                        "f:job-manager/action": {},
                        "f:scheduling.k8s.io/job-enable-oversell": {}
                      },
                      "f:labels": {
                        ".": {},
                        "f:aijob.cce.baidubce.com/ai-user-id": {},
                        "f:aijob.cce.baidubce.com/ai-user-name": {},
                        "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                        "f:aijob.cce.baidubce.com/openapi-jobid": {}
                      }
                    },
                    "f:spec": {
                      ".": {},
                      "f:pytorchReplicaSpecs": {
                        ".": {},
                        "f:Master": {
                          ".": {},
                          "f:replicas": {},
                          "f:restartPolicy": {},
                          "f:template": {
                            ".": {},
                            "f:metadata": {
                              ".": {},
                              "f:annotations": {
                                ".": {},
                                "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                                "f:aijob.cce.baidubce.com/openapi-jobid": {},
                                "f:aijob.cce.baidubce.com/pfs-id": {},
                                "f:aijob.cce.baidubce.com/raw-request": {},
                                "f:scheduling.k8s.io/job-enable-oversell": {}
                              },
                              "f:labels": {
                                ".": {},
                                "f:aijob.cce.baidubce.com/ai-user-id": {},
                                "f:aijob.cce.baidubce.com/ai-user-name": {},
                                "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                                "f:aijob.cce.baidubce.com/openapi-jobid": {}
                              }
                            },
                            "f:spec": {
                              ".": {},
                              "f:dnsPolicy": {},
                              "f:hostNetwork": {},
                              "f:schedulerName": {}
                            }
                          }
                        },
                        "f:Worker": {
                          ".": {},
                          "f:replicas": {},
                          "f:restartPolicy": {},
                          "f:template": {
                            ".": {},
                            "f:metadata": {
                              ".": {},
                              "f:annotations": {
                                ".": {},
                                "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                                "f:aijob.cce.baidubce.com/openapi-jobid": {},
                                "f:aijob.cce.baidubce.com/pfs-id": {},
                                "f:aijob.cce.baidubce.com/raw-request": {},
                                "f:scheduling.k8s.io/job-enable-oversell": {}
                              },
                              "f:labels": {
                                ".": {},
                                "f:aijob.cce.baidubce.com/ai-user-id": {},
                                "f:aijob.cce.baidubce.com/ai-user-name": {},
                                "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                                "f:aijob.cce.baidubce.com/openapi-jobid": {}
                              }
                            },
                            "f:spec": {
                              ".": {},
                              "f:dnsPolicy": {},
                              "f:hostNetwork": {},
                              "f:schedulerName": {}
                            }
                          }
                        }
                      },
                      "f:runPolicy": {
                        ".": {},
                        "f:schedulingPolicy": {
                          ".": {},
                          "f:priorityClass": {},
                          "f:queue": {}
                        }
                      }
                    }
                  },
                  "manager": "cce-ai-service",
                  "operation": "Update",
                  "time": "2024-07-18T02:19:36Z"
                },
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        "f:aijob.cce.baidubce.com/internal-fault-tolerance-time": {},
                        "f:tensorboard-gc": {}
                      }
                    },
                    "f:spec": {
                      "f:pytorchReplicaSpecs": {
                        "f:Master": {
                          "f:template": {
                            "f:metadata": {
                              "f:annotations": {
                                "f:prometheus.io/path": {},
                                "f:prometheus.io/port": {},
                                "f:prometheus.io/scrape": {}
                              }
                            },
                            "f:spec": {
                              "f:containers": {},
                              "f:serviceAccountName": {},
                              "f:shareProcessNamespace": {},
                              "f:volumes": {}
                            }
                          }
                        },
                        "f:Worker": {
                          "f:template": {
                            "f:metadata": {
                              "f:annotations": {
                                "f:prometheus.io/path": {},
                                "f:prometheus.io/port": {},
                                "f:prometheus.io/scrape": {}
                              }
                            },
                            "f:spec": {
                              "f:containers": {},
                              "f:serviceAccountName": {},
                              "f:shareProcessNamespace": {},
                              "f:volumes": {}
                            }
                          }
                        }
                      }
                    },
                    "f:status": {
                      ".": {},
                      "f:completionTime": {},
                      "f:conditions": {},
                      "f:lastReconcileTime": {},
                      "f:replicaStatuses": {
                        ".": {},
                        "f:Master": {
                          ".": {},
                          "f:failed": {}
                        },
                        "f:Worker": {
                          ".": {},
                          "f:failed": {}
                        }
                      },
                      "f:startTime": {}
                    }
                  },
                  "manager": "manager",
                  "operation": "Update",
                  "time": "2024-07-19T02:10:55Z"
                }
              ],
              "name": "llamatest0718forxiaomi",
              "namespace": "default",
              "resourceVersion": "2372379743",
              "uid": "37163e59-3e0b-4d85-94a9-093619062227"
            },
            "spec": {
              "pytorchReplicaSpecs": {
                "Master": {
                  "replicas": 1,
                  "restartPolicy": "Never",
                  "template": {
                    "metadata": {
                      "annotations": {
                        "aijob.cce.baidubce.com/fault-tolerance-enabled": "true",
                        "aijob.cce.baidubce.com/openapi-jobid": "pytorch-5961a180-13bb-49a1-8c5d-58ad07e652e4",
                        "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
                        "aijob.cce.baidubce.com/raw-request": "{\"name\":\"llamatest0718forxiaomi\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"normal\",\"oversell\":false,\"faultTolerance\":true,\"command\":\"\\n#! /bin/bash\\n\\nMEGATRON_PATH=${MEGATRON_PATH:-\\\"/workspace/AIAK-Megatron\\\"}\\nAIAK_TRAINING_PATH=${AIAK_TRAINING_PATH:-\\\"/workspace/AIAK-Training-LLM\\\"}\\n\\nDATA_PATH=${DATA_PATH:-\\\"/mnt/cluster/llama2/pile/pile-llama_text_document\\\"}\\nTOKENIZER_PATH=${TOKENIZER_PATH:-\\\"/mnt/cluster/llama2/Llama-2-70b-hf/\\\"}\\n\\nCHECKPOINT_PATH=${CHECKPOINT_PATH:-\\\"/mnt/cluster/llama2/mcore_llama2_70b_tp4_pp4\\\"}\\n\\nTENSORBOARD_PATH=${TENSORBOARD_PATH:-\\\"/mnt/cluster/aiak-training-llm/tensorboard-log/llama2-70b-tp4pp4\\\"}\\n\\nGPUS_PER_NODE=8\\n\\n# Change for multinode config\\nMASTER_ADDR=${MASTER_ADDR:-\\\"localhost\\\"}\\nMASTER_PORT=${MASTER_PORT:-\\\"6000\\\"}\\nNNODES=${WORLD_SIZE:-\\\"1\\\"}\\nNODE_RANK=${RANK:-\\\"0\\\"}\\n\\nDISTRIBUTED_ARGS=(\\n    --nproc_per_node $GPUS_PER_NODE\\n    --nnodes $NNODES\\n    --node_rank $NODE_RANK\\n    --master_addr $MASTER_ADDR\\n    --master_port $MASTER_PORT\\n)\\n\\n# you can setup llama2-70b maunally\\n#MODEL_ARGS=(\\n#    --model-name llama2\\n#    --num-layers 80\\n#    --hidden-size 8192\\n#    --ffn-hidden-size 28672\\n#    --num-attention-heads 64\\n#    --position-embedding-type rope\\n#    --normalization RMSNorm\\n#    --swiglu\\n#    --attention-dropout 0\\n#    --hidden-dropout 0\\n#    --disable-bias-linear\\n#    --untie-embeddings-and-output-weights\\n#    --group-query-attention\\n#    --num-query-groups 8\\n#)\\n\\n# or you can setup llama2-70b by using the following command\\nMODEL_ARGS=(\\n    --model-name llama2-70b # options: llama2-7b, llama2-13b, llama2-70b\\n)\\n\\nDATA_ARGS=(\\n    --tokenizer-type HFTokenizer\\n    --hf-tokenizer-path $TOKENIZER_PATH\\n    --data-path $DATA_PATH\\n    --split 949,50,1\\n)\\n\\nTRAINING_ARGS=(\\n    --training-phase pretrain # options: pretrain, sft\\n    --seq-length 4096\\n    --max-position-embeddings 4096\\n    --init-method-std 0.01\\n    --micro-batch-size 1\\n    --global-batch-size 1024\\n    --lr 0.0002\\n    --min-lr 1.0e-5\\n    --clip-grad 1.0\\n    --weight-decay 0.01\\n    --optimizer adam\\n    --adam-beta1 0.9\\n    --adam-beta2 0.95\\n    --adam-eps 1e-05\\n    --norm-epsilon 1e-6\\n    --train-iters 500000\\n    --lr-decay-iters 500000\\n    --lr-decay-style cosine\\n    --lr-warmup-fraction 0.002\\n    --initial-loss-scale 65536\\n    --fp16\\n    --save-interval 5000\\n    --eval-interval 1000\\n    --eval-iters 10\\n    #--ckpt-step 0\\n    #--no-load-optim\\n    #--no-load-rng\\n)\\n\\nMODEL_PARALLEL_ARGS=(\\n    --tensor-model-parallel-size 4\\n    --pipeline-model-parallel-size 4\\n    --use-distributed-optimizer\\n    --overlap-grad-reduce\\n    --overlap-param-gather\\n    --distributed-backend nccl\\n    --sequence-parallel\\n    #--tp-comm-overlap # require mpi envrionment\\n)\\n\\nLOGGING_ARGS=(\\n    --log-interval 1\\n    --tensorboard-dir ${TENSORBOARD_PATH}\\n    --log-timers-to-tensorboard\\n)\\n\\nif [ -n \\\"${WANDB_API_KEY}\\\" ]; then\\n    LOGGING_ARGS+=(\\n        --wandb-project ${WANDB_PROJECT}\\n        --wandb-exp-name ${WANDB_NAME} \\n    )\\nfi\\n\\nPYTHONPATH=$MEGATRON_PATH:$AIAK_TRAINING_PATH:$PYTHONPATH     torchrun ${DISTRIBUTED_ARGS[@]}     $AIAK_TRAINING_PATH/aiak_training_llm/train.py     ${MODEL_ARGS[@]}     ${DATA_ARGS[@]}     ${TRAINING_ARGS[@]}     ${MODEL_PARALLEL_ARGS[@]}     ${LOGGING_ARGS[@]}\\n\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":true,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi/output/training_logs\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"},\"Worker\":{\"replicas\":3,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi/output/training_logs\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":true,\"logPath\":\"/mnt/cluster/llamatest0718forxiaomi/output/training_logs\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":true,\"isCopyJob\":false,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
                        "prometheus.io/path": "/metrics",
                        "prometheus.io/port": "9101",
                        "prometheus.io/scrape": "true",
                        "scheduling.k8s.io/job-enable-oversell": "false"
                      },
                      "labels": {
                        "aijob.cce.baidubce.com/ai-user-id": "b5a24aa26e4d4f55bc3acf68edc4b051",
                        "aijob.cce.baidubce.com/ai-user-name": "zhangmuhua",
                        "aijob.cce.baidubce.com/create-from-aihcp": "true",
                        "aijob.cce.baidubce.com/openapi-jobid": "pytorch-5961a180-13bb-49a1-8c5d-58ad07e652e4"
                      }
                    },
                    "spec": {
                      "containers": [
                        {
                          "command": [
                            "/bin/bash",
                            "-c",
                            "\n#! /bin/bash\n\nMEGATRON_PATH=${MEGATRON_PATH:-\"/workspace/AIAK-Megatron\"}\nAIAK_TRAINING_PATH=${AIAK_TRAINING_PATH:-\"/workspace/AIAK-Training-LLM\"}\n\nDATA_PATH=${DATA_PATH:-\"/mnt/cluster/llama2/pile/pile-llama_text_document\"}\nTOKENIZER_PATH=${TOKENIZER_PATH:-\"/mnt/cluster/llama2/Llama-2-70b-hf/\"}\n\nCHECKPOINT_PATH=${CHECKPOINT_PATH:-\"/mnt/cluster/llama2/mcore_llama2_70b_tp4_pp4\"}\n\nTENSORBOARD_PATH=${TENSORBOARD_PATH:-\"/mnt/cluster/aiak-training-llm/tensorboard-log/llama2-70b-tp4pp4\"}\n\nGPUS_PER_NODE=8\n\n# Change for multinode config\nMASTER_ADDR=${MASTER_ADDR:-\"localhost\"}\nMASTER_PORT=${MASTER_PORT:-\"6000\"}\nNNODES=${WORLD_SIZE:-\"1\"}\nNODE_RANK=${RANK:-\"0\"}\n\nDISTRIBUTED_ARGS=(\n    --nproc_per_node $GPUS_PER_NODE\n    --nnodes $NNODES\n    --node_rank $NODE_RANK\n    --master_addr $MASTER_ADDR\n    --master_port $MASTER_PORT\n)\n\n# you can setup llama2-70b maunally\n#MODEL_ARGS=(\n#    --model-name llama2\n#    --num-layers 80\n#    --hidden-size 8192\n#    --ffn-hidden-size 28672\n#    --num-attention-heads 64\n#    --position-embedding-type rope\n#    --normalization RMSNorm\n#    --swiglu\n#    --attention-dropout 0\n#    --hidden-dropout 0\n#    --disable-bias-linear\n#    --untie-embeddings-and-output-weights\n#    --group-query-attention\n#    --num-query-groups 8\n#)\n\n# or you can setup llama2-70b by using the following command\nMODEL_ARGS=(\n    --model-name llama2-70b # options: llama2-7b, llama2-13b, llama2-70b\n)\n\nDATA_ARGS=(\n    --tokenizer-type HFTokenizer\n    --hf-tokenizer-path $TOKENIZER_PATH\n    --data-path $DATA_PATH\n    --split 949,50,1\n)\n\nTRAINING_ARGS=(\n    --training-phase pretrain # options: pretrain, sft\n    --seq-length 4096\n    --max-position-embeddings 4096\n    --init-method-std 0.01\n    --micro-batch-size 1\n    --global-batch-size 1024\n    --lr 0.0002\n    --min-lr 1.0e-5\n    --clip-grad 1.0\n    --weight-decay 0.01\n    --optimizer adam\n    --adam-beta1 0.9\n    --adam-beta2 0.95\n    --adam-eps 1e-05\n    --norm-epsilon 1e-6\n    --train-iters 500000\n    --lr-decay-iters 500000\n    --lr-decay-style cosine\n    --lr-warmup-fraction 0.002\n    --initial-loss-scale 65536\n    --fp16\n    --save-interval 5000\n    --eval-interval 1000\n    --eval-iters 10\n    #--ckpt-step 0\n    #--no-load-optim\n    #--no-load-rng\n)\n\nMODEL_PARALLEL_ARGS=(\n    --tensor-model-parallel-size 4\n    --pipeline-model-parallel-size 4\n    --use-distributed-optimizer\n    --overlap-grad-reduce\n    --overlap-param-gather\n    --distributed-backend nccl\n    --sequence-parallel\n    #--tp-comm-overlap # require mpi envrionment\n)\n\nLOGGING_ARGS=(\n    --log-interval 1\n    --tensorboard-dir ${TENSORBOARD_PATH}\n    --log-timers-to-tensorboard\n)\n\nif [ -n \"${WANDB_API_KEY}\" ]; then\n    LOGGING_ARGS+=(\n        --wandb-project ${WANDB_PROJECT}\n        --wandb-exp-name ${WANDB_NAME} \n    )\nfi\n\nPYTHONPATH=$MEGATRON_PATH:$AIAK_TRAINING_PATH:$PYTHONPATH     torchrun ${DISTRIBUTED_ARGS[@]}     $AIAK_TRAINING_PATH/aiak_training_llm/train.py     ${MODEL_ARGS[@]}     ${DATA_ARGS[@]}     ${TRAINING_ARGS[@]}     ${MODEL_PARALLEL_ARGS[@]}     ${LOGGING_ARGS[@]}\n"
                          ],
                          "env": [
                            {
                              "name": "AIHC_TENSORBOARD_LOG_PATH",
                              "value": "/mnt/cluster/llamatest0718forxiaomi/output/training_logs"
                            },
                            {
                              "name": "AIHC_JOB_NAME",
                              "value": "llamatest0718forxiaomi"
                            },
                            {
                              "name": "NCCL_IB_DISABLE",
                              "value": "0"
                            },
                            {
                              "name": "BCCL_BUS_BW_CALCULATE_MODE",
                              "value": "Agg"
                            },
                            {
                              "name": "BCCL_PROFILING_FILE",
                              "value": "/var/bccl/logs/busbw.cal.%h.%p"
                            }
                          ],
                          "image": "registry.baidubce.com/aihc-aiak/aiak-training-llm:ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release",
                          "imagePullPolicy": "Always",
                          "name": "pytorch",
                          "ports": [
                            {
                              "containerPort": 23456,
                              "name": "pytorchjob-port",
                              "protocol": "TCP"
                            }
                          ],
                          "resources": {
                            "limits": {
                              "baidu.com/a800_80g_cgpu": "8",
                              "rdma/hca": "1"
                            },
                            "requests": {
                              "baidu.com/a800_80g_cgpu": "8",
                              "rdma/hca": "1"
                            }
                          },
                          "securityContext": {
                            "capabilities": {
                              "add": [
                                "IPC_LOCK"
                              ]
                            }
                          },
                          "volumeMounts": [
                            {
                              "mountPath": "/dev/shm",
                              "name": "devshm"
                            },
                            {
                              "mountPath": "/mnt/cluster",
                              "name": "pvc-pfs"
                            },
                            {
                              "mountPath": "/var/bccl/logs",
                              "name": "bccl-logs-volume"
                            }
                          ]
                        },
                        {
                          "env": [
                            {
                              "name": "POD_NAME",
                              "valueFrom": {
                                "fieldRef": {
                                  "apiVersion": "v1",
                                  "fieldPath": "metadata.name"
                                }
                              }
                            },
                            {
                              "name": "POD_UID",
                              "valueFrom": {
                                "fieldRef": {
                                  "apiVersion": "v1",
                                  "fieldPath": "metadata.uid"
                                }
                              }
                            },
                            {
                              "name": "POD_NAMESPACE",
                              "valueFrom": {
                                "fieldRef": {
                                  "apiVersion": "v1",
                                  "fieldPath": "metadata.namespace"
                                }
                              }
                            },
                            {
                              "name": "NODE_NAME",
                              "valueFrom": {
                                "fieldRef": {
                                  "apiVersion": "v1",
                                  "fieldPath": "spec.nodeName"
                                }
                              }
                            },
                            {
                              "name": "JOB_NAME",
                              "value": "llamatest0718forxiaomi"
                            },
                            {
                              "name": "NODE_IP",
                              "valueFrom": {
                                "fieldRef": {
                                  "apiVersion": "v1",
                                  "fieldPath": "status.hostIP"
                                }
                              }
                            },
                            {
                              "name": "ENABLE_ELASTIC",
                              "value": "9"
                            },
                            {
                              "name": "GPUS_PER_NODE",
                              "value": "8"
                            },
                            {
                              "name": "BCCL_LOG_DIR",
                              "value": "/var/bccl/logs"
                            },
                            {
                              "name": "EXPORTER_PORT",
                              "value": "9101"
                            },
                            {
                              "name": "EXPORTER_INTERVAL",
                              "value": "60"
                            },
                            {
                              "name": "EXPORTER_PATH",
                              "value": "/metrics"
                            },
                            {
                              "name": "BCCL_BUS_BW_CALCULATE_MODE",
                              "value": "Agg"
                            },
                            {
                              "name": "BCCL_PROFILING_FILE",
                              "value": "/var/bccl/logs/busbw.cal.%h.%p"
                            }
                          ],
                          "image": "registry.baidubce.com/cce-plugin-dev/ftagent:v1.6-20240713172215",
                          "imagePullPolicy": "Always",
                          "name": "ftagent",
                          "ports": [
                            {
                              "containerPort": 9101,
                              "name": "exporter",
                              "protocol": "TCP"
                            }
                          ],
                          "resources": {},
                          "securityContext": {
                            "capabilities": {
                              "add": [
                                "IPC_LOCK"
                              ]
                            }
                          },
                          "volumeMounts": [
                            {
                              "mountPath": "/var/log/pods",
                              "name": "pod-log-volume"
                            },
                            {
                              "mountPath": "/home/cce",
                              "name": "container-log-volume"
                            },
                            {
                              "mountPath": "/var/bccl/logs",
                              "name": "bccl-logs-volume"
                            }
                          ]
                        }
                      ],
                      "dnsPolicy": "ClusterFirstWithHostNet",
                      "hostNetwork": true,
                      "schedulerName": "volcano",
                      "serviceAccountName": "ftagent-sa",
                      "shareProcessNamespace": true,
                      "volumes": [
                        {
                          "emptyDir": {
                            "medium": "Memory",
                            "sizeLimit": "10Gi"
                          },
                          "name": "devshm"
                        },
                        {
                          "name": "pvc-pfs",
                          "persistentVolumeClaim": {
                            "claimName": "pvc-pfs"
                          }
                        },
                        {
                          "emptyDir": {},
                          "name": "bccl-logs-volume"
                        },
                        {
                          "hostPath": {
                            "path": "/var/log/pods",
                            "type": "DirectoryOrCreate"
                          },
                          "name": "pod-log-volume"
                        },
                        {
                          "hostPath": {
                            "path": "/home/cce",
                            "type": "DirectoryOrCreate"
                          },
                          "name": "container-log-volume"
                        }
                      ]
                    }
                  }
                },
                "Worker": {
                  "replicas": 3,
                  "restartPolicy": "Never",
                  "template": {
                    "metadata": {
                      "annotations": {
                        "aijob.cce.baidubce.com/fault-tolerance-enabled": "true",
                        "aijob.cce.baidubce.com/openapi-jobid": "pytorch-5961a180-13bb-49a1-8c5d-58ad07e652e4",
                        "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
                        "aijob.cce.baidubce.com/raw-request": "{\"name\":\"llamatest0718forxiaomi\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"normal\",\"oversell\":false,\"faultTolerance\":true,\"command\":\"\\n#! /bin/bash\\n\\nMEGATRON_PATH=${MEGATRON_PATH:-\\\"/workspace/AIAK-Megatron\\\"}\\nAIAK_TRAINING_PATH=${AIAK_TRAINING_PATH:-\\\"/workspace/AIAK-Training-LLM\\\"}\\n\\nDATA_PATH=${DATA_PATH:-\\\"/mnt/cluster/llama2/pile/pile-llama_text_document\\\"}\\nTOKENIZER_PATH=${TOKENIZER_PATH:-\\\"/mnt/cluster/llama2/Llama-2-70b-hf/\\\"}\\n\\nCHECKPOINT_PATH=${CHECKPOINT_PATH:-\\\"/mnt/cluster/llama2/mcore_llama2_70b_tp4_pp4\\\"}\\n\\nTENSORBOARD_PATH=${TENSORBOARD_PATH:-\\\"/mnt/cluster/aiak-training-llm/tensorboard-log/llama2-70b-tp4pp4\\\"}\\n\\nGPUS_PER_NODE=8\\n\\n# Change for multinode config\\nMASTER_ADDR=${MASTER_ADDR:-\\\"localhost\\\"}\\nMASTER_PORT=${MASTER_PORT:-\\\"6000\\\"}\\nNNODES=${WORLD_SIZE:-\\\"1\\\"}\\nNODE_RANK=${RANK:-\\\"0\\\"}\\n\\nDISTRIBUTED_ARGS=(\\n    --nproc_per_node $GPUS_PER_NODE\\n    --nnodes $NNODES\\n    --node_rank $NODE_RANK\\n    --master_addr $MASTER_ADDR\\n    --master_port $MASTER_PORT\\n)\\n\\n# you can setup llama2-70b maunally\\n#MODEL_ARGS=(\\n#    --model-name llama2\\n#    --num-layers 80\\n#    --hidden-size 8192\\n#    --ffn-hidden-size 28672\\n#    --num-attention-heads 64\\n#    --position-embedding-type rope\\n#    --normalization RMSNorm\\n#    --swiglu\\n#    --attention-dropout 0\\n#    --hidden-dropout 0\\n#    --disable-bias-linear\\n#    --untie-embeddings-and-output-weights\\n#    --group-query-attention\\n#    --num-query-groups 8\\n#)\\n\\n# or you can setup llama2-70b by using the following command\\nMODEL_ARGS=(\\n    --model-name llama2-70b # options: llama2-7b, llama2-13b, llama2-70b\\n)\\n\\nDATA_ARGS=(\\n    --tokenizer-type HFTokenizer\\n    --hf-tokenizer-path $TOKENIZER_PATH\\n    --data-path $DATA_PATH\\n    --split 949,50,1\\n)\\n\\nTRAINING_ARGS=(\\n    --training-phase pretrain # options: pretrain, sft\\n    --seq-length 4096\\n    --max-position-embeddings 4096\\n    --init-method-std 0.01\\n    --micro-batch-size 1\\n    --global-batch-size 1024\\n    --lr 0.0002\\n    --min-lr 1.0e-5\\n    --clip-grad 1.0\\n    --weight-decay 0.01\\n    --optimizer adam\\n    --adam-beta1 0.9\\n    --adam-beta2 0.95\\n    --adam-eps 1e-05\\n    --norm-epsilon 1e-6\\n    --train-iters 500000\\n    --lr-decay-iters 500000\\n    --lr-decay-style cosine\\n    --lr-warmup-fraction 0.002\\n    --initial-loss-scale 65536\\n    --fp16\\n    --save-interval 5000\\n    --eval-interval 1000\\n    --eval-iters 10\\n    #--ckpt-step 0\\n    #--no-load-optim\\n    #--no-load-rng\\n)\\n\\nMODEL_PARALLEL_ARGS=(\\n    --tensor-model-parallel-size 4\\n    --pipeline-model-parallel-size 4\\n    --use-distributed-optimizer\\n    --overlap-grad-reduce\\n    --overlap-param-gather\\n    --distributed-backend nccl\\n    --sequence-parallel\\n    #--tp-comm-overlap # require mpi envrionment\\n)\\n\\nLOGGING_ARGS=(\\n    --log-interval 1\\n    --tensorboard-dir ${TENSORBOARD_PATH}\\n    --log-timers-to-tensorboard\\n)\\n\\nif [ -n \\\"${WANDB_API_KEY}\\\" ]; then\\n    LOGGING_ARGS+=(\\n        --wandb-project ${WANDB_PROJECT}\\n        --wandb-exp-name ${WANDB_NAME} \\n    )\\nfi\\n\\nPYTHONPATH=$MEGATRON_PATH:$AIAK_TRAINING_PATH:$PYTHONPATH     torchrun ${DISTRIBUTED_ARGS[@]}     $AIAK_TRAINING_PATH/aiak_training_llm/train.py     ${MODEL_ARGS[@]}     ${DATA_ARGS[@]}     ${TRAINING_ARGS[@]}     ${MODEL_PARALLEL_ARGS[@]}     ${LOGGING_ARGS[@]}\\n\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":true,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi/output/training_logs\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"},\"Worker\":{\"replicas\":3,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi/output/training_logs\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":true,\"logPath\":\"/mnt/cluster/llamatest0718forxiaomi/output/training_logs\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":true,\"isCopyJob\":false,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
                        "prometheus.io/path": "/metrics",
                        "prometheus.io/port": "9101",
                        "prometheus.io/scrape": "true",
                        "scheduling.k8s.io/job-enable-oversell": "false"
                      },
                      "labels": {
                        "aijob.cce.baidubce.com/ai-user-id": "b5a24aa26e4d4f55bc3acf68edc4b051",
                        "aijob.cce.baidubce.com/ai-user-name": "zhangmuhua",
                        "aijob.cce.baidubce.com/create-from-aihcp": "true",
                        "aijob.cce.baidubce.com/openapi-jobid": "pytorch-5961a180-13bb-49a1-8c5d-58ad07e652e4"
                      }
                    },
                    "spec": {
                      "containers": [
                        {
                          "command": [
                            "/bin/bash",
                            "-c",
                            "\n#! /bin/bash\n\nMEGATRON_PATH=${MEGATRON_PATH:-\"/workspace/AIAK-Megatron\"}\nAIAK_TRAINING_PATH=${AIAK_TRAINING_PATH:-\"/workspace/AIAK-Training-LLM\"}\n\nDATA_PATH=${DATA_PATH:-\"/mnt/cluster/llama2/pile/pile-llama_text_document\"}\nTOKENIZER_PATH=${TOKENIZER_PATH:-\"/mnt/cluster/llama2/Llama-2-70b-hf/\"}\n\nCHECKPOINT_PATH=${CHECKPOINT_PATH:-\"/mnt/cluster/llama2/mcore_llama2_70b_tp4_pp4\"}\n\nTENSORBOARD_PATH=${TENSORBOARD_PATH:-\"/mnt/cluster/aiak-training-llm/tensorboard-log/llama2-70b-tp4pp4\"}\n\nGPUS_PER_NODE=8\n\n# Change for multinode config\nMASTER_ADDR=${MASTER_ADDR:-\"localhost\"}\nMASTER_PORT=${MASTER_PORT:-\"6000\"}\nNNODES=${WORLD_SIZE:-\"1\"}\nNODE_RANK=${RANK:-\"0\"}\n\nDISTRIBUTED_ARGS=(\n    --nproc_per_node $GPUS_PER_NODE\n    --nnodes $NNODES\n    --node_rank $NODE_RANK\n    --master_addr $MASTER_ADDR\n    --master_port $MASTER_PORT\n)\n\n# you can setup llama2-70b maunally\n#MODEL_ARGS=(\n#    --model-name llama2\n#    --num-layers 80\n#    --hidden-size 8192\n#    --ffn-hidden-size 28672\n#    --num-attention-heads 64\n#    --position-embedding-type rope\n#    --normalization RMSNorm\n#    --swiglu\n#    --attention-dropout 0\n#    --hidden-dropout 0\n#    --disable-bias-linear\n#    --untie-embeddings-and-output-weights\n#    --group-query-attention\n#    --num-query-groups 8\n#)\n\n# or you can setup llama2-70b by using the following command\nMODEL_ARGS=(\n    --model-name llama2-70b # options: llama2-7b, llama2-13b, llama2-70b\n)\n\nDATA_ARGS=(\n    --tokenizer-type HFTokenizer\n    --hf-tokenizer-path $TOKENIZER_PATH\n    --data-path $DATA_PATH\n    --split 949,50,1\n)\n\nTRAINING_ARGS=(\n    --training-phase pretrain # options: pretrain, sft\n    --seq-length 4096\n    --max-position-embeddings 4096\n    --init-method-std 0.01\n    --micro-batch-size 1\n    --global-batch-size 1024\n    --lr 0.0002\n    --min-lr 1.0e-5\n    --clip-grad 1.0\n    --weight-decay 0.01\n    --optimizer adam\n    --adam-beta1 0.9\n    --adam-beta2 0.95\n    --adam-eps 1e-05\n    --norm-epsilon 1e-6\n    --train-iters 500000\n    --lr-decay-iters 500000\n    --lr-decay-style cosine\n    --lr-warmup-fraction 0.002\n    --initial-loss-scale 65536\n    --fp16\n    --save-interval 5000\n    --eval-interval 1000\n    --eval-iters 10\n    #--ckpt-step 0\n    #--no-load-optim\n    #--no-load-rng\n)\n\nMODEL_PARALLEL_ARGS=(\n    --tensor-model-parallel-size 4\n    --pipeline-model-parallel-size 4\n    --use-distributed-optimizer\n    --overlap-grad-reduce\n    --overlap-param-gather\n    --distributed-backend nccl\n    --sequence-parallel\n    #--tp-comm-overlap # require mpi envrionment\n)\n\nLOGGING_ARGS=(\n    --log-interval 1\n    --tensorboard-dir ${TENSORBOARD_PATH}\n    --log-timers-to-tensorboard\n)\n\nif [ -n \"${WANDB_API_KEY}\" ]; then\n    LOGGING_ARGS+=(\n        --wandb-project ${WANDB_PROJECT}\n        --wandb-exp-name ${WANDB_NAME} \n    )\nfi\n\nPYTHONPATH=$MEGATRON_PATH:$AIAK_TRAINING_PATH:$PYTHONPATH     torchrun ${DISTRIBUTED_ARGS[@]}     $AIAK_TRAINING_PATH/aiak_training_llm/train.py     ${MODEL_ARGS[@]}     ${DATA_ARGS[@]}     ${TRAINING_ARGS[@]}     ${MODEL_PARALLEL_ARGS[@]}     ${LOGGING_ARGS[@]}\n"
                          ],
                          "env": [
                            {
                              "name": "AIHC_TENSORBOARD_LOG_PATH",
                              "value": "/mnt/cluster/llamatest0718forxiaomi/output/training_logs"
                            },
                            {
                              "name": "AIHC_JOB_NAME",
                              "value": "llamatest0718forxiaomi"
                            },
                            {
                              "name": "NCCL_IB_DISABLE",
                              "value": "0"
                            },
                            {
                              "name": "BCCL_BUS_BW_CALCULATE_MODE",
                              "value": "Agg"
                            },
                            {
                              "name": "BCCL_PROFILING_FILE",
                              "value": "/var/bccl/logs/busbw.cal.%h.%p"
                            }
                          ],
                          "image": "registry.baidubce.com/aihc-aiak/aiak-training-llm:ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release",
                          "imagePullPolicy": "Always",
                          "name": "pytorch",
                          "ports": [
                            {
                              "containerPort": 23456,
                              "name": "pytorchjob-port",
                              "protocol": "TCP"
                            }
                          ],
                          "resources": {
                            "limits": {
                              "baidu.com/a800_80g_cgpu": "8",
                              "rdma/hca": "1"
                            },
                            "requests": {
                              "baidu.com/a800_80g_cgpu": "8",
                              "rdma/hca": "1"
                            }
                          },
                          "securityContext": {
                            "capabilities": {
                              "add": [
                                "IPC_LOCK"
                              ]
                            }
                          },
                          "volumeMounts": [
                            {
                              "mountPath": "/dev/shm",
                              "name": "devshm"
                            },
                            {
                              "mountPath": "/mnt/cluster",
                              "name": "pvc-pfs"
                            },
                            {
                              "mountPath": "/var/bccl/logs",
                              "name": "bccl-logs-volume"
                            }
                          ]
                        },
                        {
                          "env": [
                            {
                              "name": "POD_NAME",
                              "valueFrom": {
                                "fieldRef": {
                                  "apiVersion": "v1",
                                  "fieldPath": "metadata.name"
                                }
                              }
                            },
                            {
                              "name": "POD_UID",
                              "valueFrom": {
                                "fieldRef": {
                                  "apiVersion": "v1",
                                  "fieldPath": "metadata.uid"
                                }
                              }
                            },
                            {
                              "name": "POD_NAMESPACE",
                              "valueFrom": {
                                "fieldRef": {
                                  "apiVersion": "v1",
                                  "fieldPath": "metadata.namespace"
                                }
                              }
                            },
                            {
                              "name": "NODE_NAME",
                              "valueFrom": {
                                "fieldRef": {
                                  "apiVersion": "v1",
                                  "fieldPath": "spec.nodeName"
                                }
                              }
                            },
                            {
                              "name": "JOB_NAME",
                              "value": "llamatest0718forxiaomi"
                            },
                            {
                              "name": "NODE_IP",
                              "valueFrom": {
                                "fieldRef": {
                                  "apiVersion": "v1",
                                  "fieldPath": "status.hostIP"
                                }
                              }
                            },
                            {
                              "name": "ENABLE_ELASTIC",
                              "value": "9"
                            },
                            {
                              "name": "GPUS_PER_NODE",
                              "value": "8"
                            },
                            {
                              "name": "BCCL_LOG_DIR",
                              "value": "/var/bccl/logs"
                            },
                            {
                              "name": "EXPORTER_PORT",
                              "value": "9101"
                            },
                            {
                              "name": "EXPORTER_INTERVAL",
                              "value": "60"
                            },
                            {
                              "name": "EXPORTER_PATH",
                              "value": "/metrics"
                            },
                            {
                              "name": "BCCL_BUS_BW_CALCULATE_MODE",
                              "value": "Agg"
                            },
                            {
                              "name": "BCCL_PROFILING_FILE",
                              "value": "/var/bccl/logs/busbw.cal.%h.%p"
                            }
                          ],
                          "image": "registry.baidubce.com/cce-plugin-dev/ftagent:v1.6-20240713172215",
                          "imagePullPolicy": "Always",
                          "name": "ftagent",
                          "ports": [
                            {
                              "containerPort": 9101,
                              "name": "exporter",
                              "protocol": "TCP"
                            }
                          ],
                          "resources": {},
                          "securityContext": {
                            "capabilities": {
                              "add": [
                                "IPC_LOCK"
                              ]
                            }
                          },
                          "volumeMounts": [
                            {
                              "mountPath": "/var/log/pods",
                              "name": "pod-log-volume"
                            },
                            {
                              "mountPath": "/home/cce",
                              "name": "container-log-volume"
                            },
                            {
                              "mountPath": "/var/bccl/logs",
                              "name": "bccl-logs-volume"
                            }
                          ]
                        }
                      ],
                      "dnsPolicy": "ClusterFirstWithHostNet",
                      "hostNetwork": true,
                      "schedulerName": "volcano",
                      "serviceAccountName": "ftagent-sa",
                      "shareProcessNamespace": true,
                      "volumes": [
                        {
                          "emptyDir": {
                            "medium": "Memory",
                            "sizeLimit": "10Gi"
                          },
                          "name": "devshm"
                        },
                        {
                          "name": "pvc-pfs",
                          "persistentVolumeClaim": {
                            "claimName": "pvc-pfs"
                          }
                        },
                        {
                          "emptyDir": {},
                          "name": "bccl-logs-volume"
                        },
                        {
                          "hostPath": {
                            "path": "/var/log/pods",
                            "type": "DirectoryOrCreate"
                          },
                          "name": "pod-log-volume"
                        },
                        {
                          "hostPath": {
                            "path": "/home/cce",
                            "type": "DirectoryOrCreate"
                          },
                          "name": "container-log-volume"
                        }
                      ]
                    }
                  }
                }
              },
              "runPolicy": {
                "cleanPodPolicy": "None",
                "schedulingPolicy": {
                  "priorityClass": "high",
                  "queue": "default"
                }
              }
            },
            "status": {
              "completionTime": "2024-07-18T02:19:36Z",
              "conditions": [
                {
                  "lastTransitionTime": "2024-07-18T02:10:30Z",
                  "lastUpdateTime": "2024-07-18T02:10:30Z",
                  "message": "PyTorchJob llamatest0718forxiaomi is created.",
                  "reason": "PyTorchJobCreated",
                  "status": "True",
                  "type": "Created"
                },
                {
                  "lastTransitionTime": "2024-07-18T02:17:08Z",
                  "lastUpdateTime": "2024-07-18T02:17:08Z",
                  "message": "PyTorchJob llamatest0718forxiaomi is running.",
                  "reason": "JobRunning",
                  "status": "False",
                  "type": "Running"
                },
                {
                  "lastTransitionTime": "2024-07-18T02:19:36Z",
                  "lastUpdateTime": "2024-07-18T02:19:36Z",
                  "message": "PytorchJob default/llamatest0718forxiaomi is stopped",
                  "reason": "PyTorchJobStopped",
                  "status": "True",
                  "type": "Stopped"
                },
                {
                  "lastTransitionTime": "2024-07-18T02:19:36Z",
                  "lastUpdateTime": "2024-07-18T02:19:36Z",
                  "message": "PyTorchJob llamatest0718forxiaomi is failed because 3 Worker replica(s) failed.",
                  "reason": "JobFailed",
                  "status": "True",
                  "type": "Failed"
                }
              ],
              "lastReconcileTime": "2024-07-18T02:10:31Z",
              "replicaStatuses": {
                "Master": {
                  "failed": 1,
                  "selector": "training.kubeflow.org/job-name=llamatest0718forxiaomi,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=master"
                },
                "Worker": {
                  "failed": 3,
                  "selector": "training.kubeflow.org/job-name=llamatest0718forxiaomi,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=worker"
                }
              },
              "startTime": "2024-07-18T02:10:32Z"
            }
          },
          {
            "apiVersion": "kubeflow.org/v1",
            "kind": "PyTorchJob",
            "metadata": {
              "annotations": {
                "aijob.cce.baidubce.com/barrier-finish": "1d8a5926-1916-4dc1-a8ad-f45ed67f6a5e",
                "aijob.cce.baidubce.com/fault-tolerance-enabled": "true",
                "aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": "",
                "aijob.cce.baidubce.com/internal-fault-tolerance-time": "2024-07-18T02:20:19.474955307Z",
                "aijob.cce.baidubce.com/openapi-jobid": "pytorch-bb0b516a-22c8-4a4f-a0cd-6cf33b80120f",
                "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
                "aijob.cce.baidubce.com/raw-request": "{\"name\":\"llamatest0718forxiaomi2\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"high\",\"oversell\":false,\"faultTolerance\":true,\"command\":\"\\n#! /bin/bash\\n\\nMEGATRON_PATH=${MEGATRON_PATH:-\\\"/workspace/AIAK-Megatron\\\"}\\nAIAK_TRAINING_PATH=${AIAK_TRAINING_PATH:-\\\"/workspace/AIAK-Training-LLM\\\"}\\n\\nDATA_PATH=${DATA_PATH:-\\\"/mnt/cluster/llama2/pile/pile-llama_text_document\\\"}\\nTOKENIZER_PATH=${TOKENIZER_PATH:-\\\"/mnt/cluster/llama2/Llama-2-70b-hf/\\\"}\\n\\nCHECKPOINT_PATH=${CHECKPOINT_PATH:-\\\"/mnt/cluster/llama2/mcore_llama2_70b_tp4_pp4\\\"}\\n\\nTENSORBOARD_PATH=${TENSORBOARD_PATH:-\\\"/mnt/cluster/aiak-training-llm/tensorboard-log/llama2-70b-tp4pp4\\\"}\\n\\nGPUS_PER_NODE=8\\n\\n# Change for multinode config\\nMASTER_ADDR=${MASTER_ADDR:-\\\"localhost\\\"}\\nMASTER_PORT=${MASTER_PORT:-\\\"6000\\\"}\\nNNODES=${WORLD_SIZE:-\\\"1\\\"}\\nNODE_RANK=${RANK:-\\\"0\\\"}\\n\\nDISTRIBUTED_ARGS=(\\n    --nproc_per_node $GPUS_PER_NODE\\n    --nnodes $NNODES\\n    --node_rank $NODE_RANK\\n    --master_addr $MASTER_ADDR\\n    --master_port $MASTER_PORT\\n)\\n\\n# you can setup llama2-70b maunally\\n#MODEL_ARGS=(\\n#    --model-name llama2\\n#    --num-layers 80\\n#    --hidden-size 8192\\n#    --ffn-hidden-size 28672\\n#    --num-attention-heads 64\\n#    --position-embedding-type rope\\n#    --normalization RMSNorm\\n#    --swiglu\\n#    --attention-dropout 0\\n#    --hidden-dropout 0\\n#    --disable-bias-linear\\n#    --untie-embeddings-and-output-weights\\n#    --group-query-attention\\n#    --num-query-groups 8\\n#)\\n\\n# or you can setup llama2-70b by using the following command\\nMODEL_ARGS=(\\n    --model-name llama2-70b # options: llama2-7b, llama2-13b, llama2-70b\\n)\\n\\nDATA_ARGS=(\\n    --tokenizer-type HFTokenizer\\n    --hf-tokenizer-path $TOKENIZER_PATH\\n    --data-path $DATA_PATH\\n    --split 949,50,1\\n)\\n\\nTRAINING_ARGS=(\\n    --training-phase pretrain # options: pretrain, sft\\n    --seq-length 4096\\n    --max-position-embeddings 4096\\n    --init-method-std 0.01\\n    --micro-batch-size 1\\n    --global-batch-size 1024\\n    --lr 0.0002\\n    --min-lr 1.0e-5\\n    --clip-grad 1.0\\n    --weight-decay 0.01\\n    --optimizer adam\\n    --adam-beta1 0.9\\n    --adam-beta2 0.95\\n    --adam-eps 1e-05\\n    --norm-epsilon 1e-6\\n    --train-iters 500000\\n    --lr-decay-iters 500000\\n    --lr-decay-style cosine\\n    --lr-warmup-fraction 0.002\\n    --initial-loss-scale 65536\\n    --fp16\\n    --save-interval 5000\\n    --eval-interval 1000\\n    --eval-iters 10\\n    #--ckpt-step 0\\n    #--no-load-optim\\n    #--no-load-rng\\n)\\n\\nMODEL_PARALLEL_ARGS=(\\n    --tensor-model-parallel-size 4\\n    --pipeline-model-parallel-size 4\\n    --use-distributed-optimizer\\n    --overlap-grad-reduce\\n    --overlap-param-gather\\n    --distributed-backend nccl\\n    --sequence-parallel\\n    #--tp-comm-overlap # require mpi envrionment\\n)\\n\\nLOGGING_ARGS=(\\n    --log-interval 1\\n    --tensorboard-dir ${TENSORBOARD_PATH}\\n    --log-timers-to-tensorboard\\n)\\n\\nif [ -n \\\"${WANDB_API_KEY}\\\" ]; then\\n    LOGGING_ARGS+=(\\n        --wandb-project ${WANDB_PROJECT}\\n        --wandb-exp-name ${WANDB_NAME} \\n    )\\nfi\\n\\nPYTHONPATH=$MEGATRON_PATH:$AIAK_TRAINING_PATH:$PYTHONPATH     torchrun ${DISTRIBUTED_ARGS[@]}     $AIAK_TRAINING_PATH/aiak_training_llm/train.py     ${MODEL_ARGS[@]}     ${DATA_ARGS[@]}     ${TRAINING_ARGS[@]}     ${MODEL_PARALLEL_ARGS[@]}     ${LOGGING_ARGS[@]}\\n\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":true,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi2\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi2/output/training_logs\",\"CUDA_DEVICE_MAX_CONNECTIONS\":\"1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"},\"Worker\":{\"replicas\":3,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi2\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi2/output/training_logs\",\"CUDA_DEVICE_MAX_CONNECTIONS\":\"1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":true,\"logPath\":\"/mnt/cluster/llamatest0718forxiaomi2/output/training_logs\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":true,\"isCopyJob\":true,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
                "aijob.cce.baidubce.com/timeline": "[{\"conditionType\":\"Created\",\"time\":1721269167},{\"conditionType\":\"Scheduled\",\"time\":1721269169},{\"conditionType\":\"Running\",\"time\":1721269189},{\"conditionType\":\"Abnormal\",\"time\":1721269219},{\"conditionType\":\"ManualTermination\",\"time\":1721269316}]",
                "job-manager/action": "stop",
                "scheduling.k8s.io/job-enable-oversell": "false",
                "tensorboard-gc": "true"
              },
              "creationTimestamp": "2024-07-18T02:19:27Z",
              "generation": 3,
              "labels": {
                "aijob.cce.baidubce.com/ai-user-id": "b5a24aa26e4d4f55bc3acf68edc4b051",
                "aijob.cce.baidubce.com/ai-user-name": "zhangmuhua",
                "aijob.cce.baidubce.com/create-from-aihcp": "true",
                "aijob.cce.baidubce.com/openapi-jobid": "pytorch-bb0b516a-22c8-4a4f-a0cd-6cf33b80120f"
              },
              "managedFields": [
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        "f:aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": {},
                        "f:aijob.cce.baidubce.com/timeline": {}
                      }
                    },
                    "f:spec": {
                      "f:runPolicy": {
                        "f:cleanPodPolicy": {}
                      }
                    }
                  },
                  "manager": "controller",
                  "operation": "Update",
                  "time": "2024-07-18T02:19:27Z"
                },
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        "f:aijob.cce.baidubce.com/barrier-finish": {}
                      }
                    }
                  },
                  "manager": "jobbarrier",
                  "operation": "Update",
                  "time": "2024-07-18T02:19:46Z"
                },
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        ".": {},
                        "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                        "f:aijob.cce.baidubce.com/openapi-jobid": {},
                        "f:aijob.cce.baidubce.com/pfs-id": {},
                        "f:aijob.cce.baidubce.com/raw-request": {},
                        "f:job-manager/action": {},
                        "f:scheduling.k8s.io/job-enable-oversell": {}
                      },
                      "f:labels": {
                        ".": {},
                        "f:aijob.cce.baidubce.com/ai-user-id": {},
                        "f:aijob.cce.baidubce.com/ai-user-name": {},
                        "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                        "f:aijob.cce.baidubce.com/openapi-jobid": {}
                      }
                    },
                    "f:spec": {
                      ".": {},
                      "f:pytorchReplicaSpecs": {
                        ".": {},
                        "f:Master": {
                          ".": {},
                          "f:replicas": {},
                          "f:restartPolicy": {},
                          "f:template": {
                            ".": {},
                            "f:metadata": {
                              ".": {},
                              "f:annotations": {
                                ".": {},
                                "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                                "f:aijob.cce.baidubce.com/openapi-jobid": {},
                                "f:aijob.cce.baidubce.com/pfs-id": {},
                                "f:aijob.cce.baidubce.com/raw-request": {},
                                "f:scheduling.k8s.io/job-enable-oversell": {}
                              },
                              "f:labels": {
                                ".": {},
                                "f:aijob.cce.baidubce.com/ai-user-id": {},
                                "f:aijob.cce.baidubce.com/ai-user-name": {},
                                "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                                "f:aijob.cce.baidubce.com/openapi-jobid": {}
                              }
                            },
                            "f:spec": {
                              ".": {},
                              "f:dnsPolicy": {},
                              "f:hostNetwork": {},
                              "f:schedulerName": {}
                            }
                          }
                        },
                        "f:Worker": {
                          ".": {},
                          "f:replicas": {},
                          "f:restartPolicy": {},
                          "f:template": {
                            ".": {},
                            "f:metadata": {
                              ".": {},
                              "f:annotations": {
                                ".": {},
                                "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                                "f:aijob.cce.baidubce.com/openapi-jobid": {},
                                "f:aijob.cce.baidubce.com/pfs-id": {},
                                "f:aijob.cce.baidubce.com/raw-request": {},
                                "f:scheduling.k8s.io/job-enable-oversell": {}
                              },
                              "f:labels": {
                                ".": {},
                                "f:aijob.cce.baidubce.com/ai-user-id": {},
                                "f:aijob.cce.baidubce.com/ai-user-name": {},
                                "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                                "f:aijob.cce.baidubce.com/openapi-jobid": {}
                              }
                            },
                            "f:spec": {
                              ".": {},
                              "f:dnsPolicy": {},
                              "f:hostNetwork": {},
                              "f:schedulerName": {}
                            }
                          }
                        }
                      },
                      "f:runPolicy": {
                        ".": {},
                        "f:schedulingPolicy": {
                          ".": {},
                          "f:priorityClass": {},
                          "f:queue": {}
                        }
                      }
                    }
                  },
                  "manager": "cce-ai-service",
                  "operation": "Update",
                  "time": "2024-07-18T02:21:56Z"
                },
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        "f:aijob.cce.baidubce.com/internal-fault-tolerance-time": {},
                        "f:tensorboard-gc": {}
                      }
                    },
                    "f:spec": {
                      "f:pytorchReplicaSpecs": {
                        "f:Master": {
                          "f:template": {
                            "f:metadata": {
                              "f:annotations": {
                                "f:prometheus.io/path": {},
                                "f:prometheus.io/port": {},
                                "f:prometheus.io/scrape": {}
                              }
                            },
                            "f:spec": {
                              "f:containers": {},
                              "f:serviceAccountName": {},
                              "f:shareProcessNamespace": {},
                              "f:volumes": {}
                            }
                          }
                        },
                        "f:Worker": {
                          "f:template": {
                            "f:metadata": {
                              "f:annotations": {
                                "f:prometheus.io/path": {},
                                "f:prometheus.io/port": {},
                                "f:prometheus.io/scrape": {}
                              }
                            },
                            "f:spec": {
                              "f:containers": {},
                              "f:serviceAccountName": {},
                              "f:shareProcessNamespace": {},
                              "f:volumes": {}
                            }
                          }
                        }
                      }
                    },
                    "f:status": {
                      ".": {},
                      "f:completionTime": {},
                      "f:conditions": {},
                      "f:lastReconcileTime": {},
                      "f:replicaStatuses": {
                        ".": {},
                        "f:Master": {
                          ".": {},
                          "f:failed": {}
                        },
                        "f:Worker": {
                          ".": {},
                          "f:failed": {}
                        }
                      },
                      "f:startTime": {}
                    }
                  },
                  "manager": "manager",
                  "operation": "Update",
                  "time": "2024-07-19T02:19:55Z"
                }
              ],
              "name": "llamatest0718forxiaomi2",
              "namespace": "default",
              "resourceVersion": "2372387205",
              "uid": "e47f6034-7100-4e2f-9e3d-e800a2017161"
            },
            "spec": {
              "pytorchReplicaSpecs": {
                "Master": {
                  "replicas": 1,
                  "restartPolicy": "Never",
                  "template": {
                    "metadata": {
                      "annotations": {
                        "aijob.cce.baidubce.com/fault-tolerance-enabled": "true",
                        "aijob.cce.baidubce.com/openapi-jobid": "pytorch-bb0b516a-22c8-4a4f-a0cd-6cf33b80120f",
                        "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
                        "aijob.cce.baidubce.com/raw-request": "{\"name\":\"llamatest0718forxiaomi2\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"high\",\"oversell\":false,\"faultTolerance\":true,\"command\":\"\\n#! /bin/bash\\n\\nMEGATRON_PATH=${MEGATRON_PATH:-\\\"/workspace/AIAK-Megatron\\\"}\\nAIAK_TRAINING_PATH=${AIAK_TRAINING_PATH:-\\\"/workspace/AIAK-Training-LLM\\\"}\\n\\nDATA_PATH=${DATA_PATH:-\\\"/mnt/cluster/llama2/pile/pile-llama_text_document\\\"}\\nTOKENIZER_PATH=${TOKENIZER_PATH:-\\\"/mnt/cluster/llama2/Llama-2-70b-hf/\\\"}\\n\\nCHECKPOINT_PATH=${CHECKPOINT_PATH:-\\\"/mnt/cluster/llama2/mcore_llama2_70b_tp4_pp4\\\"}\\n\\nTENSORBOARD_PATH=${TENSORBOARD_PATH:-\\\"/mnt/cluster/aiak-training-llm/tensorboard-log/llama2-70b-tp4pp4\\\"}\\n\\nGPUS_PER_NODE=8\\n\\n# Change for multinode config\\nMASTER_ADDR=${MASTER_ADDR:-\\\"localhost\\\"}\\nMASTER_PORT=${MASTER_PORT:-\\\"6000\\\"}\\nNNODES=${WORLD_SIZE:-\\\"1\\\"}\\nNODE_RANK=${RANK:-\\\"0\\\"}\\n\\nDISTRIBUTED_ARGS=(\\n    --nproc_per_node $GPUS_PER_NODE\\n    --nnodes $NNODES\\n    --node_rank $NODE_RANK\\n    --master_addr $MASTER_ADDR\\n    --master_port $MASTER_PORT\\n)\\n\\n# you can setup llama2-70b maunally\\n#MODEL_ARGS=(\\n#    --model-name llama2\\n#    --num-layers 80\\n#    --hidden-size 8192\\n#    --ffn-hidden-size 28672\\n#    --num-attention-heads 64\\n#    --position-embedding-type rope\\n#    --normalization RMSNorm\\n#    --swiglu\\n#    --attention-dropout 0\\n#    --hidden-dropout 0\\n#    --disable-bias-linear\\n#    --untie-embeddings-and-output-weights\\n#    --group-query-attention\\n#    --num-query-groups 8\\n#)\\n\\n# or you can setup llama2-70b by using the following command\\nMODEL_ARGS=(\\n    --model-name llama2-70b # options: llama2-7b, llama2-13b, llama2-70b\\n)\\n\\nDATA_ARGS=(\\n    --tokenizer-type HFTokenizer\\n    --hf-tokenizer-path $TOKENIZER_PATH\\n    --data-path $DATA_PATH\\n    --split 949,50,1\\n)\\n\\nTRAINING_ARGS=(\\n    --training-phase pretrain # options: pretrain, sft\\n    --seq-length 4096\\n    --max-position-embeddings 4096\\n    --init-method-std 0.01\\n    --micro-batch-size 1\\n    --global-batch-size 1024\\n    --lr 0.0002\\n    --min-lr 1.0e-5\\n    --clip-grad 1.0\\n    --weight-decay 0.01\\n    --optimizer adam\\n    --adam-beta1 0.9\\n    --adam-beta2 0.95\\n    --adam-eps 1e-05\\n    --norm-epsilon 1e-6\\n    --train-iters 500000\\n    --lr-decay-iters 500000\\n    --lr-decay-style cosine\\n    --lr-warmup-fraction 0.002\\n    --initial-loss-scale 65536\\n    --fp16\\n    --save-interval 5000\\n    --eval-interval 1000\\n    --eval-iters 10\\n    #--ckpt-step 0\\n    #--no-load-optim\\n    #--no-load-rng\\n)\\n\\nMODEL_PARALLEL_ARGS=(\\n    --tensor-model-parallel-size 4\\n    --pipeline-model-parallel-size 4\\n    --use-distributed-optimizer\\n    --overlap-grad-reduce\\n    --overlap-param-gather\\n    --distributed-backend nccl\\n    --sequence-parallel\\n    #--tp-comm-overlap # require mpi envrionment\\n)\\n\\nLOGGING_ARGS=(\\n    --log-interval 1\\n    --tensorboard-dir ${TENSORBOARD_PATH}\\n    --log-timers-to-tensorboard\\n)\\n\\nif [ -n \\\"${WANDB_API_KEY}\\\" ]; then\\n    LOGGING_ARGS+=(\\n        --wandb-project ${WANDB_PROJECT}\\n        --wandb-exp-name ${WANDB_NAME} \\n    )\\nfi\\n\\nPYTHONPATH=$MEGATRON_PATH:$AIAK_TRAINING_PATH:$PYTHONPATH     torchrun ${DISTRIBUTED_ARGS[@]}     $AIAK_TRAINING_PATH/aiak_training_llm/train.py     ${MODEL_ARGS[@]}     ${DATA_ARGS[@]}     ${TRAINING_ARGS[@]}     ${MODEL_PARALLEL_ARGS[@]}     ${LOGGING_ARGS[@]}\\n\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":true,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi2\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi2/output/training_logs\",\"CUDA_DEVICE_MAX_CONNECTIONS\":\"1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"},\"Worker\":{\"replicas\":3,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi2\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi2/output/training_logs\",\"CUDA_DEVICE_MAX_CONNECTIONS\":\"1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":true,\"logPath\":\"/mnt/cluster/llamatest0718forxiaomi2/output/training_logs\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":true,\"isCopyJob\":true,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
                        "prometheus.io/path": "/metrics",
                        "prometheus.io/port": "9101",
                        "prometheus.io/scrape": "true",
                        "scheduling.k8s.io/job-enable-oversell": "false"
                      },
                      "labels": {
                        "aijob.cce.baidubce.com/ai-user-id": "b5a24aa26e4d4f55bc3acf68edc4b051",
                        "aijob.cce.baidubce.com/ai-user-name": "zhangmuhua",
                        "aijob.cce.baidubce.com/create-from-aihcp": "true",
                        "aijob.cce.baidubce.com/openapi-jobid": "pytorch-bb0b516a-22c8-4a4f-a0cd-6cf33b80120f"
                      }
                    },
                    "spec": {
                      "containers": [
                        {
                          "command": [
                            "/bin/bash",
                            "-c",
                            "\n#! /bin/bash\n\nMEGATRON_PATH=${MEGATRON_PATH:-\"/workspace/AIAK-Megatron\"}\nAIAK_TRAINING_PATH=${AIAK_TRAINING_PATH:-\"/workspace/AIAK-Training-LLM\"}\n\nDATA_PATH=${DATA_PATH:-\"/mnt/cluster/llama2/pile/pile-llama_text_document\"}\nTOKENIZER_PATH=${TOKENIZER_PATH:-\"/mnt/cluster/llama2/Llama-2-70b-hf/\"}\n\nCHECKPOINT_PATH=${CHECKPOINT_PATH:-\"/mnt/cluster/llama2/mcore_llama2_70b_tp4_pp4\"}\n\nTENSORBOARD_PATH=${TENSORBOARD_PATH:-\"/mnt/cluster/aiak-training-llm/tensorboard-log/llama2-70b-tp4pp4\"}\n\nGPUS_PER_NODE=8\n\n# Change for multinode config\nMASTER_ADDR=${MASTER_ADDR:-\"localhost\"}\nMASTER_PORT=${MASTER_PORT:-\"6000\"}\nNNODES=${WORLD_SIZE:-\"1\"}\nNODE_RANK=${RANK:-\"0\"}\n\nDISTRIBUTED_ARGS=(\n    --nproc_per_node $GPUS_PER_NODE\n    --nnodes $NNODES\n    --node_rank $NODE_RANK\n    --master_addr $MASTER_ADDR\n    --master_port $MASTER_PORT\n)\n\n# you can setup llama2-70b maunally\n#MODEL_ARGS=(\n#    --model-name llama2\n#    --num-layers 80\n#    --hidden-size 8192\n#    --ffn-hidden-size 28672\n#    --num-attention-heads 64\n#    --position-embedding-type rope\n#    --normalization RMSNorm\n#    --swiglu\n#    --attention-dropout 0\n#    --hidden-dropout 0\n#    --disable-bias-linear\n#    --untie-embeddings-and-output-weights\n#    --group-query-attention\n#    --num-query-groups 8\n#)\n\n# or you can setup llama2-70b by using the following command\nMODEL_ARGS=(\n    --model-name llama2-70b # options: llama2-7b, llama2-13b, llama2-70b\n)\n\nDATA_ARGS=(\n    --tokenizer-type HFTokenizer\n    --hf-tokenizer-path $TOKENIZER_PATH\n    --data-path $DATA_PATH\n    --split 949,50,1\n)\n\nTRAINING_ARGS=(\n    --training-phase pretrain # options: pretrain, sft\n    --seq-length 4096\n    --max-position-embeddings 4096\n    --init-method-std 0.01\n    --micro-batch-size 1\n    --global-batch-size 1024\n    --lr 0.0002\n    --min-lr 1.0e-5\n    --clip-grad 1.0\n    --weight-decay 0.01\n    --optimizer adam\n    --adam-beta1 0.9\n    --adam-beta2 0.95\n    --adam-eps 1e-05\n    --norm-epsilon 1e-6\n    --train-iters 500000\n    --lr-decay-iters 500000\n    --lr-decay-style cosine\n    --lr-warmup-fraction 0.002\n    --initial-loss-scale 65536\n    --fp16\n    --save-interval 5000\n    --eval-interval 1000\n    --eval-iters 10\n    #--ckpt-step 0\n    #--no-load-optim\n    #--no-load-rng\n)\n\nMODEL_PARALLEL_ARGS=(\n    --tensor-model-parallel-size 4\n    --pipeline-model-parallel-size 4\n    --use-distributed-optimizer\n    --overlap-grad-reduce\n    --overlap-param-gather\n    --distributed-backend nccl\n    --sequence-parallel\n    #--tp-comm-overlap # require mpi envrionment\n)\n\nLOGGING_ARGS=(\n    --log-interval 1\n    --tensorboard-dir ${TENSORBOARD_PATH}\n    --log-timers-to-tensorboard\n)\n\nif [ -n \"${WANDB_API_KEY}\" ]; then\n    LOGGING_ARGS+=(\n        --wandb-project ${WANDB_PROJECT}\n        --wandb-exp-name ${WANDB_NAME} \n    )\nfi\n\nPYTHONPATH=$MEGATRON_PATH:$AIAK_TRAINING_PATH:$PYTHONPATH     torchrun ${DISTRIBUTED_ARGS[@]}     $AIAK_TRAINING_PATH/aiak_training_llm/train.py     ${MODEL_ARGS[@]}     ${DATA_ARGS[@]}     ${TRAINING_ARGS[@]}     ${MODEL_PARALLEL_ARGS[@]}     ${LOGGING_ARGS[@]}\n"
                          ],
                          "env": [
                            {
                              "name": "CUDA_DEVICE_MAX_CONNECTIONS",
                              "value": "1"
                            },
                            {
                              "name": "AIHC_TENSORBOARD_LOG_PATH",
                              "value": "/mnt/cluster/llamatest0718forxiaomi2/output/training_logs"
                            },
                            {
                              "name": "AIHC_JOB_NAME",
                              "value": "llamatest0718forxiaomi2"
                            },
                            {
                              "name": "NCCL_IB_DISABLE",
                              "value": "0"
                            },
                            {
                              "name": "BCCL_BUS_BW_CALCULATE_MODE",
                              "value": "Agg"
                            },
                            {
                              "name": "BCCL_PROFILING_FILE",
                              "value": "/var/bccl/logs/busbw.cal.%h.%p"
                            }
                          ],
                          "image": "registry.baidubce.com/aihc-aiak/aiak-training-llm:ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release",
                          "imagePullPolicy": "Always",
                          "name": "pytorch",
                          "ports": [
                            {
                              "containerPort": 23456,
                              "name": "pytorchjob-port",
                              "protocol": "TCP"
                            }
                          ],
                          "resources": {
                            "limits": {
                              "baidu.com/a800_80g_cgpu": "8",
                              "rdma/hca": "1"
                            },
                            "requests": {
                              "baidu.com/a800_80g_cgpu": "8",
                              "rdma/hca": "1"
                            }
                          },
                          "securityContext": {
                            "capabilities": {
                              "add": [
                                "IPC_LOCK"
                              ]
                            }
                          },
                          "volumeMounts": [
                            {
                              "mountPath": "/dev/shm",
                              "name": "devshm"
                            },
                            {
                              "mountPath": "/mnt/cluster",
                              "name": "pvc-pfs"
                            },
                            {
                              "mountPath": "/var/bccl/logs",
                              "name": "bccl-logs-volume"
                            }
                          ]
                        },
                        {
                          "env": [
                            {
                              "name": "POD_NAME",
                              "valueFrom": {
                                "fieldRef": {
                                  "apiVersion": "v1",
                                  "fieldPath": "metadata.name"
                                }
                              }
                            },
                            {
                              "name": "POD_UID",
                              "valueFrom": {
                                "fieldRef": {
                                  "apiVersion": "v1",
                                  "fieldPath": "metadata.uid"
                                }
                              }
                            },
                            {
                              "name": "POD_NAMESPACE",
                              "valueFrom": {
                                "fieldRef": {
                                  "apiVersion": "v1",
                                  "fieldPath": "metadata.namespace"
                                }
                              }
                            },
                            {
                              "name": "NODE_NAME",
                              "valueFrom": {
                                "fieldRef": {
                                  "apiVersion": "v1",
                                  "fieldPath": "spec.nodeName"
                                }
                              }
                            },
                            {
                              "name": "JOB_NAME",
                              "value": "llamatest0718forxiaomi2"
                            },
                            {
                              "name": "NODE_IP",
                              "valueFrom": {
                                "fieldRef": {
                                  "apiVersion": "v1",
                                  "fieldPath": "status.hostIP"
                                }
                              }
                            },
                            {
                              "name": "ENABLE_ELASTIC",
                              "value": "9"
                            },
                            {
                              "name": "GPUS_PER_NODE",
                              "value": "8"
                            },
                            {
                              "name": "BCCL_LOG_DIR",
                              "value": "/var/bccl/logs"
                            },
                            {
                              "name": "EXPORTER_PORT",
                              "value": "9101"
                            },
                            {
                              "name": "EXPORTER_INTERVAL",
                              "value": "60"
                            },
                            {
                              "name": "EXPORTER_PATH",
                              "value": "/metrics"
                            },
                            {
                              "name": "BCCL_BUS_BW_CALCULATE_MODE",
                              "value": "Agg"
                            },
                            {
                              "name": "BCCL_PROFILING_FILE",
                              "value": "/var/bccl/logs/busbw.cal.%h.%p"
                            }
                          ],
                          "image": "registry.baidubce.com/cce-plugin-dev/ftagent:v1.6-20240713172215",
                          "imagePullPolicy": "Always",
                          "name": "ftagent",
                          "ports": [
                            {
                              "containerPort": 9101,
                              "name": "exporter",
                              "protocol": "TCP"
                            }
                          ],
                          "resources": {},
                          "securityContext": {
                            "capabilities": {
                              "add": [
                                "IPC_LOCK"
                              ]
                            }
                          },
                          "volumeMounts": [
                            {
                              "mountPath": "/var/log/pods",
                              "name": "pod-log-volume"
                            },
                            {
                              "mountPath": "/home/cce",
                              "name": "container-log-volume"
                            },
                            {
                              "mountPath": "/var/bccl/logs",
                              "name": "bccl-logs-volume"
                            }
                          ]
                        }
                      ],
                      "dnsPolicy": "ClusterFirstWithHostNet",
                      "hostNetwork": true,
                      "schedulerName": "volcano",
                      "serviceAccountName": "ftagent-sa",
                      "shareProcessNamespace": true,
                      "volumes": [
                        {
                          "emptyDir": {
                            "medium": "Memory",
                            "sizeLimit": "10Gi"
                          },
                          "name": "devshm"
                        },
                        {
                          "name": "pvc-pfs",
                          "persistentVolumeClaim": {
                            "claimName": "pvc-pfs"
                          }
                        },
                        {
                          "emptyDir": {},
                          "name": "bccl-logs-volume"
                        },
                        {
                          "hostPath": {
                            "path": "/var/log/pods",
                            "type": "DirectoryOrCreate"
                          },
                          "name": "pod-log-volume"
                        },
                        {
                          "hostPath": {
                            "path": "/home/cce",
                            "type": "DirectoryOrCreate"
                          },
                          "name": "container-log-volume"
                        }
                      ]
                    }
                  }
                },
                "Worker": {
                  "replicas": 3,
                  "restartPolicy": "Never",
                  "template": {
                    "metadata": {
                      "annotations": {
                        "aijob.cce.baidubce.com/fault-tolerance-enabled": "true",
                        "aijob.cce.baidubce.com/openapi-jobid": "pytorch-bb0b516a-22c8-4a4f-a0cd-6cf33b80120f",
                        "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
                        "aijob.cce.baidubce.com/raw-request": "{\"name\":\"llamatest0718forxiaomi2\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"high\",\"oversell\":false,\"faultTolerance\":true,\"command\":\"\\n#! /bin/bash\\n\\nMEGATRON_PATH=${MEGATRON_PATH:-\\\"/workspace/AIAK-Megatron\\\"}\\nAIAK_TRAINING_PATH=${AIAK_TRAINING_PATH:-\\\"/workspace/AIAK-Training-LLM\\\"}\\n\\nDATA_PATH=${DATA_PATH:-\\\"/mnt/cluster/llama2/pile/pile-llama_text_document\\\"}\\nTOKENIZER_PATH=${TOKENIZER_PATH:-\\\"/mnt/cluster/llama2/Llama-2-70b-hf/\\\"}\\n\\nCHECKPOINT_PATH=${CHECKPOINT_PATH:-\\\"/mnt/cluster/llama2/mcore_llama2_70b_tp4_pp4\\\"}\\n\\nTENSORBOARD_PATH=${TENSORBOARD_PATH:-\\\"/mnt/cluster/aiak-training-llm/tensorboard-log/llama2-70b-tp4pp4\\\"}\\n\\nGPUS_PER_NODE=8\\n\\n# Change for multinode config\\nMASTER_ADDR=${MASTER_ADDR:-\\\"localhost\\\"}\\nMASTER_PORT=${MASTER_PORT:-\\\"6000\\\"}\\nNNODES=${WORLD_SIZE:-\\\"1\\\"}\\nNODE_RANK=${RANK:-\\\"0\\\"}\\n\\nDISTRIBUTED_ARGS=(\\n    --nproc_per_node $GPUS_PER_NODE\\n    --nnodes $NNODES\\n    --node_rank $NODE_RANK\\n    --master_addr $MASTER_ADDR\\n    --master_port $MASTER_PORT\\n)\\n\\n# you can setup llama2-70b maunally\\n#MODEL_ARGS=(\\n#    --model-name llama2\\n#    --num-layers 80\\n#    --hidden-size 8192\\n#    --ffn-hidden-size 28672\\n#    --num-attention-heads 64\\n#    --position-embedding-type rope\\n#    --normalization RMSNorm\\n#    --swiglu\\n#    --attention-dropout 0\\n#    --hidden-dropout 0\\n#    --disable-bias-linear\\n#    --untie-embeddings-and-output-weights\\n#    --group-query-attention\\n#    --num-query-groups 8\\n#)\\n\\n# or you can setup llama2-70b by using the following command\\nMODEL_ARGS=(\\n    --model-name llama2-70b # options: llama2-7b, llama2-13b, llama2-70b\\n)\\n\\nDATA_ARGS=(\\n    --tokenizer-type HFTokenizer\\n    --hf-tokenizer-path $TOKENIZER_PATH\\n    --data-path $DATA_PATH\\n    --split 949,50,1\\n)\\n\\nTRAINING_ARGS=(\\n    --training-phase pretrain # options: pretrain, sft\\n    --seq-length 4096\\n    --max-position-embeddings 4096\\n    --init-method-std 0.01\\n    --micro-batch-size 1\\n    --global-batch-size 1024\\n    --lr 0.0002\\n    --min-lr 1.0e-5\\n    --clip-grad 1.0\\n    --weight-decay 0.01\\n    --optimizer adam\\n    --adam-beta1 0.9\\n    --adam-beta2 0.95\\n    --adam-eps 1e-05\\n    --norm-epsilon 1e-6\\n    --train-iters 500000\\n    --lr-decay-iters 500000\\n    --lr-decay-style cosine\\n    --lr-warmup-fraction 0.002\\n    --initial-loss-scale 65536\\n    --fp16\\n    --save-interval 5000\\n    --eval-interval 1000\\n    --eval-iters 10\\n    #--ckpt-step 0\\n    #--no-load-optim\\n    #--no-load-rng\\n)\\n\\nMODEL_PARALLEL_ARGS=(\\n    --tensor-model-parallel-size 4\\n    --pipeline-model-parallel-size 4\\n    --use-distributed-optimizer\\n    --overlap-grad-reduce\\n    --overlap-param-gather\\n    --distributed-backend nccl\\n    --sequence-parallel\\n    #--tp-comm-overlap # require mpi envrionment\\n)\\n\\nLOGGING_ARGS=(\\n    --log-interval 1\\n    --tensorboard-dir ${TENSORBOARD_PATH}\\n    --log-timers-to-tensorboard\\n)\\n\\nif [ -n \\\"${WANDB_API_KEY}\\\" ]; then\\n    LOGGING_ARGS+=(\\n        --wandb-project ${WANDB_PROJECT}\\n        --wandb-exp-name ${WANDB_NAME} \\n    )\\nfi\\n\\nPYTHONPATH=$MEGATRON_PATH:$AIAK_TRAINING_PATH:$PYTHONPATH     torchrun ${DISTRIBUTED_ARGS[@]}     $AIAK_TRAINING_PATH/aiak_training_llm/train.py     ${MODEL_ARGS[@]}     ${DATA_ARGS[@]}     ${TRAINING_ARGS[@]}     ${MODEL_PARALLEL_ARGS[@]}     ${LOGGING_ARGS[@]}\\n\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":true,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi2\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi2/output/training_logs\",\"CUDA_DEVICE_MAX_CONNECTIONS\":\"1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"},\"Worker\":{\"replicas\":3,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi2\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi2/output/training_logs\",\"CUDA_DEVICE_MAX_CONNECTIONS\":\"1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":true,\"logPath\":\"/mnt/cluster/llamatest0718forxiaomi2/output/training_logs\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":true,\"isCopyJob\":true,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
                        "prometheus.io/path": "/metrics",
                        "prometheus.io/port": "9101",
                        "prometheus.io/scrape": "true",
                        "scheduling.k8s.io/job-enable-oversell": "false"
                      },
                      "labels": {
                        "aijob.cce.baidubce.com/ai-user-id": "b5a24aa26e4d4f55bc3acf68edc4b051",
                        "aijob.cce.baidubce.com/ai-user-name": "zhangmuhua",
                        "aijob.cce.baidubce.com/create-from-aihcp": "true",
                        "aijob.cce.baidubce.com/openapi-jobid": "pytorch-bb0b516a-22c8-4a4f-a0cd-6cf33b80120f"
                      }
                    },
                    "spec": {
                      "containers": [
                        {
                          "command": [
                            "/bin/bash",
                            "-c",
                            "\n#! /bin/bash\n\nMEGATRON_PATH=${MEGATRON_PATH:-\"/workspace/AIAK-Megatron\"}\nAIAK_TRAINING_PATH=${AIAK_TRAINING_PATH:-\"/workspace/AIAK-Training-LLM\"}\n\nDATA_PATH=${DATA_PATH:-\"/mnt/cluster/llama2/pile/pile-llama_text_document\"}\nTOKENIZER_PATH=${TOKENIZER_PATH:-\"/mnt/cluster/llama2/Llama-2-70b-hf/\"}\n\nCHECKPOINT_PATH=${CHECKPOINT_PATH:-\"/mnt/cluster/llama2/mcore_llama2_70b_tp4_pp4\"}\n\nTENSORBOARD_PATH=${TENSORBOARD_PATH:-\"/mnt/cluster/aiak-training-llm/tensorboard-log/llama2-70b-tp4pp4\"}\n\nGPUS_PER_NODE=8\n\n# Change for multinode config\nMASTER_ADDR=${MASTER_ADDR:-\"localhost\"}\nMASTER_PORT=${MASTER_PORT:-\"6000\"}\nNNODES=${WORLD_SIZE:-\"1\"}\nNODE_RANK=${RANK:-\"0\"}\n\nDISTRIBUTED_ARGS=(\n    --nproc_per_node $GPUS_PER_NODE\n    --nnodes $NNODES\n    --node_rank $NODE_RANK\n    --master_addr $MASTER_ADDR\n    --master_port $MASTER_PORT\n)\n\n# you can setup llama2-70b maunally\n#MODEL_ARGS=(\n#    --model-name llama2\n#    --num-layers 80\n#    --hidden-size 8192\n#    --ffn-hidden-size 28672\n#    --num-attention-heads 64\n#    --position-embedding-type rope\n#    --normalization RMSNorm\n#    --swiglu\n#    --attention-dropout 0\n#    --hidden-dropout 0\n#    --disable-bias-linear\n#    --untie-embeddings-and-output-weights\n#    --group-query-attention\n#    --num-query-groups 8\n#)\n\n# or you can setup llama2-70b by using the following command\nMODEL_ARGS=(\n    --model-name llama2-70b # options: llama2-7b, llama2-13b, llama2-70b\n)\n\nDATA_ARGS=(\n    --tokenizer-type HFTokenizer\n    --hf-tokenizer-path $TOKENIZER_PATH\n    --data-path $DATA_PATH\n    --split 949,50,1\n)\n\nTRAINING_ARGS=(\n    --training-phase pretrain # options: pretrain, sft\n    --seq-length 4096\n    --max-position-embeddings 4096\n    --init-method-std 0.01\n    --micro-batch-size 1\n    --global-batch-size 1024\n    --lr 0.0002\n    --min-lr 1.0e-5\n    --clip-grad 1.0\n    --weight-decay 0.01\n    --optimizer adam\n    --adam-beta1 0.9\n    --adam-beta2 0.95\n    --adam-eps 1e-05\n    --norm-epsilon 1e-6\n    --train-iters 500000\n    --lr-decay-iters 500000\n    --lr-decay-style cosine\n    --lr-warmup-fraction 0.002\n    --initial-loss-scale 65536\n    --fp16\n    --save-interval 5000\n    --eval-interval 1000\n    --eval-iters 10\n    #--ckpt-step 0\n    #--no-load-optim\n    #--no-load-rng\n)\n\nMODEL_PARALLEL_ARGS=(\n    --tensor-model-parallel-size 4\n    --pipeline-model-parallel-size 4\n    --use-distributed-optimizer\n    --overlap-grad-reduce\n    --overlap-param-gather\n    --distributed-backend nccl\n    --sequence-parallel\n    #--tp-comm-overlap # require mpi envrionment\n)\n\nLOGGING_ARGS=(\n    --log-interval 1\n    --tensorboard-dir ${TENSORBOARD_PATH}\n    --log-timers-to-tensorboard\n)\n\nif [ -n \"${WANDB_API_KEY}\" ]; then\n    LOGGING_ARGS+=(\n        --wandb-project ${WANDB_PROJECT}\n        --wandb-exp-name ${WANDB_NAME} \n    )\nfi\n\nPYTHONPATH=$MEGATRON_PATH:$AIAK_TRAINING_PATH:$PYTHONPATH     torchrun ${DISTRIBUTED_ARGS[@]}     $AIAK_TRAINING_PATH/aiak_training_llm/train.py     ${MODEL_ARGS[@]}     ${DATA_ARGS[@]}     ${TRAINING_ARGS[@]}     ${MODEL_PARALLEL_ARGS[@]}     ${LOGGING_ARGS[@]}\n"
                          ],
                          "env": [
                            {
                              "name": "CUDA_DEVICE_MAX_CONNECTIONS",
                              "value": "1"
                            },
                            {
                              "name": "AIHC_TENSORBOARD_LOG_PATH",
                              "value": "/mnt/cluster/llamatest0718forxiaomi2/output/training_logs"
                            },
                            {
                              "name": "AIHC_JOB_NAME",
                              "value": "llamatest0718forxiaomi2"
                            },
                            {
                              "name": "NCCL_IB_DISABLE",
                              "value": "0"
                            },
                            {
                              "name": "BCCL_BUS_BW_CALCULATE_MODE",
                              "value": "Agg"
                            },
                            {
                              "name": "BCCL_PROFILING_FILE",
                              "value": "/var/bccl/logs/busbw.cal.%h.%p"
                            }
                          ],
                          "image": "registry.baidubce.com/aihc-aiak/aiak-training-llm:ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release",
                          "imagePullPolicy": "Always",
                          "name": "pytorch",
                          "ports": [
                            {
                              "containerPort": 23456,
                              "name": "pytorchjob-port",
                              "protocol": "TCP"
                            }
                          ],
                          "resources": {
                            "limits": {
                              "baidu.com/a800_80g_cgpu": "8",
                              "rdma/hca": "1"
                            },
                            "requests": {
                              "baidu.com/a800_80g_cgpu": "8",
                              "rdma/hca": "1"
                            }
                          },
                          "securityContext": {
                            "capabilities": {
                              "add": [
                                "IPC_LOCK"
                              ]
                            }
                          },
                          "volumeMounts": [
                            {
                              "mountPath": "/dev/shm",
                              "name": "devshm"
                            },
                            {
                              "mountPath": "/mnt/cluster",
                              "name": "pvc-pfs"
                            },
                            {
                              "mountPath": "/var/bccl/logs",
                              "name": "bccl-logs-volume"
                            }
                          ]
                        },
                        {
                          "env": [
                            {
                              "name": "POD_NAME",
                              "valueFrom": {
                                "fieldRef": {
                                  "apiVersion": "v1",
                                  "fieldPath": "metadata.name"
                                }
                              }
                            },
                            {
                              "name": "POD_UID",
                              "valueFrom": {
                                "fieldRef": {
                                  "apiVersion": "v1",
                                  "fieldPath": "metadata.uid"
                                }
                              }
                            },
                            {
                              "name": "POD_NAMESPACE",
                              "valueFrom": {
                                "fieldRef": {
                                  "apiVersion": "v1",
                                  "fieldPath": "metadata.namespace"
                                }
                              }
                            },
                            {
                              "name": "NODE_NAME",
                              "valueFrom": {
                                "fieldRef": {
                                  "apiVersion": "v1",
                                  "fieldPath": "spec.nodeName"
                                }
                              }
                            },
                            {
                              "name": "JOB_NAME",
                              "value": "llamatest0718forxiaomi2"
                            },
                            {
                              "name": "NODE_IP",
                              "valueFrom": {
                                "fieldRef": {
                                  "apiVersion": "v1",
                                  "fieldPath": "status.hostIP"
                                }
                              }
                            },
                            {
                              "name": "ENABLE_ELASTIC",
                              "value": "9"
                            },
                            {
                              "name": "GPUS_PER_NODE",
                              "value": "8"
                            },
                            {
                              "name": "BCCL_LOG_DIR",
                              "value": "/var/bccl/logs"
                            },
                            {
                              "name": "EXPORTER_PORT",
                              "value": "9101"
                            },
                            {
                              "name": "EXPORTER_INTERVAL",
                              "value": "60"
                            },
                            {
                              "name": "EXPORTER_PATH",
                              "value": "/metrics"
                            },
                            {
                              "name": "BCCL_BUS_BW_CALCULATE_MODE",
                              "value": "Agg"
                            },
                            {
                              "name": "BCCL_PROFILING_FILE",
                              "value": "/var/bccl/logs/busbw.cal.%h.%p"
                            }
                          ],
                          "image": "registry.baidubce.com/cce-plugin-dev/ftagent:v1.6-20240713172215",
                          "imagePullPolicy": "Always",
                          "name": "ftagent",
                          "ports": [
                            {
                              "containerPort": 9101,
                              "name": "exporter",
                              "protocol": "TCP"
                            }
                          ],
                          "resources": {},
                          "securityContext": {
                            "capabilities": {
                              "add": [
                                "IPC_LOCK"
                              ]
                            }
                          },
                          "volumeMounts": [
                            {
                              "mountPath": "/var/log/pods",
                              "name": "pod-log-volume"
                            },
                            {
                              "mountPath": "/home/cce",
                              "name": "container-log-volume"
                            },
                            {
                              "mountPath": "/var/bccl/logs",
                              "name": "bccl-logs-volume"
                            }
                          ]
                        }
                      ],
                      "dnsPolicy": "ClusterFirstWithHostNet",
                      "hostNetwork": true,
                      "schedulerName": "volcano",
                      "serviceAccountName": "ftagent-sa",
                      "shareProcessNamespace": true,
                      "volumes": [
                        {
                          "emptyDir": {
                            "medium": "Memory",
                            "sizeLimit": "10Gi"
                          },
                          "name": "devshm"
                        },
                        {
                          "name": "pvc-pfs",
                          "persistentVolumeClaim": {
                            "claimName": "pvc-pfs"
                          }
                        },
                        {
                          "emptyDir": {},
                          "name": "bccl-logs-volume"
                        },
                        {
                          "hostPath": {
                            "path": "/var/log/pods",
                            "type": "DirectoryOrCreate"
                          },
                          "name": "pod-log-volume"
                        },
                        {
                          "hostPath": {
                            "path": "/home/cce",
                            "type": "DirectoryOrCreate"
                          },
                          "name": "container-log-volume"
                        }
                      ]
                    }
                  }
                }
              },
              "runPolicy": {
                "cleanPodPolicy": "None",
                "schedulingPolicy": {
                  "priorityClass": "high",
                  "queue": "default"
                }
              }
            },
            "status": {
              "completionTime": "2024-07-18T02:21:56Z",
              "conditions": [
                {
                  "lastTransitionTime": "2024-07-18T02:19:27Z",
                  "lastUpdateTime": "2024-07-18T02:19:27Z",
                  "message": "PyTorchJob llamatest0718forxiaomi2 is created.",
                  "reason": "PyTorchJobCreated",
                  "status": "True",
                  "type": "Created"
                },
                {
                  "lastTransitionTime": "2024-07-18T02:19:49Z",
                  "lastUpdateTime": "2024-07-18T02:19:49Z",
                  "message": "PyTorchJob llamatest0718forxiaomi2 is running.",
                  "reason": "JobRunning",
                  "status": "False",
                  "type": "Running"
                },
                {
                  "lastTransitionTime": "2024-07-18T02:21:56Z",
                  "lastUpdateTime": "2024-07-18T02:21:56Z",
                  "message": "PytorchJob default/llamatest0718forxiaomi2 is stopped",
                  "reason": "PyTorchJobStopped",
                  "status": "True",
                  "type": "Stopped"
                },
                {
                  "lastTransitionTime": "2024-07-18T02:21:56Z",
                  "lastUpdateTime": "2024-07-18T02:21:56Z",
                  "message": "PyTorchJob llamatest0718forxiaomi2 is failed because 1 Master replica(s) failed.",
                  "reason": "JobFailed",
                  "status": "True",
                  "type": "Failed"
                }
              ],
              "lastReconcileTime": "2024-07-18T02:19:27Z",
              "replicaStatuses": {
                "Master": {
                  "failed": 1,
                  "selector": "training.kubeflow.org/job-name=llamatest0718forxiaomi2,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=master"
                },
                "Worker": {
                  "failed": 3,
                  "selector": "training.kubeflow.org/job-name=llamatest0718forxiaomi2,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=worker"
                }
              },
              "startTime": "2024-07-18T02:19:29Z"
            }
          },
          {
            "apiVersion": "kubeflow.org/v1",
            "kind": "PyTorchJob",
            "metadata": {
              "annotations": {
                "aijob.cce.baidubce.com/barrier-finish": "b95a6974-ce32-4734-8aa8-fe75aeea9668",
                "aijob.cce.baidubce.com/fault-tolerance-enabled": "true",
                "aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": "",
                "aijob.cce.baidubce.com/internal-fault-tolerance-time": "2024-07-18T02:22:31.688504306Z",
                "aijob.cce.baidubce.com/openapi-jobid": "pytorch-e973d356-59b6-4652-8e58-9e9605e1c0d8",
                "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
                "aijob.cce.baidubce.com/raw-request": "{\"name\":\"llamatest0718forxiaomi3\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"high\",\"oversell\":false,\"faultTolerance\":true,\"command\":\"\\n#! /bin/bash\\n\\nMEGATRON_PATH=${MEGATRON_PATH:-\\\"/workspace/AIAK-Megatron\\\"}\\nAIAK_TRAINING_PATH=${AIAK_TRAINING_PATH:-\\\"/workspace/AIAK-Training-LLM\\\"}\\n\\nDATA_PATH=${DATA_PATH:-\\\"/mnt/cluster/llama2/pile/pile-llama_text_document\\\"}\\nTOKENIZER_PATH=${TOKENIZER_PATH:-\\\"/mnt/cluster/llama2/Llama-2-70b-hf/tokenizer.model\\\"}\\n\\nCHECKPOINT_PATH=${CHECKPOINT_PATH:-\\\"/mnt/cluster/llama2/mcore_llama2_70b_tp4_pp4\\\"}\\n\\nTENSORBOARD_PATH=${TENSORBOARD_PATH:-\\\"/mnt/cluster/aiak-training-llm/tensorboard-log/llama2-70b-tp4pp4\\\"}\\n\\nGPUS_PER_NODE=8\\n\\n# Change for multinode config\\nMASTER_ADDR=${MASTER_ADDR:-\\\"localhost\\\"}\\nMASTER_PORT=${MASTER_PORT:-\\\"6000\\\"}\\nNNODES=${WORLD_SIZE:-\\\"1\\\"}\\nNODE_RANK=${RANK:-\\\"0\\\"}\\n\\nDISTRIBUTED_ARGS=(\\n    --nproc_per_node $GPUS_PER_NODE\\n    --nnodes $NNODES\\n    --node_rank $NODE_RANK\\n    --master_addr $MASTER_ADDR\\n    --master_port $MASTER_PORT\\n)\\n\\n# you can setup llama2-70b maunally\\n#MODEL_ARGS=(\\n#    --model-name llama2\\n#    --num-layers 80\\n#    --hidden-size 8192\\n#    --ffn-hidden-size 28672\\n#    --num-attention-heads 64\\n#    --position-embedding-type rope\\n#    --normalization RMSNorm\\n#    --swiglu\\n#    --attention-dropout 0\\n#    --hidden-dropout 0\\n#    --disable-bias-linear\\n#    --untie-embeddings-and-output-weights\\n#    --group-query-attention\\n#    --num-query-groups 8\\n#)\\n\\n# or you can setup llama2-70b by using the following command\\nMODEL_ARGS=(\\n    --model-name llama2-70b # options: llama2-7b, llama2-13b, llama2-70b\\n)\\n\\nDATA_ARGS=(\\n    --tokenizer-type HFTokenizer\\n    --hf-tokenizer-path $TOKENIZER_PATH\\n    --data-path $DATA_PATH\\n    --split 949,50,1\\n)\\n\\nTRAINING_ARGS=(\\n    --training-phase pretrain # options: pretrain, sft\\n    --seq-length 4096\\n    --max-position-embeddings 4096\\n    --init-method-std 0.01\\n    --micro-batch-size 1\\n    --global-batch-size 1024\\n    --lr 0.0002\\n    --min-lr 1.0e-5\\n    --clip-grad 1.0\\n    --weight-decay 0.01\\n    --optimizer adam\\n    --adam-beta1 0.9\\n    --adam-beta2 0.95\\n    --adam-eps 1e-05\\n    --norm-epsilon 1e-6\\n    --train-iters 500000\\n    --lr-decay-iters 500000\\n    --lr-decay-style cosine\\n    --lr-warmup-fraction 0.002\\n    --initial-loss-scale 65536\\n    --fp16\\n    --save-interval 5000\\n    --eval-interval 1000\\n    --eval-iters 10\\n    #--ckpt-step 0\\n    #--no-load-optim\\n    #--no-load-rng\\n)\\n\\nMODEL_PARALLEL_ARGS=(\\n    --tensor-model-parallel-size 4\\n    --pipeline-model-parallel-size 4\\n    --use-distributed-optimizer\\n    --overlap-grad-reduce\\n    --overlap-param-gather\\n    --distributed-backend nccl\\n    --sequence-parallel\\n    #--tp-comm-overlap # require mpi envrionment\\n)\\n\\nLOGGING_ARGS=(\\n    --log-interval 1\\n    --tensorboard-dir ${TENSORBOARD_PATH}\\n    --log-timers-to-tensorboard\\n)\\n\\nif [ -n \\\"${WANDB_API_KEY}\\\" ]; then\\n    LOGGING_ARGS+=(\\n        --wandb-project ${WANDB_PROJECT}\\n        --wandb-exp-name ${WANDB_NAME} \\n    )\\nfi\\n\\nPYTHONPATH=$MEGATRON_PATH:$AIAK_TRAINING_PATH:$PYTHONPATH     torchrun ${DISTRIBUTED_ARGS[@]}     $AIAK_TRAINING_PATH/aiak_training_llm/train.py     ${MODEL_ARGS[@]}     ${DATA_ARGS[@]}     ${TRAINING_ARGS[@]}     ${MODEL_PARALLEL_ARGS[@]}     ${LOGGING_ARGS[@]}\\n\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":true,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi3\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi3/output/training_logs\",\"CUDA_DEVICE_MAX_CONNECTIONS\":\"1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"},\"Worker\":{\"replicas\":3,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi3\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi3/output/training_logs\",\"CUDA_DEVICE_MAX_CONNECTIONS\":\"1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":true,\"logPath\":\"/mnt/cluster/llamatest0718forxiaomi3/output/training_logs\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":true,\"isCopyJob\":true,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
                "aijob.cce.baidubce.com/timeline": "[{\"conditionType\":\"Created\",\"time\":1721269309},{\"conditionType\":\"Scheduled\",\"time\":1721269311},{\"conditionType\":\"Running\",\"time\":1721269322},{\"conditionType\":\"Abnormal\",\"time\":1721269351},{\"conditionType\":\"ManualTermination\",\"time\":1721269602}]",
                "job-manager/action": "stop",
                "scheduling.k8s.io/job-enable-oversell": "false",
                "tensorboard-gc": "true"
              },
              "creationTimestamp": "2024-07-18T02:21:49Z",
              "generation": 3,
              "labels": {
                "aijob.cce.baidubce.com/ai-user-id": "b5a24aa26e4d4f55bc3acf68edc4b051",
                "aijob.cce.baidubce.com/ai-user-name": "zhangmuhua",
                "aijob.cce.baidubce.com/create-from-aihcp": "true",
                "aijob.cce.baidubce.com/openapi-jobid": "pytorch-e973d356-59b6-4652-8e58-9e9605e1c0d8"
              },
              "managedFields": [
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        "f:aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": {},
                        "f:aijob.cce.baidubce.com/timeline": {}
                      }
                    },
                    "f:spec": {
                      "f:runPolicy": {
                        "f:cleanPodPolicy": {}
                      }
                    }
                  },
                  "manager": "controller",
                  "operation": "Update",
                  "time": "2024-07-18T02:21:49Z"
                },
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        "f:aijob.cce.baidubce.com/barrier-finish": {}
                      }
                    }
                  },
                  "manager": "jobbarrier",
                  "operation": "Update",
                  "time": "2024-07-18T02:21:58Z"
                },
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        ".": {},
                        "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                        "f:aijob.cce.baidubce.com/openapi-jobid": {},
                        "f:aijob.cce.baidubce.com/pfs-id": {},
                        "f:aijob.cce.baidubce.com/raw-request": {},
                        "f:job-manager/action": {},
                        "f:scheduling.k8s.io/job-enable-oversell": {}
                      },
                      "f:labels": {
                        ".": {},
                        "f:aijob.cce.baidubce.com/ai-user-id": {},
                        "f:aijob.cce.baidubce.com/ai-user-name": {},
                        "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                        "f:aijob.cce.baidubce.com/openapi-jobid": {}
                      }
                    },
                    "f:spec": {
                      ".": {},
                      "f:pytorchReplicaSpecs": {
                        ".": {},
                        "f:Master": {
                          ".": {},
                          "f:replicas": {},
                          "f:restartPolicy": {},
                          "f:template": {
                            ".": {},
                            "f:metadata": {
                              ".": {},
                              "f:annotations": {
                                ".": {},
                                "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                                "f:aijob.cce.baidubce.com/openapi-jobid": {},
                                "f:aijob.cce.baidubce.com/pfs-id": {},
                                "f:aijob.cce.baidubce.com/raw-request": {},
                                "f:scheduling.k8s.io/job-enable-oversell": {}
                              },
                              "f:labels": {
                                ".": {},
                                "f:aijob.cce.baidubce.com/ai-user-id": {},
                                "f:aijob.cce.baidubce.com/ai-user-name": {},
                                "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                                "f:aijob.cce.baidubce.com/openapi-jobid": {}
                              }
                            },
                            "f:spec": {
                              ".": {},
                              "f:dnsPolicy": {},
                              "f:hostNetwork": {},
                              "f:schedulerName": {}
                            }
                          }
                        },
                        "f:Worker": {
                          ".": {},
                          "f:replicas": {},
                          "f:restartPolicy": {},
                          "f:template": {
                            ".": {},
                            "f:metadata": {
                              ".": {},
                              "f:annotations": {
                                ".": {},
                                "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                                "f:aijob.cce.baidubce.com/openapi-jobid": {},
                                "f:aijob.cce.baidubce.com/pfs-id": {},
                                "f:aijob.cce.baidubce.com/raw-request": {},
                                "f:scheduling.k8s.io/job-enable-oversell": {}
                              },
                              "f:labels": {
                                ".": {},
                                "f:aijob.cce.baidubce.com/ai-user-id": {},
                                "f:aijob.cce.baidubce.com/ai-user-name": {},
                                "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                                "f:aijob.cce.baidubce.com/openapi-jobid": {}
                              }
                            },
                            "f:spec": {
                              ".": {},
                              "f:dnsPolicy": {},
                              "f:hostNetwork": {},
                              "f:schedulerName": {}
                            }
                          }
                        }
                      },
                      "f:runPolicy": {
                        ".": {},
                        "f:schedulingPolicy": {
                          ".": {},
                          "f:priorityClass": {},
                          "f:queue": {}
                        }
                      }
                    }
                  },
                  "manager": "cce-ai-service",
                  "operation": "Update",
                  "time": "2024-07-18T02:26:42Z"
                },
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        "f:aijob.cce.baidubce.com/internal-fault-tolerance-time": {},
                        "f:tensorboard-gc": {}
                      }
                    },
                    "f:spec": {
                      "f:pytorchReplicaSpecs": {
                        "f:Master": {
                          "f:template": {
                            "f:metadata": {
                              "f:annotations": {
                                "f:prometheus.io/path": {},
                                "f:prometheus.io/port": {},
                                "f:prometheus.io/scrape": {}
                              }
                            },
                            "f:spec": {
                              "f:containers": {},
                              "f:serviceAccountName": {},
                              "f:shareProcessNamespace": {},
                              "f:volumes": {}
                            }
                          }
                        },
                        "f:Worker": {
                          "f:template": {
                            "f:metadata": {
                              "f:annotations": {
                                "f:prometheus.io/path": {},
                                "f:prometheus.io/port": {},
                                "f:prometheus.io/scrape": {}
                              }
                            },
                            "f:spec": {
                              "f:containers": {},
                              "f:serviceAccountName": {},
                              "f:shareProcessNamespace": {},
                              "f:volumes": {}
                            }
                          }
                        }
                      }
                    },
                    "f:status": {
                      ".": {},
                      "f:completionTime": {},
                      "f:conditions": {},
                      "f:lastReconcileTime": {},
                      "f:replicaStatuses": {
                        ".": {},
                        "f:Master": {
                          ".": {},
                          "f:failed": {}
                        },
                        "f:Worker": {
                          ".": {},
                          "f:failed": {}
                        }
                      },
                      "f:startTime": {}
                    }
                  },
                  "manager": "manager",
                  "operation": "Update",
                  "time": "2024-07-19T02:21:55Z"
                }
              ],
              "name": "llamatest0718forxiaomi3",
              "namespace": "default",
              "resourceVersion": "2372388747",
              "uid": "95cfae3c-cecc-4c60-b86b-25f654bd39ca"
            },
            "spec": {
              "pytorchReplicaSpecs": {
                "Master": {
                  "replicas": 1,
                  "restartPolicy": "Never",
                  "template": {
                    "metadata": {
                      "annotations": {
                        "aijob.cce.baidubce.com/fault-tolerance-enabled": "true",
                        "aijob.cce.baidubce.com/openapi-jobid": "pytorch-e973d356-59b6-4652-8e58-9e9605e1c0d8",
                        "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
                        "aijob.cce.baidubce.com/raw-request": "{\"name\":\"llamatest0718forxiaomi3\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"high\",\"oversell\":false,\"faultTolerance\":true,\"command\":\"\\n#! /bin/bash\\n\\nMEGATRON_PATH=${MEGATRON_PATH:-\\\"/workspace/AIAK-Megatron\\\"}\\nAIAK_TRAINING_PATH=${AIAK_TRAINING_PATH:-\\\"/workspace/AIAK-Training-LLM\\\"}\\n\\nDATA_PATH=${DATA_PATH:-\\\"/mnt/cluster/llama2/pile/pile-llama_text_document\\\"}\\nTOKENIZER_PATH=${TOKENIZER_PATH:-\\\"/mnt/cluster/llama2/Llama-2-70b-hf/tokenizer.model\\\"}\\n\\nCHECKPOINT_PATH=${CHECKPOINT_PATH:-\\\"/mnt/cluster/llama2/mcore_llama2_70b_tp4_pp4\\\"}\\n\\nTENSORBOARD_PATH=${TENSORBOARD_PATH:-\\\"/mnt/cluster/aiak-training-llm/tensorboard-log/llama2-70b-tp4pp4\\\"}\\n\\nGPUS_PER_NODE=8\\n\\n# Change for multinode config\\nMASTER_ADDR=${MASTER_ADDR:-\\\"localhost\\\"}\\nMASTER_PORT=${MASTER_PORT:-\\\"6000\\\"}\\nNNODES=${WORLD_SIZE:-\\\"1\\\"}\\nNODE_RANK=${RANK:-\\\"0\\\"}\\n\\nDISTRIBUTED_ARGS=(\\n    --nproc_per_node $GPUS_PER_NODE\\n    --nnodes $NNODES\\n    --node_rank $NODE_RANK\\n    --master_addr $MASTER_ADDR\\n    --master_port $MASTER_PORT\\n)\\n\\n# you can setup llama2-70b maunally\\n#MODEL_ARGS=(\\n#    --model-name llama2\\n#    --num-layers 80\\n#    --hidden-size 8192\\n#    --ffn-hidden-size 28672\\n#    --num-attention-heads 64\\n#    --position-embedding-type rope\\n#    --normalization RMSNorm\\n#    --swiglu\\n#    --attention-dropout 0\\n#    --hidden-dropout 0\\n#    --disable-bias-linear\\n#    --untie-embeddings-and-output-weights\\n#    --group-query-attention\\n#    --num-query-groups 8\\n#)\\n\\n# or you can setup llama2-70b by using the following command\\nMODEL_ARGS=(\\n    --model-name llama2-70b # options: llama2-7b, llama2-13b, llama2-70b\\n)\\n\\nDATA_ARGS=(\\n    --tokenizer-type HFTokenizer\\n    --hf-tokenizer-path $TOKENIZER_PATH\\n    --data-path $DATA_PATH\\n    --split 949,50,1\\n)\\n\\nTRAINING_ARGS=(\\n    --training-phase pretrain # options: pretrain, sft\\n    --seq-length 4096\\n    --max-position-embeddings 4096\\n    --init-method-std 0.01\\n    --micro-batch-size 1\\n    --global-batch-size 1024\\n    --lr 0.0002\\n    --min-lr 1.0e-5\\n    --clip-grad 1.0\\n    --weight-decay 0.01\\n    --optimizer adam\\n    --adam-beta1 0.9\\n    --adam-beta2 0.95\\n    --adam-eps 1e-05\\n    --norm-epsilon 1e-6\\n    --train-iters 500000\\n    --lr-decay-iters 500000\\n    --lr-decay-style cosine\\n    --lr-warmup-fraction 0.002\\n    --initial-loss-scale 65536\\n    --fp16\\n    --save-interval 5000\\n    --eval-interval 1000\\n    --eval-iters 10\\n    #--ckpt-step 0\\n    #--no-load-optim\\n    #--no-load-rng\\n)\\n\\nMODEL_PARALLEL_ARGS=(\\n    --tensor-model-parallel-size 4\\n    --pipeline-model-parallel-size 4\\n    --use-distributed-optimizer\\n    --overlap-grad-reduce\\n    --overlap-param-gather\\n    --distributed-backend nccl\\n    --sequence-parallel\\n    #--tp-comm-overlap # require mpi envrionment\\n)\\n\\nLOGGING_ARGS=(\\n    --log-interval 1\\n    --tensorboard-dir ${TENSORBOARD_PATH}\\n    --log-timers-to-tensorboard\\n)\\n\\nif [ -n \\\"${WANDB_API_KEY}\\\" ]; then\\n    LOGGING_ARGS+=(\\n        --wandb-project ${WANDB_PROJECT}\\n        --wandb-exp-name ${WANDB_NAME} \\n    )\\nfi\\n\\nPYTHONPATH=$MEGATRON_PATH:$AIAK_TRAINING_PATH:$PYTHONPATH     torchrun ${DISTRIBUTED_ARGS[@]}     $AIAK_TRAINING_PATH/aiak_training_llm/train.py     ${MODEL_ARGS[@]}     ${DATA_ARGS[@]}     ${TRAINING_ARGS[@]}     ${MODEL_PARALLEL_ARGS[@]}     ${LOGGING_ARGS[@]}\\n\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":true,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi3\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi3/output/training_logs\",\"CUDA_DEVICE_MAX_CONNECTIONS\":\"1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"},\"Worker\":{\"replicas\":3,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi3\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi3/output/training_logs\",\"CUDA_DEVICE_MAX_CONNECTIONS\":\"1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":true,\"logPath\":\"/mnt/cluster/llamatest0718forxiaomi3/output/training_logs\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":true,\"isCopyJob\":true,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
                        "prometheus.io/path": "/metrics",
                        "prometheus.io/port": "9101",
                        "prometheus.io/scrape": "true",
                        "scheduling.k8s.io/job-enable-oversell": "false"
                      },
                      "labels": {
                        "aijob.cce.baidubce.com/ai-user-id": "b5a24aa26e4d4f55bc3acf68edc4b051",
                        "aijob.cce.baidubce.com/ai-user-name": "zhangmuhua",
                        "aijob.cce.baidubce.com/create-from-aihcp": "true",
                        "aijob.cce.baidubce.com/openapi-jobid": "pytorch-e973d356-59b6-4652-8e58-9e9605e1c0d8"
                      }
                    },
                    "spec": {
                      "containers": [
                        {
                          "command": [
                            "/bin/bash",
                            "-c",
                            "\n#! /bin/bash\n\nMEGATRON_PATH=${MEGATRON_PATH:-\"/workspace/AIAK-Megatron\"}\nAIAK_TRAINING_PATH=${AIAK_TRAINING_PATH:-\"/workspace/AIAK-Training-LLM\"}\n\nDATA_PATH=${DATA_PATH:-\"/mnt/cluster/llama2/pile/pile-llama_text_document\"}\nTOKENIZER_PATH=${TOKENIZER_PATH:-\"/mnt/cluster/llama2/Llama-2-70b-hf/tokenizer.model\"}\n\nCHECKPOINT_PATH=${CHECKPOINT_PATH:-\"/mnt/cluster/llama2/mcore_llama2_70b_tp4_pp4\"}\n\nTENSORBOARD_PATH=${TENSORBOARD_PATH:-\"/mnt/cluster/aiak-training-llm/tensorboard-log/llama2-70b-tp4pp4\"}\n\nGPUS_PER_NODE=8\n\n# Change for multinode config\nMASTER_ADDR=${MASTER_ADDR:-\"localhost\"}\nMASTER_PORT=${MASTER_PORT:-\"6000\"}\nNNODES=${WORLD_SIZE:-\"1\"}\nNODE_RANK=${RANK:-\"0\"}\n\nDISTRIBUTED_ARGS=(\n    --nproc_per_node $GPUS_PER_NODE\n    --nnodes $NNODES\n    --node_rank $NODE_RANK\n    --master_addr $MASTER_ADDR\n    --master_port $MASTER_PORT\n)\n\n# you can setup llama2-70b maunally\n#MODEL_ARGS=(\n#    --model-name llama2\n#    --num-layers 80\n#    --hidden-size 8192\n#    --ffn-hidden-size 28672\n#    --num-attention-heads 64\n#    --position-embedding-type rope\n#    --normalization RMSNorm\n#    --swiglu\n#    --attention-dropout 0\n#    --hidden-dropout 0\n#    --disable-bias-linear\n#    --untie-embeddings-and-output-weights\n#    --group-query-attention\n#    --num-query-groups 8\n#)\n\n# or you can setup llama2-70b by using the following command\nMODEL_ARGS=(\n    --model-name llama2-70b # options: llama2-7b, llama2-13b, llama2-70b\n)\n\nDATA_ARGS=(\n    --tokenizer-type HFTokenizer\n    --hf-tokenizer-path $TOKENIZER_PATH\n    --data-path $DATA_PATH\n    --split 949,50,1\n)\n\nTRAINING_ARGS=(\n    --training-phase pretrain # options: pretrain, sft\n    --seq-length 4096\n    --max-position-embeddings 4096\n    --init-method-std 0.01\n    --micro-batch-size 1\n    --global-batch-size 1024\n    --lr 0.0002\n    --min-lr 1.0e-5\n    --clip-grad 1.0\n    --weight-decay 0.01\n    --optimizer adam\n    --adam-beta1 0.9\n    --adam-beta2 0.95\n    --adam-eps 1e-05\n    --norm-epsilon 1e-6\n    --train-iters 500000\n    --lr-decay-iters 500000\n    --lr-decay-style cosine\n    --lr-warmup-fraction 0.002\n    --initial-loss-scale 65536\n    --fp16\n    --save-interval 5000\n    --eval-interval 1000\n    --eval-iters 10\n    #--ckpt-step 0\n    #--no-load-optim\n    #--no-load-rng\n)\n\nMODEL_PARALLEL_ARGS=(\n    --tensor-model-parallel-size 4\n    --pipeline-model-parallel-size 4\n    --use-distributed-optimizer\n    --overlap-grad-reduce\n    --overlap-param-gather\n    --distributed-backend nccl\n    --sequence-parallel\n    #--tp-comm-overlap # require mpi envrionment\n)\n\nLOGGING_ARGS=(\n    --log-interval 1\n    --tensorboard-dir ${TENSORBOARD_PATH}\n    --log-timers-to-tensorboard\n)\n\nif [ -n \"${WANDB_API_KEY}\" ]; then\n    LOGGING_ARGS+=(\n        --wandb-project ${WANDB_PROJECT}\n        --wandb-exp-name ${WANDB_NAME} \n    )\nfi\n\nPYTHONPATH=$MEGATRON_PATH:$AIAK_TRAINING_PATH:$PYTHONPATH     torchrun ${DISTRIBUTED_ARGS[@]}     $AIAK_TRAINING_PATH/aiak_training_llm/train.py     ${MODEL_ARGS[@]}     ${DATA_ARGS[@]}     ${TRAINING_ARGS[@]}     ${MODEL_PARALLEL_ARGS[@]}     ${LOGGING_ARGS[@]}\n"
                          ],
                          "env": [
                            {
                              "name": "CUDA_DEVICE_MAX_CONNECTIONS",
                              "value": "1"
                            },
                            {
                              "name": "AIHC_TENSORBOARD_LOG_PATH",
                              "value": "/mnt/cluster/llamatest0718forxiaomi3/output/training_logs"
                            },
                            {
                              "name": "AIHC_JOB_NAME",
                              "value": "llamatest0718forxiaomi3"
                            },
                            {
                              "name": "NCCL_IB_DISABLE",
                              "value": "0"
                            },
                            {
                              "name": "BCCL_BUS_BW_CALCULATE_MODE",
                              "value": "Agg"
                            },
                            {
                              "name": "BCCL_PROFILING_FILE",
                              "value": "/var/bccl/logs/busbw.cal.%h.%p"
                            }
                          ],
                          "image": "registry.baidubce.com/aihc-aiak/aiak-training-llm:ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release",
                          "imagePullPolicy": "Always",
                          "name": "pytorch",
                          "ports": [
                            {
                              "containerPort": 23456,
                              "name": "pytorchjob-port",
                              "protocol": "TCP"
                            }
                          ],
                          "resources": {
                            "limits": {
                              "baidu.com/a800_80g_cgpu": "8",
                              "rdma/hca": "1"
                            },
                            "requests": {
                              "baidu.com/a800_80g_cgpu": "8",
                              "rdma/hca": "1"
                            }
                          },
                          "securityContext": {
                            "capabilities": {
                              "add": [
                                "IPC_LOCK"
                              ]
                            }
                          },
                          "volumeMounts": [
                            {
                              "mountPath": "/dev/shm",
                              "name": "devshm"
                            },
                            {
                              "mountPath": "/mnt/cluster",
                              "name": "pvc-pfs"
                            },
                            {
                              "mountPath": "/var/bccl/logs",
                              "name": "bccl-logs-volume"
                            }
                          ]
                        },
                        {
                          "env": [
                            {
                              "name": "POD_NAME",
                              "valueFrom": {
                                "fieldRef": {
                                  "apiVersion": "v1",
                                  "fieldPath": "metadata.name"
                                }
                              }
                            },
                            {
                              "name": "POD_UID",
                              "valueFrom": {
                                "fieldRef": {
                                  "apiVersion": "v1",
                                  "fieldPath": "metadata.uid"
                                }
                              }
                            },
                            {
                              "name": "POD_NAMESPACE",
                              "valueFrom": {
                                "fieldRef": {
                                  "apiVersion": "v1",
                                  "fieldPath": "metadata.namespace"
                                }
                              }
                            },
                            {
                              "name": "NODE_NAME",
                              "valueFrom": {
                                "fieldRef": {
                                  "apiVersion": "v1",
                                  "fieldPath": "spec.nodeName"
                                }
                              }
                            },
                            {
                              "name": "JOB_NAME",
                              "value": "llamatest0718forxiaomi3"
                            },
                            {
                              "name": "NODE_IP",
                              "valueFrom": {
                                "fieldRef": {
                                  "apiVersion": "v1",
                                  "fieldPath": "status.hostIP"
                                }
                              }
                            },
                            {
                              "name": "ENABLE_ELASTIC",
                              "value": "9"
                            },
                            {
                              "name": "GPUS_PER_NODE",
                              "value": "8"
                            },
                            {
                              "name": "BCCL_LOG_DIR",
                              "value": "/var/bccl/logs"
                            },
                            {
                              "name": "EXPORTER_PORT",
                              "value": "9101"
                            },
                            {
                              "name": "EXPORTER_INTERVAL",
                              "value": "60"
                            },
                            {
                              "name": "EXPORTER_PATH",
                              "value": "/metrics"
                            },
                            {
                              "name": "BCCL_BUS_BW_CALCULATE_MODE",
                              "value": "Agg"
                            },
                            {
                              "name": "BCCL_PROFILING_FILE",
                              "value": "/var/bccl/logs/busbw.cal.%h.%p"
                            }
                          ],
                          "image": "registry.baidubce.com/cce-plugin-dev/ftagent:v1.6-20240713172215",
                          "imagePullPolicy": "Always",
                          "name": "ftagent",
                          "ports": [
                            {
                              "containerPort": 9101,
                              "name": "exporter",
                              "protocol": "TCP"
                            }
                          ],
                          "resources": {},
                          "securityContext": {
                            "capabilities": {
                              "add": [
                                "IPC_LOCK"
                              ]
                            }
                          },
                          "volumeMounts": [
                            {
                              "mountPath": "/var/log/pods",
                              "name": "pod-log-volume"
                            },
                            {
                              "mountPath": "/home/cce",
                              "name": "container-log-volume"
                            },
                            {
                              "mountPath": "/var/bccl/logs",
                              "name": "bccl-logs-volume"
                            }
                          ]
                        }
                      ],
                      "dnsPolicy": "ClusterFirstWithHostNet",
                      "hostNetwork": true,
                      "schedulerName": "volcano",
                      "serviceAccountName": "ftagent-sa",
                      "shareProcessNamespace": true,
                      "volumes": [
                        {
                          "emptyDir": {
                            "medium": "Memory",
                            "sizeLimit": "10Gi"
                          },
                          "name": "devshm"
                        },
                        {
                          "name": "pvc-pfs",
                          "persistentVolumeClaim": {
                            "claimName": "pvc-pfs"
                          }
                        },
                        {
                          "emptyDir": {},
                          "name": "bccl-logs-volume"
                        },
                        {
                          "hostPath": {
                            "path": "/var/log/pods",
                            "type": "DirectoryOrCreate"
                          },
                          "name": "pod-log-volume"
                        },
                        {
                          "hostPath": {
                            "path": "/home/cce",
                            "type": "DirectoryOrCreate"
                          },
                          "name": "container-log-volume"
                        }
                      ]
                    }
                  }
                },
                "Worker": {
                  "replicas": 3,
                  "restartPolicy": "Never",
                  "template": {
                    "metadata": {
                      "annotations": {
                        "aijob.cce.baidubce.com/fault-tolerance-enabled": "true",
                        "aijob.cce.baidubce.com/openapi-jobid": "pytorch-e973d356-59b6-4652-8e58-9e9605e1c0d8",
                        "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
                        "aijob.cce.baidubce.com/raw-request": "{\"name\":\"llamatest0718forxiaomi3\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"high\",\"oversell\":false,\"faultTolerance\":true,\"command\":\"\\n#! /bin/bash\\n\\nMEGATRON_PATH=${MEGATRON_PATH:-\\\"/workspace/AIAK-Megatron\\\"}\\nAIAK_TRAINING_PATH=${AIAK_TRAINING_PATH:-\\\"/workspace/AIAK-Training-LLM\\\"}\\n\\nDATA_PATH=${DATA_PATH:-\\\"/mnt/cluster/llama2/pile/pile-llama_text_document\\\"}\\nTOKENIZER_PATH=${TOKENIZER_PATH:-\\\"/mnt/cluster/llama2/Llama-2-70b-hf/tokenizer.model\\\"}\\n\\nCHECKPOINT_PATH=${CHECKPOINT_PATH:-\\\"/mnt/cluster/llama2/mcore_llama2_70b_tp4_pp4\\\"}\\n\\nTENSORBOARD_PATH=${TENSORBOARD_PATH:-\\\"/mnt/cluster/aiak-training-llm/tensorboard-log/llama2-70b-tp4pp4\\\"}\\n\\nGPUS_PER_NODE=8\\n\\n# Change for multinode config\\nMASTER_ADDR=${MASTER_ADDR:-\\\"localhost\\\"}\\nMASTER_PORT=${MASTER_PORT:-\\\"6000\\\"}\\nNNODES=${WORLD_SIZE:-\\\"1\\\"}\\nNODE_RANK=${RANK:-\\\"0\\\"}\\n\\nDISTRIBUTED_ARGS=(\\n    --nproc_per_node $GPUS_PER_NODE\\n    --nnodes $NNODES\\n    --node_rank $NODE_RANK\\n    --master_addr $MASTER_ADDR\\n    --master_port $MASTER_PORT\\n)\\n\\n# you can setup llama2-70b maunally\\n#MODEL_ARGS=(\\n#    --model-name llama2\\n#    --num-layers 80\\n#    --hidden-size 8192\\n#    --ffn-hidden-size 28672\\n#    --num-attention-heads 64\\n#    --position-embedding-type rope\\n#    --normalization RMSNorm\\n#    --swiglu\\n#    --attention-dropout 0\\n#    --hidden-dropout 0\\n#    --disable-bias-linear\\n#    --untie-embeddings-and-output-weights\\n#    --group-query-attention\\n#    --num-query-groups 8\\n#)\\n\\n# or you can setup llama2-70b by using the following command\\nMODEL_ARGS=(\\n    --model-name llama2-70b # options: llama2-7b, llama2-13b, llama2-70b\\n)\\n\\nDATA_ARGS=(\\n    --tokenizer-type HFTokenizer\\n    --hf-tokenizer-path $TOKENIZER_PATH\\n    --data-path $DATA_PATH\\n    --split 949,50,1\\n)\\n\\nTRAINING_ARGS=(\\n    --training-phase pretrain # options: pretrain, sft\\n    --seq-length 4096\\n    --max-position-embeddings 4096\\n    --init-method-std 0.01\\n    --micro-batch-size 1\\n    --global-batch-size 1024\\n    --lr 0.0002\\n    --min-lr 1.0e-5\\n    --clip-grad 1.0\\n    --weight-decay 0.01\\n    --optimizer adam\\n    --adam-beta1 0.9\\n    --adam-beta2 0.95\\n    --adam-eps 1e-05\\n    --norm-epsilon 1e-6\\n    --train-iters 500000\\n    --lr-decay-iters 500000\\n    --lr-decay-style cosine\\n    --lr-warmup-fraction 0.002\\n    --initial-loss-scale 65536\\n    --fp16\\n    --save-interval 5000\\n    --eval-interval 1000\\n    --eval-iters 10\\n    #--ckpt-step 0\\n    #--no-load-optim\\n    #--no-load-rng\\n)\\n\\nMODEL_PARALLEL_ARGS=(\\n    --tensor-model-parallel-size 4\\n    --pipeline-model-parallel-size 4\\n    --use-distributed-optimizer\\n    --overlap-grad-reduce\\n    --overlap-param-gather\\n    --distributed-backend nccl\\n    --sequence-parallel\\n    #--tp-comm-overlap # require mpi envrionment\\n)\\n\\nLOGGING_ARGS=(\\n    --log-interval 1\\n    --tensorboard-dir ${TENSORBOARD_PATH}\\n    --log-timers-to-tensorboard\\n)\\n\\nif [ -n \\\"${WANDB_API_KEY}\\\" ]; then\\n    LOGGING_ARGS+=(\\n        --wandb-project ${WANDB_PROJECT}\\n        --wandb-exp-name ${WANDB_NAME} \\n    )\\nfi\\n\\nPYTHONPATH=$MEGATRON_PATH:$AIAK_TRAINING_PATH:$PYTHONPATH     torchrun ${DISTRIBUTED_ARGS[@]}     $AIAK_TRAINING_PATH/aiak_training_llm/train.py     ${MODEL_ARGS[@]}     ${DATA_ARGS[@]}     ${TRAINING_ARGS[@]}     ${MODEL_PARALLEL_ARGS[@]}     ${LOGGING_ARGS[@]}\\n\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":true,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi3\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi3/output/training_logs\",\"CUDA_DEVICE_MAX_CONNECTIONS\":\"1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"},\"Worker\":{\"replicas\":3,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi3\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi3/output/training_logs\",\"CUDA_DEVICE_MAX_CONNECTIONS\":\"1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":true,\"logPath\":\"/mnt/cluster/llamatest0718forxiaomi3/output/training_logs\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":true,\"isCopyJob\":true,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
                        "prometheus.io/path": "/metrics",
                        "prometheus.io/port": "9101",
                        "prometheus.io/scrape": "true",
                        "scheduling.k8s.io/job-enable-oversell": "false"
                      },
                      "labels": {
                        "aijob.cce.baidubce.com/ai-user-id": "b5a24aa26e4d4f55bc3acf68edc4b051",
                        "aijob.cce.baidubce.com/ai-user-name": "zhangmuhua",
                        "aijob.cce.baidubce.com/create-from-aihcp": "true",
                        "aijob.cce.baidubce.com/openapi-jobid": "pytorch-e973d356-59b6-4652-8e58-9e9605e1c0d8"
                      }
                    },
                    "spec": {
                      "containers": [
                        {
                          "command": [
                            "/bin/bash",
                            "-c",
                            "\n#! /bin/bash\n\nMEGATRON_PATH=${MEGATRON_PATH:-\"/workspace/AIAK-Megatron\"}\nAIAK_TRAINING_PATH=${AIAK_TRAINING_PATH:-\"/workspace/AIAK-Training-LLM\"}\n\nDATA_PATH=${DATA_PATH:-\"/mnt/cluster/llama2/pile/pile-llama_text_document\"}\nTOKENIZER_PATH=${TOKENIZER_PATH:-\"/mnt/cluster/llama2/Llama-2-70b-hf/tokenizer.model\"}\n\nCHECKPOINT_PATH=${CHECKPOINT_PATH:-\"/mnt/cluster/llama2/mcore_llama2_70b_tp4_pp4\"}\n\nTENSORBOARD_PATH=${TENSORBOARD_PATH:-\"/mnt/cluster/aiak-training-llm/tensorboard-log/llama2-70b-tp4pp4\"}\n\nGPUS_PER_NODE=8\n\n# Change for multinode config\nMASTER_ADDR=${MASTER_ADDR:-\"localhost\"}\nMASTER_PORT=${MASTER_PORT:-\"6000\"}\nNNODES=${WORLD_SIZE:-\"1\"}\nNODE_RANK=${RANK:-\"0\"}\n\nDISTRIBUTED_ARGS=(\n    --nproc_per_node $GPUS_PER_NODE\n    --nnodes $NNODES\n    --node_rank $NODE_RANK\n    --master_addr $MASTER_ADDR\n    --master_port $MASTER_PORT\n)\n\n# you can setup llama2-70b maunally\n#MODEL_ARGS=(\n#    --model-name llama2\n#    --num-layers 80\n#    --hidden-size 8192\n#    --ffn-hidden-size 28672\n#    --num-attention-heads 64\n#    --position-embedding-type rope\n#    --normalization RMSNorm\n#    --swiglu\n#    --attention-dropout 0\n#    --hidden-dropout 0\n#    --disable-bias-linear\n#    --untie-embeddings-and-output-weights\n#    --group-query-attention\n#    --num-query-groups 8\n#)\n\n# or you can setup llama2-70b by using the following command\nMODEL_ARGS=(\n    --model-name llama2-70b # options: llama2-7b, llama2-13b, llama2-70b\n)\n\nDATA_ARGS=(\n    --tokenizer-type HFTokenizer\n    --hf-tokenizer-path $TOKENIZER_PATH\n    --data-path $DATA_PATH\n    --split 949,50,1\n)\n\nTRAINING_ARGS=(\n    --training-phase pretrain # options: pretrain, sft\n    --seq-length 4096\n    --max-position-embeddings 4096\n    --init-method-std 0.01\n    --micro-batch-size 1\n    --global-batch-size 1024\n    --lr 0.0002\n    --min-lr 1.0e-5\n    --clip-grad 1.0\n    --weight-decay 0.01\n    --optimizer adam\n    --adam-beta1 0.9\n    --adam-beta2 0.95\n    --adam-eps 1e-05\n    --norm-epsilon 1e-6\n    --train-iters 500000\n    --lr-decay-iters 500000\n    --lr-decay-style cosine\n    --lr-warmup-fraction 0.002\n    --initial-loss-scale 65536\n    --fp16\n    --save-interval 5000\n    --eval-interval 1000\n    --eval-iters 10\n    #--ckpt-step 0\n    #--no-load-optim\n    #--no-load-rng\n)\n\nMODEL_PARALLEL_ARGS=(\n    --tensor-model-parallel-size 4\n    --pipeline-model-parallel-size 4\n    --use-distributed-optimizer\n    --overlap-grad-reduce\n    --overlap-param-gather\n    --distributed-backend nccl\n    --sequence-parallel\n    #--tp-comm-overlap # require mpi envrionment\n)\n\nLOGGING_ARGS=(\n    --log-interval 1\n    --tensorboard-dir ${TENSORBOARD_PATH}\n    --log-timers-to-tensorboard\n)\n\nif [ -n \"${WANDB_API_KEY}\" ]; then\n    LOGGING_ARGS+=(\n        --wandb-project ${WANDB_PROJECT}\n        --wandb-exp-name ${WANDB_NAME} \n    )\nfi\n\nPYTHONPATH=$MEGATRON_PATH:$AIAK_TRAINING_PATH:$PYTHONPATH     torchrun ${DISTRIBUTED_ARGS[@]}     $AIAK_TRAINING_PATH/aiak_training_llm/train.py     ${MODEL_ARGS[@]}     ${DATA_ARGS[@]}     ${TRAINING_ARGS[@]}     ${MODEL_PARALLEL_ARGS[@]}     ${LOGGING_ARGS[@]}\n"
                          ],
                          "env": [
                            {
                              "name": "AIHC_JOB_NAME",
                              "value": "llamatest0718forxiaomi3"
                            },
                            {
                              "name": "NCCL_IB_DISABLE",
                              "value": "0"
                            },
                            {
                              "name": "CUDA_DEVICE_MAX_CONNECTIONS",
                              "value": "1"
                            },
                            {
                              "name": "AIHC_TENSORBOARD_LOG_PATH",
                              "value": "/mnt/cluster/llamatest0718forxiaomi3/output/training_logs"
                            },
                            {
                              "name": "BCCL_BUS_BW_CALCULATE_MODE",
                              "value": "Agg"
                            },
                            {
                              "name": "BCCL_PROFILING_FILE",
                              "value": "/var/bccl/logs/busbw.cal.%h.%p"
                            }
                          ],
                          "image": "registry.baidubce.com/aihc-aiak/aiak-training-llm:ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release",
                          "imagePullPolicy": "Always",
                          "name": "pytorch",
                          "ports": [
                            {
                              "containerPort": 23456,
                              "name": "pytorchjob-port",
                              "protocol": "TCP"
                            }
                          ],
                          "resources": {
                            "limits": {
                              "baidu.com/a800_80g_cgpu": "8",
                              "rdma/hca": "1"
                            },
                            "requests": {
                              "baidu.com/a800_80g_cgpu": "8",
                              "rdma/hca": "1"
                            }
                          },
                          "securityContext": {
                            "capabilities": {
                              "add": [
                                "IPC_LOCK"
                              ]
                            }
                          },
                          "volumeMounts": [
                            {
                              "mountPath": "/dev/shm",
                              "name": "devshm"
                            },
                            {
                              "mountPath": "/mnt/cluster",
                              "name": "pvc-pfs"
                            },
                            {
                              "mountPath": "/var/bccl/logs",
                              "name": "bccl-logs-volume"
                            }
                          ]
                        },
                        {
                          "env": [
                            {
                              "name": "POD_NAME",
                              "valueFrom": {
                                "fieldRef": {
                                  "apiVersion": "v1",
                                  "fieldPath": "metadata.name"
                                }
                              }
                            },
                            {
                              "name": "POD_UID",
                              "valueFrom": {
                                "fieldRef": {
                                  "apiVersion": "v1",
                                  "fieldPath": "metadata.uid"
                                }
                              }
                            },
                            {
                              "name": "POD_NAMESPACE",
                              "valueFrom": {
                                "fieldRef": {
                                  "apiVersion": "v1",
                                  "fieldPath": "metadata.namespace"
                                }
                              }
                            },
                            {
                              "name": "NODE_NAME",
                              "valueFrom": {
                                "fieldRef": {
                                  "apiVersion": "v1",
                                  "fieldPath": "spec.nodeName"
                                }
                              }
                            },
                            {
                              "name": "JOB_NAME",
                              "value": "llamatest0718forxiaomi3"
                            },
                            {
                              "name": "NODE_IP",
                              "valueFrom": {
                                "fieldRef": {
                                  "apiVersion": "v1",
                                  "fieldPath": "status.hostIP"
                                }
                              }
                            },
                            {
                              "name": "ENABLE_ELASTIC",
                              "value": "9"
                            },
                            {
                              "name": "GPUS_PER_NODE",
                              "value": "8"
                            },
                            {
                              "name": "BCCL_LOG_DIR",
                              "value": "/var/bccl/logs"
                            },
                            {
                              "name": "EXPORTER_PORT",
                              "value": "9101"
                            },
                            {
                              "name": "EXPORTER_INTERVAL",
                              "value": "60"
                            },
                            {
                              "name": "EXPORTER_PATH",
                              "value": "/metrics"
                            },
                            {
                              "name": "BCCL_BUS_BW_CALCULATE_MODE",
                              "value": "Agg"
                            },
                            {
                              "name": "BCCL_PROFILING_FILE",
                              "value": "/var/bccl/logs/busbw.cal.%h.%p"
                            }
                          ],
                          "image": "registry.baidubce.com/cce-plugin-dev/ftagent:v1.6-20240713172215",
                          "imagePullPolicy": "Always",
                          "name": "ftagent",
                          "ports": [
                            {
                              "containerPort": 9101,
                              "name": "exporter",
                              "protocol": "TCP"
                            }
                          ],
                          "resources": {},
                          "securityContext": {
                            "capabilities": {
                              "add": [
                                "IPC_LOCK"
                              ]
                            }
                          },
                          "volumeMounts": [
                            {
                              "mountPath": "/var/log/pods",
                              "name": "pod-log-volume"
                            },
                            {
                              "mountPath": "/home/cce",
                              "name": "container-log-volume"
                            },
                            {
                              "mountPath": "/var/bccl/logs",
                              "name": "bccl-logs-volume"
                            }
                          ]
                        }
                      ],
                      "dnsPolicy": "ClusterFirstWithHostNet",
                      "hostNetwork": true,
                      "schedulerName": "volcano",
                      "serviceAccountName": "ftagent-sa",
                      "shareProcessNamespace": true,
                      "volumes": [
                        {
                          "emptyDir": {
                            "medium": "Memory",
                            "sizeLimit": "10Gi"
                          },
                          "name": "devshm"
                        },
                        {
                          "name": "pvc-pfs",
                          "persistentVolumeClaim": {
                            "claimName": "pvc-pfs"
                          }
                        },
                        {
                          "emptyDir": {},
                          "name": "bccl-logs-volume"
                        },
                        {
                          "hostPath": {
                            "path": "/var/log/pods",
                            "type": "DirectoryOrCreate"
                          },
                          "name": "pod-log-volume"
                        },
                        {
                          "hostPath": {
                            "path": "/home/cce",
                            "type": "DirectoryOrCreate"
                          },
                          "name": "container-log-volume"
                        }
                      ]
                    }
                  }
                }
              },
              "runPolicy": {
                "cleanPodPolicy": "None",
                "schedulingPolicy": {
                  "priorityClass": "high",
                  "queue": "default"
                }
              }
            },
            "status": {
              "completionTime": "2024-07-18T02:26:42Z",
              "conditions": [
                {
                  "lastTransitionTime": "2024-07-18T02:21:49Z",
                  "lastUpdateTime": "2024-07-18T02:21:49Z",
                  "message": "PyTorchJob llamatest0718forxiaomi3 is created.",
                  "reason": "PyTorchJobCreated",
                  "status": "True",
                  "type": "Created"
                },
                {
                  "lastTransitionTime": "2024-07-18T02:22:02Z",
                  "lastUpdateTime": "2024-07-18T02:22:02Z",
                  "message": "PyTorchJob llamatest0718forxiaomi3 is running.",
                  "reason": "JobRunning",
                  "status": "False",
                  "type": "Running"
                },
                {
                  "lastTransitionTime": "2024-07-18T02:26:42Z",
                  "lastUpdateTime": "2024-07-18T02:26:42Z",
                  "message": "PytorchJob default/llamatest0718forxiaomi3 is stopped",
                  "reason": "PyTorchJobStopped",
                  "status": "True",
                  "type": "Stopped"
                },
                {
                  "lastTransitionTime": "2024-07-18T02:26:42Z",
                  "lastUpdateTime": "2024-07-18T02:26:42Z",
                  "message": "PyTorchJob llamatest0718forxiaomi3 is failed because 1 Master replica(s) failed.",
                  "reason": "JobFailed",
                  "status": "True",
                  "type": "Failed"
                }
              ],
              "lastReconcileTime": "2024-07-18T02:21:50Z",
              "replicaStatuses": {
                "Master": {
                  "failed": 1,
                  "selector": "training.kubeflow.org/job-name=llamatest0718forxiaomi3,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=master"
                },
                "Worker": {
                  "failed": 3,
                  "selector": "training.kubeflow.org/job-name=llamatest0718forxiaomi3,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=worker"
                }
              },
              "startTime": "2024-07-18T02:21:50Z"
            }
          },
          {
            "apiVersion": "kubeflow.org/v1",
            "kind": "PyTorchJob",
            "metadata": {
              "annotations": {
                "aijob.cce.baidubce.com/barrier-finish": "dd6fc2af-82c1-4e46-9b76-035b4e3edcbb",
                "aijob.cce.baidubce.com/fault-tolerance-enabled": "true",
                "aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": "",
                "aijob.cce.baidubce.com/internal-fault-tolerance-time": "2024-07-18T02:27:46.670969774Z",
                "aijob.cce.baidubce.com/openapi-jobid": "pytorch-27acfb1c-f6ea-4a51-93eb-24d0ee3413ac",
                "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
                "aijob.cce.baidubce.com/raw-request": "{\"name\":\"llamatest0718forxiaomi4\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"high\",\"oversell\":false,\"faultTolerance\":true,\"command\":\"\\n#! /bin/bash\\n\\nMEGATRON_PATH=${MEGATRON_PATH:-\\\"/workspace/AIAK-Megatron\\\"}\\nAIAK_TRAINING_PATH=${AIAK_TRAINING_PATH:-\\\"/workspace/AIAK-Training-LLM\\\"}\\n\\nDATA_PATH=${DATA_PATH:-\\\"/mnt/cluster/llama2/pile/pile-llama_text_document\\\"}\\nTOKENIZER_PATH=${TOKENIZER_PATH:-\\\"/mnt/cluster/llama2/Llama-2-70b-hf/\\\"}\\n\\nCHECKPOINT_PATH=${CHECKPOINT_PATH:-\\\"/mnt/cluster/llama2/mcore_llama2_70b_tp4_pp4\\\"}\\n\\nTENSORBOARD_PATH=${TENSORBOARD_PATH:-\\\"/mnt/cluster/aiak-training-llm/tensorboard-log/llama2-70b-tp4pp4\\\"}\\n\\nGPUS_PER_NODE=8\\n\\n# Change for multinode config\\nMASTER_ADDR=${MASTER_ADDR:-\\\"localhost\\\"}\\nMASTER_PORT=${MASTER_PORT:-\\\"6000\\\"}\\nNNODES=${WORLD_SIZE:-\\\"1\\\"}\\nNODE_RANK=${RANK:-\\\"0\\\"}\\n\\nDISTRIBUTED_ARGS=(\\n    --nproc_per_node $GPUS_PER_NODE\\n    --nnodes $NNODES\\n    --node_rank $NODE_RANK\\n    --master_addr $MASTER_ADDR\\n    --master_port $MASTER_PORT\\n)\\n\\n# you can setup llama2-70b maunally\\n#MODEL_ARGS=(\\n#    --model-name llama2\\n#    --num-layers 80\\n#    --hidden-size 8192\\n#    --ffn-hidden-size 28672\\n#    --num-attention-heads 64\\n#    --position-embedding-type rope\\n#    --normalization RMSNorm\\n#    --swiglu\\n#    --attention-dropout 0\\n#    --hidden-dropout 0\\n#    --disable-bias-linear\\n#    --untie-embeddings-and-output-weights\\n#    --group-query-attention\\n#    --num-query-groups 8\\n#)\\n\\n# or you can setup llama2-70b by using the following command\\nMODEL_ARGS=(\\n    --model-name llama2-70b # options: llama2-7b, llama2-13b, llama2-70b\\n)\\n\\nDATA_ARGS=(\\n    --tokenizer-type HFTokenizer\\n    --hf-tokenizer-path $TOKENIZER_PATH\\n    --data-path $DATA_PATH\\n    --split 949,50,1\\n)\\n\\nTRAINING_ARGS=(\\n    --training-phase pretrain # options: pretrain, sft\\n    --seq-length 4096\\n    --max-position-embeddings 4096\\n    --init-method-std 0.01\\n    --micro-batch-size 1\\n    --global-batch-size 1024\\n    --lr 0.0002\\n    --min-lr 1.0e-5\\n    --clip-grad 1.0\\n    --weight-decay 0.01\\n    --optimizer adam\\n    --adam-beta1 0.9\\n    --adam-beta2 0.95\\n    --adam-eps 1e-05\\n    --norm-epsilon 1e-6\\n    --train-iters 500000\\n    --lr-decay-iters 500000\\n    --lr-decay-style cosine\\n    --lr-warmup-fraction 0.002\\n    --initial-loss-scale 65536\\n    --fp16\\n    --save-interval 5000\\n    --eval-interval 1000\\n    --eval-iters 10\\n    #--ckpt-step 0\\n    #--no-load-optim\\n    #--no-load-rng\\n)\\n\\nMODEL_PARALLEL_ARGS=(\\n    --tensor-model-parallel-size 4\\n    --pipeline-model-parallel-size 4\\n    --use-distributed-optimizer\\n    --overlap-grad-reduce\\n    --overlap-param-gather\\n    --distributed-backend nccl\\n    --sequence-parallel\\n    #--tp-comm-overlap # require mpi envrionment\\n)\\n\\nLOGGING_ARGS=(\\n    --log-interval 1\\n    --tensorboard-dir ${TENSORBOARD_PATH}\\n    --log-timers-to-tensorboard\\n)\\n\\nif [ -n \\\"${WANDB_API_KEY}\\\" ]; then\\n    LOGGING_ARGS+=(\\n        --wandb-project ${WANDB_PROJECT}\\n        --wandb-exp-name ${WANDB_NAME} \\n    )\\nfi\\n\\nPYTHONPATH=$MEGATRON_PATH:$AIAK_TRAINING_PATH:$PYTHONPATH     torchrun ${DISTRIBUTED_ARGS[@]}     $AIAK_TRAINING_PATH/aiak_training_llm/train.py     ${MODEL_ARGS[@]}     ${DATA_ARGS[@]}     ${TRAINING_ARGS[@]}     ${MODEL_PARALLEL_ARGS[@]}     ${LOGGING_ARGS[@]}\\n\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":true,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi4\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi4/output/training_logs\",\"CUDA_DEVICE_MAX_CONNECTIONS\":\"1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"},\"Worker\":{\"replicas\":3,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi4\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi4/output/training_logs\",\"CUDA_DEVICE_MAX_CONNECTIONS\":\"1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":true,\"logPath\":\"/mnt/cluster/llamatest0718forxiaomi4/output/training_logs\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":true,\"isCopyJob\":true,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
                "aijob.cce.baidubce.com/timeline": "[{\"conditionType\":\"Created\",\"time\":1721269594},{\"conditionType\":\"Scheduled\",\"time\":1721269596},{\"conditionType\":\"Running\",\"time\":1721269606},{\"conditionType\":\"Abnormal\",\"time\":1721269666},{\"conditionType\":\"ManualTermination\",\"time\":1721269834}]",
                "job-manager/action": "stop",
                "scheduling.k8s.io/job-enable-oversell": "false",
                "tensorboard-gc": "true"
              },
              "creationTimestamp": "2024-07-18T02:26:34Z",
              "generation": 3,
              "labels": {
                "aijob.cce.baidubce.com/ai-user-id": "b5a24aa26e4d4f55bc3acf68edc4b051",
                "aijob.cce.baidubce.com/ai-user-name": "zhangmuhua",
                "aijob.cce.baidubce.com/create-from-aihcp": "true",
                "aijob.cce.baidubce.com/openapi-jobid": "pytorch-27acfb1c-f6ea-4a51-93eb-24d0ee3413ac"
              },
              "managedFields": [
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        "f:aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": {},
                        "f:aijob.cce.baidubce.com/timeline": {}
                      }
                    },
                    "f:spec": {
                      "f:runPolicy": {
                        "f:cleanPodPolicy": {}
                      }
                    }
                  },
                  "manager": "controller",
                  "operation": "Update",
                  "time": "2024-07-18T02:26:34Z"
                },
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        "f:aijob.cce.baidubce.com/barrier-finish": {}
                      }
                    }
                  },
                  "manager": "jobbarrier",
                  "operation": "Update",
                  "time": "2024-07-18T02:26:43Z"
                },
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        ".": {},
                        "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                        "f:aijob.cce.baidubce.com/openapi-jobid": {},
                        "f:aijob.cce.baidubce.com/pfs-id": {},
                        "f:aijob.cce.baidubce.com/raw-request": {},
                        "f:job-manager/action": {},
                        "f:scheduling.k8s.io/job-enable-oversell": {}
                      },
                      "f:labels": {
                        ".": {},
                        "f:aijob.cce.baidubce.com/ai-user-id": {},
                        "f:aijob.cce.baidubce.com/ai-user-name": {},
                        "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                        "f:aijob.cce.baidubce.com/openapi-jobid": {}
                      }
                    },
                    "f:spec": {
                      ".": {},
                      "f:pytorchReplicaSpecs": {
                        ".": {},
                        "f:Master": {
                          ".": {},
                          "f:replicas": {},
                          "f:restartPolicy": {},
                          "f:template": {
                            ".": {},
                            "f:metadata": {
                              ".": {},
                              "f:annotations": {
                                ".": {},
                                "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                                "f:aijob.cce.baidubce.com/openapi-jobid": {},
                                "f:aijob.cce.baidubce.com/pfs-id": {},
                                "f:aijob.cce.baidubce.com/raw-request": {},
                                "f:scheduling.k8s.io/job-enable-oversell": {}
                              },
                              "f:labels": {
                                ".": {},
                                "f:aijob.cce.baidubce.com/ai-user-id": {},
                                "f:aijob.cce.baidubce.com/ai-user-name": {},
                                "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                                "f:aijob.cce.baidubce.com/openapi-jobid": {}
                              }
                            },
                            "f:spec": {
                              ".": {},
                              "f:dnsPolicy": {},
                              "f:hostNetwork": {},
                              "f:schedulerName": {}
                            }
                          }
                        },
                        "f:Worker": {
                          ".": {},
                          "f:replicas": {},
                          "f:restartPolicy": {},
                          "f:template": {
                            ".": {},
                            "f:metadata": {
                              ".": {},
                              "f:annotations": {
                                ".": {},
                                "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                                "f:aijob.cce.baidubce.com/openapi-jobid": {},
                                "f:aijob.cce.baidubce.com/pfs-id": {},
                                "f:aijob.cce.baidubce.com/raw-request": {},
                                "f:scheduling.k8s.io/job-enable-oversell": {}
                              },
                              "f:labels": {
                                ".": {},
                                "f:aijob.cce.baidubce.com/ai-user-id": {},
                                "f:aijob.cce.baidubce.com/ai-user-name": {},
                                "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                                "f:aijob.cce.baidubce.com/openapi-jobid": {}
                              }
                            },
                            "f:spec": {
                              ".": {},
                              "f:dnsPolicy": {},
                              "f:hostNetwork": {},
                              "f:schedulerName": {}
                            }
                          }
                        }
                      },
                      "f:runPolicy": {
                        ".": {},
                        "f:schedulingPolicy": {
                          ".": {},
                          "f:priorityClass": {},
                          "f:queue": {}
                        }
                      }
                    }
                  },
                  "manager": "cce-ai-service",
                  "operation": "Update",
                  "time": "2024-07-18T02:30:34Z"
                },
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        "f:aijob.cce.baidubce.com/internal-fault-tolerance-time": {},
                        "f:tensorboard-gc": {}
                      }
                    },
                    "f:spec": {
                      "f:pytorchReplicaSpecs": {
                        "f:Master": {
                          "f:template": {
                            "f:metadata": {
                              "f:annotations": {
                                "f:prometheus.io/path": {},
                                "f:prometheus.io/port": {},
                                "f:prometheus.io/scrape": {}
                              }
                            },
                            "f:spec": {
                              "f:containers": {},
                              "f:serviceAccountName": {},
                              "f:shareProcessNamespace": {},
                              "f:volumes": {}
                            }
                          }
                        },
                        "f:Worker": {
                          "f:template": {
                            "f:metadata": {
                              "f:annotations": {
                                "f:prometheus.io/path": {},
                                "f:prometheus.io/port": {},
                                "f:prometheus.io/scrape": {}
                              }
                            },
                            "f:spec": {
                              "f:containers": {},
                              "f:serviceAccountName": {},
                              "f:shareProcessNamespace": {},
                              "f:volumes": {}
                            }
                          }
                        }
                      }
                    },
                    "f:status": {
                      ".": {},
                      "f:completionTime": {},
                      "f:conditions": {},
                      "f:lastReconcileTime": {},
                      "f:replicaStatuses": {
                        ".": {},
                        "f:Master": {
                          ".": {},
                          "f:failed": {}
                        },
                        "f:Worker": {
                          ".": {},
                          "f:failed": {}
                        }
                      },
                      "f:startTime": {}
                    }
                  },
                  "manager": "manager",
                  "operation": "Update",
                  "time": "2024-07-19T02:26:55Z"
                }
              ],
              "name": "llamatest0718forxiaomi4",
              "namespace": "default",
              "resourceVersion": "2372392872",
              "uid": "58c8d30d-ea83-41d1-bbb0-b3657be888dd"
            },
            "spec": {
              "pytorchReplicaSpecs": {
                "Master": {
                  "replicas": 1,
                  "restartPolicy": "Never",
                  "template": {
                    "metadata": {
                      "annotations": {
                        "aijob.cce.baidubce.com/fault-tolerance-enabled": "true",
                        "aijob.cce.baidubce.com/openapi-jobid": "pytorch-27acfb1c-f6ea-4a51-93eb-24d0ee3413ac",
                        "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
                        "aijob.cce.baidubce.com/raw-request": "{\"name\":\"llamatest0718forxiaomi4\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"high\",\"oversell\":false,\"faultTolerance\":true,\"command\":\"\\n#! /bin/bash\\n\\nMEGATRON_PATH=${MEGATRON_PATH:-\\\"/workspace/AIAK-Megatron\\\"}\\nAIAK_TRAINING_PATH=${AIAK_TRAINING_PATH:-\\\"/workspace/AIAK-Training-LLM\\\"}\\n\\nDATA_PATH=${DATA_PATH:-\\\"/mnt/cluster/llama2/pile/pile-llama_text_document\\\"}\\nTOKENIZER_PATH=${TOKENIZER_PATH:-\\\"/mnt/cluster/llama2/Llama-2-70b-hf/\\\"}\\n\\nCHECKPOINT_PATH=${CHECKPOINT_PATH:-\\\"/mnt/cluster/llama2/mcore_llama2_70b_tp4_pp4\\\"}\\n\\nTENSORBOARD_PATH=${TENSORBOARD_PATH:-\\\"/mnt/cluster/aiak-training-llm/tensorboard-log/llama2-70b-tp4pp4\\\"}\\n\\nGPUS_PER_NODE=8\\n\\n# Change for multinode config\\nMASTER_ADDR=${MASTER_ADDR:-\\\"localhost\\\"}\\nMASTER_PORT=${MASTER_PORT:-\\\"6000\\\"}\\nNNODES=${WORLD_SIZE:-\\\"1\\\"}\\nNODE_RANK=${RANK:-\\\"0\\\"}\\n\\nDISTRIBUTED_ARGS=(\\n    --nproc_per_node $GPUS_PER_NODE\\n    --nnodes $NNODES\\n    --node_rank $NODE_RANK\\n    --master_addr $MASTER_ADDR\\n    --master_port $MASTER_PORT\\n)\\n\\n# you can setup llama2-70b maunally\\n#MODEL_ARGS=(\\n#    --model-name llama2\\n#    --num-layers 80\\n#    --hidden-size 8192\\n#    --ffn-hidden-size 28672\\n#    --num-attention-heads 64\\n#    --position-embedding-type rope\\n#    --normalization RMSNorm\\n#    --swiglu\\n#    --attention-dropout 0\\n#    --hidden-dropout 0\\n#    --disable-bias-linear\\n#    --untie-embeddings-and-output-weights\\n#    --group-query-attention\\n#    --num-query-groups 8\\n#)\\n\\n# or you can setup llama2-70b by using the following command\\nMODEL_ARGS=(\\n    --model-name llama2-70b # options: llama2-7b, llama2-13b, llama2-70b\\n)\\n\\nDATA_ARGS=(\\n    --tokenizer-type HFTokenizer\\n    --hf-tokenizer-path $TOKENIZER_PATH\\n    --data-path $DATA_PATH\\n    --split 949,50,1\\n)\\n\\nTRAINING_ARGS=(\\n    --training-phase pretrain # options: pretrain, sft\\n    --seq-length 4096\\n    --max-position-embeddings 4096\\n    --init-method-std 0.01\\n    --micro-batch-size 1\\n    --global-batch-size 1024\\n    --lr 0.0002\\n    --min-lr 1.0e-5\\n    --clip-grad 1.0\\n    --weight-decay 0.01\\n    --optimizer adam\\n    --adam-beta1 0.9\\n    --adam-beta2 0.95\\n    --adam-eps 1e-05\\n    --norm-epsilon 1e-6\\n    --train-iters 500000\\n    --lr-decay-iters 500000\\n    --lr-decay-style cosine\\n    --lr-warmup-fraction 0.002\\n    --initial-loss-scale 65536\\n    --fp16\\n    --save-interval 5000\\n    --eval-interval 1000\\n    --eval-iters 10\\n    #--ckpt-step 0\\n    #--no-load-optim\\n    #--no-load-rng\\n)\\n\\nMODEL_PARALLEL_ARGS=(\\n    --tensor-model-parallel-size 4\\n    --pipeline-model-parallel-size 4\\n    --use-distributed-optimizer\\n    --overlap-grad-reduce\\n    --overlap-param-gather\\n    --distributed-backend nccl\\n    --sequence-parallel\\n    #--tp-comm-overlap # require mpi envrionment\\n)\\n\\nLOGGING_ARGS=(\\n    --log-interval 1\\n    --tensorboard-dir ${TENSORBOARD_PATH}\\n    --log-timers-to-tensorboard\\n)\\n\\nif [ -n \\\"${WANDB_API_KEY}\\\" ]; then\\n    LOGGING_ARGS+=(\\n        --wandb-project ${WANDB_PROJECT}\\n        --wandb-exp-name ${WANDB_NAME} \\n    )\\nfi\\n\\nPYTHONPATH=$MEGATRON_PATH:$AIAK_TRAINING_PATH:$PYTHONPATH     torchrun ${DISTRIBUTED_ARGS[@]}     $AIAK_TRAINING_PATH/aiak_training_llm/train.py     ${MODEL_ARGS[@]}     ${DATA_ARGS[@]}     ${TRAINING_ARGS[@]}     ${MODEL_PARALLEL_ARGS[@]}     ${LOGGING_ARGS[@]}\\n\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":true,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi4\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi4/output/training_logs\",\"CUDA_DEVICE_MAX_CONNECTIONS\":\"1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"},\"Worker\":{\"replicas\":3,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi4\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi4/output/training_logs\",\"CUDA_DEVICE_MAX_CONNECTIONS\":\"1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":true,\"logPath\":\"/mnt/cluster/llamatest0718forxiaomi4/output/training_logs\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":true,\"isCopyJob\":true,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
                        "prometheus.io/path": "/metrics",
                        "prometheus.io/port": "9101",
                        "prometheus.io/scrape": "true",
                        "scheduling.k8s.io/job-enable-oversell": "false"
                      },
                      "labels": {
                        "aijob.cce.baidubce.com/ai-user-id": "b5a24aa26e4d4f55bc3acf68edc4b051",
                        "aijob.cce.baidubce.com/ai-user-name": "zhangmuhua",
                        "aijob.cce.baidubce.com/create-from-aihcp": "true",
                        "aijob.cce.baidubce.com/openapi-jobid": "pytorch-27acfb1c-f6ea-4a51-93eb-24d0ee3413ac"
                      }
                    },
                    "spec": {
                      "containers": [
                        {
                          "command": [
                            "/bin/bash",
                            "-c",
                            "\n#! /bin/bash\n\nMEGATRON_PATH=${MEGATRON_PATH:-\"/workspace/AIAK-Megatron\"}\nAIAK_TRAINING_PATH=${AIAK_TRAINING_PATH:-\"/workspace/AIAK-Training-LLM\"}\n\nDATA_PATH=${DATA_PATH:-\"/mnt/cluster/llama2/pile/pile-llama_text_document\"}\nTOKENIZER_PATH=${TOKENIZER_PATH:-\"/mnt/cluster/llama2/Llama-2-70b-hf/\"}\n\nCHECKPOINT_PATH=${CHECKPOINT_PATH:-\"/mnt/cluster/llama2/mcore_llama2_70b_tp4_pp4\"}\n\nTENSORBOARD_PATH=${TENSORBOARD_PATH:-\"/mnt/cluster/aiak-training-llm/tensorboard-log/llama2-70b-tp4pp4\"}\n\nGPUS_PER_NODE=8\n\n# Change for multinode config\nMASTER_ADDR=${MASTER_ADDR:-\"localhost\"}\nMASTER_PORT=${MASTER_PORT:-\"6000\"}\nNNODES=${WORLD_SIZE:-\"1\"}\nNODE_RANK=${RANK:-\"0\"}\n\nDISTRIBUTED_ARGS=(\n    --nproc_per_node $GPUS_PER_NODE\n    --nnodes $NNODES\n    --node_rank $NODE_RANK\n    --master_addr $MASTER_ADDR\n    --master_port $MASTER_PORT\n)\n\n# you can setup llama2-70b maunally\n#MODEL_ARGS=(\n#    --model-name llama2\n#    --num-layers 80\n#    --hidden-size 8192\n#    --ffn-hidden-size 28672\n#    --num-attention-heads 64\n#    --position-embedding-type rope\n#    --normalization RMSNorm\n#    --swiglu\n#    --attention-dropout 0\n#    --hidden-dropout 0\n#    --disable-bias-linear\n#    --untie-embeddings-and-output-weights\n#    --group-query-attention\n#    --num-query-groups 8\n#)\n\n# or you can setup llama2-70b by using the following command\nMODEL_ARGS=(\n    --model-name llama2-70b # options: llama2-7b, llama2-13b, llama2-70b\n)\n\nDATA_ARGS=(\n    --tokenizer-type HFTokenizer\n    --hf-tokenizer-path $TOKENIZER_PATH\n    --data-path $DATA_PATH\n    --split 949,50,1\n)\n\nTRAINING_ARGS=(\n    --training-phase pretrain # options: pretrain, sft\n    --seq-length 4096\n    --max-position-embeddings 4096\n    --init-method-std 0.01\n    --micro-batch-size 1\n    --global-batch-size 1024\n    --lr 0.0002\n    --min-lr 1.0e-5\n    --clip-grad 1.0\n    --weight-decay 0.01\n    --optimizer adam\n    --adam-beta1 0.9\n    --adam-beta2 0.95\n    --adam-eps 1e-05\n    --norm-epsilon 1e-6\n    --train-iters 500000\n    --lr-decay-iters 500000\n    --lr-decay-style cosine\n    --lr-warmup-fraction 0.002\n    --initial-loss-scale 65536\n    --fp16\n    --save-interval 5000\n    --eval-interval 1000\n    --eval-iters 10\n    #--ckpt-step 0\n    #--no-load-optim\n    #--no-load-rng\n)\n\nMODEL_PARALLEL_ARGS=(\n    --tensor-model-parallel-size 4\n    --pipeline-model-parallel-size 4\n    --use-distributed-optimizer\n    --overlap-grad-reduce\n    --overlap-param-gather\n    --distributed-backend nccl\n    --sequence-parallel\n    #--tp-comm-overlap # require mpi envrionment\n)\n\nLOGGING_ARGS=(\n    --log-interval 1\n    --tensorboard-dir ${TENSORBOARD_PATH}\n    --log-timers-to-tensorboard\n)\n\nif [ -n \"${WANDB_API_KEY}\" ]; then\n    LOGGING_ARGS+=(\n        --wandb-project ${WANDB_PROJECT}\n        --wandb-exp-name ${WANDB_NAME} \n    )\nfi\n\nPYTHONPATH=$MEGATRON_PATH:$AIAK_TRAINING_PATH:$PYTHONPATH     torchrun ${DISTRIBUTED_ARGS[@]}     $AIAK_TRAINING_PATH/aiak_training_llm/train.py     ${MODEL_ARGS[@]}     ${DATA_ARGS[@]}     ${TRAINING_ARGS[@]}     ${MODEL_PARALLEL_ARGS[@]}     ${LOGGING_ARGS[@]}\n"
                          ],
                          "env": [
                            {
                              "name": "CUDA_DEVICE_MAX_CONNECTIONS",
                              "value": "1"
                            },
                            {
                              "name": "AIHC_TENSORBOARD_LOG_PATH",
                              "value": "/mnt/cluster/llamatest0718forxiaomi4/output/training_logs"
                            },
                            {
                              "name": "AIHC_JOB_NAME",
                              "value": "llamatest0718forxiaomi4"
                            },
                            {
                              "name": "NCCL_IB_DISABLE",
                              "value": "0"
                            },
                            {
                              "name": "BCCL_BUS_BW_CALCULATE_MODE",
                              "value": "Agg"
                            },
                            {
                              "name": "BCCL_PROFILING_FILE",
                              "value": "/var/bccl/logs/busbw.cal.%h.%p"
                            }
                          ],
                          "image": "registry.baidubce.com/aihc-aiak/aiak-training-llm:ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release",
                          "imagePullPolicy": "Always",
                          "name": "pytorch",
                          "ports": [
                            {
                              "containerPort": 23456,
                              "name": "pytorchjob-port",
                              "protocol": "TCP"
                            }
                          ],
                          "resources": {
                            "limits": {
                              "baidu.com/a800_80g_cgpu": "8",
                              "rdma/hca": "1"
                            },
                            "requests": {
                              "baidu.com/a800_80g_cgpu": "8",
                              "rdma/hca": "1"
                            }
                          },
                          "securityContext": {
                            "capabilities": {
                              "add": [
                                "IPC_LOCK"
                              ]
                            }
                          },
                          "volumeMounts": [
                            {
                              "mountPath": "/dev/shm",
                              "name": "devshm"
                            },
                            {
                              "mountPath": "/mnt/cluster",
                              "name": "pvc-pfs"
                            },
                            {
                              "mountPath": "/var/bccl/logs",
                              "name": "bccl-logs-volume"
                            }
                          ]
                        },
                        {
                          "env": [
                            {
                              "name": "POD_NAME",
                              "valueFrom": {
                                "fieldRef": {
                                  "apiVersion": "v1",
                                  "fieldPath": "metadata.name"
                                }
                              }
                            },
                            {
                              "name": "POD_UID",
                              "valueFrom": {
                                "fieldRef": {
                                  "apiVersion": "v1",
                                  "fieldPath": "metadata.uid"
                                }
                              }
                            },
                            {
                              "name": "POD_NAMESPACE",
                              "valueFrom": {
                                "fieldRef": {
                                  "apiVersion": "v1",
                                  "fieldPath": "metadata.namespace"
                                }
                              }
                            },
                            {
                              "name": "NODE_NAME",
                              "valueFrom": {
                                "fieldRef": {
                                  "apiVersion": "v1",
                                  "fieldPath": "spec.nodeName"
                                }
                              }
                            },
                            {
                              "name": "JOB_NAME",
                              "value": "llamatest0718forxiaomi4"
                            },
                            {
                              "name": "NODE_IP",
                              "valueFrom": {
                                "fieldRef": {
                                  "apiVersion": "v1",
                                  "fieldPath": "status.hostIP"
                                }
                              }
                            },
                            {
                              "name": "ENABLE_ELASTIC",
                              "value": "9"
                            },
                            {
                              "name": "GPUS_PER_NODE",
                              "value": "8"
                            },
                            {
                              "name": "BCCL_LOG_DIR",
                              "value": "/var/bccl/logs"
                            },
                            {
                              "name": "EXPORTER_PORT",
                              "value": "9101"
                            },
                            {
                              "name": "EXPORTER_INTERVAL",
                              "value": "60"
                            },
                            {
                              "name": "EXPORTER_PATH",
                              "value": "/metrics"
                            },
                            {
                              "name": "BCCL_BUS_BW_CALCULATE_MODE",
                              "value": "Agg"
                            },
                            {
                              "name": "BCCL_PROFILING_FILE",
                              "value": "/var/bccl/logs/busbw.cal.%h.%p"
                            }
                          ],
                          "image": "registry.baidubce.com/cce-plugin-dev/ftagent:v1.6-20240713172215",
                          "imagePullPolicy": "Always",
                          "name": "ftagent",
                          "ports": [
                            {
                              "containerPort": 9101,
                              "name": "exporter",
                              "protocol": "TCP"
                            }
                          ],
                          "resources": {},
                          "securityContext": {
                            "capabilities": {
                              "add": [
                                "IPC_LOCK"
                              ]
                            }
                          },
                          "volumeMounts": [
                            {
                              "mountPath": "/var/log/pods",
                              "name": "pod-log-volume"
                            },
                            {
                              "mountPath": "/home/cce",
                              "name": "container-log-volume"
                            },
                            {
                              "mountPath": "/var/bccl/logs",
                              "name": "bccl-logs-volume"
                            }
                          ]
                        }
                      ],
                      "dnsPolicy": "ClusterFirstWithHostNet",
                      "hostNetwork": true,
                      "schedulerName": "volcano",
                      "serviceAccountName": "ftagent-sa",
                      "shareProcessNamespace": true,
                      "volumes": [
                        {
                          "emptyDir": {
                            "medium": "Memory",
                            "sizeLimit": "10Gi"
                          },
                          "name": "devshm"
                        },
                        {
                          "name": "pvc-pfs",
                          "persistentVolumeClaim": {
                            "claimName": "pvc-pfs"
                          }
                        },
                        {
                          "emptyDir": {},
                          "name": "bccl-logs-volume"
                        },
                        {
                          "hostPath": {
                            "path": "/var/log/pods",
                            "type": "DirectoryOrCreate"
                          },
                          "name": "pod-log-volume"
                        },
                        {
                          "hostPath": {
                            "path": "/home/cce",
                            "type": "DirectoryOrCreate"
                          },
                          "name": "container-log-volume"
                        }
                      ]
                    }
                  }
                },
                "Worker": {
                  "replicas": 3,
                  "restartPolicy": "Never",
                  "template": {
                    "metadata": {
                      "annotations": {
                        "aijob.cce.baidubce.com/fault-tolerance-enabled": "true",
                        "aijob.cce.baidubce.com/openapi-jobid": "pytorch-27acfb1c-f6ea-4a51-93eb-24d0ee3413ac",
                        "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
                        "aijob.cce.baidubce.com/raw-request": "{\"name\":\"llamatest0718forxiaomi4\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"high\",\"oversell\":false,\"faultTolerance\":true,\"command\":\"\\n#! /bin/bash\\n\\nMEGATRON_PATH=${MEGATRON_PATH:-\\\"/workspace/AIAK-Megatron\\\"}\\nAIAK_TRAINING_PATH=${AIAK_TRAINING_PATH:-\\\"/workspace/AIAK-Training-LLM\\\"}\\n\\nDATA_PATH=${DATA_PATH:-\\\"/mnt/cluster/llama2/pile/pile-llama_text_document\\\"}\\nTOKENIZER_PATH=${TOKENIZER_PATH:-\\\"/mnt/cluster/llama2/Llama-2-70b-hf/\\\"}\\n\\nCHECKPOINT_PATH=${CHECKPOINT_PATH:-\\\"/mnt/cluster/llama2/mcore_llama2_70b_tp4_pp4\\\"}\\n\\nTENSORBOARD_PATH=${TENSORBOARD_PATH:-\\\"/mnt/cluster/aiak-training-llm/tensorboard-log/llama2-70b-tp4pp4\\\"}\\n\\nGPUS_PER_NODE=8\\n\\n# Change for multinode config\\nMASTER_ADDR=${MASTER_ADDR:-\\\"localhost\\\"}\\nMASTER_PORT=${MASTER_PORT:-\\\"6000\\\"}\\nNNODES=${WORLD_SIZE:-\\\"1\\\"}\\nNODE_RANK=${RANK:-\\\"0\\\"}\\n\\nDISTRIBUTED_ARGS=(\\n    --nproc_per_node $GPUS_PER_NODE\\n    --nnodes $NNODES\\n    --node_rank $NODE_RANK\\n    --master_addr $MASTER_ADDR\\n    --master_port $MASTER_PORT\\n)\\n\\n# you can setup llama2-70b maunally\\n#MODEL_ARGS=(\\n#    --model-name llama2\\n#    --num-layers 80\\n#    --hidden-size 8192\\n#    --ffn-hidden-size 28672\\n#    --num-attention-heads 64\\n#    --position-embedding-type rope\\n#    --normalization RMSNorm\\n#    --swiglu\\n#    --attention-dropout 0\\n#    --hidden-dropout 0\\n#    --disable-bias-linear\\n#    --untie-embeddings-and-output-weights\\n#    --group-query-attention\\n#    --num-query-groups 8\\n#)\\n\\n# or you can setup llama2-70b by using the following command\\nMODEL_ARGS=(\\n    --model-name llama2-70b # options: llama2-7b, llama2-13b, llama2-70b\\n)\\n\\nDATA_ARGS=(\\n    --tokenizer-type HFTokenizer\\n    --hf-tokenizer-path $TOKENIZER_PATH\\n    --data-path $DATA_PATH\\n    --split 949,50,1\\n)\\n\\nTRAINING_ARGS=(\\n    --training-phase pretrain # options: pretrain, sft\\n    --seq-length 4096\\n    --max-position-embeddings 4096\\n    --init-method-std 0.01\\n    --micro-batch-size 1\\n    --global-batch-size 1024\\n    --lr 0.0002\\n    --min-lr 1.0e-5\\n    --clip-grad 1.0\\n    --weight-decay 0.01\\n    --optimizer adam\\n    --adam-beta1 0.9\\n    --adam-beta2 0.95\\n    --adam-eps 1e-05\\n    --norm-epsilon 1e-6\\n    --train-iters 500000\\n    --lr-decay-iters 500000\\n    --lr-decay-style cosine\\n    --lr-warmup-fraction 0.002\\n    --initial-loss-scale 65536\\n    --fp16\\n    --save-interval 5000\\n    --eval-interval 1000\\n    --eval-iters 10\\n    #--ckpt-step 0\\n    #--no-load-optim\\n    #--no-load-rng\\n)\\n\\nMODEL_PARALLEL_ARGS=(\\n    --tensor-model-parallel-size 4\\n    --pipeline-model-parallel-size 4\\n    --use-distributed-optimizer\\n    --overlap-grad-reduce\\n    --overlap-param-gather\\n    --distributed-backend nccl\\n    --sequence-parallel\\n    #--tp-comm-overlap # require mpi envrionment\\n)\\n\\nLOGGING_ARGS=(\\n    --log-interval 1\\n    --tensorboard-dir ${TENSORBOARD_PATH}\\n    --log-timers-to-tensorboard\\n)\\n\\nif [ -n \\\"${WANDB_API_KEY}\\\" ]; then\\n    LOGGING_ARGS+=(\\n        --wandb-project ${WANDB_PROJECT}\\n        --wandb-exp-name ${WANDB_NAME} \\n    )\\nfi\\n\\nPYTHONPATH=$MEGATRON_PATH:$AIAK_TRAINING_PATH:$PYTHONPATH     torchrun ${DISTRIBUTED_ARGS[@]}     $AIAK_TRAINING_PATH/aiak_training_llm/train.py     ${MODEL_ARGS[@]}     ${DATA_ARGS[@]}     ${TRAINING_ARGS[@]}     ${MODEL_PARALLEL_ARGS[@]}     ${LOGGING_ARGS[@]}\\n\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":true,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi4\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi4/output/training_logs\",\"CUDA_DEVICE_MAX_CONNECTIONS\":\"1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"},\"Worker\":{\"replicas\":3,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi4\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi4/output/training_logs\",\"CUDA_DEVICE_MAX_CONNECTIONS\":\"1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":true,\"logPath\":\"/mnt/cluster/llamatest0718forxiaomi4/output/training_logs\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":true,\"isCopyJob\":true,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
                        "prometheus.io/path": "/metrics",
                        "prometheus.io/port": "9101",
                        "prometheus.io/scrape": "true",
                        "scheduling.k8s.io/job-enable-oversell": "false"
                      },
                      "labels": {
                        "aijob.cce.baidubce.com/ai-user-id": "b5a24aa26e4d4f55bc3acf68edc4b051",
                        "aijob.cce.baidubce.com/ai-user-name": "zhangmuhua",
                        "aijob.cce.baidubce.com/create-from-aihcp": "true",
                        "aijob.cce.baidubce.com/openapi-jobid": "pytorch-27acfb1c-f6ea-4a51-93eb-24d0ee3413ac"
                      }
                    },
                    "spec": {
                      "containers": [
                        {
                          "command": [
                            "/bin/bash",
                            "-c",
                            "\n#! /bin/bash\n\nMEGATRON_PATH=${MEGATRON_PATH:-\"/workspace/AIAK-Megatron\"}\nAIAK_TRAINING_PATH=${AIAK_TRAINING_PATH:-\"/workspace/AIAK-Training-LLM\"}\n\nDATA_PATH=${DATA_PATH:-\"/mnt/cluster/llama2/pile/pile-llama_text_document\"}\nTOKENIZER_PATH=${TOKENIZER_PATH:-\"/mnt/cluster/llama2/Llama-2-70b-hf/\"}\n\nCHECKPOINT_PATH=${CHECKPOINT_PATH:-\"/mnt/cluster/llama2/mcore_llama2_70b_tp4_pp4\"}\n\nTENSORBOARD_PATH=${TENSORBOARD_PATH:-\"/mnt/cluster/aiak-training-llm/tensorboard-log/llama2-70b-tp4pp4\"}\n\nGPUS_PER_NODE=8\n\n# Change for multinode config\nMASTER_ADDR=${MASTER_ADDR:-\"localhost\"}\nMASTER_PORT=${MASTER_PORT:-\"6000\"}\nNNODES=${WORLD_SIZE:-\"1\"}\nNODE_RANK=${RANK:-\"0\"}\n\nDISTRIBUTED_ARGS=(\n    --nproc_per_node $GPUS_PER_NODE\n    --nnodes $NNODES\n    --node_rank $NODE_RANK\n    --master_addr $MASTER_ADDR\n    --master_port $MASTER_PORT\n)\n\n# you can setup llama2-70b maunally\n#MODEL_ARGS=(\n#    --model-name llama2\n#    --num-layers 80\n#    --hidden-size 8192\n#    --ffn-hidden-size 28672\n#    --num-attention-heads 64\n#    --position-embedding-type rope\n#    --normalization RMSNorm\n#    --swiglu\n#    --attention-dropout 0\n#    --hidden-dropout 0\n#    --disable-bias-linear\n#    --untie-embeddings-and-output-weights\n#    --group-query-attention\n#    --num-query-groups 8\n#)\n\n# or you can setup llama2-70b by using the following command\nMODEL_ARGS=(\n    --model-name llama2-70b # options: llama2-7b, llama2-13b, llama2-70b\n)\n\nDATA_ARGS=(\n    --tokenizer-type HFTokenizer\n    --hf-tokenizer-path $TOKENIZER_PATH\n    --data-path $DATA_PATH\n    --split 949,50,1\n)\n\nTRAINING_ARGS=(\n    --training-phase pretrain # options: pretrain, sft\n    --seq-length 4096\n    --max-position-embeddings 4096\n    --init-method-std 0.01\n    --micro-batch-size 1\n    --global-batch-size 1024\n    --lr 0.0002\n    --min-lr 1.0e-5\n    --clip-grad 1.0\n    --weight-decay 0.01\n    --optimizer adam\n    --adam-beta1 0.9\n    --adam-beta2 0.95\n    --adam-eps 1e-05\n    --norm-epsilon 1e-6\n    --train-iters 500000\n    --lr-decay-iters 500000\n    --lr-decay-style cosine\n    --lr-warmup-fraction 0.002\n    --initial-loss-scale 65536\n    --fp16\n    --save-interval 5000\n    --eval-interval 1000\n    --eval-iters 10\n    #--ckpt-step 0\n    #--no-load-optim\n    #--no-load-rng\n)\n\nMODEL_PARALLEL_ARGS=(\n    --tensor-model-parallel-size 4\n    --pipeline-model-parallel-size 4\n    --use-distributed-optimizer\n    --overlap-grad-reduce\n    --overlap-param-gather\n    --distributed-backend nccl\n    --sequence-parallel\n    #--tp-comm-overlap # require mpi envrionment\n)\n\nLOGGING_ARGS=(\n    --log-interval 1\n    --tensorboard-dir ${TENSORBOARD_PATH}\n    --log-timers-to-tensorboard\n)\n\nif [ -n \"${WANDB_API_KEY}\" ]; then\n    LOGGING_ARGS+=(\n        --wandb-project ${WANDB_PROJECT}\n        --wandb-exp-name ${WANDB_NAME} \n    )\nfi\n\nPYTHONPATH=$MEGATRON_PATH:$AIAK_TRAINING_PATH:$PYTHONPATH     torchrun ${DISTRIBUTED_ARGS[@]}     $AIAK_TRAINING_PATH/aiak_training_llm/train.py     ${MODEL_ARGS[@]}     ${DATA_ARGS[@]}     ${TRAINING_ARGS[@]}     ${MODEL_PARALLEL_ARGS[@]}     ${LOGGING_ARGS[@]}\n"
                          ],
                          "env": [
                            {
                              "name": "NCCL_IB_DISABLE",
                              "value": "0"
                            },
                            {
                              "name": "CUDA_DEVICE_MAX_CONNECTIONS",
                              "value": "1"
                            },
                            {
                              "name": "AIHC_TENSORBOARD_LOG_PATH",
                              "value": "/mnt/cluster/llamatest0718forxiaomi4/output/training_logs"
                            },
                            {
                              "name": "AIHC_JOB_NAME",
                              "value": "llamatest0718forxiaomi4"
                            },
                            {
                              "name": "BCCL_BUS_BW_CALCULATE_MODE",
                              "value": "Agg"
                            },
                            {
                              "name": "BCCL_PROFILING_FILE",
                              "value": "/var/bccl/logs/busbw.cal.%h.%p"
                            }
                          ],
                          "image": "registry.baidubce.com/aihc-aiak/aiak-training-llm:ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release",
                          "imagePullPolicy": "Always",
                          "name": "pytorch",
                          "ports": [
                            {
                              "containerPort": 23456,
                              "name": "pytorchjob-port",
                              "protocol": "TCP"
                            }
                          ],
                          "resources": {
                            "limits": {
                              "baidu.com/a800_80g_cgpu": "8",
                              "rdma/hca": "1"
                            },
                            "requests": {
                              "baidu.com/a800_80g_cgpu": "8",
                              "rdma/hca": "1"
                            }
                          },
                          "securityContext": {
                            "capabilities": {
                              "add": [
                                "IPC_LOCK"
                              ]
                            }
                          },
                          "volumeMounts": [
                            {
                              "mountPath": "/dev/shm",
                              "name": "devshm"
                            },
                            {
                              "mountPath": "/mnt/cluster",
                              "name": "pvc-pfs"
                            },
                            {
                              "mountPath": "/var/bccl/logs",
                              "name": "bccl-logs-volume"
                            }
                          ]
                        },
                        {
                          "env": [
                            {
                              "name": "POD_NAME",
                              "valueFrom": {
                                "fieldRef": {
                                  "apiVersion": "v1",
                                  "fieldPath": "metadata.name"
                                }
                              }
                            },
                            {
                              "name": "POD_UID",
                              "valueFrom": {
                                "fieldRef": {
                                  "apiVersion": "v1",
                                  "fieldPath": "metadata.uid"
                                }
                              }
                            },
                            {
                              "name": "POD_NAMESPACE",
                              "valueFrom": {
                                "fieldRef": {
                                  "apiVersion": "v1",
                                  "fieldPath": "metadata.namespace"
                                }
                              }
                            },
                            {
                              "name": "NODE_NAME",
                              "valueFrom": {
                                "fieldRef": {
                                  "apiVersion": "v1",
                                  "fieldPath": "spec.nodeName"
                                }
                              }
                            },
                            {
                              "name": "JOB_NAME",
                              "value": "llamatest0718forxiaomi4"
                            },
                            {
                              "name": "NODE_IP",
                              "valueFrom": {
                                "fieldRef": {
                                  "apiVersion": "v1",
                                  "fieldPath": "status.hostIP"
                                }
                              }
                            },
                            {
                              "name": "ENABLE_ELASTIC",
                              "value": "9"
                            },
                            {
                              "name": "GPUS_PER_NODE",
                              "value": "8"
                            },
                            {
                              "name": "BCCL_LOG_DIR",
                              "value": "/var/bccl/logs"
                            },
                            {
                              "name": "EXPORTER_PORT",
                              "value": "9101"
                            },
                            {
                              "name": "EXPORTER_INTERVAL",
                              "value": "60"
                            },
                            {
                              "name": "EXPORTER_PATH",
                              "value": "/metrics"
                            },
                            {
                              "name": "BCCL_BUS_BW_CALCULATE_MODE",
                              "value": "Agg"
                            },
                            {
                              "name": "BCCL_PROFILING_FILE",
                              "value": "/var/bccl/logs/busbw.cal.%h.%p"
                            }
                          ],
                          "image": "registry.baidubce.com/cce-plugin-dev/ftagent:v1.6-20240713172215",
                          "imagePullPolicy": "Always",
                          "name": "ftagent",
                          "ports": [
                            {
                              "containerPort": 9101,
                              "name": "exporter",
                              "protocol": "TCP"
                            }
                          ],
                          "resources": {},
                          "securityContext": {
                            "capabilities": {
                              "add": [
                                "IPC_LOCK"
                              ]
                            }
                          },
                          "volumeMounts": [
                            {
                              "mountPath": "/var/log/pods",
                              "name": "pod-log-volume"
                            },
                            {
                              "mountPath": "/home/cce",
                              "name": "container-log-volume"
                            },
                            {
                              "mountPath": "/var/bccl/logs",
                              "name": "bccl-logs-volume"
                            }
                          ]
                        }
                      ],
                      "dnsPolicy": "ClusterFirstWithHostNet",
                      "hostNetwork": true,
                      "schedulerName": "volcano",
                      "serviceAccountName": "ftagent-sa",
                      "shareProcessNamespace": true,
                      "volumes": [
                        {
                          "emptyDir": {
                            "medium": "Memory",
                            "sizeLimit": "10Gi"
                          },
                          "name": "devshm"
                        },
                        {
                          "name": "pvc-pfs",
                          "persistentVolumeClaim": {
                            "claimName": "pvc-pfs"
                          }
                        },
                        {
                          "emptyDir": {},
                          "name": "bccl-logs-volume"
                        },
                        {
                          "hostPath": {
                            "path": "/var/log/pods",
                            "type": "DirectoryOrCreate"
                          },
                          "name": "pod-log-volume"
                        },
                        {
                          "hostPath": {
                            "path": "/home/cce",
                            "type": "DirectoryOrCreate"
                          },
                          "name": "container-log-volume"
                        }
                      ]
                    }
                  }
                }
              },
              "runPolicy": {
                "cleanPodPolicy": "None",
                "schedulingPolicy": {
                  "priorityClass": "high",
                  "queue": "default"
                }
              }
            },
            "status": {
              "completionTime": "2024-07-18T02:30:34Z",
              "conditions": [
                {
                  "lastTransitionTime": "2024-07-18T02:26:34Z",
                  "lastUpdateTime": "2024-07-18T02:26:34Z",
                  "message": "PyTorchJob llamatest0718forxiaomi4 is created.",
                  "reason": "PyTorchJobCreated",
                  "status": "True",
                  "type": "Created"
                },
                {
                  "lastTransitionTime": "2024-07-18T02:26:46Z",
                  "lastUpdateTime": "2024-07-18T02:26:46Z",
                  "message": "PyTorchJob llamatest0718forxiaomi4 is running.",
                  "reason": "JobRunning",
                  "status": "False",
                  "type": "Running"
                },
                {
                  "lastTransitionTime": "2024-07-18T02:30:34Z",
                  "lastUpdateTime": "2024-07-18T02:30:34Z",
                  "message": "PytorchJob default/llamatest0718forxiaomi4 is stopped",
                  "reason": "PyTorchJobStopped",
                  "status": "True",
                  "type": "Stopped"
                },
                {
                  "lastTransitionTime": "2024-07-18T02:30:34Z",
                  "lastUpdateTime": "2024-07-18T02:30:34Z",
                  "message": "PyTorchJob llamatest0718forxiaomi4 is failed because 1 Master replica(s) failed.",
                  "reason": "JobFailed",
                  "status": "True",
                  "type": "Failed"
                }
              ],
              "lastReconcileTime": "2024-07-18T02:26:51Z",
              "replicaStatuses": {
                "Master": {
                  "failed": 1,
                  "selector": "training.kubeflow.org/job-name=llamatest0718forxiaomi4,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=master"
                },
                "Worker": {
                  "failed": 3,
                  "selector": "training.kubeflow.org/job-name=llamatest0718forxiaomi4,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=worker"
                }
              },
              "startTime": "2024-07-18T02:26:35Z"
            }
          },
          {
            "apiVersion": "kubeflow.org/v1",
            "kind": "PyTorchJob",
            "metadata": {
              "annotations": {
                "aijob.cce.baidubce.com/barrier-finish": "c5be9974-295c-403b-9b2f-a2188de562cd",
                "aijob.cce.baidubce.com/fault-tolerance-enabled": "true",
                "aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": "",
                "aijob.cce.baidubce.com/openapi-jobid": "pytorch-fcb2193b-60e3-4459-a23e-e97124d11c5b",
                "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
                "aijob.cce.baidubce.com/raw-request": "{\"name\":\"llamatest0718forxiaomi5\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"high\",\"oversell\":false,\"faultTolerance\":true,\"command\":\"\\n#! /bin/bash\\n\\nMEGATRON_PATH=${MEGATRON_PATH:-\\\"/workspace/AIAK-Megatron\\\"}\\nAIAK_TRAINING_PATH=${AIAK_TRAINING_PATH:-\\\"/workspace/AIAK-Training-LLM\\\"}\\n\\nDATA_PATH=${DATA_PATH:-\\\"/mnt/cluster/llama2/pile_llama_test/pile-llama_text_document\\\"}\\nTOKENIZER_PATH=${TOKENIZER_PATH:-\\\"/mnt/cluster/llama2/Llama-2-70b-hf/\\\"}\\n\\nCHECKPOINT_PATH=${CHECKPOINT_PATH:-\\\"/mnt/cluster/llama2/mcore_llama2_70b_tp4_pp4\\\"}\\n\\nTENSORBOARD_PATH=${TENSORBOARD_PATH:-\\\"/mnt/cluster/aiak-training-llm/tensorboard-log/llama2-70b-tp4pp4\\\"}\\n\\nGPUS_PER_NODE=8\\n\\n# Change for multinode config\\nMASTER_ADDR=${MASTER_ADDR:-\\\"localhost\\\"}\\nMASTER_PORT=${MASTER_PORT:-\\\"6000\\\"}\\nNNODES=${WORLD_SIZE:-\\\"1\\\"}\\nNODE_RANK=${RANK:-\\\"0\\\"}\\n\\nDISTRIBUTED_ARGS=(\\n    --nproc_per_node $GPUS_PER_NODE\\n    --nnodes $NNODES\\n    --node_rank $NODE_RANK\\n    --master_addr $MASTER_ADDR\\n    --master_port $MASTER_PORT\\n)\\n\\n# you can setup llama2-70b maunally\\n#MODEL_ARGS=(\\n#    --model-name llama2\\n#    --num-layers 80\\n#    --hidden-size 8192\\n#    --ffn-hidden-size 28672\\n#    --num-attention-heads 64\\n#    --position-embedding-type rope\\n#    --normalization RMSNorm\\n#    --swiglu\\n#    --attention-dropout 0\\n#    --hidden-dropout 0\\n#    --disable-bias-linear\\n#    --untie-embeddings-and-output-weights\\n#    --group-query-attention\\n#    --num-query-groups 8\\n#)\\n\\n# or you can setup llama2-70b by using the following command\\nMODEL_ARGS=(\\n    --model-name llama2-70b # options: llama2-7b, llama2-13b, llama2-70b\\n)\\n\\nDATA_ARGS=(\\n    --tokenizer-type HFTokenizer\\n    --hf-tokenizer-path $TOKENIZER_PATH\\n    --data-path $DATA_PATH\\n    --split 949,50,1\\n)\\n\\nTRAINING_ARGS=(\\n    --training-phase pretrain # options: pretrain, sft\\n    --seq-length 4096\\n    --max-position-embeddings 4096\\n    --init-method-std 0.01\\n    --micro-batch-size 1\\n    --global-batch-size 1024\\n    --lr 0.0002\\n    --min-lr 1.0e-5\\n    --clip-grad 1.0\\n    --weight-decay 0.01\\n    --optimizer adam\\n    --adam-beta1 0.9\\n    --adam-beta2 0.95\\n    --adam-eps 1e-05\\n    --norm-epsilon 1e-6\\n    --train-iters 500000\\n    --lr-decay-iters 500000\\n    --lr-decay-style cosine\\n    --lr-warmup-fraction 0.002\\n    --initial-loss-scale 65536\\n    --fp16\\n    --save-interval 5000\\n    --eval-interval 1000\\n    --eval-iters 10\\n    #--ckpt-step 0\\n    #--no-load-optim\\n    #--no-load-rng\\n)\\n\\nMODEL_PARALLEL_ARGS=(\\n    --tensor-model-parallel-size 4\\n    --pipeline-model-parallel-size 4\\n    --use-distributed-optimizer\\n    --overlap-grad-reduce\\n    --overlap-param-gather\\n    --distributed-backend nccl\\n    --sequence-parallel\\n    #--tp-comm-overlap # require mpi envrionment\\n)\\n\\nLOGGING_ARGS=(\\n    --log-interval 1\\n    --tensorboard-dir ${TENSORBOARD_PATH}\\n    --log-timers-to-tensorboard\\n)\\n\\nif [ -n \\\"${WANDB_API_KEY}\\\" ]; then\\n    LOGGING_ARGS+=(\\n        --wandb-project ${WANDB_PROJECT}\\n        --wandb-exp-name ${WANDB_NAME} \\n    )\\nfi\\n\\nPYTHONPATH=$MEGATRON_PATH:$AIAK_TRAINING_PATH:$PYTHONPATH     torchrun ${DISTRIBUTED_ARGS[@]}     $AIAK_TRAINING_PATH/aiak_training_llm/train.py     ${MODEL_ARGS[@]}     ${DATA_ARGS[@]}     ${TRAINING_ARGS[@]}     ${MODEL_PARALLEL_ARGS[@]}     ${LOGGING_ARGS[@]}\\n\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":true,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi5\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi5/output/training_logs\",\"CUDA_DEVICE_MAX_CONNECTIONS\":\"1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"},\"Worker\":{\"replicas\":3,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi5\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi5/output/training_logs\",\"CUDA_DEVICE_MAX_CONNECTIONS\":\"1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":true,\"logPath\":\"/mnt/cluster/llamatest0718forxiaomi5/output/training_logs\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":true,\"isCopyJob\":true,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
                "aijob.cce.baidubce.com/timeline": "[{\"conditionType\":\"Created\",\"time\":1721269828},{\"conditionType\":\"Scheduled\",\"time\":1721269830},{\"conditionType\":\"Running\",\"time\":1721269841},{\"conditionType\":\"ManualTermination\",\"time\":1721270912}]",
                "job-manager/action": "stop",
                "job-manager/action-succeed": "stop",
                "scheduling.k8s.io/job-enable-oversell": "false",
                "tensorboard-gc": "true"
              },
              "creationTimestamp": "2024-07-18T02:30:28Z",
              "generation": 2,
              "labels": {
                "aijob.cce.baidubce.com/ai-user-id": "b5a24aa26e4d4f55bc3acf68edc4b051",
                "aijob.cce.baidubce.com/ai-user-name": "zhangmuhua",
                "aijob.cce.baidubce.com/create-from-aihcp": "true",
                "aijob.cce.baidubce.com/openapi-jobid": "pytorch-fcb2193b-60e3-4459-a23e-e97124d11c5b"
              },
              "managedFields": [
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        "f:aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": {},
                        "f:aijob.cce.baidubce.com/timeline": {}
                      }
                    },
                    "f:spec": {
                      "f:pytorchReplicaSpecs": {
                        "f:Master": {
                          "f:template": {
                            "f:spec": {
                              "f:containers": {}
                            }
                          }
                        },
                        "f:Worker": {
                          "f:template": {
                            "f:spec": {
                              "f:containers": {}
                            }
                          }
                        }
                      },
                      "f:runPolicy": {
                        "f:cleanPodPolicy": {}
                      }
                    }
                  },
                  "manager": "controller",
                  "operation": "Update",
                  "time": "2024-07-18T02:30:28Z"
                },
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        "f:aijob.cce.baidubce.com/barrier-finish": {}
                      }
                    }
                  },
                  "manager": "jobbarrier",
                  "operation": "Update",
                  "time": "2024-07-18T02:30:37Z"
                },
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        ".": {},
                        "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                        "f:aijob.cce.baidubce.com/openapi-jobid": {},
                        "f:aijob.cce.baidubce.com/pfs-id": {},
                        "f:aijob.cce.baidubce.com/raw-request": {},
                        "f:job-manager/action": {},
                        "f:scheduling.k8s.io/job-enable-oversell": {}
                      },
                      "f:labels": {
                        ".": {},
                        "f:aijob.cce.baidubce.com/ai-user-id": {},
                        "f:aijob.cce.baidubce.com/ai-user-name": {},
                        "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                        "f:aijob.cce.baidubce.com/openapi-jobid": {}
                      }
                    },
                    "f:spec": {
                      ".": {},
                      "f:pytorchReplicaSpecs": {
                        ".": {},
                        "f:Master": {
                          ".": {},
                          "f:replicas": {},
                          "f:restartPolicy": {},
                          "f:template": {
                            ".": {},
                            "f:metadata": {
                              ".": {},
                              "f:annotations": {
                                ".": {},
                                "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                                "f:aijob.cce.baidubce.com/openapi-jobid": {},
                                "f:aijob.cce.baidubce.com/pfs-id": {},
                                "f:aijob.cce.baidubce.com/raw-request": {},
                                "f:scheduling.k8s.io/job-enable-oversell": {}
                              },
                              "f:labels": {
                                ".": {},
                                "f:aijob.cce.baidubce.com/ai-user-id": {},
                                "f:aijob.cce.baidubce.com/ai-user-name": {},
                                "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                                "f:aijob.cce.baidubce.com/openapi-jobid": {}
                              }
                            },
                            "f:spec": {
                              ".": {},
                              "f:dnsPolicy": {},
                              "f:hostNetwork": {},
                              "f:schedulerName": {},
                              "f:volumes": {}
                            }
                          }
                        },
                        "f:Worker": {
                          ".": {},
                          "f:replicas": {},
                          "f:restartPolicy": {},
                          "f:template": {
                            ".": {},
                            "f:metadata": {
                              ".": {},
                              "f:annotations": {
                                ".": {},
                                "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                                "f:aijob.cce.baidubce.com/openapi-jobid": {},
                                "f:aijob.cce.baidubce.com/pfs-id": {},
                                "f:aijob.cce.baidubce.com/raw-request": {},
                                "f:scheduling.k8s.io/job-enable-oversell": {}
                              },
                              "f:labels": {
                                ".": {},
                                "f:aijob.cce.baidubce.com/ai-user-id": {},
                                "f:aijob.cce.baidubce.com/ai-user-name": {},
                                "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                                "f:aijob.cce.baidubce.com/openapi-jobid": {}
                              }
                            },
                            "f:spec": {
                              ".": {},
                              "f:dnsPolicy": {},
                              "f:hostNetwork": {},
                              "f:schedulerName": {},
                              "f:volumes": {}
                            }
                          }
                        }
                      },
                      "f:runPolicy": {
                        ".": {},
                        "f:schedulingPolicy": {
                          ".": {},
                          "f:priorityClass": {},
                          "f:queue": {}
                        }
                      }
                    }
                  },
                  "manager": "cce-ai-service",
                  "operation": "Update",
                  "time": "2024-07-18T02:48:32Z"
                },
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        "f:job-manager/action-succeed": {}
                      }
                    }
                  },
                  "manager": "ftagent",
                  "operation": "Update",
                  "time": "2024-07-18T02:48:37Z"
                },
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        "f:tensorboard-gc": {}
                      }
                    },
                    "f:status": {
                      ".": {},
                      "f:completionTime": {},
                      "f:conditions": {},
                      "f:lastReconcileTime": {},
                      "f:replicaStatuses": {
                        ".": {},
                        "f:Master": {
                          ".": {},
                          "f:active": {}
                        },
                        "f:Worker": {
                          ".": {},
                          "f:active": {},
                          "f:failed": {}
                        }
                      },
                      "f:startTime": {}
                    }
                  },
                  "manager": "manager",
                  "operation": "Update",
                  "time": "2024-07-19T02:30:55Z"
                }
              ],
              "name": "llamatest0718forxiaomi5",
              "namespace": "default",
              "resourceVersion": "2372396298",
              "uid": "16343b84-0572-459d-a9fd-a1e4cf85c1ca"
            },
            "spec": {
              "pytorchReplicaSpecs": {
                "Master": {
                  "replicas": 1,
                  "restartPolicy": "Never",
                  "template": {
                    "metadata": {
                      "annotations": {
                        "aijob.cce.baidubce.com/fault-tolerance-enabled": "true",
                        "aijob.cce.baidubce.com/openapi-jobid": "pytorch-fcb2193b-60e3-4459-a23e-e97124d11c5b",
                        "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
                        "aijob.cce.baidubce.com/raw-request": "{\"name\":\"llamatest0718forxiaomi5\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"high\",\"oversell\":false,\"faultTolerance\":true,\"command\":\"\\n#! /bin/bash\\n\\nMEGATRON_PATH=${MEGATRON_PATH:-\\\"/workspace/AIAK-Megatron\\\"}\\nAIAK_TRAINING_PATH=${AIAK_TRAINING_PATH:-\\\"/workspace/AIAK-Training-LLM\\\"}\\n\\nDATA_PATH=${DATA_PATH:-\\\"/mnt/cluster/llama2/pile_llama_test/pile-llama_text_document\\\"}\\nTOKENIZER_PATH=${TOKENIZER_PATH:-\\\"/mnt/cluster/llama2/Llama-2-70b-hf/\\\"}\\n\\nCHECKPOINT_PATH=${CHECKPOINT_PATH:-\\\"/mnt/cluster/llama2/mcore_llama2_70b_tp4_pp4\\\"}\\n\\nTENSORBOARD_PATH=${TENSORBOARD_PATH:-\\\"/mnt/cluster/aiak-training-llm/tensorboard-log/llama2-70b-tp4pp4\\\"}\\n\\nGPUS_PER_NODE=8\\n\\n# Change for multinode config\\nMASTER_ADDR=${MASTER_ADDR:-\\\"localhost\\\"}\\nMASTER_PORT=${MASTER_PORT:-\\\"6000\\\"}\\nNNODES=${WORLD_SIZE:-\\\"1\\\"}\\nNODE_RANK=${RANK:-\\\"0\\\"}\\n\\nDISTRIBUTED_ARGS=(\\n    --nproc_per_node $GPUS_PER_NODE\\n    --nnodes $NNODES\\n    --node_rank $NODE_RANK\\n    --master_addr $MASTER_ADDR\\n    --master_port $MASTER_PORT\\n)\\n\\n# you can setup llama2-70b maunally\\n#MODEL_ARGS=(\\n#    --model-name llama2\\n#    --num-layers 80\\n#    --hidden-size 8192\\n#    --ffn-hidden-size 28672\\n#    --num-attention-heads 64\\n#    --position-embedding-type rope\\n#    --normalization RMSNorm\\n#    --swiglu\\n#    --attention-dropout 0\\n#    --hidden-dropout 0\\n#    --disable-bias-linear\\n#    --untie-embeddings-and-output-weights\\n#    --group-query-attention\\n#    --num-query-groups 8\\n#)\\n\\n# or you can setup llama2-70b by using the following command\\nMODEL_ARGS=(\\n    --model-name llama2-70b # options: llama2-7b, llama2-13b, llama2-70b\\n)\\n\\nDATA_ARGS=(\\n    --tokenizer-type HFTokenizer\\n    --hf-tokenizer-path $TOKENIZER_PATH\\n    --data-path $DATA_PATH\\n    --split 949,50,1\\n)\\n\\nTRAINING_ARGS=(\\n    --training-phase pretrain # options: pretrain, sft\\n    --seq-length 4096\\n    --max-position-embeddings 4096\\n    --init-method-std 0.01\\n    --micro-batch-size 1\\n    --global-batch-size 1024\\n    --lr 0.0002\\n    --min-lr 1.0e-5\\n    --clip-grad 1.0\\n    --weight-decay 0.01\\n    --optimizer adam\\n    --adam-beta1 0.9\\n    --adam-beta2 0.95\\n    --adam-eps 1e-05\\n    --norm-epsilon 1e-6\\n    --train-iters 500000\\n    --lr-decay-iters 500000\\n    --lr-decay-style cosine\\n    --lr-warmup-fraction 0.002\\n    --initial-loss-scale 65536\\n    --fp16\\n    --save-interval 5000\\n    --eval-interval 1000\\n    --eval-iters 10\\n    #--ckpt-step 0\\n    #--no-load-optim\\n    #--no-load-rng\\n)\\n\\nMODEL_PARALLEL_ARGS=(\\n    --tensor-model-parallel-size 4\\n    --pipeline-model-parallel-size 4\\n    --use-distributed-optimizer\\n    --overlap-grad-reduce\\n    --overlap-param-gather\\n    --distributed-backend nccl\\n    --sequence-parallel\\n    #--tp-comm-overlap # require mpi envrionment\\n)\\n\\nLOGGING_ARGS=(\\n    --log-interval 1\\n    --tensorboard-dir ${TENSORBOARD_PATH}\\n    --log-timers-to-tensorboard\\n)\\n\\nif [ -n \\\"${WANDB_API_KEY}\\\" ]; then\\n    LOGGING_ARGS+=(\\n        --wandb-project ${WANDB_PROJECT}\\n        --wandb-exp-name ${WANDB_NAME} \\n    )\\nfi\\n\\nPYTHONPATH=$MEGATRON_PATH:$AIAK_TRAINING_PATH:$PYTHONPATH     torchrun ${DISTRIBUTED_ARGS[@]}     $AIAK_TRAINING_PATH/aiak_training_llm/train.py     ${MODEL_ARGS[@]}     ${DATA_ARGS[@]}     ${TRAINING_ARGS[@]}     ${MODEL_PARALLEL_ARGS[@]}     ${LOGGING_ARGS[@]}\\n\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":true,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi5\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi5/output/training_logs\",\"CUDA_DEVICE_MAX_CONNECTIONS\":\"1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"},\"Worker\":{\"replicas\":3,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi5\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi5/output/training_logs\",\"CUDA_DEVICE_MAX_CONNECTIONS\":\"1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":true,\"logPath\":\"/mnt/cluster/llamatest0718forxiaomi5/output/training_logs\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":true,\"isCopyJob\":true,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
                        "scheduling.k8s.io/job-enable-oversell": "false"
                      },
                      "labels": {
                        "aijob.cce.baidubce.com/ai-user-id": "b5a24aa26e4d4f55bc3acf68edc4b051",
                        "aijob.cce.baidubce.com/ai-user-name": "zhangmuhua",
                        "aijob.cce.baidubce.com/create-from-aihcp": "true",
                        "aijob.cce.baidubce.com/openapi-jobid": "pytorch-fcb2193b-60e3-4459-a23e-e97124d11c5b"
                      }
                    },
                    "spec": {
                      "containers": [
                        {
                          "command": [
                            "/bin/bash",
                            "-c",
                            "\n#! /bin/bash\n\nMEGATRON_PATH=${MEGATRON_PATH:-\"/workspace/AIAK-Megatron\"}\nAIAK_TRAINING_PATH=${AIAK_TRAINING_PATH:-\"/workspace/AIAK-Training-LLM\"}\n\nDATA_PATH=${DATA_PATH:-\"/mnt/cluster/llama2/pile_llama_test/pile-llama_text_document\"}\nTOKENIZER_PATH=${TOKENIZER_PATH:-\"/mnt/cluster/llama2/Llama-2-70b-hf/\"}\n\nCHECKPOINT_PATH=${CHECKPOINT_PATH:-\"/mnt/cluster/llama2/mcore_llama2_70b_tp4_pp4\"}\n\nTENSORBOARD_PATH=${TENSORBOARD_PATH:-\"/mnt/cluster/aiak-training-llm/tensorboard-log/llama2-70b-tp4pp4\"}\n\nGPUS_PER_NODE=8\n\n# Change for multinode config\nMASTER_ADDR=${MASTER_ADDR:-\"localhost\"}\nMASTER_PORT=${MASTER_PORT:-\"6000\"}\nNNODES=${WORLD_SIZE:-\"1\"}\nNODE_RANK=${RANK:-\"0\"}\n\nDISTRIBUTED_ARGS=(\n    --nproc_per_node $GPUS_PER_NODE\n    --nnodes $NNODES\n    --node_rank $NODE_RANK\n    --master_addr $MASTER_ADDR\n    --master_port $MASTER_PORT\n)\n\n# you can setup llama2-70b maunally\n#MODEL_ARGS=(\n#    --model-name llama2\n#    --num-layers 80\n#    --hidden-size 8192\n#    --ffn-hidden-size 28672\n#    --num-attention-heads 64\n#    --position-embedding-type rope\n#    --normalization RMSNorm\n#    --swiglu\n#    --attention-dropout 0\n#    --hidden-dropout 0\n#    --disable-bias-linear\n#    --untie-embeddings-and-output-weights\n#    --group-query-attention\n#    --num-query-groups 8\n#)\n\n# or you can setup llama2-70b by using the following command\nMODEL_ARGS=(\n    --model-name llama2-70b # options: llama2-7b, llama2-13b, llama2-70b\n)\n\nDATA_ARGS=(\n    --tokenizer-type HFTokenizer\n    --hf-tokenizer-path $TOKENIZER_PATH\n    --data-path $DATA_PATH\n    --split 949,50,1\n)\n\nTRAINING_ARGS=(\n    --training-phase pretrain # options: pretrain, sft\n    --seq-length 4096\n    --max-position-embeddings 4096\n    --init-method-std 0.01\n    --micro-batch-size 1\n    --global-batch-size 1024\n    --lr 0.0002\n    --min-lr 1.0e-5\n    --clip-grad 1.0\n    --weight-decay 0.01\n    --optimizer adam\n    --adam-beta1 0.9\n    --adam-beta2 0.95\n    --adam-eps 1e-05\n    --norm-epsilon 1e-6\n    --train-iters 500000\n    --lr-decay-iters 500000\n    --lr-decay-style cosine\n    --lr-warmup-fraction 0.002\n    --initial-loss-scale 65536\n    --fp16\n    --save-interval 5000\n    --eval-interval 1000\n    --eval-iters 10\n    #--ckpt-step 0\n    #--no-load-optim\n    #--no-load-rng\n)\n\nMODEL_PARALLEL_ARGS=(\n    --tensor-model-parallel-size 4\n    --pipeline-model-parallel-size 4\n    --use-distributed-optimizer\n    --overlap-grad-reduce\n    --overlap-param-gather\n    --distributed-backend nccl\n    --sequence-parallel\n    #--tp-comm-overlap # require mpi envrionment\n)\n\nLOGGING_ARGS=(\n    --log-interval 1\n    --tensorboard-dir ${TENSORBOARD_PATH}\n    --log-timers-to-tensorboard\n)\n\nif [ -n \"${WANDB_API_KEY}\" ]; then\n    LOGGING_ARGS+=(\n        --wandb-project ${WANDB_PROJECT}\n        --wandb-exp-name ${WANDB_NAME} \n    )\nfi\n\nPYTHONPATH=$MEGATRON_PATH:$AIAK_TRAINING_PATH:$PYTHONPATH     torchrun ${DISTRIBUTED_ARGS[@]}     $AIAK_TRAINING_PATH/aiak_training_llm/train.py     ${MODEL_ARGS[@]}     ${DATA_ARGS[@]}     ${TRAINING_ARGS[@]}     ${MODEL_PARALLEL_ARGS[@]}     ${LOGGING_ARGS[@]}\n"
                          ],
                          "env": [
                            {
                              "name": "CUDA_DEVICE_MAX_CONNECTIONS",
                              "value": "1"
                            },
                            {
                              "name": "AIHC_TENSORBOARD_LOG_PATH",
                              "value": "/mnt/cluster/llamatest0718forxiaomi5/output/training_logs"
                            },
                            {
                              "name": "AIHC_JOB_NAME",
                              "value": "llamatest0718forxiaomi5"
                            },
                            {
                              "name": "NCCL_IB_DISABLE",
                              "value": "0"
                            }
                          ],
                          "image": "registry.baidubce.com/aihc-aiak/aiak-training-llm:ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release",
                          "imagePullPolicy": "Always",
                          "name": "pytorch",
                          "ports": [
                            {
                              "containerPort": 23456,
                              "name": "pytorchjob-port",
                              "protocol": "TCP"
                            }
                          ],
                          "resources": {
                            "limits": {
                              "baidu.com/a800_80g_cgpu": "8",
                              "rdma/hca": "1"
                            },
                            "requests": {
                              "baidu.com/a800_80g_cgpu": "8",
                              "rdma/hca": "1"
                            }
                          },
                          "securityContext": {
                            "capabilities": {
                              "add": [
                                "IPC_LOCK"
                              ]
                            }
                          },
                          "volumeMounts": [
                            {
                              "mountPath": "/dev/shm",
                              "name": "devshm"
                            },
                            {
                              "mountPath": "/mnt/cluster",
                              "name": "pvc-pfs"
                            }
                          ]
                        }
                      ],
                      "dnsPolicy": "ClusterFirstWithHostNet",
                      "hostNetwork": true,
                      "schedulerName": "volcano",
                      "volumes": [
                        {
                          "emptyDir": {
                            "medium": "Memory",
                            "sizeLimit": "10Gi"
                          },
                          "name": "devshm"
                        },
                        {
                          "name": "pvc-pfs",
                          "persistentVolumeClaim": {
                            "claimName": "pvc-pfs"
                          }
                        }
                      ]
                    }
                  }
                },
                "Worker": {
                  "replicas": 3,
                  "restartPolicy": "Never",
                  "template": {
                    "metadata": {
                      "annotations": {
                        "aijob.cce.baidubce.com/fault-tolerance-enabled": "true",
                        "aijob.cce.baidubce.com/openapi-jobid": "pytorch-fcb2193b-60e3-4459-a23e-e97124d11c5b",
                        "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
                        "aijob.cce.baidubce.com/raw-request": "{\"name\":\"llamatest0718forxiaomi5\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"high\",\"oversell\":false,\"faultTolerance\":true,\"command\":\"\\n#! /bin/bash\\n\\nMEGATRON_PATH=${MEGATRON_PATH:-\\\"/workspace/AIAK-Megatron\\\"}\\nAIAK_TRAINING_PATH=${AIAK_TRAINING_PATH:-\\\"/workspace/AIAK-Training-LLM\\\"}\\n\\nDATA_PATH=${DATA_PATH:-\\\"/mnt/cluster/llama2/pile_llama_test/pile-llama_text_document\\\"}\\nTOKENIZER_PATH=${TOKENIZER_PATH:-\\\"/mnt/cluster/llama2/Llama-2-70b-hf/\\\"}\\n\\nCHECKPOINT_PATH=${CHECKPOINT_PATH:-\\\"/mnt/cluster/llama2/mcore_llama2_70b_tp4_pp4\\\"}\\n\\nTENSORBOARD_PATH=${TENSORBOARD_PATH:-\\\"/mnt/cluster/aiak-training-llm/tensorboard-log/llama2-70b-tp4pp4\\\"}\\n\\nGPUS_PER_NODE=8\\n\\n# Change for multinode config\\nMASTER_ADDR=${MASTER_ADDR:-\\\"localhost\\\"}\\nMASTER_PORT=${MASTER_PORT:-\\\"6000\\\"}\\nNNODES=${WORLD_SIZE:-\\\"1\\\"}\\nNODE_RANK=${RANK:-\\\"0\\\"}\\n\\nDISTRIBUTED_ARGS=(\\n    --nproc_per_node $GPUS_PER_NODE\\n    --nnodes $NNODES\\n    --node_rank $NODE_RANK\\n    --master_addr $MASTER_ADDR\\n    --master_port $MASTER_PORT\\n)\\n\\n# you can setup llama2-70b maunally\\n#MODEL_ARGS=(\\n#    --model-name llama2\\n#    --num-layers 80\\n#    --hidden-size 8192\\n#    --ffn-hidden-size 28672\\n#    --num-attention-heads 64\\n#    --position-embedding-type rope\\n#    --normalization RMSNorm\\n#    --swiglu\\n#    --attention-dropout 0\\n#    --hidden-dropout 0\\n#    --disable-bias-linear\\n#    --untie-embeddings-and-output-weights\\n#    --group-query-attention\\n#    --num-query-groups 8\\n#)\\n\\n# or you can setup llama2-70b by using the following command\\nMODEL_ARGS=(\\n    --model-name llama2-70b # options: llama2-7b, llama2-13b, llama2-70b\\n)\\n\\nDATA_ARGS=(\\n    --tokenizer-type HFTokenizer\\n    --hf-tokenizer-path $TOKENIZER_PATH\\n    --data-path $DATA_PATH\\n    --split 949,50,1\\n)\\n\\nTRAINING_ARGS=(\\n    --training-phase pretrain # options: pretrain, sft\\n    --seq-length 4096\\n    --max-position-embeddings 4096\\n    --init-method-std 0.01\\n    --micro-batch-size 1\\n    --global-batch-size 1024\\n    --lr 0.0002\\n    --min-lr 1.0e-5\\n    --clip-grad 1.0\\n    --weight-decay 0.01\\n    --optimizer adam\\n    --adam-beta1 0.9\\n    --adam-beta2 0.95\\n    --adam-eps 1e-05\\n    --norm-epsilon 1e-6\\n    --train-iters 500000\\n    --lr-decay-iters 500000\\n    --lr-decay-style cosine\\n    --lr-warmup-fraction 0.002\\n    --initial-loss-scale 65536\\n    --fp16\\n    --save-interval 5000\\n    --eval-interval 1000\\n    --eval-iters 10\\n    #--ckpt-step 0\\n    #--no-load-optim\\n    #--no-load-rng\\n)\\n\\nMODEL_PARALLEL_ARGS=(\\n    --tensor-model-parallel-size 4\\n    --pipeline-model-parallel-size 4\\n    --use-distributed-optimizer\\n    --overlap-grad-reduce\\n    --overlap-param-gather\\n    --distributed-backend nccl\\n    --sequence-parallel\\n    #--tp-comm-overlap # require mpi envrionment\\n)\\n\\nLOGGING_ARGS=(\\n    --log-interval 1\\n    --tensorboard-dir ${TENSORBOARD_PATH}\\n    --log-timers-to-tensorboard\\n)\\n\\nif [ -n \\\"${WANDB_API_KEY}\\\" ]; then\\n    LOGGING_ARGS+=(\\n        --wandb-project ${WANDB_PROJECT}\\n        --wandb-exp-name ${WANDB_NAME} \\n    )\\nfi\\n\\nPYTHONPATH=$MEGATRON_PATH:$AIAK_TRAINING_PATH:$PYTHONPATH     torchrun ${DISTRIBUTED_ARGS[@]}     $AIAK_TRAINING_PATH/aiak_training_llm/train.py     ${MODEL_ARGS[@]}     ${DATA_ARGS[@]}     ${TRAINING_ARGS[@]}     ${MODEL_PARALLEL_ARGS[@]}     ${LOGGING_ARGS[@]}\\n\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":true,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi5\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi5/output/training_logs\",\"CUDA_DEVICE_MAX_CONNECTIONS\":\"1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"},\"Worker\":{\"replicas\":3,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi5\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi5/output/training_logs\",\"CUDA_DEVICE_MAX_CONNECTIONS\":\"1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":true,\"logPath\":\"/mnt/cluster/llamatest0718forxiaomi5/output/training_logs\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":true,\"isCopyJob\":true,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
                        "scheduling.k8s.io/job-enable-oversell": "false"
                      },
                      "labels": {
                        "aijob.cce.baidubce.com/ai-user-id": "b5a24aa26e4d4f55bc3acf68edc4b051",
                        "aijob.cce.baidubce.com/ai-user-name": "zhangmuhua",
                        "aijob.cce.baidubce.com/create-from-aihcp": "true",
                        "aijob.cce.baidubce.com/openapi-jobid": "pytorch-fcb2193b-60e3-4459-a23e-e97124d11c5b"
                      }
                    },
                    "spec": {
                      "containers": [
                        {
                          "command": [
                            "/bin/bash",
                            "-c",
                            "\n#! /bin/bash\n\nMEGATRON_PATH=${MEGATRON_PATH:-\"/workspace/AIAK-Megatron\"}\nAIAK_TRAINING_PATH=${AIAK_TRAINING_PATH:-\"/workspace/AIAK-Training-LLM\"}\n\nDATA_PATH=${DATA_PATH:-\"/mnt/cluster/llama2/pile_llama_test/pile-llama_text_document\"}\nTOKENIZER_PATH=${TOKENIZER_PATH:-\"/mnt/cluster/llama2/Llama-2-70b-hf/\"}\n\nCHECKPOINT_PATH=${CHECKPOINT_PATH:-\"/mnt/cluster/llama2/mcore_llama2_70b_tp4_pp4\"}\n\nTENSORBOARD_PATH=${TENSORBOARD_PATH:-\"/mnt/cluster/aiak-training-llm/tensorboard-log/llama2-70b-tp4pp4\"}\n\nGPUS_PER_NODE=8\n\n# Change for multinode config\nMASTER_ADDR=${MASTER_ADDR:-\"localhost\"}\nMASTER_PORT=${MASTER_PORT:-\"6000\"}\nNNODES=${WORLD_SIZE:-\"1\"}\nNODE_RANK=${RANK:-\"0\"}\n\nDISTRIBUTED_ARGS=(\n    --nproc_per_node $GPUS_PER_NODE\n    --nnodes $NNODES\n    --node_rank $NODE_RANK\n    --master_addr $MASTER_ADDR\n    --master_port $MASTER_PORT\n)\n\n# you can setup llama2-70b maunally\n#MODEL_ARGS=(\n#    --model-name llama2\n#    --num-layers 80\n#    --hidden-size 8192\n#    --ffn-hidden-size 28672\n#    --num-attention-heads 64\n#    --position-embedding-type rope\n#    --normalization RMSNorm\n#    --swiglu\n#    --attention-dropout 0\n#    --hidden-dropout 0\n#    --disable-bias-linear\n#    --untie-embeddings-and-output-weights\n#    --group-query-attention\n#    --num-query-groups 8\n#)\n\n# or you can setup llama2-70b by using the following command\nMODEL_ARGS=(\n    --model-name llama2-70b # options: llama2-7b, llama2-13b, llama2-70b\n)\n\nDATA_ARGS=(\n    --tokenizer-type HFTokenizer\n    --hf-tokenizer-path $TOKENIZER_PATH\n    --data-path $DATA_PATH\n    --split 949,50,1\n)\n\nTRAINING_ARGS=(\n    --training-phase pretrain # options: pretrain, sft\n    --seq-length 4096\n    --max-position-embeddings 4096\n    --init-method-std 0.01\n    --micro-batch-size 1\n    --global-batch-size 1024\n    --lr 0.0002\n    --min-lr 1.0e-5\n    --clip-grad 1.0\n    --weight-decay 0.01\n    --optimizer adam\n    --adam-beta1 0.9\n    --adam-beta2 0.95\n    --adam-eps 1e-05\n    --norm-epsilon 1e-6\n    --train-iters 500000\n    --lr-decay-iters 500000\n    --lr-decay-style cosine\n    --lr-warmup-fraction 0.002\n    --initial-loss-scale 65536\n    --fp16\n    --save-interval 5000\n    --eval-interval 1000\n    --eval-iters 10\n    #--ckpt-step 0\n    #--no-load-optim\n    #--no-load-rng\n)\n\nMODEL_PARALLEL_ARGS=(\n    --tensor-model-parallel-size 4\n    --pipeline-model-parallel-size 4\n    --use-distributed-optimizer\n    --overlap-grad-reduce\n    --overlap-param-gather\n    --distributed-backend nccl\n    --sequence-parallel\n    #--tp-comm-overlap # require mpi envrionment\n)\n\nLOGGING_ARGS=(\n    --log-interval 1\n    --tensorboard-dir ${TENSORBOARD_PATH}\n    --log-timers-to-tensorboard\n)\n\nif [ -n \"${WANDB_API_KEY}\" ]; then\n    LOGGING_ARGS+=(\n        --wandb-project ${WANDB_PROJECT}\n        --wandb-exp-name ${WANDB_NAME} \n    )\nfi\n\nPYTHONPATH=$MEGATRON_PATH:$AIAK_TRAINING_PATH:$PYTHONPATH     torchrun ${DISTRIBUTED_ARGS[@]}     $AIAK_TRAINING_PATH/aiak_training_llm/train.py     ${MODEL_ARGS[@]}     ${DATA_ARGS[@]}     ${TRAINING_ARGS[@]}     ${MODEL_PARALLEL_ARGS[@]}     ${LOGGING_ARGS[@]}\n"
                          ],
                          "env": [
                            {
                              "name": "NCCL_IB_DISABLE",
                              "value": "0"
                            },
                            {
                              "name": "CUDA_DEVICE_MAX_CONNECTIONS",
                              "value": "1"
                            },
                            {
                              "name": "AIHC_TENSORBOARD_LOG_PATH",
                              "value": "/mnt/cluster/llamatest0718forxiaomi5/output/training_logs"
                            },
                            {
                              "name": "AIHC_JOB_NAME",
                              "value": "llamatest0718forxiaomi5"
                            }
                          ],
                          "image": "registry.baidubce.com/aihc-aiak/aiak-training-llm:ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release",
                          "imagePullPolicy": "Always",
                          "name": "pytorch",
                          "ports": [
                            {
                              "containerPort": 23456,
                              "name": "pytorchjob-port",
                              "protocol": "TCP"
                            }
                          ],
                          "resources": {
                            "limits": {
                              "baidu.com/a800_80g_cgpu": "8",
                              "rdma/hca": "1"
                            },
                            "requests": {
                              "baidu.com/a800_80g_cgpu": "8",
                              "rdma/hca": "1"
                            }
                          },
                          "securityContext": {
                            "capabilities": {
                              "add": [
                                "IPC_LOCK"
                              ]
                            }
                          },
                          "volumeMounts": [
                            {
                              "mountPath": "/dev/shm",
                              "name": "devshm"
                            },
                            {
                              "mountPath": "/mnt/cluster",
                              "name": "pvc-pfs"
                            }
                          ]
                        }
                      ],
                      "dnsPolicy": "ClusterFirstWithHostNet",
                      "hostNetwork": true,
                      "schedulerName": "volcano",
                      "volumes": [
                        {
                          "emptyDir": {
                            "medium": "Memory",
                            "sizeLimit": "10Gi"
                          },
                          "name": "devshm"
                        },
                        {
                          "name": "pvc-pfs",
                          "persistentVolumeClaim": {
                            "claimName": "pvc-pfs"
                          }
                        }
                      ]
                    }
                  }
                }
              },
              "runPolicy": {
                "cleanPodPolicy": "None",
                "schedulingPolicy": {
                  "priorityClass": "high",
                  "queue": "default"
                }
              }
            },
            "status": {
              "completionTime": "2024-07-18T02:48:38Z",
              "conditions": [
                {
                  "lastTransitionTime": "2024-07-18T02:30:28Z",
                  "lastUpdateTime": "2024-07-18T02:30:28Z",
                  "message": "PyTorchJob llamatest0718forxiaomi5 is created.",
                  "reason": "PyTorchJobCreated",
                  "status": "True",
                  "type": "Created"
                },
                {
                  "lastTransitionTime": "2024-07-18T02:30:41Z",
                  "lastUpdateTime": "2024-07-18T02:30:41Z",
                  "message": "PyTorchJob llamatest0718forxiaomi5 is running.",
                  "reason": "JobRunning",
                  "status": "False",
                  "type": "Running"
                },
                {
                  "lastTransitionTime": "2024-07-18T02:48:32Z",
                  "lastUpdateTime": "2024-07-18T02:48:32Z",
                  "message": "PytorchJob default/llamatest0718forxiaomi5 is stopped",
                  "reason": "PyTorchJobStopped",
                  "status": "True",
                  "type": "Stopped"
                },
                {
                  "lastTransitionTime": "2024-07-18T02:48:38Z",
                  "lastUpdateTime": "2024-07-18T02:48:38Z",
                  "message": "PyTorchJob llamatest0718forxiaomi5 is failed because 1 Worker replica(s) failed.",
                  "reason": "JobFailed",
                  "status": "True",
                  "type": "Failed"
                }
              ],
              "lastReconcileTime": "2024-07-18T02:30:28Z",
              "replicaStatuses": {
                "Master": {
                  "active": 1,
                  "selector": "training.kubeflow.org/job-name=llamatest0718forxiaomi5,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=master"
                },
                "Worker": {
                  "active": 2,
                  "failed": 1,
                  "selector": "training.kubeflow.org/job-name=llamatest0718forxiaomi5,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=worker"
                }
              },
              "startTime": "2024-07-18T02:30:29Z"
            }
          },
          {
            "apiVersion": "kubeflow.org/v1",
            "kind": "PyTorchJob",
            "metadata": {
              "annotations": {
                "aijob.cce.baidubce.com/barrier-finish": "edae2b9f-0624-43ca-a8a5-2bf5322fe37f",
                "aijob.cce.baidubce.com/fault-tolerance-enabled": "true",
                "aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": "",
                "aijob.cce.baidubce.com/openapi-jobid": "pytorch-3f701207-b25e-48e7-ba06-a3d396838961",
                "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
                "aijob.cce.baidubce.com/raw-request": "{\"name\":\"llamatest0718forxiaomi6\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"high\",\"oversell\":false,\"faultTolerance\":true,\"command\":\"\\n#! /bin/bash\\n\\nMEGATRON_PATH=${MEGATRON_PATH:-\\\"/workspace/AIAK-Megatron\\\"}\\nAIAK_TRAINING_PATH=${AIAK_TRAINING_PATH:-\\\"/workspace/AIAK-Training-LLM\\\"}\\n\\nDATA_PATH=${DATA_PATH:-\\\"/mnt/cluster/llama2/pile_llama_test/pile-llama_text_document\\\"}\\nTOKENIZER_PATH=${TOKENIZER_PATH:-\\\"/mnt/cluster/llama2/Llama-2-70b-hf/\\\"}\\n\\nCHECKPOINT_PATH=${CHECKPOINT_PATH:-\\\"/mnt/cluster/llama2/mcore_llama2_70b_tp4_pp4\\\"}\\n\\nTENSORBOARD_PATH=${TENSORBOARD_PATH:-\\\"/mnt/cluster/aiak-training-llm/tensorboard-log/llama2-70b-tp4pp4\\\"}\\n\\nGPUS_PER_NODE=8\\n\\n# Change for multinode config\\nMASTER_ADDR=${MASTER_ADDR:-\\\"localhost\\\"}\\nMASTER_PORT=${MASTER_PORT:-\\\"6000\\\"}\\nNNODES=${WORLD_SIZE:-\\\"1\\\"}\\nNODE_RANK=${RANK:-\\\"0\\\"}\\n\\nDISTRIBUTED_ARGS=(\\n    --nproc_per_node $GPUS_PER_NODE\\n    --nnodes $NNODES\\n    --node_rank $NODE_RANK\\n    --master_addr $MASTER_ADDR\\n    --master_port $MASTER_PORT\\n)\\n\\n# you can setup llama2-70b maunally\\n#MODEL_ARGS=(\\n#    --model-name llama2\\n#    --num-layers 80\\n#    --hidden-size 8192\\n#    --ffn-hidden-size 28672\\n#    --num-attention-heads 64\\n#    --position-embedding-type rope\\n#    --normalization RMSNorm\\n#    --swiglu\\n#    --attention-dropout 0\\n#    --hidden-dropout 0\\n#    --disable-bias-linear\\n#    --untie-embeddings-and-output-weights\\n#    --group-query-attention\\n#    --num-query-groups 8\\n#)\\n\\n# or you can setup llama2-70b by using the following command\\nMODEL_ARGS=(\\n    --model-name llama2-70b # options: llama2-7b, llama2-13b, llama2-70b\\n)\\n\\nDATA_ARGS=(\\n    --tokenizer-type HFTokenizer\\n    --hf-tokenizer-path $TOKENIZER_PATH\\n    --data-path $DATA_PATH\\n    --split 949,50,1\\n)\\n\\nTRAINING_ARGS=(\\n    --training-phase pretrain # options: pretrain, sft\\n    --seq-length 4096\\n    --max-position-embeddings 4096\\n    --init-method-std 0.01\\n    --micro-batch-size 1\\n    --global-batch-size 128\\n    --lr 0.0002\\n    --min-lr 1.0e-5\\n    --clip-grad 1.0\\n    --weight-decay 0.01\\n    --optimizer adam\\n    --adam-beta1 0.9\\n    --adam-beta2 0.95\\n    --adam-eps 1e-05\\n    --norm-epsilon 1e-6\\n    --train-iters 500000\\n    --lr-decay-iters 500000\\n    --lr-decay-style cosine\\n    --lr-warmup-fraction 0.002\\n    --initial-loss-scale 65536\\n    --fp16\\n    --save-interval 5000\\n    --eval-interval 1000\\n    --eval-iters 10\\n    --offload-optimizer auto\\n    #--ckpt-step 0\\n    #--no-load-optim\\n    #--no-load-rng\\n)\\n\\nMODEL_PARALLEL_ARGS=(\\n    --tensor-model-parallel-size 2\\n    --pipeline-model-parallel-size 8\\n    --use-distributed-optimizer\\n    --overlap-grad-reduce\\n    --overlap-param-gather\\n    --distributed-backend nccl\\n    --sequence-parallel\\n    #--tp-comm-overlap # require mpi envrionment\\n)\\n\\nLOGGING_ARGS=(\\n    --log-interval 1\\n    --tensorboard-dir ${TENSORBOARD_PATH}\\n    --log-timers-to-tensorboard\\n)\\n\\nif [ -n \\\"${WANDB_API_KEY}\\\" ]; then\\n    LOGGING_ARGS+=(\\n        --wandb-project ${WANDB_PROJECT}\\n        --wandb-exp-name ${WANDB_NAME} \\n    )\\nfi\\n\\nPYTHONPATH=$MEGATRON_PATH:$AIAK_TRAINING_PATH:$PYTHONPATH     torchrun ${DISTRIBUTED_ARGS[@]}     $AIAK_TRAINING_PATH/aiak_training_llm/train.py     ${MODEL_ARGS[@]}     ${DATA_ARGS[@]}     ${TRAINING_ARGS[@]}     ${MODEL_PARALLEL_ARGS[@]}     ${LOGGING_ARGS[@]}\\n\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":true,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi6\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi6/output/training_logs\",\"CUDA_DEVICE_MAX_CONNECTIONS\":\"1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"},\"Worker\":{\"replicas\":3,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi6\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi6/output/training_logs\",\"CUDA_DEVICE_MAX_CONNECTIONS\":\"1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":true,\"logPath\":\"/mnt/cluster/llamatest0718forxiaomi6/output/training_logs\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":true,\"isCopyJob\":true,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
                "aijob.cce.baidubce.com/timeline": "[{\"conditionType\":\"Created\",\"time\":1721270898},{\"conditionType\":\"Scheduled\",\"time\":1721270899},{\"conditionType\":\"Running\",\"time\":1721270910},{\"conditionType\":\"ManualTermination\",\"time\":1721271258}]",
                "job-manager/action": "stop",
                "job-manager/action-succeed": "stop",
                "scheduling.k8s.io/job-enable-oversell": "false",
                "tensorboard-gc": "true"
              },
              "creationTimestamp": "2024-07-18T02:48:18Z",
              "generation": 2,
              "labels": {
                "aijob.cce.baidubce.com/ai-user-id": "b5a24aa26e4d4f55bc3acf68edc4b051",
                "aijob.cce.baidubce.com/ai-user-name": "zhangmuhua",
                "aijob.cce.baidubce.com/create-from-aihcp": "true",
                "aijob.cce.baidubce.com/openapi-jobid": "pytorch-3f701207-b25e-48e7-ba06-a3d396838961"
              },
              "managedFields": [
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        "f:aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": {},
                        "f:aijob.cce.baidubce.com/timeline": {}
                      }
                    },
                    "f:spec": {
                      "f:pytorchReplicaSpecs": {
                        "f:Master": {
                          "f:template": {
                            "f:spec": {
                              "f:containers": {}
                            }
                          }
                        },
                        "f:Worker": {
                          "f:template": {
                            "f:spec": {
                              "f:containers": {}
                            }
                          }
                        }
                      },
                      "f:runPolicy": {
                        "f:cleanPodPolicy": {}
                      }
                    }
                  },
                  "manager": "controller",
                  "operation": "Update",
                  "time": "2024-07-18T02:48:18Z"
                },
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        "f:aijob.cce.baidubce.com/barrier-finish": {}
                      }
                    }
                  },
                  "manager": "jobbarrier",
                  "operation": "Update",
                  "time": "2024-07-18T02:48:27Z"
                },
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        ".": {},
                        "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                        "f:aijob.cce.baidubce.com/openapi-jobid": {},
                        "f:aijob.cce.baidubce.com/pfs-id": {},
                        "f:aijob.cce.baidubce.com/raw-request": {},
                        "f:job-manager/action": {},
                        "f:scheduling.k8s.io/job-enable-oversell": {}
                      },
                      "f:labels": {
                        ".": {},
                        "f:aijob.cce.baidubce.com/ai-user-id": {},
                        "f:aijob.cce.baidubce.com/ai-user-name": {},
                        "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                        "f:aijob.cce.baidubce.com/openapi-jobid": {}
                      }
                    },
                    "f:spec": {
                      ".": {},
                      "f:pytorchReplicaSpecs": {
                        ".": {},
                        "f:Master": {
                          ".": {},
                          "f:replicas": {},
                          "f:restartPolicy": {},
                          "f:template": {
                            ".": {},
                            "f:metadata": {
                              ".": {},
                              "f:annotations": {
                                ".": {},
                                "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                                "f:aijob.cce.baidubce.com/openapi-jobid": {},
                                "f:aijob.cce.baidubce.com/pfs-id": {},
                                "f:aijob.cce.baidubce.com/raw-request": {},
                                "f:scheduling.k8s.io/job-enable-oversell": {}
                              },
                              "f:labels": {
                                ".": {},
                                "f:aijob.cce.baidubce.com/ai-user-id": {},
                                "f:aijob.cce.baidubce.com/ai-user-name": {},
                                "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                                "f:aijob.cce.baidubce.com/openapi-jobid": {}
                              }
                            },
                            "f:spec": {
                              ".": {},
                              "f:dnsPolicy": {},
                              "f:hostNetwork": {},
                              "f:schedulerName": {},
                              "f:volumes": {}
                            }
                          }
                        },
                        "f:Worker": {
                          ".": {},
                          "f:replicas": {},
                          "f:restartPolicy": {},
                          "f:template": {
                            ".": {},
                            "f:metadata": {
                              ".": {},
                              "f:annotations": {
                                ".": {},
                                "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                                "f:aijob.cce.baidubce.com/openapi-jobid": {},
                                "f:aijob.cce.baidubce.com/pfs-id": {},
                                "f:aijob.cce.baidubce.com/raw-request": {},
                                "f:scheduling.k8s.io/job-enable-oversell": {}
                              },
                              "f:labels": {
                                ".": {},
                                "f:aijob.cce.baidubce.com/ai-user-id": {},
                                "f:aijob.cce.baidubce.com/ai-user-name": {},
                                "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                                "f:aijob.cce.baidubce.com/openapi-jobid": {}
                              }
                            },
                            "f:spec": {
                              ".": {},
                              "f:dnsPolicy": {},
                              "f:hostNetwork": {},
                              "f:schedulerName": {},
                              "f:volumes": {}
                            }
                          }
                        }
                      },
                      "f:runPolicy": {
                        ".": {},
                        "f:schedulingPolicy": {
                          ".": {},
                          "f:priorityClass": {},
                          "f:queue": {}
                        }
                      }
                    }
                  },
                  "manager": "cce-ai-service",
                  "operation": "Update",
                  "time": "2024-07-18T02:54:18Z"
                },
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        "f:job-manager/action-succeed": {}
                      }
                    }
                  },
                  "manager": "ftagent",
                  "operation": "Update",
                  "time": "2024-07-18T02:54:23Z"
                },
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        "f:tensorboard-gc": {}
                      }
                    },
                    "f:status": {
                      ".": {},
                      "f:completionTime": {},
                      "f:conditions": {},
                      "f:lastReconcileTime": {},
                      "f:replicaStatuses": {
                        ".": {},
                        "f:Master": {
                          ".": {},
                          "f:active": {}
                        },
                        "f:Worker": {
                          ".": {},
                          "f:active": {},
                          "f:failed": {}
                        }
                      },
                      "f:startTime": {}
                    }
                  },
                  "manager": "manager",
                  "operation": "Update",
                  "time": "2024-07-19T02:48:56Z"
                }
              ],
              "name": "llamatest0718forxiaomi6",
              "namespace": "default",
              "resourceVersion": "2372410633",
              "uid": "9b140464-2b9e-4f49-9e05-ba7190c73857"
            },
            "spec": {
              "pytorchReplicaSpecs": {
                "Master": {
                  "replicas": 1,
                  "restartPolicy": "Never",
                  "template": {
                    "metadata": {
                      "annotations": {
                        "aijob.cce.baidubce.com/fault-tolerance-enabled": "true",
                        "aijob.cce.baidubce.com/openapi-jobid": "pytorch-3f701207-b25e-48e7-ba06-a3d396838961",
                        "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
                        "aijob.cce.baidubce.com/raw-request": "{\"name\":\"llamatest0718forxiaomi6\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"high\",\"oversell\":false,\"faultTolerance\":true,\"command\":\"\\n#! /bin/bash\\n\\nMEGATRON_PATH=${MEGATRON_PATH:-\\\"/workspace/AIAK-Megatron\\\"}\\nAIAK_TRAINING_PATH=${AIAK_TRAINING_PATH:-\\\"/workspace/AIAK-Training-LLM\\\"}\\n\\nDATA_PATH=${DATA_PATH:-\\\"/mnt/cluster/llama2/pile_llama_test/pile-llama_text_document\\\"}\\nTOKENIZER_PATH=${TOKENIZER_PATH:-\\\"/mnt/cluster/llama2/Llama-2-70b-hf/\\\"}\\n\\nCHECKPOINT_PATH=${CHECKPOINT_PATH:-\\\"/mnt/cluster/llama2/mcore_llama2_70b_tp4_pp4\\\"}\\n\\nTENSORBOARD_PATH=${TENSORBOARD_PATH:-\\\"/mnt/cluster/aiak-training-llm/tensorboard-log/llama2-70b-tp4pp4\\\"}\\n\\nGPUS_PER_NODE=8\\n\\n# Change for multinode config\\nMASTER_ADDR=${MASTER_ADDR:-\\\"localhost\\\"}\\nMASTER_PORT=${MASTER_PORT:-\\\"6000\\\"}\\nNNODES=${WORLD_SIZE:-\\\"1\\\"}\\nNODE_RANK=${RANK:-\\\"0\\\"}\\n\\nDISTRIBUTED_ARGS=(\\n    --nproc_per_node $GPUS_PER_NODE\\n    --nnodes $NNODES\\n    --node_rank $NODE_RANK\\n    --master_addr $MASTER_ADDR\\n    --master_port $MASTER_PORT\\n)\\n\\n# you can setup llama2-70b maunally\\n#MODEL_ARGS=(\\n#    --model-name llama2\\n#    --num-layers 80\\n#    --hidden-size 8192\\n#    --ffn-hidden-size 28672\\n#    --num-attention-heads 64\\n#    --position-embedding-type rope\\n#    --normalization RMSNorm\\n#    --swiglu\\n#    --attention-dropout 0\\n#    --hidden-dropout 0\\n#    --disable-bias-linear\\n#    --untie-embeddings-and-output-weights\\n#    --group-query-attention\\n#    --num-query-groups 8\\n#)\\n\\n# or you can setup llama2-70b by using the following command\\nMODEL_ARGS=(\\n    --model-name llama2-70b # options: llama2-7b, llama2-13b, llama2-70b\\n)\\n\\nDATA_ARGS=(\\n    --tokenizer-type HFTokenizer\\n    --hf-tokenizer-path $TOKENIZER_PATH\\n    --data-path $DATA_PATH\\n    --split 949,50,1\\n)\\n\\nTRAINING_ARGS=(\\n    --training-phase pretrain # options: pretrain, sft\\n    --seq-length 4096\\n    --max-position-embeddings 4096\\n    --init-method-std 0.01\\n    --micro-batch-size 1\\n    --global-batch-size 128\\n    --lr 0.0002\\n    --min-lr 1.0e-5\\n    --clip-grad 1.0\\n    --weight-decay 0.01\\n    --optimizer adam\\n    --adam-beta1 0.9\\n    --adam-beta2 0.95\\n    --adam-eps 1e-05\\n    --norm-epsilon 1e-6\\n    --train-iters 500000\\n    --lr-decay-iters 500000\\n    --lr-decay-style cosine\\n    --lr-warmup-fraction 0.002\\n    --initial-loss-scale 65536\\n    --fp16\\n    --save-interval 5000\\n    --eval-interval 1000\\n    --eval-iters 10\\n    --offload-optimizer auto\\n    #--ckpt-step 0\\n    #--no-load-optim\\n    #--no-load-rng\\n)\\n\\nMODEL_PARALLEL_ARGS=(\\n    --tensor-model-parallel-size 2\\n    --pipeline-model-parallel-size 8\\n    --use-distributed-optimizer\\n    --overlap-grad-reduce\\n    --overlap-param-gather\\n    --distributed-backend nccl\\n    --sequence-parallel\\n    #--tp-comm-overlap # require mpi envrionment\\n)\\n\\nLOGGING_ARGS=(\\n    --log-interval 1\\n    --tensorboard-dir ${TENSORBOARD_PATH}\\n    --log-timers-to-tensorboard\\n)\\n\\nif [ -n \\\"${WANDB_API_KEY}\\\" ]; then\\n    LOGGING_ARGS+=(\\n        --wandb-project ${WANDB_PROJECT}\\n        --wandb-exp-name ${WANDB_NAME} \\n    )\\nfi\\n\\nPYTHONPATH=$MEGATRON_PATH:$AIAK_TRAINING_PATH:$PYTHONPATH     torchrun ${DISTRIBUTED_ARGS[@]}     $AIAK_TRAINING_PATH/aiak_training_llm/train.py     ${MODEL_ARGS[@]}     ${DATA_ARGS[@]}     ${TRAINING_ARGS[@]}     ${MODEL_PARALLEL_ARGS[@]}     ${LOGGING_ARGS[@]}\\n\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":true,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi6\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi6/output/training_logs\",\"CUDA_DEVICE_MAX_CONNECTIONS\":\"1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"},\"Worker\":{\"replicas\":3,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi6\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi6/output/training_logs\",\"CUDA_DEVICE_MAX_CONNECTIONS\":\"1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":true,\"logPath\":\"/mnt/cluster/llamatest0718forxiaomi6/output/training_logs\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":true,\"isCopyJob\":true,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
                        "scheduling.k8s.io/job-enable-oversell": "false"
                      },
                      "labels": {
                        "aijob.cce.baidubce.com/ai-user-id": "b5a24aa26e4d4f55bc3acf68edc4b051",
                        "aijob.cce.baidubce.com/ai-user-name": "zhangmuhua",
                        "aijob.cce.baidubce.com/create-from-aihcp": "true",
                        "aijob.cce.baidubce.com/openapi-jobid": "pytorch-3f701207-b25e-48e7-ba06-a3d396838961"
                      }
                    },
                    "spec": {
                      "containers": [
                        {
                          "command": [
                            "/bin/bash",
                            "-c",
                            "\n#! /bin/bash\n\nMEGATRON_PATH=${MEGATRON_PATH:-\"/workspace/AIAK-Megatron\"}\nAIAK_TRAINING_PATH=${AIAK_TRAINING_PATH:-\"/workspace/AIAK-Training-LLM\"}\n\nDATA_PATH=${DATA_PATH:-\"/mnt/cluster/llama2/pile_llama_test/pile-llama_text_document\"}\nTOKENIZER_PATH=${TOKENIZER_PATH:-\"/mnt/cluster/llama2/Llama-2-70b-hf/\"}\n\nCHECKPOINT_PATH=${CHECKPOINT_PATH:-\"/mnt/cluster/llama2/mcore_llama2_70b_tp4_pp4\"}\n\nTENSORBOARD_PATH=${TENSORBOARD_PATH:-\"/mnt/cluster/aiak-training-llm/tensorboard-log/llama2-70b-tp4pp4\"}\n\nGPUS_PER_NODE=8\n\n# Change for multinode config\nMASTER_ADDR=${MASTER_ADDR:-\"localhost\"}\nMASTER_PORT=${MASTER_PORT:-\"6000\"}\nNNODES=${WORLD_SIZE:-\"1\"}\nNODE_RANK=${RANK:-\"0\"}\n\nDISTRIBUTED_ARGS=(\n    --nproc_per_node $GPUS_PER_NODE\n    --nnodes $NNODES\n    --node_rank $NODE_RANK\n    --master_addr $MASTER_ADDR\n    --master_port $MASTER_PORT\n)\n\n# you can setup llama2-70b maunally\n#MODEL_ARGS=(\n#    --model-name llama2\n#    --num-layers 80\n#    --hidden-size 8192\n#    --ffn-hidden-size 28672\n#    --num-attention-heads 64\n#    --position-embedding-type rope\n#    --normalization RMSNorm\n#    --swiglu\n#    --attention-dropout 0\n#    --hidden-dropout 0\n#    --disable-bias-linear\n#    --untie-embeddings-and-output-weights\n#    --group-query-attention\n#    --num-query-groups 8\n#)\n\n# or you can setup llama2-70b by using the following command\nMODEL_ARGS=(\n    --model-name llama2-70b # options: llama2-7b, llama2-13b, llama2-70b\n)\n\nDATA_ARGS=(\n    --tokenizer-type HFTokenizer\n    --hf-tokenizer-path $TOKENIZER_PATH\n    --data-path $DATA_PATH\n    --split 949,50,1\n)\n\nTRAINING_ARGS=(\n    --training-phase pretrain # options: pretrain, sft\n    --seq-length 4096\n    --max-position-embeddings 4096\n    --init-method-std 0.01\n    --micro-batch-size 1\n    --global-batch-size 128\n    --lr 0.0002\n    --min-lr 1.0e-5\n    --clip-grad 1.0\n    --weight-decay 0.01\n    --optimizer adam\n    --adam-beta1 0.9\n    --adam-beta2 0.95\n    --adam-eps 1e-05\n    --norm-epsilon 1e-6\n    --train-iters 500000\n    --lr-decay-iters 500000\n    --lr-decay-style cosine\n    --lr-warmup-fraction 0.002\n    --initial-loss-scale 65536\n    --fp16\n    --save-interval 5000\n    --eval-interval 1000\n    --eval-iters 10\n    --offload-optimizer auto\n    #--ckpt-step 0\n    #--no-load-optim\n    #--no-load-rng\n)\n\nMODEL_PARALLEL_ARGS=(\n    --tensor-model-parallel-size 2\n    --pipeline-model-parallel-size 8\n    --use-distributed-optimizer\n    --overlap-grad-reduce\n    --overlap-param-gather\n    --distributed-backend nccl\n    --sequence-parallel\n    #--tp-comm-overlap # require mpi envrionment\n)\n\nLOGGING_ARGS=(\n    --log-interval 1\n    --tensorboard-dir ${TENSORBOARD_PATH}\n    --log-timers-to-tensorboard\n)\n\nif [ -n \"${WANDB_API_KEY}\" ]; then\n    LOGGING_ARGS+=(\n        --wandb-project ${WANDB_PROJECT}\n        --wandb-exp-name ${WANDB_NAME} \n    )\nfi\n\nPYTHONPATH=$MEGATRON_PATH:$AIAK_TRAINING_PATH:$PYTHONPATH     torchrun ${DISTRIBUTED_ARGS[@]}     $AIAK_TRAINING_PATH/aiak_training_llm/train.py     ${MODEL_ARGS[@]}     ${DATA_ARGS[@]}     ${TRAINING_ARGS[@]}     ${MODEL_PARALLEL_ARGS[@]}     ${LOGGING_ARGS[@]}\n"
                          ],
                          "env": [
                            {
                              "name": "NCCL_IB_DISABLE",
                              "value": "0"
                            },
                            {
                              "name": "CUDA_DEVICE_MAX_CONNECTIONS",
                              "value": "1"
                            },
                            {
                              "name": "AIHC_TENSORBOARD_LOG_PATH",
                              "value": "/mnt/cluster/llamatest0718forxiaomi6/output/training_logs"
                            },
                            {
                              "name": "AIHC_JOB_NAME",
                              "value": "llamatest0718forxiaomi6"
                            }
                          ],
                          "image": "registry.baidubce.com/aihc-aiak/aiak-training-llm:ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release",
                          "imagePullPolicy": "Always",
                          "name": "pytorch",
                          "ports": [
                            {
                              "containerPort": 23456,
                              "name": "pytorchjob-port",
                              "protocol": "TCP"
                            }
                          ],
                          "resources": {
                            "limits": {
                              "baidu.com/a800_80g_cgpu": "8",
                              "rdma/hca": "1"
                            },
                            "requests": {
                              "baidu.com/a800_80g_cgpu": "8",
                              "rdma/hca": "1"
                            }
                          },
                          "securityContext": {
                            "capabilities": {
                              "add": [
                                "IPC_LOCK"
                              ]
                            }
                          },
                          "volumeMounts": [
                            {
                              "mountPath": "/dev/shm",
                              "name": "devshm"
                            },
                            {
                              "mountPath": "/mnt/cluster",
                              "name": "pvc-pfs"
                            }
                          ]
                        }
                      ],
                      "dnsPolicy": "ClusterFirstWithHostNet",
                      "hostNetwork": true,
                      "schedulerName": "volcano",
                      "volumes": [
                        {
                          "emptyDir": {
                            "medium": "Memory",
                            "sizeLimit": "10Gi"
                          },
                          "name": "devshm"
                        },
                        {
                          "name": "pvc-pfs",
                          "persistentVolumeClaim": {
                            "claimName": "pvc-pfs"
                          }
                        }
                      ]
                    }
                  }
                },
                "Worker": {
                  "replicas": 3,
                  "restartPolicy": "Never",
                  "template": {
                    "metadata": {
                      "annotations": {
                        "aijob.cce.baidubce.com/fault-tolerance-enabled": "true",
                        "aijob.cce.baidubce.com/openapi-jobid": "pytorch-3f701207-b25e-48e7-ba06-a3d396838961",
                        "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
                        "aijob.cce.baidubce.com/raw-request": "{\"name\":\"llamatest0718forxiaomi6\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"high\",\"oversell\":false,\"faultTolerance\":true,\"command\":\"\\n#! /bin/bash\\n\\nMEGATRON_PATH=${MEGATRON_PATH:-\\\"/workspace/AIAK-Megatron\\\"}\\nAIAK_TRAINING_PATH=${AIAK_TRAINING_PATH:-\\\"/workspace/AIAK-Training-LLM\\\"}\\n\\nDATA_PATH=${DATA_PATH:-\\\"/mnt/cluster/llama2/pile_llama_test/pile-llama_text_document\\\"}\\nTOKENIZER_PATH=${TOKENIZER_PATH:-\\\"/mnt/cluster/llama2/Llama-2-70b-hf/\\\"}\\n\\nCHECKPOINT_PATH=${CHECKPOINT_PATH:-\\\"/mnt/cluster/llama2/mcore_llama2_70b_tp4_pp4\\\"}\\n\\nTENSORBOARD_PATH=${TENSORBOARD_PATH:-\\\"/mnt/cluster/aiak-training-llm/tensorboard-log/llama2-70b-tp4pp4\\\"}\\n\\nGPUS_PER_NODE=8\\n\\n# Change for multinode config\\nMASTER_ADDR=${MASTER_ADDR:-\\\"localhost\\\"}\\nMASTER_PORT=${MASTER_PORT:-\\\"6000\\\"}\\nNNODES=${WORLD_SIZE:-\\\"1\\\"}\\nNODE_RANK=${RANK:-\\\"0\\\"}\\n\\nDISTRIBUTED_ARGS=(\\n    --nproc_per_node $GPUS_PER_NODE\\n    --nnodes $NNODES\\n    --node_rank $NODE_RANK\\n    --master_addr $MASTER_ADDR\\n    --master_port $MASTER_PORT\\n)\\n\\n# you can setup llama2-70b maunally\\n#MODEL_ARGS=(\\n#    --model-name llama2\\n#    --num-layers 80\\n#    --hidden-size 8192\\n#    --ffn-hidden-size 28672\\n#    --num-attention-heads 64\\n#    --position-embedding-type rope\\n#    --normalization RMSNorm\\n#    --swiglu\\n#    --attention-dropout 0\\n#    --hidden-dropout 0\\n#    --disable-bias-linear\\n#    --untie-embeddings-and-output-weights\\n#    --group-query-attention\\n#    --num-query-groups 8\\n#)\\n\\n# or you can setup llama2-70b by using the following command\\nMODEL_ARGS=(\\n    --model-name llama2-70b # options: llama2-7b, llama2-13b, llama2-70b\\n)\\n\\nDATA_ARGS=(\\n    --tokenizer-type HFTokenizer\\n    --hf-tokenizer-path $TOKENIZER_PATH\\n    --data-path $DATA_PATH\\n    --split 949,50,1\\n)\\n\\nTRAINING_ARGS=(\\n    --training-phase pretrain # options: pretrain, sft\\n    --seq-length 4096\\n    --max-position-embeddings 4096\\n    --init-method-std 0.01\\n    --micro-batch-size 1\\n    --global-batch-size 128\\n    --lr 0.0002\\n    --min-lr 1.0e-5\\n    --clip-grad 1.0\\n    --weight-decay 0.01\\n    --optimizer adam\\n    --adam-beta1 0.9\\n    --adam-beta2 0.95\\n    --adam-eps 1e-05\\n    --norm-epsilon 1e-6\\n    --train-iters 500000\\n    --lr-decay-iters 500000\\n    --lr-decay-style cosine\\n    --lr-warmup-fraction 0.002\\n    --initial-loss-scale 65536\\n    --fp16\\n    --save-interval 5000\\n    --eval-interval 1000\\n    --eval-iters 10\\n    --offload-optimizer auto\\n    #--ckpt-step 0\\n    #--no-load-optim\\n    #--no-load-rng\\n)\\n\\nMODEL_PARALLEL_ARGS=(\\n    --tensor-model-parallel-size 2\\n    --pipeline-model-parallel-size 8\\n    --use-distributed-optimizer\\n    --overlap-grad-reduce\\n    --overlap-param-gather\\n    --distributed-backend nccl\\n    --sequence-parallel\\n    #--tp-comm-overlap # require mpi envrionment\\n)\\n\\nLOGGING_ARGS=(\\n    --log-interval 1\\n    --tensorboard-dir ${TENSORBOARD_PATH}\\n    --log-timers-to-tensorboard\\n)\\n\\nif [ -n \\\"${WANDB_API_KEY}\\\" ]; then\\n    LOGGING_ARGS+=(\\n        --wandb-project ${WANDB_PROJECT}\\n        --wandb-exp-name ${WANDB_NAME} \\n    )\\nfi\\n\\nPYTHONPATH=$MEGATRON_PATH:$AIAK_TRAINING_PATH:$PYTHONPATH     torchrun ${DISTRIBUTED_ARGS[@]}     $AIAK_TRAINING_PATH/aiak_training_llm/train.py     ${MODEL_ARGS[@]}     ${DATA_ARGS[@]}     ${TRAINING_ARGS[@]}     ${MODEL_PARALLEL_ARGS[@]}     ${LOGGING_ARGS[@]}\\n\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":true,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi6\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi6/output/training_logs\",\"CUDA_DEVICE_MAX_CONNECTIONS\":\"1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"},\"Worker\":{\"replicas\":3,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi6\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi6/output/training_logs\",\"CUDA_DEVICE_MAX_CONNECTIONS\":\"1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":true,\"logPath\":\"/mnt/cluster/llamatest0718forxiaomi6/output/training_logs\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":true,\"isCopyJob\":true,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
                        "scheduling.k8s.io/job-enable-oversell": "false"
                      },
                      "labels": {
                        "aijob.cce.baidubce.com/ai-user-id": "b5a24aa26e4d4f55bc3acf68edc4b051",
                        "aijob.cce.baidubce.com/ai-user-name": "zhangmuhua",
                        "aijob.cce.baidubce.com/create-from-aihcp": "true",
                        "aijob.cce.baidubce.com/openapi-jobid": "pytorch-3f701207-b25e-48e7-ba06-a3d396838961"
                      }
                    },
                    "spec": {
                      "containers": [
                        {
                          "command": [
                            "/bin/bash",
                            "-c",
                            "\n#! /bin/bash\n\nMEGATRON_PATH=${MEGATRON_PATH:-\"/workspace/AIAK-Megatron\"}\nAIAK_TRAINING_PATH=${AIAK_TRAINING_PATH:-\"/workspace/AIAK-Training-LLM\"}\n\nDATA_PATH=${DATA_PATH:-\"/mnt/cluster/llama2/pile_llama_test/pile-llama_text_document\"}\nTOKENIZER_PATH=${TOKENIZER_PATH:-\"/mnt/cluster/llama2/Llama-2-70b-hf/\"}\n\nCHECKPOINT_PATH=${CHECKPOINT_PATH:-\"/mnt/cluster/llama2/mcore_llama2_70b_tp4_pp4\"}\n\nTENSORBOARD_PATH=${TENSORBOARD_PATH:-\"/mnt/cluster/aiak-training-llm/tensorboard-log/llama2-70b-tp4pp4\"}\n\nGPUS_PER_NODE=8\n\n# Change for multinode config\nMASTER_ADDR=${MASTER_ADDR:-\"localhost\"}\nMASTER_PORT=${MASTER_PORT:-\"6000\"}\nNNODES=${WORLD_SIZE:-\"1\"}\nNODE_RANK=${RANK:-\"0\"}\n\nDISTRIBUTED_ARGS=(\n    --nproc_per_node $GPUS_PER_NODE\n    --nnodes $NNODES\n    --node_rank $NODE_RANK\n    --master_addr $MASTER_ADDR\n    --master_port $MASTER_PORT\n)\n\n# you can setup llama2-70b maunally\n#MODEL_ARGS=(\n#    --model-name llama2\n#    --num-layers 80\n#    --hidden-size 8192\n#    --ffn-hidden-size 28672\n#    --num-attention-heads 64\n#    --position-embedding-type rope\n#    --normalization RMSNorm\n#    --swiglu\n#    --attention-dropout 0\n#    --hidden-dropout 0\n#    --disable-bias-linear\n#    --untie-embeddings-and-output-weights\n#    --group-query-attention\n#    --num-query-groups 8\n#)\n\n# or you can setup llama2-70b by using the following command\nMODEL_ARGS=(\n    --model-name llama2-70b # options: llama2-7b, llama2-13b, llama2-70b\n)\n\nDATA_ARGS=(\n    --tokenizer-type HFTokenizer\n    --hf-tokenizer-path $TOKENIZER_PATH\n    --data-path $DATA_PATH\n    --split 949,50,1\n)\n\nTRAINING_ARGS=(\n    --training-phase pretrain # options: pretrain, sft\n    --seq-length 4096\n    --max-position-embeddings 4096\n    --init-method-std 0.01\n    --micro-batch-size 1\n    --global-batch-size 128\n    --lr 0.0002\n    --min-lr 1.0e-5\n    --clip-grad 1.0\n    --weight-decay 0.01\n    --optimizer adam\n    --adam-beta1 0.9\n    --adam-beta2 0.95\n    --adam-eps 1e-05\n    --norm-epsilon 1e-6\n    --train-iters 500000\n    --lr-decay-iters 500000\n    --lr-decay-style cosine\n    --lr-warmup-fraction 0.002\n    --initial-loss-scale 65536\n    --fp16\n    --save-interval 5000\n    --eval-interval 1000\n    --eval-iters 10\n    --offload-optimizer auto\n    #--ckpt-step 0\n    #--no-load-optim\n    #--no-load-rng\n)\n\nMODEL_PARALLEL_ARGS=(\n    --tensor-model-parallel-size 2\n    --pipeline-model-parallel-size 8\n    --use-distributed-optimizer\n    --overlap-grad-reduce\n    --overlap-param-gather\n    --distributed-backend nccl\n    --sequence-parallel\n    #--tp-comm-overlap # require mpi envrionment\n)\n\nLOGGING_ARGS=(\n    --log-interval 1\n    --tensorboard-dir ${TENSORBOARD_PATH}\n    --log-timers-to-tensorboard\n)\n\nif [ -n \"${WANDB_API_KEY}\" ]; then\n    LOGGING_ARGS+=(\n        --wandb-project ${WANDB_PROJECT}\n        --wandb-exp-name ${WANDB_NAME} \n    )\nfi\n\nPYTHONPATH=$MEGATRON_PATH:$AIAK_TRAINING_PATH:$PYTHONPATH     torchrun ${DISTRIBUTED_ARGS[@]}     $AIAK_TRAINING_PATH/aiak_training_llm/train.py     ${MODEL_ARGS[@]}     ${DATA_ARGS[@]}     ${TRAINING_ARGS[@]}     ${MODEL_PARALLEL_ARGS[@]}     ${LOGGING_ARGS[@]}\n"
                          ],
                          "env": [
                            {
                              "name": "CUDA_DEVICE_MAX_CONNECTIONS",
                              "value": "1"
                            },
                            {
                              "name": "AIHC_TENSORBOARD_LOG_PATH",
                              "value": "/mnt/cluster/llamatest0718forxiaomi6/output/training_logs"
                            },
                            {
                              "name": "AIHC_JOB_NAME",
                              "value": "llamatest0718forxiaomi6"
                            },
                            {
                              "name": "NCCL_IB_DISABLE",
                              "value": "0"
                            }
                          ],
                          "image": "registry.baidubce.com/aihc-aiak/aiak-training-llm:ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release",
                          "imagePullPolicy": "Always",
                          "name": "pytorch",
                          "ports": [
                            {
                              "containerPort": 23456,
                              "name": "pytorchjob-port",
                              "protocol": "TCP"
                            }
                          ],
                          "resources": {
                            "limits": {
                              "baidu.com/a800_80g_cgpu": "8",
                              "rdma/hca": "1"
                            },
                            "requests": {
                              "baidu.com/a800_80g_cgpu": "8",
                              "rdma/hca": "1"
                            }
                          },
                          "securityContext": {
                            "capabilities": {
                              "add": [
                                "IPC_LOCK"
                              ]
                            }
                          },
                          "volumeMounts": [
                            {
                              "mountPath": "/dev/shm",
                              "name": "devshm"
                            },
                            {
                              "mountPath": "/mnt/cluster",
                              "name": "pvc-pfs"
                            }
                          ]
                        }
                      ],
                      "dnsPolicy": "ClusterFirstWithHostNet",
                      "hostNetwork": true,
                      "schedulerName": "volcano",
                      "volumes": [
                        {
                          "emptyDir": {
                            "medium": "Memory",
                            "sizeLimit": "10Gi"
                          },
                          "name": "devshm"
                        },
                        {
                          "name": "pvc-pfs",
                          "persistentVolumeClaim": {
                            "claimName": "pvc-pfs"
                          }
                        }
                      ]
                    }
                  }
                }
              },
              "runPolicy": {
                "cleanPodPolicy": "None",
                "schedulingPolicy": {
                  "priorityClass": "high",
                  "queue": "default"
                }
              }
            },
            "status": {
              "completionTime": "2024-07-18T02:54:25Z",
              "conditions": [
                {
                  "lastTransitionTime": "2024-07-18T02:48:18Z",
                  "lastUpdateTime": "2024-07-18T02:48:18Z",
                  "message": "PyTorchJob llamatest0718forxiaomi6 is created.",
                  "reason": "PyTorchJobCreated",
                  "status": "True",
                  "type": "Created"
                },
                {
                  "lastTransitionTime": "2024-07-18T02:48:30Z",
                  "lastUpdateTime": "2024-07-18T02:48:30Z",
                  "message": "PyTorchJob llamatest0718forxiaomi6 is running.",
                  "reason": "JobRunning",
                  "status": "False",
                  "type": "Running"
                },
                {
                  "lastTransitionTime": "2024-07-18T02:54:18Z",
                  "lastUpdateTime": "2024-07-18T02:54:18Z",
                  "message": "PytorchJob default/llamatest0718forxiaomi6 is stopped",
                  "reason": "PyTorchJobStopped",
                  "status": "True",
                  "type": "Stopped"
                },
                {
                  "lastTransitionTime": "2024-07-18T02:54:25Z",
                  "lastUpdateTime": "2024-07-18T02:54:25Z",
                  "message": "PyTorchJob llamatest0718forxiaomi6 is failed because 1 Worker replica(s) failed.",
                  "reason": "JobFailed",
                  "status": "True",
                  "type": "Failed"
                }
              ],
              "lastReconcileTime": "2024-07-18T02:48:18Z",
              "replicaStatuses": {
                "Master": {
                  "active": 1,
                  "selector": "training.kubeflow.org/job-name=llamatest0718forxiaomi6,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=master"
                },
                "Worker": {
                  "active": 2,
                  "failed": 1,
                  "selector": "training.kubeflow.org/job-name=llamatest0718forxiaomi6,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=worker"
                }
              },
              "startTime": "2024-07-18T02:48:19Z"
            }
          },
          {
            "apiVersion": "kubeflow.org/v1",
            "kind": "PyTorchJob",
            "metadata": {
              "annotations": {
                "aijob.cce.baidubce.com/barrier-finish": "09d85585-87d1-4f0a-8e9c-7bb83accb9cb",
                "aijob.cce.baidubce.com/fault-tolerance-enabled": "true",
                "aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": "",
                "aijob.cce.baidubce.com/openapi-jobid": "pytorch-ee8727ec-0af3-4f80-8fa5-ed511ae8e47e",
                "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
                "aijob.cce.baidubce.com/raw-request": "{\"name\":\"llamatest0718forxiaomi7\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"high\",\"oversell\":false,\"faultTolerance\":true,\"command\":\"\\n#! /bin/bash\\n\\nMEGATRON_PATH=${MEGATRON_PATH:-\\\"/workspace/AIAK-Megatron\\\"}\\nAIAK_TRAINING_PATH=${AIAK_TRAINING_PATH:-\\\"/workspace/AIAK-Training-LLM\\\"}\\n\\nDATA_PATH=${DATA_PATH:-\\\"/mnt/cluster/llama2/pile_llama_test/pile-llama_text_document\\\"}\\nTOKENIZER_PATH=${TOKENIZER_PATH:-\\\"/mnt/cluster/llama2/Llama-2-70b-hf/\\\"}\\n\\nCHECKPOINT_PATH=${CHECKPOINT_PATH:-\\\"/mnt/cluster/llama2/mcore_llama2_70b_tp4_pp4\\\"}\\n\\nTENSORBOARD_PATH=${TENSORBOARD_PATH:-\\\"/mnt/cluster/aiak-training-llm/tensorboard-log/llama2-70b-tp4pp4\\\"}\\n\\nGPUS_PER_NODE=8\\n\\n# Change for multinode config\\nMASTER_ADDR=${MASTER_ADDR:-\\\"localhost\\\"}\\nMASTER_PORT=${MASTER_PORT:-\\\"6000\\\"}\\nNNODES=${WORLD_SIZE:-\\\"1\\\"}\\nNODE_RANK=${RANK:-\\\"0\\\"}\\n\\nDISTRIBUTED_ARGS=(\\n    --nproc_per_node $GPUS_PER_NODE\\n    --nnodes $NNODES\\n    --node_rank $NODE_RANK\\n    --master_addr $MASTER_ADDR\\n    --master_port $MASTER_PORT\\n)\\n\\n# you can setup llama2-70b maunally\\n#MODEL_ARGS=(\\n#    --model-name llama2\\n#    --num-layers 80\\n#    --hidden-size 8192\\n#    --ffn-hidden-size 28672\\n#    --num-attention-heads 64\\n#    --position-embedding-type rope\\n#    --normalization RMSNorm\\n#    --swiglu\\n#    --attention-dropout 0\\n#    --hidden-dropout 0\\n#    --disable-bias-linear\\n#    --untie-embeddings-and-output-weights\\n#    --group-query-attention\\n#    --num-query-groups 8\\n#)\\n\\n# or you can setup llama2-70b by using the following command\\nMODEL_ARGS=(\\n    --model-name llama2-70b # options: llama2-7b, llama2-13b, llama2-70b\\n)\\n\\nDATA_ARGS=(\\n    --tokenizer-type HFTokenizer\\n    --hf-tokenizer-path $TOKENIZER_PATH\\n    --data-path $DATA_PATH\\n    --split 949,50,1\\n)\\n\\nTRAINING_ARGS=(\\n    --training-phase pretrain # options: pretrain, sft\\n    --seq-length 4096\\n    --max-position-embeddings 4096\\n    --init-method-std 0.01\\n    --micro-batch-size 1\\n    --global-batch-size 128\\n    --lr 0.0002\\n    --min-lr 1.0e-5\\n    --clip-grad 1.0\\n    --weight-decay 0.01\\n    --optimizer adam\\n    --adam-beta1 0.9\\n    --adam-beta2 0.95\\n    --adam-eps 1e-05\\n    --norm-epsilon 1e-6\\n    --train-iters 500000\\n    --lr-decay-iters 500000\\n    --lr-decay-style cosine\\n    --lr-warmup-fraction 0.002\\n    --initial-loss-scale 65536\\n    --fp16\\n    --save-interval 5000\\n    --eval-interval 1000\\n    --eval-iters 10\\n    #--ckpt-step 0\\n    #--no-load-optim\\n    #--no-load-rng\\n)\\n\\nMODEL_PARALLEL_ARGS=(\\n    --tensor-model-parallel-size 4\\n    --pipeline-model-parallel-size 4\\n    --use-distributed-optimizer\\n    --overlap-grad-reduce\\n    --overlap-param-gather\\n    --distributed-backend nccl\\n    --sequence-parallel\\n    #--tp-comm-overlap # require mpi envrionment\\n)\\n\\nLOGGING_ARGS=(\\n    --log-interval 1\\n    --tensorboard-dir ${TENSORBOARD_PATH}\\n    --log-timers-to-tensorboard\\n)\\n\\nif [ -n \\\"${WANDB_API_KEY}\\\" ]; then\\n    LOGGING_ARGS+=(\\n        --wandb-project ${WANDB_PROJECT}\\n        --wandb-exp-name ${WANDB_NAME} \\n    )\\nfi\\n\\nPYTHONPATH=$MEGATRON_PATH:$AIAK_TRAINING_PATH:$PYTHONPATH     torchrun ${DISTRIBUTED_ARGS[@]}     $AIAK_TRAINING_PATH/aiak_training_llm/train.py     ${MODEL_ARGS[@]}     ${DATA_ARGS[@]}     ${TRAINING_ARGS[@]}     ${MODEL_PARALLEL_ARGS[@]}     ${LOGGING_ARGS[@]}\\n\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":true,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi7\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi7/output/training_logs\",\"CUDA_DEVICE_MAX_CONNECTIONS\":\"1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"},\"Worker\":{\"replicas\":3,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi7\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi7/output/training_logs\",\"CUDA_DEVICE_MAX_CONNECTIONS\":\"1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":true,\"logPath\":\"/mnt/cluster/llamatest0718forxiaomi7/output/training_logs\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":true,\"isCopyJob\":true,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
                "aijob.cce.baidubce.com/timeline": "[{\"conditionType\":\"Created\",\"time\":1721271251},{\"conditionType\":\"Scheduled\",\"time\":1721271252},{\"conditionType\":\"Running\",\"time\":1721271264},{\"conditionType\":\"ManualTermination\",\"time\":1721271770}]",
                "job-manager/action": "stop",
                "job-manager/action-succeed": "stop",
                "scheduling.k8s.io/job-enable-oversell": "false",
                "tensorboard-gc": "true"
              },
              "creationTimestamp": "2024-07-18T02:54:11Z",
              "generation": 2,
              "labels": {
                "aijob.cce.baidubce.com/ai-user-id": "b5a24aa26e4d4f55bc3acf68edc4b051",
                "aijob.cce.baidubce.com/ai-user-name": "zhangmuhua",
                "aijob.cce.baidubce.com/create-from-aihcp": "true",
                "aijob.cce.baidubce.com/openapi-jobid": "pytorch-ee8727ec-0af3-4f80-8fa5-ed511ae8e47e"
              },
              "managedFields": [
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        "f:aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": {},
                        "f:aijob.cce.baidubce.com/timeline": {}
                      }
                    },
                    "f:spec": {
                      "f:pytorchReplicaSpecs": {
                        "f:Master": {
                          "f:template": {
                            "f:spec": {
                              "f:containers": {}
                            }
                          }
                        },
                        "f:Worker": {
                          "f:template": {
                            "f:spec": {
                              "f:containers": {}
                            }
                          }
                        }
                      },
                      "f:runPolicy": {
                        "f:cleanPodPolicy": {}
                      }
                    }
                  },
                  "manager": "controller",
                  "operation": "Update",
                  "time": "2024-07-18T02:54:11Z"
                },
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        "f:aijob.cce.baidubce.com/barrier-finish": {}
                      }
                    }
                  },
                  "manager": "jobbarrier",
                  "operation": "Update",
                  "time": "2024-07-18T02:54:20Z"
                },
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        ".": {},
                        "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                        "f:aijob.cce.baidubce.com/openapi-jobid": {},
                        "f:aijob.cce.baidubce.com/pfs-id": {},
                        "f:aijob.cce.baidubce.com/raw-request": {},
                        "f:job-manager/action": {},
                        "f:scheduling.k8s.io/job-enable-oversell": {}
                      },
                      "f:labels": {
                        ".": {},
                        "f:aijob.cce.baidubce.com/ai-user-id": {},
                        "f:aijob.cce.baidubce.com/ai-user-name": {},
                        "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                        "f:aijob.cce.baidubce.com/openapi-jobid": {}
                      }
                    },
                    "f:spec": {
                      ".": {},
                      "f:pytorchReplicaSpecs": {
                        ".": {},
                        "f:Master": {
                          ".": {},
                          "f:replicas": {},
                          "f:restartPolicy": {},
                          "f:template": {
                            ".": {},
                            "f:metadata": {
                              ".": {},
                              "f:annotations": {
                                ".": {},
                                "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                                "f:aijob.cce.baidubce.com/openapi-jobid": {},
                                "f:aijob.cce.baidubce.com/pfs-id": {},
                                "f:aijob.cce.baidubce.com/raw-request": {},
                                "f:scheduling.k8s.io/job-enable-oversell": {}
                              },
                              "f:labels": {
                                ".": {},
                                "f:aijob.cce.baidubce.com/ai-user-id": {},
                                "f:aijob.cce.baidubce.com/ai-user-name": {},
                                "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                                "f:aijob.cce.baidubce.com/openapi-jobid": {}
                              }
                            },
                            "f:spec": {
                              ".": {},
                              "f:dnsPolicy": {},
                              "f:hostNetwork": {},
                              "f:schedulerName": {},
                              "f:volumes": {}
                            }
                          }
                        },
                        "f:Worker": {
                          ".": {},
                          "f:replicas": {},
                          "f:restartPolicy": {},
                          "f:template": {
                            ".": {},
                            "f:metadata": {
                              ".": {},
                              "f:annotations": {
                                ".": {},
                                "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                                "f:aijob.cce.baidubce.com/openapi-jobid": {},
                                "f:aijob.cce.baidubce.com/pfs-id": {},
                                "f:aijob.cce.baidubce.com/raw-request": {},
                                "f:scheduling.k8s.io/job-enable-oversell": {}
                              },
                              "f:labels": {
                                ".": {},
                                "f:aijob.cce.baidubce.com/ai-user-id": {},
                                "f:aijob.cce.baidubce.com/ai-user-name": {},
                                "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                                "f:aijob.cce.baidubce.com/openapi-jobid": {}
                              }
                            },
                            "f:spec": {
                              ".": {},
                              "f:dnsPolicy": {},
                              "f:hostNetwork": {},
                              "f:schedulerName": {},
                              "f:volumes": {}
                            }
                          }
                        }
                      },
                      "f:runPolicy": {
                        ".": {},
                        "f:schedulingPolicy": {
                          ".": {},
                          "f:priorityClass": {},
                          "f:queue": {}
                        }
                      }
                    }
                  },
                  "manager": "cce-ai-service",
                  "operation": "Update",
                  "time": "2024-07-18T03:02:50Z"
                },
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        "f:job-manager/action-succeed": {}
                      }
                    }
                  },
                  "manager": "ftagent",
                  "operation": "Update",
                  "time": "2024-07-18T03:02:55Z"
                },
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        "f:tensorboard-gc": {}
                      }
                    },
                    "f:status": {
                      ".": {},
                      "f:completionTime": {},
                      "f:conditions": {},
                      "f:lastReconcileTime": {},
                      "f:replicaStatuses": {
                        ".": {},
                        "f:Master": {
                          ".": {},
                          "f:failed": {}
                        },
                        "f:Worker": {
                          ".": {},
                          "f:active": {}
                        }
                      },
                      "f:startTime": {}
                    }
                  },
                  "manager": "manager",
                  "operation": "Update",
                  "time": "2024-07-19T02:54:56Z"
                }
              ],
              "name": "llamatest0718forxiaomi7",
              "namespace": "default",
              "resourceVersion": "2372416037",
              "uid": "23b6eaf3-423c-48de-800e-3fe709057ba3"
            },
            "spec": {
              "pytorchReplicaSpecs": {
                "Master": {
                  "replicas": 1,
                  "restartPolicy": "Never",
                  "template": {
                    "metadata": {
                      "annotations": {
                        "aijob.cce.baidubce.com/fault-tolerance-enabled": "true",
                        "aijob.cce.baidubce.com/openapi-jobid": "pytorch-ee8727ec-0af3-4f80-8fa5-ed511ae8e47e",
                        "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
                        "aijob.cce.baidubce.com/raw-request": "{\"name\":\"llamatest0718forxiaomi7\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"high\",\"oversell\":false,\"faultTolerance\":true,\"command\":\"\\n#! /bin/bash\\n\\nMEGATRON_PATH=${MEGATRON_PATH:-\\\"/workspace/AIAK-Megatron\\\"}\\nAIAK_TRAINING_PATH=${AIAK_TRAINING_PATH:-\\\"/workspace/AIAK-Training-LLM\\\"}\\n\\nDATA_PATH=${DATA_PATH:-\\\"/mnt/cluster/llama2/pile_llama_test/pile-llama_text_document\\\"}\\nTOKENIZER_PATH=${TOKENIZER_PATH:-\\\"/mnt/cluster/llama2/Llama-2-70b-hf/\\\"}\\n\\nCHECKPOINT_PATH=${CHECKPOINT_PATH:-\\\"/mnt/cluster/llama2/mcore_llama2_70b_tp4_pp4\\\"}\\n\\nTENSORBOARD_PATH=${TENSORBOARD_PATH:-\\\"/mnt/cluster/aiak-training-llm/tensorboard-log/llama2-70b-tp4pp4\\\"}\\n\\nGPUS_PER_NODE=8\\n\\n# Change for multinode config\\nMASTER_ADDR=${MASTER_ADDR:-\\\"localhost\\\"}\\nMASTER_PORT=${MASTER_PORT:-\\\"6000\\\"}\\nNNODES=${WORLD_SIZE:-\\\"1\\\"}\\nNODE_RANK=${RANK:-\\\"0\\\"}\\n\\nDISTRIBUTED_ARGS=(\\n    --nproc_per_node $GPUS_PER_NODE\\n    --nnodes $NNODES\\n    --node_rank $NODE_RANK\\n    --master_addr $MASTER_ADDR\\n    --master_port $MASTER_PORT\\n)\\n\\n# you can setup llama2-70b maunally\\n#MODEL_ARGS=(\\n#    --model-name llama2\\n#    --num-layers 80\\n#    --hidden-size 8192\\n#    --ffn-hidden-size 28672\\n#    --num-attention-heads 64\\n#    --position-embedding-type rope\\n#    --normalization RMSNorm\\n#    --swiglu\\n#    --attention-dropout 0\\n#    --hidden-dropout 0\\n#    --disable-bias-linear\\n#    --untie-embeddings-and-output-weights\\n#    --group-query-attention\\n#    --num-query-groups 8\\n#)\\n\\n# or you can setup llama2-70b by using the following command\\nMODEL_ARGS=(\\n    --model-name llama2-70b # options: llama2-7b, llama2-13b, llama2-70b\\n)\\n\\nDATA_ARGS=(\\n    --tokenizer-type HFTokenizer\\n    --hf-tokenizer-path $TOKENIZER_PATH\\n    --data-path $DATA_PATH\\n    --split 949,50,1\\n)\\n\\nTRAINING_ARGS=(\\n    --training-phase pretrain # options: pretrain, sft\\n    --seq-length 4096\\n    --max-position-embeddings 4096\\n    --init-method-std 0.01\\n    --micro-batch-size 1\\n    --global-batch-size 128\\n    --lr 0.0002\\n    --min-lr 1.0e-5\\n    --clip-grad 1.0\\n    --weight-decay 0.01\\n    --optimizer adam\\n    --adam-beta1 0.9\\n    --adam-beta2 0.95\\n    --adam-eps 1e-05\\n    --norm-epsilon 1e-6\\n    --train-iters 500000\\n    --lr-decay-iters 500000\\n    --lr-decay-style cosine\\n    --lr-warmup-fraction 0.002\\n    --initial-loss-scale 65536\\n    --fp16\\n    --save-interval 5000\\n    --eval-interval 1000\\n    --eval-iters 10\\n    #--ckpt-step 0\\n    #--no-load-optim\\n    #--no-load-rng\\n)\\n\\nMODEL_PARALLEL_ARGS=(\\n    --tensor-model-parallel-size 4\\n    --pipeline-model-parallel-size 4\\n    --use-distributed-optimizer\\n    --overlap-grad-reduce\\n    --overlap-param-gather\\n    --distributed-backend nccl\\n    --sequence-parallel\\n    #--tp-comm-overlap # require mpi envrionment\\n)\\n\\nLOGGING_ARGS=(\\n    --log-interval 1\\n    --tensorboard-dir ${TENSORBOARD_PATH}\\n    --log-timers-to-tensorboard\\n)\\n\\nif [ -n \\\"${WANDB_API_KEY}\\\" ]; then\\n    LOGGING_ARGS+=(\\n        --wandb-project ${WANDB_PROJECT}\\n        --wandb-exp-name ${WANDB_NAME} \\n    )\\nfi\\n\\nPYTHONPATH=$MEGATRON_PATH:$AIAK_TRAINING_PATH:$PYTHONPATH     torchrun ${DISTRIBUTED_ARGS[@]}     $AIAK_TRAINING_PATH/aiak_training_llm/train.py     ${MODEL_ARGS[@]}     ${DATA_ARGS[@]}     ${TRAINING_ARGS[@]}     ${MODEL_PARALLEL_ARGS[@]}     ${LOGGING_ARGS[@]}\\n\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":true,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi7\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi7/output/training_logs\",\"CUDA_DEVICE_MAX_CONNECTIONS\":\"1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"},\"Worker\":{\"replicas\":3,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi7\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi7/output/training_logs\",\"CUDA_DEVICE_MAX_CONNECTIONS\":\"1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":true,\"logPath\":\"/mnt/cluster/llamatest0718forxiaomi7/output/training_logs\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":true,\"isCopyJob\":true,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
                        "scheduling.k8s.io/job-enable-oversell": "false"
                      },
                      "labels": {
                        "aijob.cce.baidubce.com/ai-user-id": "b5a24aa26e4d4f55bc3acf68edc4b051",
                        "aijob.cce.baidubce.com/ai-user-name": "zhangmuhua",
                        "aijob.cce.baidubce.com/create-from-aihcp": "true",
                        "aijob.cce.baidubce.com/openapi-jobid": "pytorch-ee8727ec-0af3-4f80-8fa5-ed511ae8e47e"
                      }
                    },
                    "spec": {
                      "containers": [
                        {
                          "command": [
                            "/bin/bash",
                            "-c",
                            "\n#! /bin/bash\n\nMEGATRON_PATH=${MEGATRON_PATH:-\"/workspace/AIAK-Megatron\"}\nAIAK_TRAINING_PATH=${AIAK_TRAINING_PATH:-\"/workspace/AIAK-Training-LLM\"}\n\nDATA_PATH=${DATA_PATH:-\"/mnt/cluster/llama2/pile_llama_test/pile-llama_text_document\"}\nTOKENIZER_PATH=${TOKENIZER_PATH:-\"/mnt/cluster/llama2/Llama-2-70b-hf/\"}\n\nCHECKPOINT_PATH=${CHECKPOINT_PATH:-\"/mnt/cluster/llama2/mcore_llama2_70b_tp4_pp4\"}\n\nTENSORBOARD_PATH=${TENSORBOARD_PATH:-\"/mnt/cluster/aiak-training-llm/tensorboard-log/llama2-70b-tp4pp4\"}\n\nGPUS_PER_NODE=8\n\n# Change for multinode config\nMASTER_ADDR=${MASTER_ADDR:-\"localhost\"}\nMASTER_PORT=${MASTER_PORT:-\"6000\"}\nNNODES=${WORLD_SIZE:-\"1\"}\nNODE_RANK=${RANK:-\"0\"}\n\nDISTRIBUTED_ARGS=(\n    --nproc_per_node $GPUS_PER_NODE\n    --nnodes $NNODES\n    --node_rank $NODE_RANK\n    --master_addr $MASTER_ADDR\n    --master_port $MASTER_PORT\n)\n\n# you can setup llama2-70b maunally\n#MODEL_ARGS=(\n#    --model-name llama2\n#    --num-layers 80\n#    --hidden-size 8192\n#    --ffn-hidden-size 28672\n#    --num-attention-heads 64\n#    --position-embedding-type rope\n#    --normalization RMSNorm\n#    --swiglu\n#    --attention-dropout 0\n#    --hidden-dropout 0\n#    --disable-bias-linear\n#    --untie-embeddings-and-output-weights\n#    --group-query-attention\n#    --num-query-groups 8\n#)\n\n# or you can setup llama2-70b by using the following command\nMODEL_ARGS=(\n    --model-name llama2-70b # options: llama2-7b, llama2-13b, llama2-70b\n)\n\nDATA_ARGS=(\n    --tokenizer-type HFTokenizer\n    --hf-tokenizer-path $TOKENIZER_PATH\n    --data-path $DATA_PATH\n    --split 949,50,1\n)\n\nTRAINING_ARGS=(\n    --training-phase pretrain # options: pretrain, sft\n    --seq-length 4096\n    --max-position-embeddings 4096\n    --init-method-std 0.01\n    --micro-batch-size 1\n    --global-batch-size 128\n    --lr 0.0002\n    --min-lr 1.0e-5\n    --clip-grad 1.0\n    --weight-decay 0.01\n    --optimizer adam\n    --adam-beta1 0.9\n    --adam-beta2 0.95\n    --adam-eps 1e-05\n    --norm-epsilon 1e-6\n    --train-iters 500000\n    --lr-decay-iters 500000\n    --lr-decay-style cosine\n    --lr-warmup-fraction 0.002\n    --initial-loss-scale 65536\n    --fp16\n    --save-interval 5000\n    --eval-interval 1000\n    --eval-iters 10\n    #--ckpt-step 0\n    #--no-load-optim\n    #--no-load-rng\n)\n\nMODEL_PARALLEL_ARGS=(\n    --tensor-model-parallel-size 4\n    --pipeline-model-parallel-size 4\n    --use-distributed-optimizer\n    --overlap-grad-reduce\n    --overlap-param-gather\n    --distributed-backend nccl\n    --sequence-parallel\n    #--tp-comm-overlap # require mpi envrionment\n)\n\nLOGGING_ARGS=(\n    --log-interval 1\n    --tensorboard-dir ${TENSORBOARD_PATH}\n    --log-timers-to-tensorboard\n)\n\nif [ -n \"${WANDB_API_KEY}\" ]; then\n    LOGGING_ARGS+=(\n        --wandb-project ${WANDB_PROJECT}\n        --wandb-exp-name ${WANDB_NAME} \n    )\nfi\n\nPYTHONPATH=$MEGATRON_PATH:$AIAK_TRAINING_PATH:$PYTHONPATH     torchrun ${DISTRIBUTED_ARGS[@]}     $AIAK_TRAINING_PATH/aiak_training_llm/train.py     ${MODEL_ARGS[@]}     ${DATA_ARGS[@]}     ${TRAINING_ARGS[@]}     ${MODEL_PARALLEL_ARGS[@]}     ${LOGGING_ARGS[@]}\n"
                          ],
                          "env": [
                            {
                              "name": "CUDA_DEVICE_MAX_CONNECTIONS",
                              "value": "1"
                            },
                            {
                              "name": "AIHC_TENSORBOARD_LOG_PATH",
                              "value": "/mnt/cluster/llamatest0718forxiaomi7/output/training_logs"
                            },
                            {
                              "name": "AIHC_JOB_NAME",
                              "value": "llamatest0718forxiaomi7"
                            },
                            {
                              "name": "NCCL_IB_DISABLE",
                              "value": "0"
                            }
                          ],
                          "image": "registry.baidubce.com/aihc-aiak/aiak-training-llm:ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release",
                          "imagePullPolicy": "Always",
                          "name": "pytorch",
                          "ports": [
                            {
                              "containerPort": 23456,
                              "name": "pytorchjob-port",
                              "protocol": "TCP"
                            }
                          ],
                          "resources": {
                            "limits": {
                              "baidu.com/a800_80g_cgpu": "8",
                              "rdma/hca": "1"
                            },
                            "requests": {
                              "baidu.com/a800_80g_cgpu": "8",
                              "rdma/hca": "1"
                            }
                          },
                          "securityContext": {
                            "capabilities": {
                              "add": [
                                "IPC_LOCK"
                              ]
                            }
                          },
                          "volumeMounts": [
                            {
                              "mountPath": "/dev/shm",
                              "name": "devshm"
                            },
                            {
                              "mountPath": "/mnt/cluster",
                              "name": "pvc-pfs"
                            }
                          ]
                        }
                      ],
                      "dnsPolicy": "ClusterFirstWithHostNet",
                      "hostNetwork": true,
                      "schedulerName": "volcano",
                      "volumes": [
                        {
                          "emptyDir": {
                            "medium": "Memory",
                            "sizeLimit": "10Gi"
                          },
                          "name": "devshm"
                        },
                        {
                          "name": "pvc-pfs",
                          "persistentVolumeClaim": {
                            "claimName": "pvc-pfs"
                          }
                        }
                      ]
                    }
                  }
                },
                "Worker": {
                  "replicas": 3,
                  "restartPolicy": "Never",
                  "template": {
                    "metadata": {
                      "annotations": {
                        "aijob.cce.baidubce.com/fault-tolerance-enabled": "true",
                        "aijob.cce.baidubce.com/openapi-jobid": "pytorch-ee8727ec-0af3-4f80-8fa5-ed511ae8e47e",
                        "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
                        "aijob.cce.baidubce.com/raw-request": "{\"name\":\"llamatest0718forxiaomi7\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"high\",\"oversell\":false,\"faultTolerance\":true,\"command\":\"\\n#! /bin/bash\\n\\nMEGATRON_PATH=${MEGATRON_PATH:-\\\"/workspace/AIAK-Megatron\\\"}\\nAIAK_TRAINING_PATH=${AIAK_TRAINING_PATH:-\\\"/workspace/AIAK-Training-LLM\\\"}\\n\\nDATA_PATH=${DATA_PATH:-\\\"/mnt/cluster/llama2/pile_llama_test/pile-llama_text_document\\\"}\\nTOKENIZER_PATH=${TOKENIZER_PATH:-\\\"/mnt/cluster/llama2/Llama-2-70b-hf/\\\"}\\n\\nCHECKPOINT_PATH=${CHECKPOINT_PATH:-\\\"/mnt/cluster/llama2/mcore_llama2_70b_tp4_pp4\\\"}\\n\\nTENSORBOARD_PATH=${TENSORBOARD_PATH:-\\\"/mnt/cluster/aiak-training-llm/tensorboard-log/llama2-70b-tp4pp4\\\"}\\n\\nGPUS_PER_NODE=8\\n\\n# Change for multinode config\\nMASTER_ADDR=${MASTER_ADDR:-\\\"localhost\\\"}\\nMASTER_PORT=${MASTER_PORT:-\\\"6000\\\"}\\nNNODES=${WORLD_SIZE:-\\\"1\\\"}\\nNODE_RANK=${RANK:-\\\"0\\\"}\\n\\nDISTRIBUTED_ARGS=(\\n    --nproc_per_node $GPUS_PER_NODE\\n    --nnodes $NNODES\\n    --node_rank $NODE_RANK\\n    --master_addr $MASTER_ADDR\\n    --master_port $MASTER_PORT\\n)\\n\\n# you can setup llama2-70b maunally\\n#MODEL_ARGS=(\\n#    --model-name llama2\\n#    --num-layers 80\\n#    --hidden-size 8192\\n#    --ffn-hidden-size 28672\\n#    --num-attention-heads 64\\n#    --position-embedding-type rope\\n#    --normalization RMSNorm\\n#    --swiglu\\n#    --attention-dropout 0\\n#    --hidden-dropout 0\\n#    --disable-bias-linear\\n#    --untie-embeddings-and-output-weights\\n#    --group-query-attention\\n#    --num-query-groups 8\\n#)\\n\\n# or you can setup llama2-70b by using the following command\\nMODEL_ARGS=(\\n    --model-name llama2-70b # options: llama2-7b, llama2-13b, llama2-70b\\n)\\n\\nDATA_ARGS=(\\n    --tokenizer-type HFTokenizer\\n    --hf-tokenizer-path $TOKENIZER_PATH\\n    --data-path $DATA_PATH\\n    --split 949,50,1\\n)\\n\\nTRAINING_ARGS=(\\n    --training-phase pretrain # options: pretrain, sft\\n    --seq-length 4096\\n    --max-position-embeddings 4096\\n    --init-method-std 0.01\\n    --micro-batch-size 1\\n    --global-batch-size 128\\n    --lr 0.0002\\n    --min-lr 1.0e-5\\n    --clip-grad 1.0\\n    --weight-decay 0.01\\n    --optimizer adam\\n    --adam-beta1 0.9\\n    --adam-beta2 0.95\\n    --adam-eps 1e-05\\n    --norm-epsilon 1e-6\\n    --train-iters 500000\\n    --lr-decay-iters 500000\\n    --lr-decay-style cosine\\n    --lr-warmup-fraction 0.002\\n    --initial-loss-scale 65536\\n    --fp16\\n    --save-interval 5000\\n    --eval-interval 1000\\n    --eval-iters 10\\n    #--ckpt-step 0\\n    #--no-load-optim\\n    #--no-load-rng\\n)\\n\\nMODEL_PARALLEL_ARGS=(\\n    --tensor-model-parallel-size 4\\n    --pipeline-model-parallel-size 4\\n    --use-distributed-optimizer\\n    --overlap-grad-reduce\\n    --overlap-param-gather\\n    --distributed-backend nccl\\n    --sequence-parallel\\n    #--tp-comm-overlap # require mpi envrionment\\n)\\n\\nLOGGING_ARGS=(\\n    --log-interval 1\\n    --tensorboard-dir ${TENSORBOARD_PATH}\\n    --log-timers-to-tensorboard\\n)\\n\\nif [ -n \\\"${WANDB_API_KEY}\\\" ]; then\\n    LOGGING_ARGS+=(\\n        --wandb-project ${WANDB_PROJECT}\\n        --wandb-exp-name ${WANDB_NAME} \\n    )\\nfi\\n\\nPYTHONPATH=$MEGATRON_PATH:$AIAK_TRAINING_PATH:$PYTHONPATH     torchrun ${DISTRIBUTED_ARGS[@]}     $AIAK_TRAINING_PATH/aiak_training_llm/train.py     ${MODEL_ARGS[@]}     ${DATA_ARGS[@]}     ${TRAINING_ARGS[@]}     ${MODEL_PARALLEL_ARGS[@]}     ${LOGGING_ARGS[@]}\\n\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":true,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi7\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi7/output/training_logs\",\"CUDA_DEVICE_MAX_CONNECTIONS\":\"1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"},\"Worker\":{\"replicas\":3,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi7\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi7/output/training_logs\",\"CUDA_DEVICE_MAX_CONNECTIONS\":\"1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":true,\"logPath\":\"/mnt/cluster/llamatest0718forxiaomi7/output/training_logs\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":true,\"isCopyJob\":true,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
                        "scheduling.k8s.io/job-enable-oversell": "false"
                      },
                      "labels": {
                        "aijob.cce.baidubce.com/ai-user-id": "b5a24aa26e4d4f55bc3acf68edc4b051",
                        "aijob.cce.baidubce.com/ai-user-name": "zhangmuhua",
                        "aijob.cce.baidubce.com/create-from-aihcp": "true",
                        "aijob.cce.baidubce.com/openapi-jobid": "pytorch-ee8727ec-0af3-4f80-8fa5-ed511ae8e47e"
                      }
                    },
                    "spec": {
                      "containers": [
                        {
                          "command": [
                            "/bin/bash",
                            "-c",
                            "\n#! /bin/bash\n\nMEGATRON_PATH=${MEGATRON_PATH:-\"/workspace/AIAK-Megatron\"}\nAIAK_TRAINING_PATH=${AIAK_TRAINING_PATH:-\"/workspace/AIAK-Training-LLM\"}\n\nDATA_PATH=${DATA_PATH:-\"/mnt/cluster/llama2/pile_llama_test/pile-llama_text_document\"}\nTOKENIZER_PATH=${TOKENIZER_PATH:-\"/mnt/cluster/llama2/Llama-2-70b-hf/\"}\n\nCHECKPOINT_PATH=${CHECKPOINT_PATH:-\"/mnt/cluster/llama2/mcore_llama2_70b_tp4_pp4\"}\n\nTENSORBOARD_PATH=${TENSORBOARD_PATH:-\"/mnt/cluster/aiak-training-llm/tensorboard-log/llama2-70b-tp4pp4\"}\n\nGPUS_PER_NODE=8\n\n# Change for multinode config\nMASTER_ADDR=${MASTER_ADDR:-\"localhost\"}\nMASTER_PORT=${MASTER_PORT:-\"6000\"}\nNNODES=${WORLD_SIZE:-\"1\"}\nNODE_RANK=${RANK:-\"0\"}\n\nDISTRIBUTED_ARGS=(\n    --nproc_per_node $GPUS_PER_NODE\n    --nnodes $NNODES\n    --node_rank $NODE_RANK\n    --master_addr $MASTER_ADDR\n    --master_port $MASTER_PORT\n)\n\n# you can setup llama2-70b maunally\n#MODEL_ARGS=(\n#    --model-name llama2\n#    --num-layers 80\n#    --hidden-size 8192\n#    --ffn-hidden-size 28672\n#    --num-attention-heads 64\n#    --position-embedding-type rope\n#    --normalization RMSNorm\n#    --swiglu\n#    --attention-dropout 0\n#    --hidden-dropout 0\n#    --disable-bias-linear\n#    --untie-embeddings-and-output-weights\n#    --group-query-attention\n#    --num-query-groups 8\n#)\n\n# or you can setup llama2-70b by using the following command\nMODEL_ARGS=(\n    --model-name llama2-70b # options: llama2-7b, llama2-13b, llama2-70b\n)\n\nDATA_ARGS=(\n    --tokenizer-type HFTokenizer\n    --hf-tokenizer-path $TOKENIZER_PATH\n    --data-path $DATA_PATH\n    --split 949,50,1\n)\n\nTRAINING_ARGS=(\n    --training-phase pretrain # options: pretrain, sft\n    --seq-length 4096\n    --max-position-embeddings 4096\n    --init-method-std 0.01\n    --micro-batch-size 1\n    --global-batch-size 128\n    --lr 0.0002\n    --min-lr 1.0e-5\n    --clip-grad 1.0\n    --weight-decay 0.01\n    --optimizer adam\n    --adam-beta1 0.9\n    --adam-beta2 0.95\n    --adam-eps 1e-05\n    --norm-epsilon 1e-6\n    --train-iters 500000\n    --lr-decay-iters 500000\n    --lr-decay-style cosine\n    --lr-warmup-fraction 0.002\n    --initial-loss-scale 65536\n    --fp16\n    --save-interval 5000\n    --eval-interval 1000\n    --eval-iters 10\n    #--ckpt-step 0\n    #--no-load-optim\n    #--no-load-rng\n)\n\nMODEL_PARALLEL_ARGS=(\n    --tensor-model-parallel-size 4\n    --pipeline-model-parallel-size 4\n    --use-distributed-optimizer\n    --overlap-grad-reduce\n    --overlap-param-gather\n    --distributed-backend nccl\n    --sequence-parallel\n    #--tp-comm-overlap # require mpi envrionment\n)\n\nLOGGING_ARGS=(\n    --log-interval 1\n    --tensorboard-dir ${TENSORBOARD_PATH}\n    --log-timers-to-tensorboard\n)\n\nif [ -n \"${WANDB_API_KEY}\" ]; then\n    LOGGING_ARGS+=(\n        --wandb-project ${WANDB_PROJECT}\n        --wandb-exp-name ${WANDB_NAME} \n    )\nfi\n\nPYTHONPATH=$MEGATRON_PATH:$AIAK_TRAINING_PATH:$PYTHONPATH     torchrun ${DISTRIBUTED_ARGS[@]}     $AIAK_TRAINING_PATH/aiak_training_llm/train.py     ${MODEL_ARGS[@]}     ${DATA_ARGS[@]}     ${TRAINING_ARGS[@]}     ${MODEL_PARALLEL_ARGS[@]}     ${LOGGING_ARGS[@]}\n"
                          ],
                          "env": [
                            {
                              "name": "CUDA_DEVICE_MAX_CONNECTIONS",
                              "value": "1"
                            },
                            {
                              "name": "AIHC_TENSORBOARD_LOG_PATH",
                              "value": "/mnt/cluster/llamatest0718forxiaomi7/output/training_logs"
                            },
                            {
                              "name": "AIHC_JOB_NAME",
                              "value": "llamatest0718forxiaomi7"
                            },
                            {
                              "name": "NCCL_IB_DISABLE",
                              "value": "0"
                            }
                          ],
                          "image": "registry.baidubce.com/aihc-aiak/aiak-training-llm:ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release",
                          "imagePullPolicy": "Always",
                          "name": "pytorch",
                          "ports": [
                            {
                              "containerPort": 23456,
                              "name": "pytorchjob-port",
                              "protocol": "TCP"
                            }
                          ],
                          "resources": {
                            "limits": {
                              "baidu.com/a800_80g_cgpu": "8",
                              "rdma/hca": "1"
                            },
                            "requests": {
                              "baidu.com/a800_80g_cgpu": "8",
                              "rdma/hca": "1"
                            }
                          },
                          "securityContext": {
                            "capabilities": {
                              "add": [
                                "IPC_LOCK"
                              ]
                            }
                          },
                          "volumeMounts": [
                            {
                              "mountPath": "/dev/shm",
                              "name": "devshm"
                            },
                            {
                              "mountPath": "/mnt/cluster",
                              "name": "pvc-pfs"
                            }
                          ]
                        }
                      ],
                      "dnsPolicy": "ClusterFirstWithHostNet",
                      "hostNetwork": true,
                      "schedulerName": "volcano",
                      "volumes": [
                        {
                          "emptyDir": {
                            "medium": "Memory",
                            "sizeLimit": "10Gi"
                          },
                          "name": "devshm"
                        },
                        {
                          "name": "pvc-pfs",
                          "persistentVolumeClaim": {
                            "claimName": "pvc-pfs"
                          }
                        }
                      ]
                    }
                  }
                }
              },
              "runPolicy": {
                "cleanPodPolicy": "None",
                "schedulingPolicy": {
                  "priorityClass": "high",
                  "queue": "default"
                }
              }
            },
            "status": {
              "completionTime": "2024-07-18T03:02:54Z",
              "conditions": [
                {
                  "lastTransitionTime": "2024-07-18T02:54:11Z",
                  "lastUpdateTime": "2024-07-18T02:54:11Z",
                  "message": "PyTorchJob llamatest0718forxiaomi7 is created.",
                  "reason": "PyTorchJobCreated",
                  "status": "True",
                  "type": "Created"
                },
                {
                  "lastTransitionTime": "2024-07-18T02:54:24Z",
                  "lastUpdateTime": "2024-07-18T02:54:24Z",
                  "message": "PyTorchJob llamatest0718forxiaomi7 is running.",
                  "reason": "JobRunning",
                  "status": "False",
                  "type": "Running"
                },
                {
                  "lastTransitionTime": "2024-07-18T03:02:50Z",
                  "lastUpdateTime": "2024-07-18T03:02:50Z",
                  "message": "PytorchJob default/llamatest0718forxiaomi7 is stopped",
                  "reason": "PyTorchJobStopped",
                  "status": "True",
                  "type": "Stopped"
                },
                {
                  "lastTransitionTime": "2024-07-18T03:02:54Z",
                  "lastUpdateTime": "2024-07-18T03:02:54Z",
                  "message": "PyTorchJob llamatest0718forxiaomi7 is failed because 1 Master replica(s) failed.",
                  "reason": "JobFailed",
                  "status": "True",
                  "type": "Failed"
                }
              ],
              "lastReconcileTime": "2024-07-18T02:54:11Z",
              "replicaStatuses": {
                "Master": {
                  "failed": 1,
                  "selector": "training.kubeflow.org/job-name=llamatest0718forxiaomi7,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=master"
                },
                "Worker": {
                  "active": 3,
                  "selector": "training.kubeflow.org/job-name=llamatest0718forxiaomi7,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=worker"
                }
              },
              "startTime": "2024-07-18T02:54:11Z"
            }
          },
          {
            "apiVersion": "kubeflow.org/v1",
            "kind": "PyTorchJob",
            "metadata": {
              "annotations": {
                "aijob.cce.baidubce.com/barrier-finish": "8b92a18c-0c8d-40aa-b27a-6f6129729c34",
                "aijob.cce.baidubce.com/fault-tolerance-enabled": "true",
                "aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": "",
                "aijob.cce.baidubce.com/openapi-jobid": "pytorch-be7cbb30-0a0a-471b-b6ff-e0825477ada6",
                "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
                "aijob.cce.baidubce.com/raw-request": "{\"name\":\"llamatest0718forxiaomi8\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"high\",\"oversell\":false,\"faultTolerance\":true,\"command\":\"\\n#! /bin/bash\\n\\nMEGATRON_PATH=${MEGATRON_PATH:-\\\"/workspace/AIAK-Megatron\\\"}\\nAIAK_TRAINING_PATH=${AIAK_TRAINING_PATH:-\\\"/workspace/AIAK-Training-LLM\\\"}\\n\\nDATA_PATH=${DATA_PATH:-\\\"/mnt/cluster/llama2/pile_llama_test/pile-llama_text_document\\\"}\\nTOKENIZER_PATH=${TOKENIZER_PATH:-\\\"/mnt/cluster/llama2/Llama-2-70b-hf/\\\"}\\n\\nCHECKPOINT_PATH=${CHECKPOINT_PATH:-\\\"/mnt/cluster/llama2/mcore_llama2_70b_tp4_pp4\\\"}\\n\\nTENSORBOARD_PATH=${TENSORBOARD_PATH:-\\\"/mnt/cluster/aiak-training-llm/tensorboard-log/llama2-70b-tp4pp4\\\"}\\n\\nGPUS_PER_NODE=8\\n\\n# Change for multinode config\\nMASTER_ADDR=${MASTER_ADDR:-\\\"localhost\\\"}\\nMASTER_PORT=${MASTER_PORT:-\\\"6000\\\"}\\nNNODES=${WORLD_SIZE:-\\\"1\\\"}\\nNODE_RANK=${RANK:-\\\"0\\\"}\\n\\nDISTRIBUTED_ARGS=(\\n    --nproc_per_node $GPUS_PER_NODE\\n    --nnodes $NNODES\\n    --node_rank $NODE_RANK\\n    --master_addr $MASTER_ADDR\\n    --master_port $MASTER_PORT\\n)\\n\\n# you can setup llama2-70b maunally\\n#MODEL_ARGS=(\\n#    --model-name llama2\\n#    --num-layers 80\\n#    --hidden-size 8192\\n#    --ffn-hidden-size 28672\\n#    --num-attention-heads 64\\n#    --position-embedding-type rope\\n#    --normalization RMSNorm\\n#    --swiglu\\n#    --attention-dropout 0\\n#    --hidden-dropout 0\\n#    --disable-bias-linear\\n#    --untie-embeddings-and-output-weights\\n#    --group-query-attention\\n#    --num-query-groups 8\\n#)\\n\\n# or you can setup llama2-70b by using the following command\\nMODEL_ARGS=(\\n    --model-name llama2-70b # options: llama2-7b, llama2-13b, llama2-70b\\n)\\n\\nDATA_ARGS=(\\n    --tokenizer-type HFTokenizer\\n    --hf-tokenizer-path $TOKENIZER_PATH\\n    --data-path $DATA_PATH\\n    --split 949,50,1\\n)\\n\\nTRAINING_ARGS=(\\n    --training-phase pretrain # options: pretrain, sft\\n    --seq-length 4096\\n    --max-position-embeddings 4096\\n    --init-method-std 0.01\\n    --micro-batch-size 1\\n    --global-batch-size 1024\\n    --lr 0.0002\\n    --min-lr 1.0e-5\\n    --clip-grad 1.0\\n    --weight-decay 0.01\\n    --optimizer adam\\n    --adam-beta1 0.9\\n    --adam-beta2 0.95\\n    --adam-eps 1e-05\\n    --norm-epsilon 1e-6\\n    --train-iters 500000\\n    --lr-decay-iters 500000\\n    --lr-decay-style cosine\\n    --lr-warmup-fraction 0.002\\n    --initial-loss-scale 256\\n    --fp16\\n    --save-interval 5000\\n    --eval-interval 1000\\n    --eval-iters 10\\n    #--ckpt-step 0\\n    #--no-load-optim\\n    #--no-load-rng\\n)\\n\\nMODEL_PARALLEL_ARGS=(\\n    --tensor-model-parallel-size 4\\n    --pipeline-model-parallel-size 4\\n    --use-distributed-optimizer\\n    --overlap-grad-reduce\\n    --overlap-param-gather\\n    --distributed-backend nccl\\n    --sequence-parallel\\n    #--tp-comm-overlap # require mpi envrionment\\n)\\n\\nLOGGING_ARGS=(\\n    --log-interval 1\\n    --tensorboard-dir ${TENSORBOARD_PATH}\\n    --log-timers-to-tensorboard\\n)\\n\\nif [ -n \\\"${WANDB_API_KEY}\\\" ]; then\\n    LOGGING_ARGS+=(\\n        --wandb-project ${WANDB_PROJECT}\\n        --wandb-exp-name ${WANDB_NAME} \\n    )\\nfi\\n\\nPYTHONPATH=$MEGATRON_PATH:$AIAK_TRAINING_PATH:$PYTHONPATH     torchrun ${DISTRIBUTED_ARGS[@]}     $AIAK_TRAINING_PATH/aiak_training_llm/train.py     ${MODEL_ARGS[@]}     ${DATA_ARGS[@]}     ${TRAINING_ARGS[@]}     ${MODEL_PARALLEL_ARGS[@]}     ${LOGGING_ARGS[@]}\\n\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":true,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi8\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi8/output/training_logs\",\"CUDA_DEVICE_MAX_CONNECTIONS\":\"1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"},\"Worker\":{\"replicas\":3,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi8\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi8/output/training_logs\",\"CUDA_DEVICE_MAX_CONNECTIONS\":\"1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":true,\"logPath\":\"/mnt/cluster/llamatest0718forxiaomi8/output/training_logs\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":true,\"isCopyJob\":true,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
                "aijob.cce.baidubce.com/timeline": "[{\"conditionType\":\"Created\",\"time\":1721271762},{\"conditionType\":\"Scheduled\",\"time\":1721271763},{\"conditionType\":\"Running\",\"time\":1721271774},{\"conditionType\":\"ManualTermination\",\"time\":1721291996}]",
                "job-manager/action": "stop",
                "job-manager/action-succeed": "stop",
                "scheduling.k8s.io/job-enable-oversell": "false",
                "tensorboard-gc": "true"
              },
              "creationTimestamp": "2024-07-18T03:02:42Z",
              "generation": 2,
              "labels": {
                "aijob.cce.baidubce.com/ai-user-id": "b5a24aa26e4d4f55bc3acf68edc4b051",
                "aijob.cce.baidubce.com/ai-user-name": "zhangmuhua",
                "aijob.cce.baidubce.com/create-from-aihcp": "true",
                "aijob.cce.baidubce.com/openapi-jobid": "pytorch-be7cbb30-0a0a-471b-b6ff-e0825477ada6"
              },
              "managedFields": [
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        "f:aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": {},
                        "f:aijob.cce.baidubce.com/timeline": {}
                      }
                    },
                    "f:spec": {
                      "f:pytorchReplicaSpecs": {
                        "f:Master": {
                          "f:template": {
                            "f:spec": {
                              "f:containers": {}
                            }
                          }
                        },
                        "f:Worker": {
                          "f:template": {
                            "f:spec": {
                              "f:containers": {}
                            }
                          }
                        }
                      },
                      "f:runPolicy": {
                        "f:cleanPodPolicy": {}
                      }
                    }
                  },
                  "manager": "controller",
                  "operation": "Update",
                  "time": "2024-07-18T03:02:42Z"
                },
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        "f:aijob.cce.baidubce.com/barrier-finish": {}
                      }
                    }
                  },
                  "manager": "jobbarrier",
                  "operation": "Update",
                  "time": "2024-07-18T03:02:51Z"
                },
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        ".": {},
                        "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                        "f:aijob.cce.baidubce.com/openapi-jobid": {},
                        "f:aijob.cce.baidubce.com/pfs-id": {},
                        "f:aijob.cce.baidubce.com/raw-request": {},
                        "f:job-manager/action": {},
                        "f:scheduling.k8s.io/job-enable-oversell": {}
                      },
                      "f:labels": {
                        ".": {},
                        "f:aijob.cce.baidubce.com/ai-user-id": {},
                        "f:aijob.cce.baidubce.com/ai-user-name": {},
                        "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                        "f:aijob.cce.baidubce.com/openapi-jobid": {}
                      }
                    },
                    "f:spec": {
                      ".": {},
                      "f:pytorchReplicaSpecs": {
                        ".": {},
                        "f:Master": {
                          ".": {},
                          "f:replicas": {},
                          "f:restartPolicy": {},
                          "f:template": {
                            ".": {},
                            "f:metadata": {
                              ".": {},
                              "f:annotations": {
                                ".": {},
                                "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                                "f:aijob.cce.baidubce.com/openapi-jobid": {},
                                "f:aijob.cce.baidubce.com/pfs-id": {},
                                "f:aijob.cce.baidubce.com/raw-request": {},
                                "f:scheduling.k8s.io/job-enable-oversell": {}
                              },
                              "f:labels": {
                                ".": {},
                                "f:aijob.cce.baidubce.com/ai-user-id": {},
                                "f:aijob.cce.baidubce.com/ai-user-name": {},
                                "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                                "f:aijob.cce.baidubce.com/openapi-jobid": {}
                              }
                            },
                            "f:spec": {
                              ".": {},
                              "f:dnsPolicy": {},
                              "f:hostNetwork": {},
                              "f:schedulerName": {},
                              "f:volumes": {}
                            }
                          }
                        },
                        "f:Worker": {
                          ".": {},
                          "f:replicas": {},
                          "f:restartPolicy": {},
                          "f:template": {
                            ".": {},
                            "f:metadata": {
                              ".": {},
                              "f:annotations": {
                                ".": {},
                                "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                                "f:aijob.cce.baidubce.com/openapi-jobid": {},
                                "f:aijob.cce.baidubce.com/pfs-id": {},
                                "f:aijob.cce.baidubce.com/raw-request": {},
                                "f:scheduling.k8s.io/job-enable-oversell": {}
                              },
                              "f:labels": {
                                ".": {},
                                "f:aijob.cce.baidubce.com/ai-user-id": {},
                                "f:aijob.cce.baidubce.com/ai-user-name": {},
                                "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                                "f:aijob.cce.baidubce.com/openapi-jobid": {}
                              }
                            },
                            "f:spec": {
                              ".": {},
                              "f:dnsPolicy": {},
                              "f:hostNetwork": {},
                              "f:schedulerName": {},
                              "f:volumes": {}
                            }
                          }
                        }
                      },
                      "f:runPolicy": {
                        ".": {},
                        "f:schedulingPolicy": {
                          ".": {},
                          "f:priorityClass": {},
                          "f:queue": {}
                        }
                      }
                    }
                  },
                  "manager": "cce-ai-service",
                  "operation": "Update",
                  "time": "2024-07-18T08:39:56Z"
                },
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        "f:job-manager/action-succeed": {}
                      }
                    }
                  },
                  "manager": "ftagent",
                  "operation": "Update",
                  "time": "2024-07-18T08:40:03Z"
                },
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        "f:tensorboard-gc": {}
                      }
                    },
                    "f:status": {
                      ".": {},
                      "f:completionTime": {},
                      "f:conditions": {},
                      "f:lastReconcileTime": {},
                      "f:replicaStatuses": {
                        ".": {},
                        "f:Master": {
                          ".": {},
                          "f:active": {}
                        },
                        "f:Worker": {
                          ".": {},
                          "f:active": {},
                          "f:failed": {}
                        }
                      },
                      "f:startTime": {}
                    }
                  },
                  "manager": "manager",
                  "operation": "Update",
                  "time": "2024-07-19T03:02:56Z"
                }
              ],
              "name": "llamatest0718forxiaomi8",
              "namespace": "default",
              "resourceVersion": "2372422590",
              "uid": "11240b44-0997-4805-b6e7-21b594c2fbcb"
            },
            "spec": {
              "pytorchReplicaSpecs": {
                "Master": {
                  "replicas": 1,
                  "restartPolicy": "Never",
                  "template": {
                    "metadata": {
                      "annotations": {
                        "aijob.cce.baidubce.com/fault-tolerance-enabled": "true",
                        "aijob.cce.baidubce.com/openapi-jobid": "pytorch-be7cbb30-0a0a-471b-b6ff-e0825477ada6",
                        "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
                        "aijob.cce.baidubce.com/raw-request": "{\"name\":\"llamatest0718forxiaomi8\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"high\",\"oversell\":false,\"faultTolerance\":true,\"command\":\"\\n#! /bin/bash\\n\\nMEGATRON_PATH=${MEGATRON_PATH:-\\\"/workspace/AIAK-Megatron\\\"}\\nAIAK_TRAINING_PATH=${AIAK_TRAINING_PATH:-\\\"/workspace/AIAK-Training-LLM\\\"}\\n\\nDATA_PATH=${DATA_PATH:-\\\"/mnt/cluster/llama2/pile_llama_test/pile-llama_text_document\\\"}\\nTOKENIZER_PATH=${TOKENIZER_PATH:-\\\"/mnt/cluster/llama2/Llama-2-70b-hf/\\\"}\\n\\nCHECKPOINT_PATH=${CHECKPOINT_PATH:-\\\"/mnt/cluster/llama2/mcore_llama2_70b_tp4_pp4\\\"}\\n\\nTENSORBOARD_PATH=${TENSORBOARD_PATH:-\\\"/mnt/cluster/aiak-training-llm/tensorboard-log/llama2-70b-tp4pp4\\\"}\\n\\nGPUS_PER_NODE=8\\n\\n# Change for multinode config\\nMASTER_ADDR=${MASTER_ADDR:-\\\"localhost\\\"}\\nMASTER_PORT=${MASTER_PORT:-\\\"6000\\\"}\\nNNODES=${WORLD_SIZE:-\\\"1\\\"}\\nNODE_RANK=${RANK:-\\\"0\\\"}\\n\\nDISTRIBUTED_ARGS=(\\n    --nproc_per_node $GPUS_PER_NODE\\n    --nnodes $NNODES\\n    --node_rank $NODE_RANK\\n    --master_addr $MASTER_ADDR\\n    --master_port $MASTER_PORT\\n)\\n\\n# you can setup llama2-70b maunally\\n#MODEL_ARGS=(\\n#    --model-name llama2\\n#    --num-layers 80\\n#    --hidden-size 8192\\n#    --ffn-hidden-size 28672\\n#    --num-attention-heads 64\\n#    --position-embedding-type rope\\n#    --normalization RMSNorm\\n#    --swiglu\\n#    --attention-dropout 0\\n#    --hidden-dropout 0\\n#    --disable-bias-linear\\n#    --untie-embeddings-and-output-weights\\n#    --group-query-attention\\n#    --num-query-groups 8\\n#)\\n\\n# or you can setup llama2-70b by using the following command\\nMODEL_ARGS=(\\n    --model-name llama2-70b # options: llama2-7b, llama2-13b, llama2-70b\\n)\\n\\nDATA_ARGS=(\\n    --tokenizer-type HFTokenizer\\n    --hf-tokenizer-path $TOKENIZER_PATH\\n    --data-path $DATA_PATH\\n    --split 949,50,1\\n)\\n\\nTRAINING_ARGS=(\\n    --training-phase pretrain # options: pretrain, sft\\n    --seq-length 4096\\n    --max-position-embeddings 4096\\n    --init-method-std 0.01\\n    --micro-batch-size 1\\n    --global-batch-size 1024\\n    --lr 0.0002\\n    --min-lr 1.0e-5\\n    --clip-grad 1.0\\n    --weight-decay 0.01\\n    --optimizer adam\\n    --adam-beta1 0.9\\n    --adam-beta2 0.95\\n    --adam-eps 1e-05\\n    --norm-epsilon 1e-6\\n    --train-iters 500000\\n    --lr-decay-iters 500000\\n    --lr-decay-style cosine\\n    --lr-warmup-fraction 0.002\\n    --initial-loss-scale 256\\n    --fp16\\n    --save-interval 5000\\n    --eval-interval 1000\\n    --eval-iters 10\\n    #--ckpt-step 0\\n    #--no-load-optim\\n    #--no-load-rng\\n)\\n\\nMODEL_PARALLEL_ARGS=(\\n    --tensor-model-parallel-size 4\\n    --pipeline-model-parallel-size 4\\n    --use-distributed-optimizer\\n    --overlap-grad-reduce\\n    --overlap-param-gather\\n    --distributed-backend nccl\\n    --sequence-parallel\\n    #--tp-comm-overlap # require mpi envrionment\\n)\\n\\nLOGGING_ARGS=(\\n    --log-interval 1\\n    --tensorboard-dir ${TENSORBOARD_PATH}\\n    --log-timers-to-tensorboard\\n)\\n\\nif [ -n \\\"${WANDB_API_KEY}\\\" ]; then\\n    LOGGING_ARGS+=(\\n        --wandb-project ${WANDB_PROJECT}\\n        --wandb-exp-name ${WANDB_NAME} \\n    )\\nfi\\n\\nPYTHONPATH=$MEGATRON_PATH:$AIAK_TRAINING_PATH:$PYTHONPATH     torchrun ${DISTRIBUTED_ARGS[@]}     $AIAK_TRAINING_PATH/aiak_training_llm/train.py     ${MODEL_ARGS[@]}     ${DATA_ARGS[@]}     ${TRAINING_ARGS[@]}     ${MODEL_PARALLEL_ARGS[@]}     ${LOGGING_ARGS[@]}\\n\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":true,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi8\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi8/output/training_logs\",\"CUDA_DEVICE_MAX_CONNECTIONS\":\"1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"},\"Worker\":{\"replicas\":3,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi8\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi8/output/training_logs\",\"CUDA_DEVICE_MAX_CONNECTIONS\":\"1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":true,\"logPath\":\"/mnt/cluster/llamatest0718forxiaomi8/output/training_logs\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":true,\"isCopyJob\":true,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
                        "scheduling.k8s.io/job-enable-oversell": "false"
                      },
                      "labels": {
                        "aijob.cce.baidubce.com/ai-user-id": "b5a24aa26e4d4f55bc3acf68edc4b051",
                        "aijob.cce.baidubce.com/ai-user-name": "zhangmuhua",
                        "aijob.cce.baidubce.com/create-from-aihcp": "true",
                        "aijob.cce.baidubce.com/openapi-jobid": "pytorch-be7cbb30-0a0a-471b-b6ff-e0825477ada6"
                      }
                    },
                    "spec": {
                      "containers": [
                        {
                          "command": [
                            "/bin/bash",
                            "-c",
                            "\n#! /bin/bash\n\nMEGATRON_PATH=${MEGATRON_PATH:-\"/workspace/AIAK-Megatron\"}\nAIAK_TRAINING_PATH=${AIAK_TRAINING_PATH:-\"/workspace/AIAK-Training-LLM\"}\n\nDATA_PATH=${DATA_PATH:-\"/mnt/cluster/llama2/pile_llama_test/pile-llama_text_document\"}\nTOKENIZER_PATH=${TOKENIZER_PATH:-\"/mnt/cluster/llama2/Llama-2-70b-hf/\"}\n\nCHECKPOINT_PATH=${CHECKPOINT_PATH:-\"/mnt/cluster/llama2/mcore_llama2_70b_tp4_pp4\"}\n\nTENSORBOARD_PATH=${TENSORBOARD_PATH:-\"/mnt/cluster/aiak-training-llm/tensorboard-log/llama2-70b-tp4pp4\"}\n\nGPUS_PER_NODE=8\n\n# Change for multinode config\nMASTER_ADDR=${MASTER_ADDR:-\"localhost\"}\nMASTER_PORT=${MASTER_PORT:-\"6000\"}\nNNODES=${WORLD_SIZE:-\"1\"}\nNODE_RANK=${RANK:-\"0\"}\n\nDISTRIBUTED_ARGS=(\n    --nproc_per_node $GPUS_PER_NODE\n    --nnodes $NNODES\n    --node_rank $NODE_RANK\n    --master_addr $MASTER_ADDR\n    --master_port $MASTER_PORT\n)\n\n# you can setup llama2-70b maunally\n#MODEL_ARGS=(\n#    --model-name llama2\n#    --num-layers 80\n#    --hidden-size 8192\n#    --ffn-hidden-size 28672\n#    --num-attention-heads 64\n#    --position-embedding-type rope\n#    --normalization RMSNorm\n#    --swiglu\n#    --attention-dropout 0\n#    --hidden-dropout 0\n#    --disable-bias-linear\n#    --untie-embeddings-and-output-weights\n#    --group-query-attention\n#    --num-query-groups 8\n#)\n\n# or you can setup llama2-70b by using the following command\nMODEL_ARGS=(\n    --model-name llama2-70b # options: llama2-7b, llama2-13b, llama2-70b\n)\n\nDATA_ARGS=(\n    --tokenizer-type HFTokenizer\n    --hf-tokenizer-path $TOKENIZER_PATH\n    --data-path $DATA_PATH\n    --split 949,50,1\n)\n\nTRAINING_ARGS=(\n    --training-phase pretrain # options: pretrain, sft\n    --seq-length 4096\n    --max-position-embeddings 4096\n    --init-method-std 0.01\n    --micro-batch-size 1\n    --global-batch-size 1024\n    --lr 0.0002\n    --min-lr 1.0e-5\n    --clip-grad 1.0\n    --weight-decay 0.01\n    --optimizer adam\n    --adam-beta1 0.9\n    --adam-beta2 0.95\n    --adam-eps 1e-05\n    --norm-epsilon 1e-6\n    --train-iters 500000\n    --lr-decay-iters 500000\n    --lr-decay-style cosine\n    --lr-warmup-fraction 0.002\n    --initial-loss-scale 256\n    --fp16\n    --save-interval 5000\n    --eval-interval 1000\n    --eval-iters 10\n    #--ckpt-step 0\n    #--no-load-optim\n    #--no-load-rng\n)\n\nMODEL_PARALLEL_ARGS=(\n    --tensor-model-parallel-size 4\n    --pipeline-model-parallel-size 4\n    --use-distributed-optimizer\n    --overlap-grad-reduce\n    --overlap-param-gather\n    --distributed-backend nccl\n    --sequence-parallel\n    #--tp-comm-overlap # require mpi envrionment\n)\n\nLOGGING_ARGS=(\n    --log-interval 1\n    --tensorboard-dir ${TENSORBOARD_PATH}\n    --log-timers-to-tensorboard\n)\n\nif [ -n \"${WANDB_API_KEY}\" ]; then\n    LOGGING_ARGS+=(\n        --wandb-project ${WANDB_PROJECT}\n        --wandb-exp-name ${WANDB_NAME} \n    )\nfi\n\nPYTHONPATH=$MEGATRON_PATH:$AIAK_TRAINING_PATH:$PYTHONPATH     torchrun ${DISTRIBUTED_ARGS[@]}     $AIAK_TRAINING_PATH/aiak_training_llm/train.py     ${MODEL_ARGS[@]}     ${DATA_ARGS[@]}     ${TRAINING_ARGS[@]}     ${MODEL_PARALLEL_ARGS[@]}     ${LOGGING_ARGS[@]}\n"
                          ],
                          "env": [
                            {
                              "name": "CUDA_DEVICE_MAX_CONNECTIONS",
                              "value": "1"
                            },
                            {
                              "name": "AIHC_TENSORBOARD_LOG_PATH",
                              "value": "/mnt/cluster/llamatest0718forxiaomi8/output/training_logs"
                            },
                            {
                              "name": "AIHC_JOB_NAME",
                              "value": "llamatest0718forxiaomi8"
                            },
                            {
                              "name": "NCCL_IB_DISABLE",
                              "value": "0"
                            }
                          ],
                          "image": "registry.baidubce.com/aihc-aiak/aiak-training-llm:ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release",
                          "imagePullPolicy": "Always",
                          "name": "pytorch",
                          "ports": [
                            {
                              "containerPort": 23456,
                              "name": "pytorchjob-port",
                              "protocol": "TCP"
                            }
                          ],
                          "resources": {
                            "limits": {
                              "baidu.com/a800_80g_cgpu": "8",
                              "rdma/hca": "1"
                            },
                            "requests": {
                              "baidu.com/a800_80g_cgpu": "8",
                              "rdma/hca": "1"
                            }
                          },
                          "securityContext": {
                            "capabilities": {
                              "add": [
                                "IPC_LOCK"
                              ]
                            }
                          },
                          "volumeMounts": [
                            {
                              "mountPath": "/dev/shm",
                              "name": "devshm"
                            },
                            {
                              "mountPath": "/mnt/cluster",
                              "name": "pvc-pfs"
                            }
                          ]
                        }
                      ],
                      "dnsPolicy": "ClusterFirstWithHostNet",
                      "hostNetwork": true,
                      "schedulerName": "volcano",
                      "volumes": [
                        {
                          "emptyDir": {
                            "medium": "Memory",
                            "sizeLimit": "10Gi"
                          },
                          "name": "devshm"
                        },
                        {
                          "name": "pvc-pfs",
                          "persistentVolumeClaim": {
                            "claimName": "pvc-pfs"
                          }
                        }
                      ]
                    }
                  }
                },
                "Worker": {
                  "replicas": 3,
                  "restartPolicy": "Never",
                  "template": {
                    "metadata": {
                      "annotations": {
                        "aijob.cce.baidubce.com/fault-tolerance-enabled": "true",
                        "aijob.cce.baidubce.com/openapi-jobid": "pytorch-be7cbb30-0a0a-471b-b6ff-e0825477ada6",
                        "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
                        "aijob.cce.baidubce.com/raw-request": "{\"name\":\"llamatest0718forxiaomi8\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"high\",\"oversell\":false,\"faultTolerance\":true,\"command\":\"\\n#! /bin/bash\\n\\nMEGATRON_PATH=${MEGATRON_PATH:-\\\"/workspace/AIAK-Megatron\\\"}\\nAIAK_TRAINING_PATH=${AIAK_TRAINING_PATH:-\\\"/workspace/AIAK-Training-LLM\\\"}\\n\\nDATA_PATH=${DATA_PATH:-\\\"/mnt/cluster/llama2/pile_llama_test/pile-llama_text_document\\\"}\\nTOKENIZER_PATH=${TOKENIZER_PATH:-\\\"/mnt/cluster/llama2/Llama-2-70b-hf/\\\"}\\n\\nCHECKPOINT_PATH=${CHECKPOINT_PATH:-\\\"/mnt/cluster/llama2/mcore_llama2_70b_tp4_pp4\\\"}\\n\\nTENSORBOARD_PATH=${TENSORBOARD_PATH:-\\\"/mnt/cluster/aiak-training-llm/tensorboard-log/llama2-70b-tp4pp4\\\"}\\n\\nGPUS_PER_NODE=8\\n\\n# Change for multinode config\\nMASTER_ADDR=${MASTER_ADDR:-\\\"localhost\\\"}\\nMASTER_PORT=${MASTER_PORT:-\\\"6000\\\"}\\nNNODES=${WORLD_SIZE:-\\\"1\\\"}\\nNODE_RANK=${RANK:-\\\"0\\\"}\\n\\nDISTRIBUTED_ARGS=(\\n    --nproc_per_node $GPUS_PER_NODE\\n    --nnodes $NNODES\\n    --node_rank $NODE_RANK\\n    --master_addr $MASTER_ADDR\\n    --master_port $MASTER_PORT\\n)\\n\\n# you can setup llama2-70b maunally\\n#MODEL_ARGS=(\\n#    --model-name llama2\\n#    --num-layers 80\\n#    --hidden-size 8192\\n#    --ffn-hidden-size 28672\\n#    --num-attention-heads 64\\n#    --position-embedding-type rope\\n#    --normalization RMSNorm\\n#    --swiglu\\n#    --attention-dropout 0\\n#    --hidden-dropout 0\\n#    --disable-bias-linear\\n#    --untie-embeddings-and-output-weights\\n#    --group-query-attention\\n#    --num-query-groups 8\\n#)\\n\\n# or you can setup llama2-70b by using the following command\\nMODEL_ARGS=(\\n    --model-name llama2-70b # options: llama2-7b, llama2-13b, llama2-70b\\n)\\n\\nDATA_ARGS=(\\n    --tokenizer-type HFTokenizer\\n    --hf-tokenizer-path $TOKENIZER_PATH\\n    --data-path $DATA_PATH\\n    --split 949,50,1\\n)\\n\\nTRAINING_ARGS=(\\n    --training-phase pretrain # options: pretrain, sft\\n    --seq-length 4096\\n    --max-position-embeddings 4096\\n    --init-method-std 0.01\\n    --micro-batch-size 1\\n    --global-batch-size 1024\\n    --lr 0.0002\\n    --min-lr 1.0e-5\\n    --clip-grad 1.0\\n    --weight-decay 0.01\\n    --optimizer adam\\n    --adam-beta1 0.9\\n    --adam-beta2 0.95\\n    --adam-eps 1e-05\\n    --norm-epsilon 1e-6\\n    --train-iters 500000\\n    --lr-decay-iters 500000\\n    --lr-decay-style cosine\\n    --lr-warmup-fraction 0.002\\n    --initial-loss-scale 256\\n    --fp16\\n    --save-interval 5000\\n    --eval-interval 1000\\n    --eval-iters 10\\n    #--ckpt-step 0\\n    #--no-load-optim\\n    #--no-load-rng\\n)\\n\\nMODEL_PARALLEL_ARGS=(\\n    --tensor-model-parallel-size 4\\n    --pipeline-model-parallel-size 4\\n    --use-distributed-optimizer\\n    --overlap-grad-reduce\\n    --overlap-param-gather\\n    --distributed-backend nccl\\n    --sequence-parallel\\n    #--tp-comm-overlap # require mpi envrionment\\n)\\n\\nLOGGING_ARGS=(\\n    --log-interval 1\\n    --tensorboard-dir ${TENSORBOARD_PATH}\\n    --log-timers-to-tensorboard\\n)\\n\\nif [ -n \\\"${WANDB_API_KEY}\\\" ]; then\\n    LOGGING_ARGS+=(\\n        --wandb-project ${WANDB_PROJECT}\\n        --wandb-exp-name ${WANDB_NAME} \\n    )\\nfi\\n\\nPYTHONPATH=$MEGATRON_PATH:$AIAK_TRAINING_PATH:$PYTHONPATH     torchrun ${DISTRIBUTED_ARGS[@]}     $AIAK_TRAINING_PATH/aiak_training_llm/train.py     ${MODEL_ARGS[@]}     ${DATA_ARGS[@]}     ${TRAINING_ARGS[@]}     ${MODEL_PARALLEL_ARGS[@]}     ${LOGGING_ARGS[@]}\\n\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":true,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi8\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi8/output/training_logs\",\"CUDA_DEVICE_MAX_CONNECTIONS\":\"1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"},\"Worker\":{\"replicas\":3,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi8\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi8/output/training_logs\",\"CUDA_DEVICE_MAX_CONNECTIONS\":\"1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":true,\"logPath\":\"/mnt/cluster/llamatest0718forxiaomi8/output/training_logs\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":true,\"isCopyJob\":true,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
                        "scheduling.k8s.io/job-enable-oversell": "false"
                      },
                      "labels": {
                        "aijob.cce.baidubce.com/ai-user-id": "b5a24aa26e4d4f55bc3acf68edc4b051",
                        "aijob.cce.baidubce.com/ai-user-name": "zhangmuhua",
                        "aijob.cce.baidubce.com/create-from-aihcp": "true",
                        "aijob.cce.baidubce.com/openapi-jobid": "pytorch-be7cbb30-0a0a-471b-b6ff-e0825477ada6"
                      }
                    },
                    "spec": {
                      "containers": [
                        {
                          "command": [
                            "/bin/bash",
                            "-c",
                            "\n#! /bin/bash\n\nMEGATRON_PATH=${MEGATRON_PATH:-\"/workspace/AIAK-Megatron\"}\nAIAK_TRAINING_PATH=${AIAK_TRAINING_PATH:-\"/workspace/AIAK-Training-LLM\"}\n\nDATA_PATH=${DATA_PATH:-\"/mnt/cluster/llama2/pile_llama_test/pile-llama_text_document\"}\nTOKENIZER_PATH=${TOKENIZER_PATH:-\"/mnt/cluster/llama2/Llama-2-70b-hf/\"}\n\nCHECKPOINT_PATH=${CHECKPOINT_PATH:-\"/mnt/cluster/llama2/mcore_llama2_70b_tp4_pp4\"}\n\nTENSORBOARD_PATH=${TENSORBOARD_PATH:-\"/mnt/cluster/aiak-training-llm/tensorboard-log/llama2-70b-tp4pp4\"}\n\nGPUS_PER_NODE=8\n\n# Change for multinode config\nMASTER_ADDR=${MASTER_ADDR:-\"localhost\"}\nMASTER_PORT=${MASTER_PORT:-\"6000\"}\nNNODES=${WORLD_SIZE:-\"1\"}\nNODE_RANK=${RANK:-\"0\"}\n\nDISTRIBUTED_ARGS=(\n    --nproc_per_node $GPUS_PER_NODE\n    --nnodes $NNODES\n    --node_rank $NODE_RANK\n    --master_addr $MASTER_ADDR\n    --master_port $MASTER_PORT\n)\n\n# you can setup llama2-70b maunally\n#MODEL_ARGS=(\n#    --model-name llama2\n#    --num-layers 80\n#    --hidden-size 8192\n#    --ffn-hidden-size 28672\n#    --num-attention-heads 64\n#    --position-embedding-type rope\n#    --normalization RMSNorm\n#    --swiglu\n#    --attention-dropout 0\n#    --hidden-dropout 0\n#    --disable-bias-linear\n#    --untie-embeddings-and-output-weights\n#    --group-query-attention\n#    --num-query-groups 8\n#)\n\n# or you can setup llama2-70b by using the following command\nMODEL_ARGS=(\n    --model-name llama2-70b # options: llama2-7b, llama2-13b, llama2-70b\n)\n\nDATA_ARGS=(\n    --tokenizer-type HFTokenizer\n    --hf-tokenizer-path $TOKENIZER_PATH\n    --data-path $DATA_PATH\n    --split 949,50,1\n)\n\nTRAINING_ARGS=(\n    --training-phase pretrain # options: pretrain, sft\n    --seq-length 4096\n    --max-position-embeddings 4096\n    --init-method-std 0.01\n    --micro-batch-size 1\n    --global-batch-size 1024\n    --lr 0.0002\n    --min-lr 1.0e-5\n    --clip-grad 1.0\n    --weight-decay 0.01\n    --optimizer adam\n    --adam-beta1 0.9\n    --adam-beta2 0.95\n    --adam-eps 1e-05\n    --norm-epsilon 1e-6\n    --train-iters 500000\n    --lr-decay-iters 500000\n    --lr-decay-style cosine\n    --lr-warmup-fraction 0.002\n    --initial-loss-scale 256\n    --fp16\n    --save-interval 5000\n    --eval-interval 1000\n    --eval-iters 10\n    #--ckpt-step 0\n    #--no-load-optim\n    #--no-load-rng\n)\n\nMODEL_PARALLEL_ARGS=(\n    --tensor-model-parallel-size 4\n    --pipeline-model-parallel-size 4\n    --use-distributed-optimizer\n    --overlap-grad-reduce\n    --overlap-param-gather\n    --distributed-backend nccl\n    --sequence-parallel\n    #--tp-comm-overlap # require mpi envrionment\n)\n\nLOGGING_ARGS=(\n    --log-interval 1\n    --tensorboard-dir ${TENSORBOARD_PATH}\n    --log-timers-to-tensorboard\n)\n\nif [ -n \"${WANDB_API_KEY}\" ]; then\n    LOGGING_ARGS+=(\n        --wandb-project ${WANDB_PROJECT}\n        --wandb-exp-name ${WANDB_NAME} \n    )\nfi\n\nPYTHONPATH=$MEGATRON_PATH:$AIAK_TRAINING_PATH:$PYTHONPATH     torchrun ${DISTRIBUTED_ARGS[@]}     $AIAK_TRAINING_PATH/aiak_training_llm/train.py     ${MODEL_ARGS[@]}     ${DATA_ARGS[@]}     ${TRAINING_ARGS[@]}     ${MODEL_PARALLEL_ARGS[@]}     ${LOGGING_ARGS[@]}\n"
                          ],
                          "env": [
                            {
                              "name": "NCCL_IB_DISABLE",
                              "value": "0"
                            },
                            {
                              "name": "CUDA_DEVICE_MAX_CONNECTIONS",
                              "value": "1"
                            },
                            {
                              "name": "AIHC_TENSORBOARD_LOG_PATH",
                              "value": "/mnt/cluster/llamatest0718forxiaomi8/output/training_logs"
                            },
                            {
                              "name": "AIHC_JOB_NAME",
                              "value": "llamatest0718forxiaomi8"
                            }
                          ],
                          "image": "registry.baidubce.com/aihc-aiak/aiak-training-llm:ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release",
                          "imagePullPolicy": "Always",
                          "name": "pytorch",
                          "ports": [
                            {
                              "containerPort": 23456,
                              "name": "pytorchjob-port",
                              "protocol": "TCP"
                            }
                          ],
                          "resources": {
                            "limits": {
                              "baidu.com/a800_80g_cgpu": "8",
                              "rdma/hca": "1"
                            },
                            "requests": {
                              "baidu.com/a800_80g_cgpu": "8",
                              "rdma/hca": "1"
                            }
                          },
                          "securityContext": {
                            "capabilities": {
                              "add": [
                                "IPC_LOCK"
                              ]
                            }
                          },
                          "volumeMounts": [
                            {
                              "mountPath": "/dev/shm",
                              "name": "devshm"
                            },
                            {
                              "mountPath": "/mnt/cluster",
                              "name": "pvc-pfs"
                            }
                          ]
                        }
                      ],
                      "dnsPolicy": "ClusterFirstWithHostNet",
                      "hostNetwork": true,
                      "schedulerName": "volcano",
                      "volumes": [
                        {
                          "emptyDir": {
                            "medium": "Memory",
                            "sizeLimit": "10Gi"
                          },
                          "name": "devshm"
                        },
                        {
                          "name": "pvc-pfs",
                          "persistentVolumeClaim": {
                            "claimName": "pvc-pfs"
                          }
                        }
                      ]
                    }
                  }
                }
              },
              "runPolicy": {
                "cleanPodPolicy": "None",
                "schedulingPolicy": {
                  "priorityClass": "high",
                  "queue": "default"
                }
              }
            },
            "status": {
              "completionTime": "2024-07-18T08:40:08Z",
              "conditions": [
                {
                  "lastTransitionTime": "2024-07-18T03:02:42Z",
                  "lastUpdateTime": "2024-07-18T03:02:42Z",
                  "message": "PyTorchJob llamatest0718forxiaomi8 is created.",
                  "reason": "PyTorchJobCreated",
                  "status": "True",
                  "type": "Created"
                },
                {
                  "lastTransitionTime": "2024-07-18T03:02:54Z",
                  "lastUpdateTime": "2024-07-18T03:02:54Z",
                  "message": "PyTorchJob llamatest0718forxiaomi8 is running.",
                  "reason": "JobRunning",
                  "status": "False",
                  "type": "Running"
                },
                {
                  "lastTransitionTime": "2024-07-18T08:39:56Z",
                  "lastUpdateTime": "2024-07-18T08:39:56Z",
                  "message": "PytorchJob default/llamatest0718forxiaomi8 is stopped",
                  "reason": "PyTorchJobStopped",
                  "status": "True",
                  "type": "Stopped"
                },
                {
                  "lastTransitionTime": "2024-07-18T08:40:08Z",
                  "lastUpdateTime": "2024-07-18T08:40:08Z",
                  "message": "PyTorchJob llamatest0718forxiaomi8 is failed because 1 Worker replica(s) failed.",
                  "reason": "JobFailed",
                  "status": "True",
                  "type": "Failed"
                }
              ],
              "lastReconcileTime": "2024-07-18T03:02:42Z",
              "replicaStatuses": {
                "Master": {
                  "active": 1,
                  "selector": "training.kubeflow.org/job-name=llamatest0718forxiaomi8,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=master"
                },
                "Worker": {
                  "active": 2,
                  "failed": 1,
                  "selector": "training.kubeflow.org/job-name=llamatest0718forxiaomi8,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=worker"
                }
              },
              "startTime": "2024-07-18T03:02:43Z"
            }
          },
          {
            "apiVersion": "kubeflow.org/v1",
            "kind": "PyTorchJob",
            "metadata": {
              "annotations": {
                "aijob.cce.baidubce.com/barrier-finish": "2dc24e3c-baa2-42cd-bbc9-705e8178aab4",
                "aijob.cce.baidubce.com/fault-tolerance-enabled": "true",
                "aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": "",
                "aijob.cce.baidubce.com/openapi-jobid": "pytorch-6ae32368-97b5-4e0d-9d78-1dcab6fd0361",
                "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
                "aijob.cce.baidubce.com/raw-request": "{\"name\":\"llamatest0718forxiaomi9\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"high\",\"oversell\":false,\"faultTolerance\":true,\"command\":\"\\n#! /bin/bash\\n\\nMEGATRON_PATH=${MEGATRON_PATH:-\\\"/workspace/AIAK-Megatron\\\"}\\nAIAK_TRAINING_PATH=${AIAK_TRAINING_PATH:-\\\"/workspace/AIAK-Training-LLM\\\"}\\n\\nDATA_PATH=${DATA_PATH:-\\\"/mnt/cluster/llama2/pile_llama_test/pile-llama_text_document\\\"}\\nTOKENIZER_PATH=${TOKENIZER_PATH:-\\\"/mnt/cluster/llama2/Llama-2-70b-hf/\\\"}\\n\\nCHECKPOINT_PATH=${CHECKPOINT_PATH:-\\\"/mnt/cluster/llama2/mcore_llama2_70b_tp4_pp4\\\"}\\n\\nTENSORBOARD_PATH=${TENSORBOARD_PATH:-\\\"/mnt/cluster/aiak-training-llm/tensorboard-log/llama2-70b-tp4pp4\\\"}\\n\\nGPUS_PER_NODE=8\\n\\n# Change for multinode config\\nMASTER_ADDR=${MASTER_ADDR:-\\\"localhost\\\"}\\nMASTER_PORT=${MASTER_PORT:-\\\"6000\\\"}\\nNNODES=${WORLD_SIZE:-\\\"1\\\"}\\nNODE_RANK=${RANK:-\\\"0\\\"}\\n\\nDISTRIBUTED_ARGS=(\\n    --nproc_per_node $GPUS_PER_NODE\\n    --nnodes $NNODES\\n    --node_rank $NODE_RANK\\n    --master_addr $MASTER_ADDR\\n    --master_port $MASTER_PORT\\n)\\n\\n# you can setup llama2-70b maunally\\n#MODEL_ARGS=(\\n#    --model-name llama2\\n#    --num-layers 80\\n#    --hidden-size 8192\\n#    --ffn-hidden-size 28672\\n#    --num-attention-heads 64\\n#    --position-embedding-type rope\\n#    --normalization RMSNorm\\n#    --swiglu\\n#    --attention-dropout 0\\n#    --hidden-dropout 0\\n#    --disable-bias-linear\\n#    --untie-embeddings-and-output-weights\\n#    --group-query-attention\\n#    --num-query-groups 8\\n#)\\n\\n# or you can setup llama2-70b by using the following command\\nMODEL_ARGS=(\\n    --model-name llama2-70b # options: llama2-7b, llama2-13b, llama2-70b\\n)\\n\\nDATA_ARGS=(\\n    --tokenizer-type HFTokenizer\\n    --hf-tokenizer-path $TOKENIZER_PATH\\n    --data-path $DATA_PATH\\n    --split 949,50,1\\n)\\n\\nTRAINING_ARGS=(\\n    --training-phase pretrain # options: pretrain, sft\\n    --seq-length 4096\\n    --max-position-embeddings 4096\\n    --init-method-std 0.01\\n    --micro-batch-size 1\\n    --global-batch-size 1024\\n    --lr 0.0002\\n    --min-lr 1.0e-5\\n    --clip-grad 1.0\\n    --weight-decay 0.01\\n    --optimizer adam\\n    --adam-beta1 0.9\\n    --adam-beta2 0.95\\n    --adam-eps 1e-05\\n    --norm-epsilon 1e-6\\n    --train-iters 500000\\n    --lr-decay-iters 500000\\n    --lr-decay-style cosine\\n    --lr-warmup-fraction 0.002\\n    --initial-loss-scale 16\\n    --fp16\\n    --save-interval 5000\\n    --eval-interval 1000\\n    --eval-iters 10\\n    #--ckpt-step 0\\n    #--no-load-optim\\n    #--no-load-rng\\n)\\n\\nMODEL_PARALLEL_ARGS=(\\n    --tensor-model-parallel-size 4\\n    --pipeline-model-parallel-size 4\\n    --use-distributed-optimizer\\n    --overlap-grad-reduce\\n    --overlap-param-gather\\n    --distributed-backend nccl\\n    --sequence-parallel\\n    #--tp-comm-overlap # require mpi envrionment\\n)\\n\\nLOGGING_ARGS=(\\n    --log-interval 1\\n    --tensorboard-dir ${TENSORBOARD_PATH}\\n    --log-timers-to-tensorboard\\n)\\n\\nif [ -n \\\"${WANDB_API_KEY}\\\" ]; then\\n    LOGGING_ARGS+=(\\n        --wandb-project ${WANDB_PROJECT}\\n        --wandb-exp-name ${WANDB_NAME} \\n    )\\nfi\\n\\nPYTHONPATH=$MEGATRON_PATH:$AIAK_TRAINING_PATH:$PYTHONPATH     torchrun ${DISTRIBUTED_ARGS[@]}     $AIAK_TRAINING_PATH/aiak_training_llm/train.py     ${MODEL_ARGS[@]}     ${DATA_ARGS[@]}     ${TRAINING_ARGS[@]}     ${MODEL_PARALLEL_ARGS[@]}     ${LOGGING_ARGS[@]}\\n\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":true,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi9\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi9/output/training_logs\",\"CUDA_DEVICE_MAX_CONNECTIONS\":\"1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"},\"Worker\":{\"replicas\":3,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi9\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi9/output/training_logs\",\"CUDA_DEVICE_MAX_CONNECTIONS\":\"1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":true,\"logPath\":\"/mnt/cluster/llamatest0718forxiaomi9/output/training_logs\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":true,\"isCopyJob\":true,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
                "aijob.cce.baidubce.com/timeline": "[{\"conditionType\":\"Created\",\"time\":1721291978},{\"conditionType\":\"Scheduled\",\"time\":1721292009},{\"conditionType\":\"Running\",\"time\":1721292052},{\"conditionType\":\"ManualTermination\",\"time\":1721387985}]",
                "job-manager/action": "stop",
                "job-manager/action-succeed": "stop",
                "scheduling.k8s.io/job-enable-oversell": "false",
                "tensorboard-gc": "true"
              },
              "creationTimestamp": "2024-07-18T08:39:38Z",
              "generation": 2,
              "labels": {
                "aijob.cce.baidubce.com/ai-user-id": "dd0cc6ebcaa04da5af73af3448ffb35d",
                "aijob.cce.baidubce.com/ai-user-name": "wangzhuyun",
                "aijob.cce.baidubce.com/create-from-aihcp": "true",
                "aijob.cce.baidubce.com/openapi-jobid": "pytorch-6ae32368-97b5-4e0d-9d78-1dcab6fd0361"
              },
              "managedFields": [
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        "f:aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": {},
                        "f:aijob.cce.baidubce.com/timeline": {}
                      }
                    },
                    "f:spec": {
                      "f:pytorchReplicaSpecs": {
                        "f:Master": {
                          "f:template": {
                            "f:spec": {
                              "f:containers": {}
                            }
                          }
                        },
                        "f:Worker": {
                          "f:template": {
                            "f:spec": {
                              "f:containers": {}
                            }
                          }
                        }
                      },
                      "f:runPolicy": {
                        "f:cleanPodPolicy": {}
                      }
                    }
                  },
                  "manager": "controller",
                  "operation": "Update",
                  "time": "2024-07-18T08:39:38Z"
                },
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        "f:aijob.cce.baidubce.com/barrier-finish": {}
                      }
                    }
                  },
                  "manager": "jobbarrier",
                  "operation": "Update",
                  "time": "2024-07-18T08:40:48Z"
                },
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        ".": {},
                        "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                        "f:aijob.cce.baidubce.com/openapi-jobid": {},
                        "f:aijob.cce.baidubce.com/pfs-id": {},
                        "f:aijob.cce.baidubce.com/raw-request": {},
                        "f:job-manager/action": {},
                        "f:scheduling.k8s.io/job-enable-oversell": {}
                      },
                      "f:labels": {
                        ".": {},
                        "f:aijob.cce.baidubce.com/ai-user-id": {},
                        "f:aijob.cce.baidubce.com/ai-user-name": {},
                        "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                        "f:aijob.cce.baidubce.com/openapi-jobid": {}
                      }
                    },
                    "f:spec": {
                      ".": {},
                      "f:pytorchReplicaSpecs": {
                        ".": {},
                        "f:Master": {
                          ".": {},
                          "f:replicas": {},
                          "f:restartPolicy": {},
                          "f:template": {
                            ".": {},
                            "f:metadata": {
                              ".": {},
                              "f:annotations": {
                                ".": {},
                                "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                                "f:aijob.cce.baidubce.com/openapi-jobid": {},
                                "f:aijob.cce.baidubce.com/pfs-id": {},
                                "f:aijob.cce.baidubce.com/raw-request": {},
                                "f:scheduling.k8s.io/job-enable-oversell": {}
                              },
                              "f:labels": {
                                ".": {},
                                "f:aijob.cce.baidubce.com/ai-user-id": {},
                                "f:aijob.cce.baidubce.com/ai-user-name": {},
                                "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                                "f:aijob.cce.baidubce.com/openapi-jobid": {}
                              }
                            },
                            "f:spec": {
                              ".": {},
                              "f:dnsPolicy": {},
                              "f:hostNetwork": {},
                              "f:schedulerName": {},
                              "f:volumes": {}
                            }
                          }
                        },
                        "f:Worker": {
                          ".": {},
                          "f:replicas": {},
                          "f:restartPolicy": {},
                          "f:template": {
                            ".": {},
                            "f:metadata": {
                              ".": {},
                              "f:annotations": {
                                ".": {},
                                "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                                "f:aijob.cce.baidubce.com/openapi-jobid": {},
                                "f:aijob.cce.baidubce.com/pfs-id": {},
                                "f:aijob.cce.baidubce.com/raw-request": {},
                                "f:scheduling.k8s.io/job-enable-oversell": {}
                              },
                              "f:labels": {
                                ".": {},
                                "f:aijob.cce.baidubce.com/ai-user-id": {},
                                "f:aijob.cce.baidubce.com/ai-user-name": {},
                                "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                                "f:aijob.cce.baidubce.com/openapi-jobid": {}
                              }
                            },
                            "f:spec": {
                              ".": {},
                              "f:dnsPolicy": {},
                              "f:hostNetwork": {},
                              "f:schedulerName": {},
                              "f:volumes": {}
                            }
                          }
                        }
                      },
                      "f:runPolicy": {
                        ".": {},
                        "f:schedulingPolicy": {
                          ".": {},
                          "f:priorityClass": {},
                          "f:queue": {}
                        }
                      }
                    }
                  },
                  "manager": "cce-ai-service",
                  "operation": "Update",
                  "time": "2024-07-19T11:19:45Z"
                },
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        "f:job-manager/action-succeed": {}
                      }
                    }
                  },
                  "manager": "ftagent",
                  "operation": "Update",
                  "time": "2024-07-19T11:19:51Z"
                },
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        "f:tensorboard-gc": {}
                      }
                    },
                    "f:status": {
                      ".": {},
                      "f:completionTime": {},
                      "f:conditions": {},
                      "f:lastReconcileTime": {},
                      "f:replicaStatuses": {
                        ".": {},
                        "f:Master": {
                          ".": {},
                          "f:active": {}
                        },
                        "f:Worker": {
                          ".": {},
                          "f:active": {},
                          "f:failed": {}
                        }
                      },
                      "f:startTime": {}
                    }
                  },
                  "manager": "manager",
                  "operation": "Update",
                  "time": "2024-07-19T11:19:57Z"
                }
              ],
              "name": "llamatest0718forxiaomi9",
              "namespace": "default",
              "resourceVersion": "2372827685",
              "uid": "1d954d68-56f0-4537-82b7-9d1ea765ca5f"
            },
            "spec": {
              "pytorchReplicaSpecs": {
                "Master": {
                  "replicas": 1,
                  "restartPolicy": "Never",
                  "template": {
                    "metadata": {
                      "annotations": {
                        "aijob.cce.baidubce.com/fault-tolerance-enabled": "true",
                        "aijob.cce.baidubce.com/openapi-jobid": "pytorch-6ae32368-97b5-4e0d-9d78-1dcab6fd0361",
                        "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
                        "aijob.cce.baidubce.com/raw-request": "{\"name\":\"llamatest0718forxiaomi9\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"high\",\"oversell\":false,\"faultTolerance\":true,\"command\":\"\\n#! /bin/bash\\n\\nMEGATRON_PATH=${MEGATRON_PATH:-\\\"/workspace/AIAK-Megatron\\\"}\\nAIAK_TRAINING_PATH=${AIAK_TRAINING_PATH:-\\\"/workspace/AIAK-Training-LLM\\\"}\\n\\nDATA_PATH=${DATA_PATH:-\\\"/mnt/cluster/llama2/pile_llama_test/pile-llama_text_document\\\"}\\nTOKENIZER_PATH=${TOKENIZER_PATH:-\\\"/mnt/cluster/llama2/Llama-2-70b-hf/\\\"}\\n\\nCHECKPOINT_PATH=${CHECKPOINT_PATH:-\\\"/mnt/cluster/llama2/mcore_llama2_70b_tp4_pp4\\\"}\\n\\nTENSORBOARD_PATH=${TENSORBOARD_PATH:-\\\"/mnt/cluster/aiak-training-llm/tensorboard-log/llama2-70b-tp4pp4\\\"}\\n\\nGPUS_PER_NODE=8\\n\\n# Change for multinode config\\nMASTER_ADDR=${MASTER_ADDR:-\\\"localhost\\\"}\\nMASTER_PORT=${MASTER_PORT:-\\\"6000\\\"}\\nNNODES=${WORLD_SIZE:-\\\"1\\\"}\\nNODE_RANK=${RANK:-\\\"0\\\"}\\n\\nDISTRIBUTED_ARGS=(\\n    --nproc_per_node $GPUS_PER_NODE\\n    --nnodes $NNODES\\n    --node_rank $NODE_RANK\\n    --master_addr $MASTER_ADDR\\n    --master_port $MASTER_PORT\\n)\\n\\n# you can setup llama2-70b maunally\\n#MODEL_ARGS=(\\n#    --model-name llama2\\n#    --num-layers 80\\n#    --hidden-size 8192\\n#    --ffn-hidden-size 28672\\n#    --num-attention-heads 64\\n#    --position-embedding-type rope\\n#    --normalization RMSNorm\\n#    --swiglu\\n#    --attention-dropout 0\\n#    --hidden-dropout 0\\n#    --disable-bias-linear\\n#    --untie-embeddings-and-output-weights\\n#    --group-query-attention\\n#    --num-query-groups 8\\n#)\\n\\n# or you can setup llama2-70b by using the following command\\nMODEL_ARGS=(\\n    --model-name llama2-70b # options: llama2-7b, llama2-13b, llama2-70b\\n)\\n\\nDATA_ARGS=(\\n    --tokenizer-type HFTokenizer\\n    --hf-tokenizer-path $TOKENIZER_PATH\\n    --data-path $DATA_PATH\\n    --split 949,50,1\\n)\\n\\nTRAINING_ARGS=(\\n    --training-phase pretrain # options: pretrain, sft\\n    --seq-length 4096\\n    --max-position-embeddings 4096\\n    --init-method-std 0.01\\n    --micro-batch-size 1\\n    --global-batch-size 1024\\n    --lr 0.0002\\n    --min-lr 1.0e-5\\n    --clip-grad 1.0\\n    --weight-decay 0.01\\n    --optimizer adam\\n    --adam-beta1 0.9\\n    --adam-beta2 0.95\\n    --adam-eps 1e-05\\n    --norm-epsilon 1e-6\\n    --train-iters 500000\\n    --lr-decay-iters 500000\\n    --lr-decay-style cosine\\n    --lr-warmup-fraction 0.002\\n    --initial-loss-scale 16\\n    --fp16\\n    --save-interval 5000\\n    --eval-interval 1000\\n    --eval-iters 10\\n    #--ckpt-step 0\\n    #--no-load-optim\\n    #--no-load-rng\\n)\\n\\nMODEL_PARALLEL_ARGS=(\\n    --tensor-model-parallel-size 4\\n    --pipeline-model-parallel-size 4\\n    --use-distributed-optimizer\\n    --overlap-grad-reduce\\n    --overlap-param-gather\\n    --distributed-backend nccl\\n    --sequence-parallel\\n    #--tp-comm-overlap # require mpi envrionment\\n)\\n\\nLOGGING_ARGS=(\\n    --log-interval 1\\n    --tensorboard-dir ${TENSORBOARD_PATH}\\n    --log-timers-to-tensorboard\\n)\\n\\nif [ -n \\\"${WANDB_API_KEY}\\\" ]; then\\n    LOGGING_ARGS+=(\\n        --wandb-project ${WANDB_PROJECT}\\n        --wandb-exp-name ${WANDB_NAME} \\n    )\\nfi\\n\\nPYTHONPATH=$MEGATRON_PATH:$AIAK_TRAINING_PATH:$PYTHONPATH     torchrun ${DISTRIBUTED_ARGS[@]}     $AIAK_TRAINING_PATH/aiak_training_llm/train.py     ${MODEL_ARGS[@]}     ${DATA_ARGS[@]}     ${TRAINING_ARGS[@]}     ${MODEL_PARALLEL_ARGS[@]}     ${LOGGING_ARGS[@]}\\n\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":true,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi9\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi9/output/training_logs\",\"CUDA_DEVICE_MAX_CONNECTIONS\":\"1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"},\"Worker\":{\"replicas\":3,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi9\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi9/output/training_logs\",\"CUDA_DEVICE_MAX_CONNECTIONS\":\"1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":true,\"logPath\":\"/mnt/cluster/llamatest0718forxiaomi9/output/training_logs\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":true,\"isCopyJob\":true,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
                        "scheduling.k8s.io/job-enable-oversell": "false"
                      },
                      "labels": {
                        "aijob.cce.baidubce.com/ai-user-id": "dd0cc6ebcaa04da5af73af3448ffb35d",
                        "aijob.cce.baidubce.com/ai-user-name": "wangzhuyun",
                        "aijob.cce.baidubce.com/create-from-aihcp": "true",
                        "aijob.cce.baidubce.com/openapi-jobid": "pytorch-6ae32368-97b5-4e0d-9d78-1dcab6fd0361"
                      }
                    },
                    "spec": {
                      "containers": [
                        {
                          "command": [
                            "/bin/bash",
                            "-c",
                            "\n#! /bin/bash\n\nMEGATRON_PATH=${MEGATRON_PATH:-\"/workspace/AIAK-Megatron\"}\nAIAK_TRAINING_PATH=${AIAK_TRAINING_PATH:-\"/workspace/AIAK-Training-LLM\"}\n\nDATA_PATH=${DATA_PATH:-\"/mnt/cluster/llama2/pile_llama_test/pile-llama_text_document\"}\nTOKENIZER_PATH=${TOKENIZER_PATH:-\"/mnt/cluster/llama2/Llama-2-70b-hf/\"}\n\nCHECKPOINT_PATH=${CHECKPOINT_PATH:-\"/mnt/cluster/llama2/mcore_llama2_70b_tp4_pp4\"}\n\nTENSORBOARD_PATH=${TENSORBOARD_PATH:-\"/mnt/cluster/aiak-training-llm/tensorboard-log/llama2-70b-tp4pp4\"}\n\nGPUS_PER_NODE=8\n\n# Change for multinode config\nMASTER_ADDR=${MASTER_ADDR:-\"localhost\"}\nMASTER_PORT=${MASTER_PORT:-\"6000\"}\nNNODES=${WORLD_SIZE:-\"1\"}\nNODE_RANK=${RANK:-\"0\"}\n\nDISTRIBUTED_ARGS=(\n    --nproc_per_node $GPUS_PER_NODE\n    --nnodes $NNODES\n    --node_rank $NODE_RANK\n    --master_addr $MASTER_ADDR\n    --master_port $MASTER_PORT\n)\n\n# you can setup llama2-70b maunally\n#MODEL_ARGS=(\n#    --model-name llama2\n#    --num-layers 80\n#    --hidden-size 8192\n#    --ffn-hidden-size 28672\n#    --num-attention-heads 64\n#    --position-embedding-type rope\n#    --normalization RMSNorm\n#    --swiglu\n#    --attention-dropout 0\n#    --hidden-dropout 0\n#    --disable-bias-linear\n#    --untie-embeddings-and-output-weights\n#    --group-query-attention\n#    --num-query-groups 8\n#)\n\n# or you can setup llama2-70b by using the following command\nMODEL_ARGS=(\n    --model-name llama2-70b # options: llama2-7b, llama2-13b, llama2-70b\n)\n\nDATA_ARGS=(\n    --tokenizer-type HFTokenizer\n    --hf-tokenizer-path $TOKENIZER_PATH\n    --data-path $DATA_PATH\n    --split 949,50,1\n)\n\nTRAINING_ARGS=(\n    --training-phase pretrain # options: pretrain, sft\n    --seq-length 4096\n    --max-position-embeddings 4096\n    --init-method-std 0.01\n    --micro-batch-size 1\n    --global-batch-size 1024\n    --lr 0.0002\n    --min-lr 1.0e-5\n    --clip-grad 1.0\n    --weight-decay 0.01\n    --optimizer adam\n    --adam-beta1 0.9\n    --adam-beta2 0.95\n    --adam-eps 1e-05\n    --norm-epsilon 1e-6\n    --train-iters 500000\n    --lr-decay-iters 500000\n    --lr-decay-style cosine\n    --lr-warmup-fraction 0.002\n    --initial-loss-scale 16\n    --fp16\n    --save-interval 5000\n    --eval-interval 1000\n    --eval-iters 10\n    #--ckpt-step 0\n    #--no-load-optim\n    #--no-load-rng\n)\n\nMODEL_PARALLEL_ARGS=(\n    --tensor-model-parallel-size 4\n    --pipeline-model-parallel-size 4\n    --use-distributed-optimizer\n    --overlap-grad-reduce\n    --overlap-param-gather\n    --distributed-backend nccl\n    --sequence-parallel\n    #--tp-comm-overlap # require mpi envrionment\n)\n\nLOGGING_ARGS=(\n    --log-interval 1\n    --tensorboard-dir ${TENSORBOARD_PATH}\n    --log-timers-to-tensorboard\n)\n\nif [ -n \"${WANDB_API_KEY}\" ]; then\n    LOGGING_ARGS+=(\n        --wandb-project ${WANDB_PROJECT}\n        --wandb-exp-name ${WANDB_NAME} \n    )\nfi\n\nPYTHONPATH=$MEGATRON_PATH:$AIAK_TRAINING_PATH:$PYTHONPATH     torchrun ${DISTRIBUTED_ARGS[@]}     $AIAK_TRAINING_PATH/aiak_training_llm/train.py     ${MODEL_ARGS[@]}     ${DATA_ARGS[@]}     ${TRAINING_ARGS[@]}     ${MODEL_PARALLEL_ARGS[@]}     ${LOGGING_ARGS[@]}\n"
                          ],
                          "env": [
                            {
                              "name": "CUDA_DEVICE_MAX_CONNECTIONS",
                              "value": "1"
                            },
                            {
                              "name": "AIHC_TENSORBOARD_LOG_PATH",
                              "value": "/mnt/cluster/llamatest0718forxiaomi9/output/training_logs"
                            },
                            {
                              "name": "AIHC_JOB_NAME",
                              "value": "llamatest0718forxiaomi9"
                            },
                            {
                              "name": "NCCL_IB_DISABLE",
                              "value": "0"
                            }
                          ],
                          "image": "registry.baidubce.com/aihc-aiak/aiak-training-llm:ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release",
                          "imagePullPolicy": "Always",
                          "name": "pytorch",
                          "ports": [
                            {
                              "containerPort": 23456,
                              "name": "pytorchjob-port",
                              "protocol": "TCP"
                            }
                          ],
                          "resources": {
                            "limits": {
                              "baidu.com/a800_80g_cgpu": "8",
                              "rdma/hca": "1"
                            },
                            "requests": {
                              "baidu.com/a800_80g_cgpu": "8",
                              "rdma/hca": "1"
                            }
                          },
                          "securityContext": {
                            "capabilities": {
                              "add": [
                                "IPC_LOCK"
                              ]
                            }
                          },
                          "volumeMounts": [
                            {
                              "mountPath": "/dev/shm",
                              "name": "devshm"
                            },
                            {
                              "mountPath": "/mnt/cluster",
                              "name": "pvc-pfs"
                            }
                          ]
                        }
                      ],
                      "dnsPolicy": "ClusterFirstWithHostNet",
                      "hostNetwork": true,
                      "schedulerName": "volcano",
                      "volumes": [
                        {
                          "emptyDir": {
                            "medium": "Memory",
                            "sizeLimit": "10Gi"
                          },
                          "name": "devshm"
                        },
                        {
                          "name": "pvc-pfs",
                          "persistentVolumeClaim": {
                            "claimName": "pvc-pfs"
                          }
                        }
                      ]
                    }
                  }
                },
                "Worker": {
                  "replicas": 3,
                  "restartPolicy": "Never",
                  "template": {
                    "metadata": {
                      "annotations": {
                        "aijob.cce.baidubce.com/fault-tolerance-enabled": "true",
                        "aijob.cce.baidubce.com/openapi-jobid": "pytorch-6ae32368-97b5-4e0d-9d78-1dcab6fd0361",
                        "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
                        "aijob.cce.baidubce.com/raw-request": "{\"name\":\"llamatest0718forxiaomi9\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"high\",\"oversell\":false,\"faultTolerance\":true,\"command\":\"\\n#! /bin/bash\\n\\nMEGATRON_PATH=${MEGATRON_PATH:-\\\"/workspace/AIAK-Megatron\\\"}\\nAIAK_TRAINING_PATH=${AIAK_TRAINING_PATH:-\\\"/workspace/AIAK-Training-LLM\\\"}\\n\\nDATA_PATH=${DATA_PATH:-\\\"/mnt/cluster/llama2/pile_llama_test/pile-llama_text_document\\\"}\\nTOKENIZER_PATH=${TOKENIZER_PATH:-\\\"/mnt/cluster/llama2/Llama-2-70b-hf/\\\"}\\n\\nCHECKPOINT_PATH=${CHECKPOINT_PATH:-\\\"/mnt/cluster/llama2/mcore_llama2_70b_tp4_pp4\\\"}\\n\\nTENSORBOARD_PATH=${TENSORBOARD_PATH:-\\\"/mnt/cluster/aiak-training-llm/tensorboard-log/llama2-70b-tp4pp4\\\"}\\n\\nGPUS_PER_NODE=8\\n\\n# Change for multinode config\\nMASTER_ADDR=${MASTER_ADDR:-\\\"localhost\\\"}\\nMASTER_PORT=${MASTER_PORT:-\\\"6000\\\"}\\nNNODES=${WORLD_SIZE:-\\\"1\\\"}\\nNODE_RANK=${RANK:-\\\"0\\\"}\\n\\nDISTRIBUTED_ARGS=(\\n    --nproc_per_node $GPUS_PER_NODE\\n    --nnodes $NNODES\\n    --node_rank $NODE_RANK\\n    --master_addr $MASTER_ADDR\\n    --master_port $MASTER_PORT\\n)\\n\\n# you can setup llama2-70b maunally\\n#MODEL_ARGS=(\\n#    --model-name llama2\\n#    --num-layers 80\\n#    --hidden-size 8192\\n#    --ffn-hidden-size 28672\\n#    --num-attention-heads 64\\n#    --position-embedding-type rope\\n#    --normalization RMSNorm\\n#    --swiglu\\n#    --attention-dropout 0\\n#    --hidden-dropout 0\\n#    --disable-bias-linear\\n#    --untie-embeddings-and-output-weights\\n#    --group-query-attention\\n#    --num-query-groups 8\\n#)\\n\\n# or you can setup llama2-70b by using the following command\\nMODEL_ARGS=(\\n    --model-name llama2-70b # options: llama2-7b, llama2-13b, llama2-70b\\n)\\n\\nDATA_ARGS=(\\n    --tokenizer-type HFTokenizer\\n    --hf-tokenizer-path $TOKENIZER_PATH\\n    --data-path $DATA_PATH\\n    --split 949,50,1\\n)\\n\\nTRAINING_ARGS=(\\n    --training-phase pretrain # options: pretrain, sft\\n    --seq-length 4096\\n    --max-position-embeddings 4096\\n    --init-method-std 0.01\\n    --micro-batch-size 1\\n    --global-batch-size 1024\\n    --lr 0.0002\\n    --min-lr 1.0e-5\\n    --clip-grad 1.0\\n    --weight-decay 0.01\\n    --optimizer adam\\n    --adam-beta1 0.9\\n    --adam-beta2 0.95\\n    --adam-eps 1e-05\\n    --norm-epsilon 1e-6\\n    --train-iters 500000\\n    --lr-decay-iters 500000\\n    --lr-decay-style cosine\\n    --lr-warmup-fraction 0.002\\n    --initial-loss-scale 16\\n    --fp16\\n    --save-interval 5000\\n    --eval-interval 1000\\n    --eval-iters 10\\n    #--ckpt-step 0\\n    #--no-load-optim\\n    #--no-load-rng\\n)\\n\\nMODEL_PARALLEL_ARGS=(\\n    --tensor-model-parallel-size 4\\n    --pipeline-model-parallel-size 4\\n    --use-distributed-optimizer\\n    --overlap-grad-reduce\\n    --overlap-param-gather\\n    --distributed-backend nccl\\n    --sequence-parallel\\n    #--tp-comm-overlap # require mpi envrionment\\n)\\n\\nLOGGING_ARGS=(\\n    --log-interval 1\\n    --tensorboard-dir ${TENSORBOARD_PATH}\\n    --log-timers-to-tensorboard\\n)\\n\\nif [ -n \\\"${WANDB_API_KEY}\\\" ]; then\\n    LOGGING_ARGS+=(\\n        --wandb-project ${WANDB_PROJECT}\\n        --wandb-exp-name ${WANDB_NAME} \\n    )\\nfi\\n\\nPYTHONPATH=$MEGATRON_PATH:$AIAK_TRAINING_PATH:$PYTHONPATH     torchrun ${DISTRIBUTED_ARGS[@]}     $AIAK_TRAINING_PATH/aiak_training_llm/train.py     ${MODEL_ARGS[@]}     ${DATA_ARGS[@]}     ${TRAINING_ARGS[@]}     ${MODEL_PARALLEL_ARGS[@]}     ${LOGGING_ARGS[@]}\\n\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":true,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi9\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi9/output/training_logs\",\"CUDA_DEVICE_MAX_CONNECTIONS\":\"1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"},\"Worker\":{\"replicas\":3,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi9\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi9/output/training_logs\",\"CUDA_DEVICE_MAX_CONNECTIONS\":\"1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":true,\"logPath\":\"/mnt/cluster/llamatest0718forxiaomi9/output/training_logs\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":true,\"isCopyJob\":true,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
                        "scheduling.k8s.io/job-enable-oversell": "false"
                      },
                      "labels": {
                        "aijob.cce.baidubce.com/ai-user-id": "dd0cc6ebcaa04da5af73af3448ffb35d",
                        "aijob.cce.baidubce.com/ai-user-name": "wangzhuyun",
                        "aijob.cce.baidubce.com/create-from-aihcp": "true",
                        "aijob.cce.baidubce.com/openapi-jobid": "pytorch-6ae32368-97b5-4e0d-9d78-1dcab6fd0361"
                      }
                    },
                    "spec": {
                      "containers": [
                        {
                          "command": [
                            "/bin/bash",
                            "-c",
                            "\n#! /bin/bash\n\nMEGATRON_PATH=${MEGATRON_PATH:-\"/workspace/AIAK-Megatron\"}\nAIAK_TRAINING_PATH=${AIAK_TRAINING_PATH:-\"/workspace/AIAK-Training-LLM\"}\n\nDATA_PATH=${DATA_PATH:-\"/mnt/cluster/llama2/pile_llama_test/pile-llama_text_document\"}\nTOKENIZER_PATH=${TOKENIZER_PATH:-\"/mnt/cluster/llama2/Llama-2-70b-hf/\"}\n\nCHECKPOINT_PATH=${CHECKPOINT_PATH:-\"/mnt/cluster/llama2/mcore_llama2_70b_tp4_pp4\"}\n\nTENSORBOARD_PATH=${TENSORBOARD_PATH:-\"/mnt/cluster/aiak-training-llm/tensorboard-log/llama2-70b-tp4pp4\"}\n\nGPUS_PER_NODE=8\n\n# Change for multinode config\nMASTER_ADDR=${MASTER_ADDR:-\"localhost\"}\nMASTER_PORT=${MASTER_PORT:-\"6000\"}\nNNODES=${WORLD_SIZE:-\"1\"}\nNODE_RANK=${RANK:-\"0\"}\n\nDISTRIBUTED_ARGS=(\n    --nproc_per_node $GPUS_PER_NODE\n    --nnodes $NNODES\n    --node_rank $NODE_RANK\n    --master_addr $MASTER_ADDR\n    --master_port $MASTER_PORT\n)\n\n# you can setup llama2-70b maunally\n#MODEL_ARGS=(\n#    --model-name llama2\n#    --num-layers 80\n#    --hidden-size 8192\n#    --ffn-hidden-size 28672\n#    --num-attention-heads 64\n#    --position-embedding-type rope\n#    --normalization RMSNorm\n#    --swiglu\n#    --attention-dropout 0\n#    --hidden-dropout 0\n#    --disable-bias-linear\n#    --untie-embeddings-and-output-weights\n#    --group-query-attention\n#    --num-query-groups 8\n#)\n\n# or you can setup llama2-70b by using the following command\nMODEL_ARGS=(\n    --model-name llama2-70b # options: llama2-7b, llama2-13b, llama2-70b\n)\n\nDATA_ARGS=(\n    --tokenizer-type HFTokenizer\n    --hf-tokenizer-path $TOKENIZER_PATH\n    --data-path $DATA_PATH\n    --split 949,50,1\n)\n\nTRAINING_ARGS=(\n    --training-phase pretrain # options: pretrain, sft\n    --seq-length 4096\n    --max-position-embeddings 4096\n    --init-method-std 0.01\n    --micro-batch-size 1\n    --global-batch-size 1024\n    --lr 0.0002\n    --min-lr 1.0e-5\n    --clip-grad 1.0\n    --weight-decay 0.01\n    --optimizer adam\n    --adam-beta1 0.9\n    --adam-beta2 0.95\n    --adam-eps 1e-05\n    --norm-epsilon 1e-6\n    --train-iters 500000\n    --lr-decay-iters 500000\n    --lr-decay-style cosine\n    --lr-warmup-fraction 0.002\n    --initial-loss-scale 16\n    --fp16\n    --save-interval 5000\n    --eval-interval 1000\n    --eval-iters 10\n    #--ckpt-step 0\n    #--no-load-optim\n    #--no-load-rng\n)\n\nMODEL_PARALLEL_ARGS=(\n    --tensor-model-parallel-size 4\n    --pipeline-model-parallel-size 4\n    --use-distributed-optimizer\n    --overlap-grad-reduce\n    --overlap-param-gather\n    --distributed-backend nccl\n    --sequence-parallel\n    #--tp-comm-overlap # require mpi envrionment\n)\n\nLOGGING_ARGS=(\n    --log-interval 1\n    --tensorboard-dir ${TENSORBOARD_PATH}\n    --log-timers-to-tensorboard\n)\n\nif [ -n \"${WANDB_API_KEY}\" ]; then\n    LOGGING_ARGS+=(\n        --wandb-project ${WANDB_PROJECT}\n        --wandb-exp-name ${WANDB_NAME} \n    )\nfi\n\nPYTHONPATH=$MEGATRON_PATH:$AIAK_TRAINING_PATH:$PYTHONPATH     torchrun ${DISTRIBUTED_ARGS[@]}     $AIAK_TRAINING_PATH/aiak_training_llm/train.py     ${MODEL_ARGS[@]}     ${DATA_ARGS[@]}     ${TRAINING_ARGS[@]}     ${MODEL_PARALLEL_ARGS[@]}     ${LOGGING_ARGS[@]}\n"
                          ],
                          "env": [
                            {
                              "name": "AIHC_TENSORBOARD_LOG_PATH",
                              "value": "/mnt/cluster/llamatest0718forxiaomi9/output/training_logs"
                            },
                            {
                              "name": "AIHC_JOB_NAME",
                              "value": "llamatest0718forxiaomi9"
                            },
                            {
                              "name": "NCCL_IB_DISABLE",
                              "value": "0"
                            },
                            {
                              "name": "CUDA_DEVICE_MAX_CONNECTIONS",
                              "value": "1"
                            }
                          ],
                          "image": "registry.baidubce.com/aihc-aiak/aiak-training-llm:ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release",
                          "imagePullPolicy": "Always",
                          "name": "pytorch",
                          "ports": [
                            {
                              "containerPort": 23456,
                              "name": "pytorchjob-port",
                              "protocol": "TCP"
                            }
                          ],
                          "resources": {
                            "limits": {
                              "baidu.com/a800_80g_cgpu": "8",
                              "rdma/hca": "1"
                            },
                            "requests": {
                              "baidu.com/a800_80g_cgpu": "8",
                              "rdma/hca": "1"
                            }
                          },
                          "securityContext": {
                            "capabilities": {
                              "add": [
                                "IPC_LOCK"
                              ]
                            }
                          },
                          "volumeMounts": [
                            {
                              "mountPath": "/dev/shm",
                              "name": "devshm"
                            },
                            {
                              "mountPath": "/mnt/cluster",
                              "name": "pvc-pfs"
                            }
                          ]
                        }
                      ],
                      "dnsPolicy": "ClusterFirstWithHostNet",
                      "hostNetwork": true,
                      "schedulerName": "volcano",
                      "volumes": [
                        {
                          "emptyDir": {
                            "medium": "Memory",
                            "sizeLimit": "10Gi"
                          },
                          "name": "devshm"
                        },
                        {
                          "name": "pvc-pfs",
                          "persistentVolumeClaim": {
                            "claimName": "pvc-pfs"
                          }
                        }
                      ]
                    }
                  }
                }
              },
              "runPolicy": {
                "cleanPodPolicy": "None",
                "schedulingPolicy": {
                  "priorityClass": "high",
                  "queue": "default"
                }
              }
            },
            "status": {
              "completionTime": "2024-07-19T11:19:57Z",
              "conditions": [
                {
                  "lastTransitionTime": "2024-07-18T08:39:38Z",
                  "lastUpdateTime": "2024-07-18T08:39:38Z",
                  "message": "PyTorchJob llamatest0718forxiaomi9 is created.",
                  "reason": "PyTorchJobCreated",
                  "status": "True",
                  "type": "Created"
                },
                {
                  "lastTransitionTime": "2024-07-18T08:40:52Z",
                  "lastUpdateTime": "2024-07-18T08:40:52Z",
                  "message": "PyTorchJob llamatest0718forxiaomi9 is running.",
                  "reason": "JobRunning",
                  "status": "False",
                  "type": "Running"
                },
                {
                  "lastTransitionTime": "2024-07-19T11:19:45Z",
                  "lastUpdateTime": "2024-07-19T11:19:45Z",
                  "message": "PytorchJob default/llamatest0718forxiaomi9 is stopped",
                  "reason": "PyTorchJobStopped",
                  "status": "True",
                  "type": "Stopped"
                },
                {
                  "lastTransitionTime": "2024-07-19T11:19:57Z",
                  "lastUpdateTime": "2024-07-19T11:19:57Z",
                  "message": "PyTorchJob llamatest0718forxiaomi9 is failed because 1 Worker replica(s) failed.",
                  "reason": "JobFailed",
                  "status": "True",
                  "type": "Failed"
                }
              ],
              "lastReconcileTime": "2024-07-18T08:39:38Z",
              "replicaStatuses": {
                "Master": {
                  "active": 1,
                  "selector": "training.kubeflow.org/job-name=llamatest0718forxiaomi9,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=master"
                },
                "Worker": {
                  "active": 2,
                  "failed": 1,
                  "selector": "training.kubeflow.org/job-name=llamatest0718forxiaomi9,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=worker"
                }
              },
              "startTime": "2024-07-18T08:39:39Z"
            }
          },
          {
            "apiVersion": "kubeflow.org/v1",
            "kind": "PyTorchJob",
            "metadata": {
              "annotations": {
                "aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": "",
                "aijob.cce.baidubce.com/timeline": "[{\"conditionType\":\"Created\",\"time\":1721028726},{\"conditionType\":\"Scheduled\",\"time\":1721028727},{\"conditionType\":\"Running\",\"time\":1721028737},{\"conditionType\":\"Failed\",\"time\":1721272510}]",
                "kubectl.kubernetes.io/last-applied-configuration": "{\"apiVersion\":\"kubeflow.org/v1\",\"kind\":\"PyTorchJob\",\"metadata\":{\"annotations\":{},\"name\":\"pangbo-12h-modelcompass-eval\",\"namespace\":\"default\"},\"spec\":{\"pytorchReplicaSpecs\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"template\":{\"metadata\":null,\"spec\":{\"containers\":[{\"command\":[\"bash\",\"-c\",\"sleep 4d\",\"/workspace/launch.sh\"],\"env\":[{\"name\":\"CUDA_DEVICE_MAX_CONNECTIONS\",\"value\":\"1\"},{\"name\":\"NCCL_DEBUG\",\"value\":\"INFO\"},{\"name\":\"NCCL_IB_DISABLE\",\"value\":\"0\"},{\"name\":\"MASTER\",\"value\":\"1\"}],\"image\":\"registry.baidubce.com/cce-ai-native/aiak-algo:0.1\",\"imagePullPolicy\":\"Always\",\"name\":\"pytorch\",\"resources\":{\"limits\":{\"nvidia.com/gpu\":8,\"rdma/hca\":1}},\"securityContext\":{\"capabilities\":{\"add\":[\"IPC_LOCK\"]}},\"volumeMounts\":[{\"mountPath\":\"/dev/shm\",\"name\":\"cache-volume\"},{\"mountPath\":\"/workspace/launch.sh\",\"name\":\"config-volume\",\"subPath\":\"launch.sh\"},{\"mountPath\":\"/mnt/cluster\",\"name\":\"data\"}]}],\"schedulerName\":\"volcano\",\"volumes\":[{\"emptyDir\":{\"medium\":\"Memory\"},\"name\":\"cache-volume\"},{\"configMap\":{\"name\":\"pangbo-12h-modelcompass-eval\"},\"name\":\"config-volume\"},{\"name\":\"data\",\"persistentVolumeClaim\":{\"claimName\":\"pvc-pfs\"}}]}}}}}}\n"
              },
              "creationTimestamp": "2024-07-15T07:32:06Z",
              "generation": 2,
              "managedFields": [
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        "f:aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": {},
                        "f:aijob.cce.baidubce.com/timeline": {}
                      }
                    },
                    "f:spec": {
                      "f:pytorchReplicaSpecs": {
                        "f:Master": {
                          "f:template": {
                            "f:metadata": {},
                            "f:spec": {
                              "f:containers": {}
                            }
                          }
                        }
                      },
                      "f:runPolicy": {
                        ".": {},
                        "f:cleanPodPolicy": {}
                      }
                    }
                  },
                  "manager": "controller",
                  "operation": "Update",
                  "time": "2024-07-15T07:32:06Z"
                },
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        ".": {},
                        "f:kubectl.kubernetes.io/last-applied-configuration": {}
                      }
                    },
                    "f:spec": {
                      ".": {},
                      "f:pytorchReplicaSpecs": {
                        ".": {},
                        "f:Master": {
                          ".": {},
                          "f:replicas": {},
                          "f:restartPolicy": {},
                          "f:template": {
                            ".": {},
                            "f:spec": {
                              ".": {},
                              "f:schedulerName": {},
                              "f:volumes": {}
                            }
                          }
                        }
                      }
                    }
                  },
                  "manager": "kubectl-client-side-apply",
                  "operation": "Update",
                  "time": "2024-07-15T07:32:06Z"
                },
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:status": {
                      ".": {},
                      "f:completionTime": {},
                      "f:conditions": {},
                      "f:lastReconcileTime": {},
                      "f:replicaStatuses": {
                        ".": {},
                        "f:Master": {
                          ".": {},
                          "f:failed": {},
                          "f:selector": {}
                        }
                      },
                      "f:startTime": {}
                    }
                  },
                  "manager": "manager",
                  "operation": "Update",
                  "time": "2024-07-18T03:15:10Z"
                }
              ],
              "name": "pangbo-12h-modelcompass-eval",
              "namespace": "default",
              "resourceVersion": "2371234821",
              "uid": "fec5fdd4-ffcd-46cc-832a-913ec1717de8"
            },
            "spec": {
              "pytorchReplicaSpecs": {
                "Master": {
                  "replicas": 1,
                  "restartPolicy": "Never",
                  "template": {
                    "metadata": {},
                    "spec": {
                      "containers": [
                        {
                          "command": [
                            "bash",
                            "-c",
                            "sleep 4d",
                            "/workspace/launch.sh"
                          ],
                          "env": [
                            {
                              "name": "CUDA_DEVICE_MAX_CONNECTIONS",
                              "value": "1"
                            },
                            {
                              "name": "NCCL_DEBUG",
                              "value": "INFO"
                            },
                            {
                              "name": "NCCL_IB_DISABLE",
                              "value": "0"
                            },
                            {
                              "name": "MASTER",
                              "value": "1"
                            }
                          ],
                          "image": "registry.baidubce.com/cce-ai-native/aiak-algo:0.1",
                          "imagePullPolicy": "Always",
                          "name": "pytorch",
                          "ports": [
                            {
                              "containerPort": 23456,
                              "name": "pytorchjob-port",
                              "protocol": "TCP"
                            }
                          ],
                          "resources": {
                            "limits": {
                              "nvidia.com/gpu": "8",
                              "rdma/hca": "1"
                            }
                          },
                          "securityContext": {
                            "capabilities": {
                              "add": [
                                "IPC_LOCK"
                              ]
                            }
                          },
                          "volumeMounts": [
                            {
                              "mountPath": "/dev/shm",
                              "name": "cache-volume"
                            },
                            {
                              "mountPath": "/workspace/launch.sh",
                              "name": "config-volume",
                              "subPath": "launch.sh"
                            },
                            {
                              "mountPath": "/mnt/cluster",
                              "name": "data"
                            }
                          ]
                        }
                      ],
                      "schedulerName": "volcano",
                      "volumes": [
                        {
                          "emptyDir": {
                            "medium": "Memory"
                          },
                          "name": "cache-volume"
                        },
                        {
                          "configMap": {
                            "name": "pangbo-12h-modelcompass-eval"
                          },
                          "name": "config-volume"
                        },
                        {
                          "name": "data",
                          "persistentVolumeClaim": {
                            "claimName": "pvc-pfs"
                          }
                        }
                      ]
                    }
                  }
                }
              },
              "runPolicy": {
                "cleanPodPolicy": "None"
              }
            },
            "status": {
              "completionTime": "2024-07-18T03:15:10Z",
              "conditions": [
                {
                  "lastTransitionTime": "2024-07-15T07:32:06Z",
                  "lastUpdateTime": "2024-07-15T07:32:06Z",
                  "message": "PyTorchJob pangbo-12h-modelcompass-eval is created.",
                  "reason": "PyTorchJobCreated",
                  "status": "True",
                  "type": "Created"
                },
                {
                  "lastTransitionTime": "2024-07-15T07:32:17Z",
                  "lastUpdateTime": "2024-07-15T07:32:17Z",
                  "message": "PyTorchJob pangbo-12h-modelcompass-eval is running.",
                  "reason": "JobRunning",
                  "status": "False",
                  "type": "Running"
                },
                {
                  "lastTransitionTime": "2024-07-18T03:15:10Z",
                  "lastUpdateTime": "2024-07-18T03:15:10Z",
                  "message": "PyTorchJob pangbo-12h-modelcompass-eval is failed because 1 Master replica(s) failed.",
                  "reason": "JobFailed",
                  "status": "True",
                  "type": "Failed"
                }
              ],
              "lastReconcileTime": "2024-07-15T07:32:06Z",
              "replicaStatuses": {
                "Master": {
                  "failed": 1,
                  "selector": "training.kubeflow.org/job-name=pangbo-12h-modelcompass-eval,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=master"
                }
              },
              "startTime": "2024-07-15T07:32:07Z"
            }
          },
          {
            "apiVersion": "kubeflow.org/v1",
            "kind": "PyTorchJob",
            "metadata": {
              "annotations": {
                "aijob.cce.baidubce.com/fault-tolerance-enabled": "true",
                "aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": "",
                "aijob.cce.baidubce.com/timeline": "[{\"conditionType\":\"Created\",\"time\":1721655040}]",
                "kubectl.kubernetes.io/last-applied-configuration": "{\"apiVersion\":\"kubeflow.org/v1\",\"kind\":\"PyTorchJob\",\"metadata\":{\"annotations\":{},\"name\":\"pangbo-48h-megatron-llama3-longcontext-pre\",\"namespace\":\"default\"},\"spec\":{\"pytorchReplicaSpecs\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"template\":{\"metadata\":null,\"spec\":{\"containers\":[{\"command\":[\"bash\",\"/workspace/launch.sh\"],\"env\":[{\"name\":\"CUDA_DEVICE_MAX_CONNECTIONS\",\"value\":\"1\"},{\"name\":\"NCCL_DEBUG\",\"value\":\"INFO\"},{\"name\":\"NCCL_IB_DISABLE\",\"value\":\"0\"},{\"name\":\"MASTER\",\"value\":\"1\"}],\"image\":\"registry.baidubce.com/hac-aiacc/aiak-training-llm:ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_dev_20240718_204220\",\"imagePullPolicy\":\"Always\",\"name\":\"pytorch\",\"resources\":{\"limits\":{\"nvidia.com/gpu\":8,\"rdma/hca\":1}},\"securityContext\":{\"capabilities\":{\"add\":[\"IPC_LOCK\"]}},\"volumeMounts\":[{\"mountPath\":\"/dev/shm\",\"name\":\"cache-volume\"},{\"mountPath\":\"/workspace/launch.sh\",\"name\":\"config-volume\",\"subPath\":\"launch.sh\"},{\"mountPath\":\"/mnt/cluster\",\"name\":\"data\"}]}],\"schedulerName\":\"volcano\",\"volumes\":[{\"emptyDir\":{\"medium\":\"Memory\"},\"name\":\"cache-volume\"},{\"configMap\":{\"name\":\"pangbo-48h-megatron-llama3-longcontext-pre\"},\"name\":\"config-volume\"},{\"name\":\"data\",\"persistentVolumeClaim\":{\"claimName\":\"pvc-pfs\"}}]}}},\"Worker\":{\"replicas\":3,\"restartPolicy\":\"Never\",\"template\":{\"spec\":{\"containers\":[{\"command\":[\"bash\",\"/workspace/launch.sh\"],\"env\":[{\"name\":\"CUDA_DEVICE_MAX_CONNECTIONS\",\"value\":\"1\"},{\"name\":\"NCCL_DEBUG\",\"value\":\"INFO\"},{\"name\":\"NCCL_IB_DISABLE\",\"value\":\"0\"}],\"image\":\"registry.baidubce.com/hac-aiacc/aiak-training-llm:ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_dev_20240718_204220\",\"imagePullPolicy\":\"Always\",\"name\":\"pytorch\",\"resources\":{\"limits\":{\"nvidia.com/gpu\":8,\"rdma/hca\":1}},\"securityContext\":{\"capabilities\":{\"add\":[\"IPC_LOCK\"]}},\"volumeMounts\":[{\"mountPath\":\"/dev/shm\",\"name\":\"cache-volume\"},{\"mountPath\":\"/workspace/launch.sh\",\"name\":\"config-volume\",\"subPath\":\"launch.sh\"},{\"mountPath\":\"/mnt/cluster\",\"name\":\"data\"}]}],\"schedulerName\":\"volcano\",\"volumes\":[{\"emptyDir\":{\"medium\":\"Memory\"},\"name\":\"cache-volume\"},{\"configMap\":{\"name\":\"pangbo-48h-megatron-llama3-longcontext-pre\"},\"name\":\"config-volume\"},{\"name\":\"data\",\"persistentVolumeClaim\":{\"claimName\":\"pvc-pfs\"}}]}}}}}}\n"
              },
              "creationTimestamp": "2024-07-22T13:30:40Z",
              "generation": 2,
              "managedFields": [
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        "f:aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": {},
                        "f:aijob.cce.baidubce.com/timeline": {}
                      }
                    }
                  },
                  "manager": "controller",
                  "operation": "Update",
                  "time": "2024-07-22T13:30:40Z"
                },
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        ".": {},
                        "f:kubectl.kubernetes.io/last-applied-configuration": {}
                      }
                    },
                    "f:spec": {
                      ".": {},
                      "f:pytorchReplicaSpecs": {
                        ".": {},
                        "f:Master": {
                          ".": {},
                          "f:replicas": {},
                          "f:restartPolicy": {},
                          "f:template": {
                            ".": {},
                            "f:spec": {
                              ".": {},
                              "f:schedulerName": {},
                              "f:volumes": {}
                            }
                          }
                        },
                        "f:Worker": {
                          ".": {},
                          "f:replicas": {},
                          "f:restartPolicy": {},
                          "f:template": {
                            ".": {},
                            "f:spec": {
                              ".": {},
                              "f:schedulerName": {},
                              "f:volumes": {}
                            }
                          }
                        }
                      }
                    }
                  },
                  "manager": "kubectl-client-side-apply",
                  "operation": "Update",
                  "time": "2024-07-22T13:30:40Z"
                },
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {}
                      }
                    },
                    "f:spec": {
                      "f:pytorchReplicaSpecs": {
                        "f:Master": {
                          "f:template": {
                            "f:metadata": {},
                            "f:spec": {
                              "f:containers": {}
                            }
                          }
                        },
                        "f:Worker": {
                          "f:template": {
                            "f:metadata": {},
                            "f:spec": {
                              "f:containers": {}
                            }
                          }
                        }
                      },
                      "f:runPolicy": {
                        ".": {},
                        "f:cleanPodPolicy": {}
                      }
                    },
                    "f:status": {
                      ".": {},
                      "f:conditions": {},
                      "f:lastReconcileTime": {},
                      "f:replicaStatuses": {
                        ".": {},
                        "f:Master": {
                          ".": {},
                          "f:selector": {}
                        },
                        "f:Worker": {
                          ".": {},
                          "f:selector": {}
                        }
                      },
                      "f:startTime": {}
                    }
                  },
                  "manager": "manager",
                  "operation": "Update",
                  "time": "2024-07-22T13:30:41Z"
                }
              ],
              "name": "pangbo-48h-megatron-llama3-longcontext-pre",
              "namespace": "default",
              "resourceVersion": "2376331138",
              "uid": "6f074d4f-0e40-4539-9db0-39805a24f55a"
            },
            "spec": {
              "pytorchReplicaSpecs": {
                "Master": {
                  "replicas": 1,
                  "restartPolicy": "Never",
                  "template": {
                    "metadata": {},
                    "spec": {
                      "containers": [
                        {
                          "command": [
                            "bash",
                            "/workspace/launch.sh"
                          ],
                          "env": [
                            {
                              "name": "CUDA_DEVICE_MAX_CONNECTIONS",
                              "value": "1"
                            },
                            {
                              "name": "NCCL_DEBUG",
                              "value": "INFO"
                            },
                            {
                              "name": "NCCL_IB_DISABLE",
                              "value": "0"
                            },
                            {
                              "name": "MASTER",
                              "value": "1"
                            }
                          ],
                          "image": "registry.baidubce.com/hac-aiacc/aiak-training-llm:ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_dev_20240718_204220",
                          "imagePullPolicy": "Always",
                          "name": "pytorch",
                          "ports": [
                            {
                              "containerPort": 23456,
                              "name": "pytorchjob-port",
                              "protocol": "TCP"
                            }
                          ],
                          "resources": {
                            "limits": {
                              "nvidia.com/gpu": "8",
                              "rdma/hca": "1"
                            }
                          },
                          "securityContext": {
                            "capabilities": {
                              "add": [
                                "IPC_LOCK"
                              ]
                            }
                          },
                          "volumeMounts": [
                            {
                              "mountPath": "/dev/shm",
                              "name": "cache-volume"
                            },
                            {
                              "mountPath": "/workspace/launch.sh",
                              "name": "config-volume",
                              "subPath": "launch.sh"
                            },
                            {
                              "mountPath": "/mnt/cluster",
                              "name": "data"
                            }
                          ]
                        }
                      ],
                      "schedulerName": "volcano",
                      "volumes": [
                        {
                          "emptyDir": {
                            "medium": "Memory"
                          },
                          "name": "cache-volume"
                        },
                        {
                          "configMap": {
                            "name": "pangbo-48h-megatron-llama3-longcontext-pre"
                          },
                          "name": "config-volume"
                        },
                        {
                          "name": "data",
                          "persistentVolumeClaim": {
                            "claimName": "pvc-pfs"
                          }
                        }
                      ]
                    }
                  }
                },
                "Worker": {
                  "replicas": 3,
                  "restartPolicy": "Never",
                  "template": {
                    "metadata": {},
                    "spec": {
                      "containers": [
                        {
                          "command": [
                            "bash",
                            "/workspace/launch.sh"
                          ],
                          "env": [
                            {
                              "name": "CUDA_DEVICE_MAX_CONNECTIONS",
                              "value": "1"
                            },
                            {
                              "name": "NCCL_DEBUG",
                              "value": "INFO"
                            },
                            {
                              "name": "NCCL_IB_DISABLE",
                              "value": "0"
                            }
                          ],
                          "image": "registry.baidubce.com/hac-aiacc/aiak-training-llm:ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_dev_20240718_204220",
                          "imagePullPolicy": "Always",
                          "name": "pytorch",
                          "ports": [
                            {
                              "containerPort": 23456,
                              "name": "pytorchjob-port",
                              "protocol": "TCP"
                            }
                          ],
                          "resources": {
                            "limits": {
                              "nvidia.com/gpu": "8",
                              "rdma/hca": "1"
                            }
                          },
                          "securityContext": {
                            "capabilities": {
                              "add": [
                                "IPC_LOCK"
                              ]
                            }
                          },
                          "volumeMounts": [
                            {
                              "mountPath": "/dev/shm",
                              "name": "cache-volume"
                            },
                            {
                              "mountPath": "/workspace/launch.sh",
                              "name": "config-volume",
                              "subPath": "launch.sh"
                            },
                            {
                              "mountPath": "/mnt/cluster",
                              "name": "data"
                            }
                          ]
                        }
                      ],
                      "schedulerName": "volcano",
                      "volumes": [
                        {
                          "emptyDir": {
                            "medium": "Memory"
                          },
                          "name": "cache-volume"
                        },
                        {
                          "configMap": {
                            "name": "pangbo-48h-megatron-llama3-longcontext-pre"
                          },
                          "name": "config-volume"
                        },
                        {
                          "name": "data",
                          "persistentVolumeClaim": {
                            "claimName": "pvc-pfs"
                          }
                        }
                      ]
                    }
                  }
                }
              },
              "runPolicy": {
                "cleanPodPolicy": "None"
              }
            },
            "status": {
              "conditions": [
                {
                  "lastTransitionTime": "2024-07-22T13:30:40Z",
                  "lastUpdateTime": "2024-07-22T13:30:40Z",
                  "message": "PyTorchJob pangbo-48h-megatron-llama3-longcontext-pre is created.",
                  "reason": "PyTorchJobCreated",
                  "status": "True",
                  "type": "Created"
                }
              ],
              "lastReconcileTime": "2024-07-22T13:30:41Z",
              "replicaStatuses": {
                "Master": {
                  "selector": "training.kubeflow.org/job-name=pangbo-48h-megatron-llama3-longcontext-pre,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=master"
                },
                "Worker": {
                  "selector": "training.kubeflow.org/job-name=pangbo-48h-megatron-llama3-longcontext-pre,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=worker"
                }
              },
              "startTime": "2024-07-22T13:30:41Z"
            }
          },
          {
            "apiVersion": "kubeflow.org/v1",
            "kind": "PyTorchJob",
            "metadata": {
              "annotations": {
                "aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": "",
                "aijob.cce.baidubce.com/timeline": "[{\"conditionType\":\"Created\",\"time\":1721371809},{\"conditionType\":\"Scheduled\",\"time\":1721371811},{\"conditionType\":\"Running\",\"time\":1721371823}]",
                "kubectl.kubernetes.io/last-applied-configuration": "{\"apiVersion\":\"kubeflow.org/v1\",\"kind\":\"PyTorchJob\",\"metadata\":{\"annotations\":{},\"name\":\"pangbo-modelcompass-longcontext\",\"namespace\":\"default\"},\"spec\":{\"pytorchReplicaSpecs\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"template\":{\"metadata\":null,\"spec\":{\"containers\":[{\"command\":[\"bash\",\"-c\",\"sleep infinity\",\"/workspace/launch.sh\"],\"env\":[{\"name\":\"CUDA_DEVICE_MAX_CONNECTIONS\",\"value\":\"1\"},{\"name\":\"NCCL_DEBUG\",\"value\":\"INFO\"},{\"name\":\"NCCL_IB_DISABLE\",\"value\":\"0\"},{\"name\":\"MASTER\",\"value\":\"1\"}],\"image\":\"registry.baidubce.com/cce-ai-native/aiak-algo:0.1\",\"imagePullPolicy\":\"Always\",\"name\":\"pytorch\",\"resources\":{\"limits\":{\"nvidia.com/gpu\":8,\"rdma/hca\":1}},\"securityContext\":{\"capabilities\":{\"add\":[\"IPC_LOCK\"]}},\"volumeMounts\":[{\"mountPath\":\"/dev/shm\",\"name\":\"cache-volume\"},{\"mountPath\":\"/workspace/launch.sh\",\"name\":\"config-volume\",\"subPath\":\"launch.sh\"},{\"mountPath\":\"/mnt/cluster\",\"name\":\"data\"}]}],\"schedulerName\":\"volcano\",\"volumes\":[{\"emptyDir\":{\"medium\":\"Memory\"},\"name\":\"cache-volume\"},{\"configMap\":{\"name\":\"pangbo-modelcompass-longcontext\"},\"name\":\"config-volume\"},{\"name\":\"data\",\"persistentVolumeClaim\":{\"claimName\":\"pvc-pfs\"}}]}}}}}}\n"
              },
              "creationTimestamp": "2024-07-19T06:50:09Z",
              "generation": 2,
              "managedFields": [
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        "f:aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": {},
                        "f:aijob.cce.baidubce.com/timeline": {}
                      }
                    },
                    "f:spec": {
                      "f:pytorchReplicaSpecs": {
                        "f:Master": {
                          "f:template": {
                            "f:metadata": {},
                            "f:spec": {
                              "f:containers": {}
                            }
                          }
                        }
                      },
                      "f:runPolicy": {
                        ".": {},
                        "f:cleanPodPolicy": {}
                      }
                    }
                  },
                  "manager": "controller",
                  "operation": "Update",
                  "time": "2024-07-19T06:50:09Z"
                },
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        ".": {},
                        "f:kubectl.kubernetes.io/last-applied-configuration": {}
                      }
                    },
                    "f:spec": {
                      ".": {},
                      "f:pytorchReplicaSpecs": {
                        ".": {},
                        "f:Master": {
                          ".": {},
                          "f:replicas": {},
                          "f:restartPolicy": {},
                          "f:template": {
                            ".": {},
                            "f:spec": {
                              ".": {},
                              "f:schedulerName": {},
                              "f:volumes": {}
                            }
                          }
                        }
                      }
                    }
                  },
                  "manager": "kubectl-client-side-apply",
                  "operation": "Update",
                  "time": "2024-07-19T06:50:09Z"
                },
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:status": {
                      ".": {},
                      "f:conditions": {},
                      "f:lastReconcileTime": {},
                      "f:replicaStatuses": {
                        ".": {},
                        "f:Master": {
                          ".": {},
                          "f:active": {},
                          "f:selector": {}
                        }
                      },
                      "f:startTime": {}
                    }
                  },
                  "manager": "manager",
                  "operation": "Update",
                  "time": "2024-07-19T06:50:23Z"
                }
              ],
              "name": "pangbo-modelcompass-longcontext",
              "namespace": "default",
              "resourceVersion": "2372606547",
              "uid": "b8698c07-ca1e-4dd7-bb61-029dbcd4d754"
            },
            "spec": {
              "pytorchReplicaSpecs": {
                "Master": {
                  "replicas": 1,
                  "restartPolicy": "Never",
                  "template": {
                    "metadata": {},
                    "spec": {
                      "containers": [
                        {
                          "command": [
                            "bash",
                            "-c",
                            "sleep infinity",
                            "/workspace/launch.sh"
                          ],
                          "env": [
                            {
                              "name": "CUDA_DEVICE_MAX_CONNECTIONS",
                              "value": "1"
                            },
                            {
                              "name": "NCCL_DEBUG",
                              "value": "INFO"
                            },
                            {
                              "name": "NCCL_IB_DISABLE",
                              "value": "0"
                            },
                            {
                              "name": "MASTER",
                              "value": "1"
                            }
                          ],
                          "image": "registry.baidubce.com/cce-ai-native/aiak-algo:0.1",
                          "imagePullPolicy": "Always",
                          "name": "pytorch",
                          "ports": [
                            {
                              "containerPort": 23456,
                              "name": "pytorchjob-port",
                              "protocol": "TCP"
                            }
                          ],
                          "resources": {
                            "limits": {
                              "nvidia.com/gpu": "8",
                              "rdma/hca": "1"
                            }
                          },
                          "securityContext": {
                            "capabilities": {
                              "add": [
                                "IPC_LOCK"
                              ]
                            }
                          },
                          "volumeMounts": [
                            {
                              "mountPath": "/dev/shm",
                              "name": "cache-volume"
                            },
                            {
                              "mountPath": "/workspace/launch.sh",
                              "name": "config-volume",
                              "subPath": "launch.sh"
                            },
                            {
                              "mountPath": "/mnt/cluster",
                              "name": "data"
                            }
                          ]
                        }
                      ],
                      "schedulerName": "volcano",
                      "volumes": [
                        {
                          "emptyDir": {
                            "medium": "Memory"
                          },
                          "name": "cache-volume"
                        },
                        {
                          "configMap": {
                            "name": "pangbo-modelcompass-longcontext"
                          },
                          "name": "config-volume"
                        },
                        {
                          "name": "data",
                          "persistentVolumeClaim": {
                            "claimName": "pvc-pfs"
                          }
                        }
                      ]
                    }
                  }
                }
              },
              "runPolicy": {
                "cleanPodPolicy": "None"
              }
            },
            "status": {
              "conditions": [
                {
                  "lastTransitionTime": "2024-07-19T06:50:09Z",
                  "lastUpdateTime": "2024-07-19T06:50:09Z",
                  "message": "PyTorchJob pangbo-modelcompass-longcontext is created.",
                  "reason": "PyTorchJobCreated",
                  "status": "True",
                  "type": "Created"
                },
                {
                  "lastTransitionTime": "2024-07-19T06:50:23Z",
                  "lastUpdateTime": "2024-07-19T06:50:23Z",
                  "message": "PyTorchJob pangbo-modelcompass-longcontext is running.",
                  "reason": "JobRunning",
                  "status": "True",
                  "type": "Running"
                }
              ],
              "lastReconcileTime": "2024-07-19T06:50:09Z",
              "replicaStatuses": {
                "Master": {
                  "active": 1,
                  "selector": "training.kubeflow.org/job-name=pangbo-modelcompass-longcontext,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=master"
                }
              },
              "startTime": "2024-07-19T06:50:10Z"
            }
          },
          {
            "apiVersion": "kubeflow.org/v1",
            "kind": "PyTorchJob",
            "metadata": {
              "annotations": {
                "aijob.cce.baidubce.com/barrier-finish": "55a7279d-e844-4868-9f72-766bf94d7fd1",
                "aijob.cce.baidubce.com/fault-tolerance-enabled": "false",
                "aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": "",
                "aijob.cce.baidubce.com/openapi-jobid": "pytorch-bcdbd3fe-46d7-4caf-a587-93aa8c501a3f",
                "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
                "aijob.cce.baidubce.com/raw-request": "{\"name\":\"pengxiangyu-48hours-deepseek3\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"high\",\"oversell\":false,\"faultTolerance\":false,\"command\":\"sleep 100000000\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":true,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/hac-aiacc/pxy_megatron\",\"tag\":\"20240722\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"pengxiangyu-48hours-deepseek3\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"},\"Worker\":{\"replicas\":7,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/hac-aiacc/pxy_megatron\",\"tag\":\"20240722\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"pengxiangyu-48hours-deepseek3\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":false,\"logPath\":\"\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":true,\"isCopyJob\":true,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
                "aijob.cce.baidubce.com/timeline": "[{\"conditionType\":\"Created\",\"time\":1721640261},{\"conditionType\":\"Scheduled\",\"time\":1721640451},{\"conditionType\":\"Running\",\"time\":1721640803}]",
                "scheduling.k8s.io/job-enable-oversell": "false"
              },
              "creationTimestamp": "2024-07-22T09:24:21Z",
              "generation": 2,
              "labels": {
                "aijob.cce.baidubce.com/ai-user-id": "b54a2f2a03dc4237b19f5df1b1b6e252",
                "aijob.cce.baidubce.com/ai-user-name": "pengxiangyu",
                "aijob.cce.baidubce.com/create-from-aihcp": "true",
                "aijob.cce.baidubce.com/openapi-jobid": "pytorch-bcdbd3fe-46d7-4caf-a587-93aa8c501a3f"
              },
              "managedFields": [
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        ".": {},
                        "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                        "f:aijob.cce.baidubce.com/openapi-jobid": {},
                        "f:aijob.cce.baidubce.com/pfs-id": {},
                        "f:aijob.cce.baidubce.com/raw-request": {},
                        "f:scheduling.k8s.io/job-enable-oversell": {}
                      },
                      "f:labels": {
                        ".": {},
                        "f:aijob.cce.baidubce.com/ai-user-id": {},
                        "f:aijob.cce.baidubce.com/ai-user-name": {},
                        "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                        "f:aijob.cce.baidubce.com/openapi-jobid": {}
                      }
                    },
                    "f:spec": {
                      ".": {},
                      "f:pytorchReplicaSpecs": {
                        ".": {},
                        "f:Master": {
                          ".": {},
                          "f:replicas": {},
                          "f:restartPolicy": {},
                          "f:template": {
                            ".": {},
                            "f:metadata": {
                              ".": {},
                              "f:annotations": {
                                ".": {},
                                "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                                "f:aijob.cce.baidubce.com/openapi-jobid": {},
                                "f:aijob.cce.baidubce.com/pfs-id": {},
                                "f:aijob.cce.baidubce.com/raw-request": {},
                                "f:scheduling.k8s.io/job-enable-oversell": {}
                              },
                              "f:labels": {
                                ".": {},
                                "f:aijob.cce.baidubce.com/ai-user-id": {},
                                "f:aijob.cce.baidubce.com/ai-user-name": {},
                                "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                                "f:aijob.cce.baidubce.com/openapi-jobid": {}
                              }
                            },
                            "f:spec": {
                              ".": {},
                              "f:dnsPolicy": {},
                              "f:hostNetwork": {},
                              "f:schedulerName": {},
                              "f:volumes": {}
                            }
                          }
                        },
                        "f:Worker": {
                          ".": {},
                          "f:replicas": {},
                          "f:restartPolicy": {},
                          "f:template": {
                            ".": {},
                            "f:metadata": {
                              ".": {},
                              "f:annotations": {
                                ".": {},
                                "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                                "f:aijob.cce.baidubce.com/openapi-jobid": {},
                                "f:aijob.cce.baidubce.com/pfs-id": {},
                                "f:aijob.cce.baidubce.com/raw-request": {},
                                "f:scheduling.k8s.io/job-enable-oversell": {}
                              },
                              "f:labels": {
                                ".": {},
                                "f:aijob.cce.baidubce.com/ai-user-id": {},
                                "f:aijob.cce.baidubce.com/ai-user-name": {},
                                "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                                "f:aijob.cce.baidubce.com/openapi-jobid": {}
                              }
                            },
                            "f:spec": {
                              ".": {},
                              "f:dnsPolicy": {},
                              "f:hostNetwork": {},
                              "f:schedulerName": {},
                              "f:volumes": {}
                            }
                          }
                        }
                      },
                      "f:runPolicy": {
                        ".": {},
                        "f:schedulingPolicy": {
                          ".": {},
                          "f:priorityClass": {},
                          "f:queue": {}
                        }
                      }
                    }
                  },
                  "manager": "cce-ai-service",
                  "operation": "Update",
                  "time": "2024-07-22T09:24:21Z"
                },
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        "f:aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": {},
                        "f:aijob.cce.baidubce.com/timeline": {}
                      }
                    },
                    "f:spec": {
                      "f:pytorchReplicaSpecs": {
                        "f:Master": {
                          "f:template": {
                            "f:spec": {
                              "f:containers": {}
                            }
                          }
                        },
                        "f:Worker": {
                          "f:template": {
                            "f:spec": {
                              "f:containers": {}
                            }
                          }
                        }
                      },
                      "f:runPolicy": {
                        "f:cleanPodPolicy": {}
                      }
                    }
                  },
                  "manager": "controller",
                  "operation": "Update",
                  "time": "2024-07-22T09:24:21Z"
                },
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        "f:aijob.cce.baidubce.com/barrier-finish": {}
                      }
                    }
                  },
                  "manager": "jobbarrier",
                  "operation": "Update",
                  "time": "2024-07-22T09:33:20Z"
                },
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:status": {
                      ".": {},
                      "f:conditions": {},
                      "f:lastReconcileTime": {},
                      "f:replicaStatuses": {
                        ".": {},
                        "f:Master": {
                          ".": {},
                          "f:active": {},
                          "f:selector": {}
                        },
                        "f:Worker": {
                          ".": {},
                          "f:active": {},
                          "f:selector": {}
                        }
                      },
                      "f:startTime": {}
                    }
                  },
                  "manager": "manager",
                  "operation": "Update",
                  "time": "2024-07-22T09:33:27Z"
                }
              ],
              "name": "pengxiangyu-48hours-deepseek3",
              "namespace": "default",
              "resourceVersion": "2376142069",
              "uid": "2c2d004e-987d-4518-9ec2-3a0bafaccaf9"
            },
            "spec": {
              "pytorchReplicaSpecs": {
                "Master": {
                  "replicas": 1,
                  "restartPolicy": "Never",
                  "template": {
                    "metadata": {
                      "annotations": {
                        "aijob.cce.baidubce.com/fault-tolerance-enabled": "false",
                        "aijob.cce.baidubce.com/openapi-jobid": "pytorch-bcdbd3fe-46d7-4caf-a587-93aa8c501a3f",
                        "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
                        "aijob.cce.baidubce.com/raw-request": "{\"name\":\"pengxiangyu-48hours-deepseek3\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"high\",\"oversell\":false,\"faultTolerance\":false,\"command\":\"sleep 100000000\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":true,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/hac-aiacc/pxy_megatron\",\"tag\":\"20240722\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"pengxiangyu-48hours-deepseek3\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"},\"Worker\":{\"replicas\":7,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/hac-aiacc/pxy_megatron\",\"tag\":\"20240722\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"pengxiangyu-48hours-deepseek3\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":false,\"logPath\":\"\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":true,\"isCopyJob\":true,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
                        "scheduling.k8s.io/job-enable-oversell": "false"
                      },
                      "labels": {
                        "aijob.cce.baidubce.com/ai-user-id": "b54a2f2a03dc4237b19f5df1b1b6e252",
                        "aijob.cce.baidubce.com/ai-user-name": "pengxiangyu",
                        "aijob.cce.baidubce.com/create-from-aihcp": "true",
                        "aijob.cce.baidubce.com/openapi-jobid": "pytorch-bcdbd3fe-46d7-4caf-a587-93aa8c501a3f"
                      }
                    },
                    "spec": {
                      "containers": [
                        {
                          "command": [
                            "/bin/bash",
                            "-c",
                            "sleep 100000000"
                          ],
                          "env": [
                            {
                              "name": "AIHC_JOB_NAME",
                              "value": "pengxiangyu-48hours-deepseek3"
                            },
                            {
                              "name": "NCCL_IB_DISABLE",
                              "value": "0"
                            }
                          ],
                          "image": "registry.baidubce.com/hac-aiacc/pxy_megatron:20240722",
                          "imagePullPolicy": "Always",
                          "name": "pytorch",
                          "ports": [
                            {
                              "containerPort": 23456,
                              "name": "pytorchjob-port",
                              "protocol": "TCP"
                            }
                          ],
                          "resources": {
                            "limits": {
                              "baidu.com/a800_80g_cgpu": "8",
                              "rdma/hca": "1"
                            },
                            "requests": {
                              "baidu.com/a800_80g_cgpu": "8",
                              "rdma/hca": "1"
                            }
                          },
                          "securityContext": {
                            "capabilities": {
                              "add": [
                                "IPC_LOCK"
                              ]
                            }
                          },
                          "volumeMounts": [
                            {
                              "mountPath": "/dev/shm",
                              "name": "devshm"
                            },
                            {
                              "mountPath": "/mnt/cluster",
                              "name": "pvc-pfs"
                            }
                          ]
                        }
                      ],
                      "dnsPolicy": "ClusterFirstWithHostNet",
                      "hostNetwork": true,
                      "schedulerName": "volcano",
                      "volumes": [
                        {
                          "emptyDir": {
                            "medium": "Memory",
                            "sizeLimit": "10Gi"
                          },
                          "name": "devshm"
                        },
                        {
                          "name": "pvc-pfs",
                          "persistentVolumeClaim": {
                            "claimName": "pvc-pfs"
                          }
                        }
                      ]
                    }
                  }
                },
                "Worker": {
                  "replicas": 7,
                  "restartPolicy": "Never",
                  "template": {
                    "metadata": {
                      "annotations": {
                        "aijob.cce.baidubce.com/fault-tolerance-enabled": "false",
                        "aijob.cce.baidubce.com/openapi-jobid": "pytorch-bcdbd3fe-46d7-4caf-a587-93aa8c501a3f",
                        "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
                        "aijob.cce.baidubce.com/raw-request": "{\"name\":\"pengxiangyu-48hours-deepseek3\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"high\",\"oversell\":false,\"faultTolerance\":false,\"command\":\"sleep 100000000\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":true,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/hac-aiacc/pxy_megatron\",\"tag\":\"20240722\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"pengxiangyu-48hours-deepseek3\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"},\"Worker\":{\"replicas\":7,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/hac-aiacc/pxy_megatron\",\"tag\":\"20240722\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"pengxiangyu-48hours-deepseek3\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":false,\"logPath\":\"\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":true,\"isCopyJob\":true,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
                        "scheduling.k8s.io/job-enable-oversell": "false"
                      },
                      "labels": {
                        "aijob.cce.baidubce.com/ai-user-id": "b54a2f2a03dc4237b19f5df1b1b6e252",
                        "aijob.cce.baidubce.com/ai-user-name": "pengxiangyu",
                        "aijob.cce.baidubce.com/create-from-aihcp": "true",
                        "aijob.cce.baidubce.com/openapi-jobid": "pytorch-bcdbd3fe-46d7-4caf-a587-93aa8c501a3f"
                      }
                    },
                    "spec": {
                      "containers": [
                        {
                          "command": [
                            "/bin/bash",
                            "-c",
                            "sleep 100000000"
                          ],
                          "env": [
                            {
                              "name": "AIHC_JOB_NAME",
                              "value": "pengxiangyu-48hours-deepseek3"
                            },
                            {
                              "name": "NCCL_IB_DISABLE",
                              "value": "0"
                            }
                          ],
                          "image": "registry.baidubce.com/hac-aiacc/pxy_megatron:20240722",
                          "imagePullPolicy": "Always",
                          "name": "pytorch",
                          "ports": [
                            {
                              "containerPort": 23456,
                              "name": "pytorchjob-port",
                              "protocol": "TCP"
                            }
                          ],
                          "resources": {
                            "limits": {
                              "baidu.com/a800_80g_cgpu": "8",
                              "rdma/hca": "1"
                            },
                            "requests": {
                              "baidu.com/a800_80g_cgpu": "8",
                              "rdma/hca": "1"
                            }
                          },
                          "securityContext": {
                            "capabilities": {
                              "add": [
                                "IPC_LOCK"
                              ]
                            }
                          },
                          "volumeMounts": [
                            {
                              "mountPath": "/dev/shm",
                              "name": "devshm"
                            },
                            {
                              "mountPath": "/mnt/cluster",
                              "name": "pvc-pfs"
                            }
                          ]
                        }
                      ],
                      "dnsPolicy": "ClusterFirstWithHostNet",
                      "hostNetwork": true,
                      "schedulerName": "volcano",
                      "volumes": [
                        {
                          "emptyDir": {
                            "medium": "Memory",
                            "sizeLimit": "10Gi"
                          },
                          "name": "devshm"
                        },
                        {
                          "name": "pvc-pfs",
                          "persistentVolumeClaim": {
                            "claimName": "pvc-pfs"
                          }
                        }
                      ]
                    }
                  }
                }
              },
              "runPolicy": {
                "cleanPodPolicy": "None",
                "schedulingPolicy": {
                  "priorityClass": "high",
                  "queue": "default"
                }
              }
            },
            "status": {
              "conditions": [
                {
                  "lastTransitionTime": "2024-07-22T09:24:21Z",
                  "lastUpdateTime": "2024-07-22T09:24:21Z",
                  "message": "PyTorchJob pengxiangyu-48hours-deepseek3 is created.",
                  "reason": "PyTorchJobCreated",
                  "status": "True",
                  "type": "Created"
                },
                {
                  "lastTransitionTime": "2024-07-22T09:33:23Z",
                  "lastUpdateTime": "2024-07-22T09:33:23Z",
                  "message": "PyTorchJob pengxiangyu-48hours-deepseek3 is running.",
                  "reason": "JobRunning",
                  "status": "True",
                  "type": "Running"
                }
              ],
              "lastReconcileTime": "2024-07-22T09:26:42Z",
              "replicaStatuses": {
                "Master": {
                  "active": 1,
                  "selector": "training.kubeflow.org/job-name=pengxiangyu-48hours-deepseek3,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=master"
                },
                "Worker": {
                  "active": 7,
                  "selector": "training.kubeflow.org/job-name=pengxiangyu-48hours-deepseek3,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=worker"
                }
              },
              "startTime": "2024-07-22T09:27:31Z"
            }
          },
          {
            "apiVersion": "kubeflow.org/v1",
            "kind": "PyTorchJob",
            "metadata": {
              "annotations": {
                "aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": "",
                "aijob.cce.baidubce.com/timeline": "[{\"conditionType\":\"Created\",\"time\":1721116231},{\"conditionType\":\"Scheduled\",\"time\":1721116233},{\"conditionType\":\"Running\",\"time\":1721116579},{\"conditionType\":\"Failed\",\"time\":1721187332}]",
                "kubectl.kubernetes.io/last-applied-configuration": "{\"apiVersion\":\"kubeflow.org/v1\",\"kind\":\"PyTorchJob\",\"metadata\":{\"annotations\":{},\"name\":\"robin4-task-for-8gpu\",\"namespace\":\"default\"},\"spec\":{\"pytorchReplicaSpecs\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"template\":{\"metadata\":null,\"spec\":{\"containers\":[{\"command\":[\"bash\",\"/workspace/Megatron-LM/examples/launch.sh\"],\"env\":[{\"name\":\"CUDA_DEVICE_MAX_CONNECTIONS\",\"value\":\"1\"},{\"name\":\"NCCL_DEBUG\",\"value\":\"INFO\"},{\"name\":\"NCCL_IB_DISABLE\",\"value\":\"0\"},{\"name\":\"MASTER\",\"value\":\"1\"}],\"image\":\"registry.baidubce.com/cce-ai-native/aiak-megatron:ubuntu22.04-cu12.2-torch2.1.0-py310_v1.2.4.2\",\"imagePullPolicy\":\"Always\",\"name\":\"pytorch\",\"resources\":{\"limits\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1}},\"securityContext\":{\"capabilities\":{\"add\":[\"IPC_LOCK\"]}},\"volumeMounts\":[{\"mountPath\":\"/dev/shm\",\"name\":\"cache-volume\"},{\"mountPath\":\"/tmp\",\"name\":\"tmp-volume\"},{\"mountPath\":\"/workspace/Megatron-LM/examples/launch.sh\",\"name\":\"config-volume\",\"subPath\":\"launch.sh\"},{\"mountPath\":\"/mnt/cluster\",\"name\":\"data\"}]}],\"schedulerName\":\"volcano\",\"volumes\":[{\"emptyDir\":{\"medium\":\"Memory\"},\"name\":\"cache-volume\"},{\"emptyDir\":{\"medium\":\"Memory\"},\"name\":\"tmp-volume\"},{\"configMap\":{\"name\":\"robin4-task-for-8gpu\"},\"name\":\"config-volume\"},{\"name\":\"data\",\"persistentVolumeClaim\":{\"claimName\":\"pvc-pfs\"}}]}}}}}}\n"
              },
              "creationTimestamp": "2024-07-16T07:50:31Z",
              "generation": 2,
              "managedFields": [
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        ".": {},
                        "f:kubectl.kubernetes.io/last-applied-configuration": {}
                      }
                    },
                    "f:spec": {
                      ".": {},
                      "f:pytorchReplicaSpecs": {
                        ".": {},
                        "f:Master": {
                          ".": {},
                          "f:replicas": {},
                          "f:restartPolicy": {},
                          "f:template": {
                            ".": {},
                            "f:spec": {
                              ".": {},
                              "f:schedulerName": {},
                              "f:volumes": {}
                            }
                          }
                        }
                      }
                    }
                  },
                  "manager": "kubectl-client-side-apply",
                  "operation": "Update",
                  "time": "2024-07-16T07:50:31Z"
                },
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        "f:aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": {},
                        "f:aijob.cce.baidubce.com/timeline": {}
                      }
                    },
                    "f:spec": {
                      "f:pytorchReplicaSpecs": {
                        "f:Master": {
                          "f:template": {
                            "f:metadata": {},
                            "f:spec": {
                              "f:containers": {}
                            }
                          }
                        }
                      },
                      "f:runPolicy": {
                        ".": {},
                        "f:cleanPodPolicy": {}
                      }
                    }
                  },
                  "manager": "controller",
                  "operation": "Update",
                  "time": "2024-07-16T07:50:32Z"
                },
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:status": {
                      ".": {},
                      "f:completionTime": {},
                      "f:conditions": {},
                      "f:lastReconcileTime": {},
                      "f:replicaStatuses": {
                        ".": {},
                        "f:Master": {
                          ".": {},
                          "f:failed": {},
                          "f:selector": {}
                        }
                      },
                      "f:startTime": {}
                    }
                  },
                  "manager": "manager",
                  "operation": "Update",
                  "time": "2024-07-17T03:35:32Z"
                }
              ],
              "name": "robin4-task-for-8gpu",
              "namespace": "default",
              "resourceVersion": "2369998659",
              "uid": "938bee1a-1877-42e9-be00-da9d8f682f03"
            },
            "spec": {
              "pytorchReplicaSpecs": {
                "Master": {
                  "replicas": 1,
                  "restartPolicy": "Never",
                  "template": {
                    "metadata": {},
                    "spec": {
                      "containers": [
                        {
                          "command": [
                            "bash",
                            "/workspace/Megatron-LM/examples/launch.sh"
                          ],
                          "env": [
                            {
                              "name": "CUDA_DEVICE_MAX_CONNECTIONS",
                              "value": "1"
                            },
                            {
                              "name": "NCCL_DEBUG",
                              "value": "INFO"
                            },
                            {
                              "name": "NCCL_IB_DISABLE",
                              "value": "0"
                            },
                            {
                              "name": "MASTER",
                              "value": "1"
                            }
                          ],
                          "image": "registry.baidubce.com/cce-ai-native/aiak-megatron:ubuntu22.04-cu12.2-torch2.1.0-py310_v1.2.4.2",
                          "imagePullPolicy": "Always",
                          "name": "pytorch",
                          "ports": [
                            {
                              "containerPort": 23456,
                              "name": "pytorchjob-port",
                              "protocol": "TCP"
                            }
                          ],
                          "resources": {
                            "limits": {
                              "baidu.com/a800_80g_cgpu": "8",
                              "rdma/hca": "1"
                            }
                          },
                          "securityContext": {
                            "capabilities": {
                              "add": [
                                "IPC_LOCK"
                              ]
                            }
                          },
                          "volumeMounts": [
                            {
                              "mountPath": "/dev/shm",
                              "name": "cache-volume"
                            },
                            {
                              "mountPath": "/tmp",
                              "name": "tmp-volume"
                            },
                            {
                              "mountPath": "/workspace/Megatron-LM/examples/launch.sh",
                              "name": "config-volume",
                              "subPath": "launch.sh"
                            },
                            {
                              "mountPath": "/mnt/cluster",
                              "name": "data"
                            }
                          ]
                        }
                      ],
                      "schedulerName": "volcano",
                      "volumes": [
                        {
                          "emptyDir": {
                            "medium": "Memory"
                          },
                          "name": "cache-volume"
                        },
                        {
                          "emptyDir": {
                            "medium": "Memory"
                          },
                          "name": "tmp-volume"
                        },
                        {
                          "configMap": {
                            "name": "robin4-task-for-8gpu"
                          },
                          "name": "config-volume"
                        },
                        {
                          "name": "data",
                          "persistentVolumeClaim": {
                            "claimName": "pvc-pfs"
                          }
                        }
                      ]
                    }
                  }
                }
              },
              "runPolicy": {
                "cleanPodPolicy": "None"
              }
            },
            "status": {
              "completionTime": "2024-07-17T03:35:32Z",
              "conditions": [
                {
                  "lastTransitionTime": "2024-07-16T07:50:31Z",
                  "lastUpdateTime": "2024-07-16T07:50:31Z",
                  "message": "PyTorchJob robin4-task-for-8gpu is created.",
                  "reason": "PyTorchJobCreated",
                  "status": "True",
                  "type": "Created"
                },
                {
                  "lastTransitionTime": "2024-07-16T07:56:19Z",
                  "lastUpdateTime": "2024-07-16T07:56:19Z",
                  "message": "PyTorchJob robin4-task-for-8gpu is running.",
                  "reason": "JobRunning",
                  "status": "False",
                  "type": "Running"
                },
                {
                  "lastTransitionTime": "2024-07-17T03:35:32Z",
                  "lastUpdateTime": "2024-07-17T03:35:32Z",
                  "message": "PyTorchJob robin4-task-for-8gpu is failed because 1 Master replica(s) failed.",
                  "reason": "JobFailed",
                  "status": "True",
                  "type": "Failed"
                }
              ],
              "lastReconcileTime": "2024-07-16T07:50:32Z",
              "replicaStatuses": {
                "Master": {
                  "failed": 1,
                  "selector": "training.kubeflow.org/job-name=robin4-task-for-8gpu,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=master"
                }
              },
              "startTime": "2024-07-16T07:50:32Z"
            }
          },
          {
            "apiVersion": "kubeflow.org/v1",
            "kind": "PyTorchJob",
            "metadata": {
              "annotations": {
                "aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": "",
                "aijob.cce.baidubce.com/timeline": "[{\"conditionType\":\"Created\",\"time\":1721287168},{\"conditionType\":\"Scheduled\",\"time\":1721290353},{\"conditionType\":\"Running\",\"time\":1721290368},{\"conditionType\":\"Failed\",\"time\":1721614767}]",
                "job-manager/action-succeed": "stop",
                "kubectl.kubernetes.io/last-applied-configuration": "{\"apiVersion\":\"kubeflow.org/v1\",\"kind\":\"PyTorchJob\",\"metadata\":{\"annotations\":{},\"name\":\"robin5-task-for-8gpu\",\"namespace\":\"default\"},\"spec\":{\"pytorchReplicaSpecs\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"template\":{\"metadata\":null,\"spec\":{\"containers\":[{\"command\":[\"bash\",\"/workspace/Megatron-LM/examples/launch.sh\"],\"env\":[{\"name\":\"CUDA_DEVICE_MAX_CONNECTIONS\",\"value\":\"1\"},{\"name\":\"NCCL_DEBUG\",\"value\":\"INFO\"},{\"name\":\"NCCL_IB_DISABLE\",\"value\":\"0\"},{\"name\":\"MASTER\",\"value\":\"1\"}],\"image\":\"registry.baidubce.com/cce-ai-native/aiak-megatron:ubuntu22.04-cu12.2-torch2.1.0-py310_v1.2.4.2\",\"imagePullPolicy\":\"Always\",\"name\":\"pytorch\",\"resources\":{\"limits\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1}},\"securityContext\":{\"capabilities\":{\"add\":[\"IPC_LOCK\"]}},\"volumeMounts\":[{\"mountPath\":\"/dev/shm\",\"name\":\"cache-volume\"},{\"mountPath\":\"/tmp\",\"name\":\"tmp-volume\"},{\"mountPath\":\"/workspace/Megatron-LM/examples/launch.sh\",\"name\":\"config-volume\",\"subPath\":\"launch.sh\"},{\"mountPath\":\"/mnt/cluster\",\"name\":\"data\"}]}],\"schedulerName\":\"volcano\",\"volumes\":[{\"emptyDir\":{\"medium\":\"Memory\"},\"name\":\"cache-volume\"},{\"emptyDir\":{\"medium\":\"Memory\"},\"name\":\"tmp-volume\"},{\"configMap\":{\"name\":\"robin5-task-for-8gpu\"},\"name\":\"config-volume\"},{\"name\":\"data\",\"persistentVolumeClaim\":{\"claimName\":\"pvc-pfs\"}}]}}}}}}\n"
              },
              "creationTimestamp": "2024-07-18T07:19:28Z",
              "generation": 2,
              "managedFields": [
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        "f:aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": {},
                        "f:aijob.cce.baidubce.com/timeline": {}
                      }
                    },
                    "f:spec": {
                      "f:pytorchReplicaSpecs": {
                        "f:Master": {
                          "f:template": {
                            "f:metadata": {},
                            "f:spec": {
                              "f:containers": {}
                            }
                          }
                        }
                      },
                      "f:runPolicy": {
                        ".": {},
                        "f:cleanPodPolicy": {}
                      }
                    }
                  },
                  "manager": "controller",
                  "operation": "Update",
                  "time": "2024-07-18T07:19:28Z"
                },
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        ".": {},
                        "f:kubectl.kubernetes.io/last-applied-configuration": {}
                      }
                    },
                    "f:spec": {
                      ".": {},
                      "f:pytorchReplicaSpecs": {
                        ".": {},
                        "f:Master": {
                          ".": {},
                          "f:replicas": {},
                          "f:restartPolicy": {},
                          "f:template": {
                            ".": {},
                            "f:spec": {
                              ".": {},
                              "f:schedulerName": {},
                              "f:volumes": {}
                            }
                          }
                        }
                      }
                    }
                  },
                  "manager": "kubectl-client-side-apply",
                  "operation": "Update",
                  "time": "2024-07-18T07:19:28Z"
                },
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:status": {
                      ".": {},
                      "f:completionTime": {},
                      "f:conditions": {},
                      "f:lastReconcileTime": {},
                      "f:replicaStatuses": {
                        ".": {},
                        "f:Master": {
                          ".": {},
                          "f:failed": {},
                          "f:selector": {}
                        }
                      },
                      "f:startTime": {}
                    }
                  },
                  "manager": "manager",
                  "operation": "Update",
                  "time": "2024-07-22T02:19:27Z"
                },
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        "f:job-manager/action-succeed": {}
                      }
                    }
                  },
                  "manager": "ftagent",
                  "operation": "Update",
                  "time": "2024-07-22T02:19:34Z"
                }
              ],
              "name": "robin5-task-for-8gpu",
              "namespace": "default",
              "resourceVersion": "2375788011",
              "uid": "44eff632-1f0d-4042-8f0d-42be75e5543c"
            },
            "spec": {
              "pytorchReplicaSpecs": {
                "Master": {
                  "replicas": 1,
                  "restartPolicy": "Never",
                  "template": {
                    "metadata": {},
                    "spec": {
                      "containers": [
                        {
                          "command": [
                            "bash",
                            "/workspace/Megatron-LM/examples/launch.sh"
                          ],
                          "env": [
                            {
                              "name": "CUDA_DEVICE_MAX_CONNECTIONS",
                              "value": "1"
                            },
                            {
                              "name": "NCCL_DEBUG",
                              "value": "INFO"
                            },
                            {
                              "name": "NCCL_IB_DISABLE",
                              "value": "0"
                            },
                            {
                              "name": "MASTER",
                              "value": "1"
                            }
                          ],
                          "image": "registry.baidubce.com/cce-ai-native/aiak-megatron:ubuntu22.04-cu12.2-torch2.1.0-py310_v1.2.4.2",
                          "imagePullPolicy": "Always",
                          "name": "pytorch",
                          "ports": [
                            {
                              "containerPort": 23456,
                              "name": "pytorchjob-port",
                              "protocol": "TCP"
                            }
                          ],
                          "resources": {
                            "limits": {
                              "baidu.com/a800_80g_cgpu": "8",
                              "rdma/hca": "1"
                            }
                          },
                          "securityContext": {
                            "capabilities": {
                              "add": [
                                "IPC_LOCK"
                              ]
                            }
                          },
                          "volumeMounts": [
                            {
                              "mountPath": "/dev/shm",
                              "name": "cache-volume"
                            },
                            {
                              "mountPath": "/tmp",
                              "name": "tmp-volume"
                            },
                            {
                              "mountPath": "/workspace/Megatron-LM/examples/launch.sh",
                              "name": "config-volume",
                              "subPath": "launch.sh"
                            },
                            {
                              "mountPath": "/mnt/cluster",
                              "name": "data"
                            }
                          ]
                        }
                      ],
                      "schedulerName": "volcano",
                      "volumes": [
                        {
                          "emptyDir": {
                            "medium": "Memory"
                          },
                          "name": "cache-volume"
                        },
                        {
                          "emptyDir": {
                            "medium": "Memory"
                          },
                          "name": "tmp-volume"
                        },
                        {
                          "configMap": {
                            "name": "robin5-task-for-8gpu"
                          },
                          "name": "config-volume"
                        },
                        {
                          "name": "data",
                          "persistentVolumeClaim": {
                            "claimName": "pvc-pfs"
                          }
                        }
                      ]
                    }
                  }
                }
              },
              "runPolicy": {
                "cleanPodPolicy": "None"
              }
            },
            "status": {
              "completionTime": "2024-07-22T02:19:27Z",
              "conditions": [
                {
                  "lastTransitionTime": "2024-07-18T07:19:28Z",
                  "lastUpdateTime": "2024-07-18T07:19:28Z",
                  "message": "PyTorchJob robin5-task-for-8gpu is created.",
                  "reason": "PyTorchJobCreated",
                  "status": "True",
                  "type": "Created"
                },
                {
                  "lastTransitionTime": "2024-07-18T08:12:48Z",
                  "lastUpdateTime": "2024-07-18T08:12:48Z",
                  "message": "PyTorchJob robin5-task-for-8gpu is running.",
                  "reason": "JobRunning",
                  "status": "False",
                  "type": "Running"
                },
                {
                  "lastTransitionTime": "2024-07-22T02:19:27Z",
                  "lastUpdateTime": "2024-07-22T02:19:27Z",
                  "message": "PyTorchJob robin5-task-for-8gpu is failed because 1 Master replica(s) failed.",
                  "reason": "JobFailed",
                  "status": "True",
                  "type": "Failed"
                }
              ],
              "lastReconcileTime": "2024-07-18T07:23:50Z",
              "replicaStatuses": {
                "Master": {
                  "failed": 1,
                  "selector": "training.kubeflow.org/job-name=robin5-task-for-8gpu,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=master"
                }
              },
              "startTime": "2024-07-18T07:24:01Z"
            }
          },
          {
            "apiVersion": "kubeflow.org/v1",
            "kind": "PyTorchJob",
            "metadata": {
              "annotations": {
                "aijob.cce.baidubce.com/fault-tolerance-enabled": "true",
                "aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": "",
                "aijob.cce.baidubce.com/openapi-jobid": "pytorch-2dd06763-040a-41ee-bb76-5f222085f746",
                "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
                "aijob.cce.baidubce.com/raw-request": "{\"name\":\"test-pfs\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"normal\",\"oversell\":false,\"faultTolerance\":true,\"command\":\"sleep 36000\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/pfs\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":false,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihcp-public/pytorch\",\"tag\":\"22.08-py3\",\"resource\":{\"baidu.com/a800_80g_cgpu\":1,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"test-pfs\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":false,\"logPath\":\"\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":false,\"isCopyJob\":false,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
                "aijob.cce.baidubce.com/timeline": "[{\"conditionType\":\"Created\",\"time\":1721376494},{\"conditionType\":\"Scheduled\",\"time\":1721376496},{\"conditionType\":\"Running\",\"time\":1721376743},{\"conditionType\":\"Succeeded\",\"time\":1721412750}]",
                "scheduling.k8s.io/job-enable-oversell": "false"
              },
              "creationTimestamp": "2024-07-19T08:08:14Z",
              "generation": 2,
              "labels": {
                "aijob.cce.baidubce.com/ai-user-id": "60e7857753284b0e8da9689beead6615",
                "aijob.cce.baidubce.com/ai-user-name": "zhangwenjing01",
                "aijob.cce.baidubce.com/create-from-aihcp": "true",
                "aijob.cce.baidubce.com/openapi-jobid": "pytorch-2dd06763-040a-41ee-bb76-5f222085f746"
              },
              "managedFields": [
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        ".": {},
                        "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                        "f:aijob.cce.baidubce.com/openapi-jobid": {},
                        "f:aijob.cce.baidubce.com/pfs-id": {},
                        "f:aijob.cce.baidubce.com/raw-request": {},
                        "f:scheduling.k8s.io/job-enable-oversell": {}
                      },
                      "f:labels": {
                        ".": {},
                        "f:aijob.cce.baidubce.com/ai-user-id": {},
                        "f:aijob.cce.baidubce.com/ai-user-name": {},
                        "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                        "f:aijob.cce.baidubce.com/openapi-jobid": {}
                      }
                    },
                    "f:spec": {
                      ".": {},
                      "f:pytorchReplicaSpecs": {
                        ".": {},
                        "f:Master": {
                          ".": {},
                          "f:replicas": {},
                          "f:restartPolicy": {},
                          "f:template": {
                            ".": {},
                            "f:metadata": {
                              ".": {},
                              "f:annotations": {
                                ".": {},
                                "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                                "f:aijob.cce.baidubce.com/openapi-jobid": {},
                                "f:aijob.cce.baidubce.com/pfs-id": {},
                                "f:aijob.cce.baidubce.com/raw-request": {},
                                "f:scheduling.k8s.io/job-enable-oversell": {}
                              },
                              "f:labels": {
                                ".": {},
                                "f:aijob.cce.baidubce.com/ai-user-id": {},
                                "f:aijob.cce.baidubce.com/ai-user-name": {},
                                "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                                "f:aijob.cce.baidubce.com/openapi-jobid": {}
                              }
                            },
                            "f:spec": {
                              ".": {},
                              "f:schedulerName": {},
                              "f:volumes": {}
                            }
                          }
                        }
                      },
                      "f:runPolicy": {
                        ".": {},
                        "f:schedulingPolicy": {
                          ".": {},
                          "f:priorityClass": {},
                          "f:queue": {}
                        }
                      }
                    }
                  },
                  "manager": "cce-ai-service",
                  "operation": "Update",
                  "time": "2024-07-19T08:08:14Z"
                },
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        "f:aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": {},
                        "f:aijob.cce.baidubce.com/timeline": {}
                      }
                    },
                    "f:spec": {
                      "f:pytorchReplicaSpecs": {
                        "f:Master": {
                          "f:template": {
                            "f:spec": {
                              "f:containers": {}
                            }
                          }
                        }
                      },
                      "f:runPolicy": {
                        "f:cleanPodPolicy": {}
                      }
                    }
                  },
                  "manager": "controller",
                  "operation": "Update",
                  "time": "2024-07-19T08:08:14Z"
                },
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:status": {
                      ".": {},
                      "f:completionTime": {},
                      "f:conditions": {},
                      "f:lastReconcileTime": {},
                      "f:replicaStatuses": {
                        ".": {},
                        "f:Master": {
                          ".": {},
                          "f:selector": {},
                          "f:succeeded": {}
                        }
                      },
                      "f:startTime": {}
                    }
                  },
                  "manager": "manager",
                  "operation": "Update",
                  "time": "2024-07-19T18:12:30Z"
                }
              ],
              "name": "test-pfs",
              "namespace": "default",
              "resourceVersion": "2373153106",
              "uid": "07cb89c2-4fe7-4a74-ad4e-fe59c3bb207d"
            },
            "spec": {
              "pytorchReplicaSpecs": {
                "Master": {
                  "replicas": 1,
                  "restartPolicy": "Never",
                  "template": {
                    "metadata": {
                      "annotations": {
                        "aijob.cce.baidubce.com/fault-tolerance-enabled": "true",
                        "aijob.cce.baidubce.com/openapi-jobid": "pytorch-2dd06763-040a-41ee-bb76-5f222085f746",
                        "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
                        "aijob.cce.baidubce.com/raw-request": "{\"name\":\"test-pfs\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"normal\",\"oversell\":false,\"faultTolerance\":true,\"command\":\"sleep 36000\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/pfs\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":false,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihcp-public/pytorch\",\"tag\":\"22.08-py3\",\"resource\":{\"baidu.com/a800_80g_cgpu\":1,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"test-pfs\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":false,\"logPath\":\"\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":false,\"isCopyJob\":false,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
                        "scheduling.k8s.io/job-enable-oversell": "false"
                      },
                      "labels": {
                        "aijob.cce.baidubce.com/ai-user-id": "60e7857753284b0e8da9689beead6615",
                        "aijob.cce.baidubce.com/ai-user-name": "zhangwenjing01",
                        "aijob.cce.baidubce.com/create-from-aihcp": "true",
                        "aijob.cce.baidubce.com/openapi-jobid": "pytorch-2dd06763-040a-41ee-bb76-5f222085f746"
                      }
                    },
                    "spec": {
                      "containers": [
                        {
                          "command": [
                            "/bin/bash",
                            "-c",
                            "sleep 36000"
                          ],
                          "env": [
                            {
                              "name": "AIHC_JOB_NAME",
                              "value": "test-pfs"
                            },
                            {
                              "name": "NCCL_IB_DISABLE",
                              "value": "0"
                            }
                          ],
                          "image": "registry.baidubce.com/aihcp-public/pytorch:22.08-py3",
                          "imagePullPolicy": "Always",
                          "name": "pytorch",
                          "ports": [
                            {
                              "containerPort": 23456,
                              "name": "pytorchjob-port",
                              "protocol": "TCP"
                            }
                          ],
                          "resources": {
                            "limits": {
                              "baidu.com/a800_80g_cgpu": "1",
                              "rdma/hca": "1"
                            },
                            "requests": {
                              "baidu.com/a800_80g_cgpu": "1",
                              "rdma/hca": "1"
                            }
                          },
                          "securityContext": {
                            "capabilities": {
                              "add": [
                                "IPC_LOCK"
                              ]
                            }
                          },
                          "volumeMounts": [
                            {
                              "mountPath": "/dev/shm",
                              "name": "devshm"
                            },
                            {
                              "mountPath": "/mnt/pfs",
                              "name": "pvc-pfs"
                            }
                          ]
                        }
                      ],
                      "schedulerName": "volcano",
                      "volumes": [
                        {
                          "emptyDir": {
                            "medium": "Memory",
                            "sizeLimit": "10Gi"
                          },
                          "name": "devshm"
                        },
                        {
                          "name": "pvc-pfs",
                          "persistentVolumeClaim": {
                            "claimName": "pvc-pfs"
                          }
                        }
                      ]
                    }
                  }
                }
              },
              "runPolicy": {
                "cleanPodPolicy": "None",
                "schedulingPolicy": {
                  "priorityClass": "normal",
                  "queue": "default"
                }
              }
            },
            "status": {
              "completionTime": "2024-07-19T18:12:30Z",
              "conditions": [
                {
                  "lastTransitionTime": "2024-07-19T08:08:14Z",
                  "lastUpdateTime": "2024-07-19T08:08:14Z",
                  "message": "PyTorchJob test-pfs is created.",
                  "reason": "PyTorchJobCreated",
                  "status": "True",
                  "type": "Created"
                },
                {
                  "lastTransitionTime": "2024-07-19T08:12:23Z",
                  "lastUpdateTime": "2024-07-19T08:12:23Z",
                  "message": "PyTorchJob test-pfs is running.",
                  "reason": "JobRunning",
                  "status": "False",
                  "type": "Running"
                },
                {
                  "lastTransitionTime": "2024-07-19T18:12:30Z",
                  "lastUpdateTime": "2024-07-19T18:12:30Z",
                  "message": "PyTorchJob test-pfs is successfully completed.",
                  "reason": "JobSucceeded",
                  "status": "True",
                  "type": "Succeeded"
                }
              ],
              "lastReconcileTime": "2024-07-19T08:08:14Z",
              "replicaStatuses": {
                "Master": {
                  "selector": "training.kubeflow.org/job-name=test-pfs,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=master",
                  "succeeded": 1
                }
              },
              "startTime": "2024-07-19T08:08:15Z"
            }
          },
          {
            "apiVersion": "kubeflow.org/v1",
            "kind": "PyTorchJob",
            "metadata": {
              "annotations": {
                "aijob.cce.baidubce.com/fault-tolerance-enabled": "true",
                "aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": "",
                "aijob.cce.baidubce.com/internal-fault-tolerance-time": "2024-07-15T07:23:58.72041018Z",
                "aijob.cce.baidubce.com/openapi-jobid": "pytorch-0d2baffc-5ac5-40ff-98be-56b4f25eb192",
                "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
                "aijob.cce.baidubce.com/raw-request": "{\"name\":\"testlxq-1\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"normal\",\"oversell\":false,\"faultTolerance\":true,\"command\":\"sleep-inf\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":false,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihcp-public/pytorch\",\"tag\":\"22.08-py3\",\"resource\":{\"baidu.com/a800_80g_cgpu\":1,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"testlxq-1\",\"LOG_COLLECTION\":\"true\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":false,\"logPath\":\"\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":false,\"isCopyJob\":true,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
                "aijob.cce.baidubce.com/timeline": "[{\"conditionType\":\"Created\",\"time\":1721027977},{\"conditionType\":\"Scheduled\",\"time\":1721027979},{\"conditionType\":\"Running\",\"time\":1721028208},{\"conditionType\":\"Abnormal\",\"time\":1721028238},{\"conditionType\":\"Failed\",\"time\":1721028843}]",
                "scheduling.k8s.io/job-enable-oversell": "false"
              },
              "creationTimestamp": "2024-07-15T07:19:37Z",
              "generation": 3,
              "labels": {
                "aijob.cce.baidubce.com/ai-user-id": "d2871024f2904725b16e04b75914d9ca",
                "aijob.cce.baidubce.com/ai-user-name": "xingyushan",
                "aijob.cce.baidubce.com/create-from-aihcp": "true",
                "aijob.cce.baidubce.com/openapi-jobid": "pytorch-0d2baffc-5ac5-40ff-98be-56b4f25eb192"
              },
              "managedFields": [
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        ".": {},
                        "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                        "f:aijob.cce.baidubce.com/openapi-jobid": {},
                        "f:aijob.cce.baidubce.com/pfs-id": {},
                        "f:aijob.cce.baidubce.com/raw-request": {},
                        "f:scheduling.k8s.io/job-enable-oversell": {}
                      },
                      "f:labels": {
                        ".": {},
                        "f:aijob.cce.baidubce.com/ai-user-id": {},
                        "f:aijob.cce.baidubce.com/ai-user-name": {},
                        "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                        "f:aijob.cce.baidubce.com/openapi-jobid": {}
                      }
                    },
                    "f:spec": {
                      ".": {},
                      "f:pytorchReplicaSpecs": {
                        ".": {},
                        "f:Master": {
                          ".": {},
                          "f:replicas": {},
                          "f:restartPolicy": {},
                          "f:template": {
                            ".": {},
                            "f:metadata": {
                              ".": {},
                              "f:annotations": {
                                ".": {},
                                "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                                "f:aijob.cce.baidubce.com/openapi-jobid": {},
                                "f:aijob.cce.baidubce.com/pfs-id": {},
                                "f:aijob.cce.baidubce.com/raw-request": {},
                                "f:scheduling.k8s.io/job-enable-oversell": {}
                              },
                              "f:labels": {
                                ".": {},
                                "f:aijob.cce.baidubce.com/ai-user-id": {},
                                "f:aijob.cce.baidubce.com/ai-user-name": {},
                                "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                                "f:aijob.cce.baidubce.com/openapi-jobid": {}
                              }
                            },
                            "f:spec": {
                              ".": {},
                              "f:schedulerName": {}
                            }
                          }
                        }
                      },
                      "f:runPolicy": {
                        ".": {},
                        "f:schedulingPolicy": {
                          ".": {},
                          "f:priorityClass": {},
                          "f:queue": {}
                        }
                      }
                    }
                  },
                  "manager": "cce-ai-service",
                  "operation": "Update",
                  "time": "2024-07-15T07:19:37Z"
                },
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        "f:aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": {},
                        "f:aijob.cce.baidubce.com/timeline": {}
                      }
                    },
                    "f:spec": {
                      "f:runPolicy": {
                        "f:cleanPodPolicy": {}
                      }
                    }
                  },
                  "manager": "controller",
                  "operation": "Update",
                  "time": "2024-07-15T07:19:37Z"
                },
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        "f:aijob.cce.baidubce.com/internal-fault-tolerance-time": {}
                      }
                    },
                    "f:spec": {
                      "f:pytorchReplicaSpecs": {
                        "f:Master": {
                          "f:template": {
                            "f:metadata": {
                              "f:annotations": {
                                "f:prometheus.io/path": {},
                                "f:prometheus.io/port": {},
                                "f:prometheus.io/scrape": {}
                              }
                            },
                            "f:spec": {
                              "f:containers": {},
                              "f:serviceAccountName": {},
                              "f:shareProcessNamespace": {},
                              "f:volumes": {}
                            }
                          }
                        }
                      }
                    },
                    "f:status": {
                      ".": {},
                      "f:completionTime": {},
                      "f:conditions": {},
                      "f:lastReconcileTime": {},
                      "f:replicaStatuses": {
                        ".": {},
                        "f:Master": {
                          ".": {},
                          "f:failed": {},
                          "f:selector": {}
                        }
                      },
                      "f:startTime": {}
                    }
                  },
                  "manager": "manager",
                  "operation": "Update",
                  "time": "2024-07-15T07:34:03Z"
                }
              ],
              "name": "testlxq-1",
              "namespace": "default",
              "resourceVersion": "2367492714",
              "uid": "f235bcb8-431b-421c-96a5-0a520cc110c8"
            },
            "spec": {
              "pytorchReplicaSpecs": {
                "Master": {
                  "replicas": 1,
                  "restartPolicy": "Never",
                  "template": {
                    "metadata": {
                      "annotations": {
                        "aijob.cce.baidubce.com/fault-tolerance-enabled": "true",
                        "aijob.cce.baidubce.com/openapi-jobid": "pytorch-0d2baffc-5ac5-40ff-98be-56b4f25eb192",
                        "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
                        "aijob.cce.baidubce.com/raw-request": "{\"name\":\"testlxq-1\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"normal\",\"oversell\":false,\"faultTolerance\":true,\"command\":\"sleep-inf\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":false,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihcp-public/pytorch\",\"tag\":\"22.08-py3\",\"resource\":{\"baidu.com/a800_80g_cgpu\":1,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"testlxq-1\",\"LOG_COLLECTION\":\"true\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":false,\"logPath\":\"\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":false,\"isCopyJob\":true,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
                        "prometheus.io/path": "/metrics",
                        "prometheus.io/port": "9101",
                        "prometheus.io/scrape": "true",
                        "scheduling.k8s.io/job-enable-oversell": "false"
                      },
                      "labels": {
                        "aijob.cce.baidubce.com/ai-user-id": "d2871024f2904725b16e04b75914d9ca",
                        "aijob.cce.baidubce.com/ai-user-name": "xingyushan",
                        "aijob.cce.baidubce.com/create-from-aihcp": "true",
                        "aijob.cce.baidubce.com/openapi-jobid": "pytorch-0d2baffc-5ac5-40ff-98be-56b4f25eb192"
                      }
                    },
                    "spec": {
                      "containers": [
                        {
                          "command": [
                            "/bin/bash",
                            "-c",
                            "sleep-inf"
                          ],
                          "env": [
                            {
                              "name": "LOG_COLLECTION",
                              "value": "true"
                            },
                            {
                              "name": "AIHC_JOB_NAME",
                              "value": "testlxq-1"
                            },
                            {
                              "name": "NCCL_IB_DISABLE",
                              "value": "0"
                            },
                            {
                              "name": "BCCL_BUS_BW_CALCULATE_MODE",
                              "value": "Agg"
                            },
                            {
                              "name": "BCCL_PROFILING_FILE",
                              "value": "/var/bccl/logs/busbw.cal.%h.%p"
                            }
                          ],
                          "image": "registry.baidubce.com/aihcp-public/pytorch:22.08-py3",
                          "imagePullPolicy": "Always",
                          "name": "pytorch",
                          "ports": [
                            {
                              "containerPort": 23456,
                              "name": "pytorchjob-port",
                              "protocol": "TCP"
                            }
                          ],
                          "resources": {
                            "limits": {
                              "baidu.com/a800_80g_cgpu": "1",
                              "rdma/hca": "1"
                            },
                            "requests": {
                              "baidu.com/a800_80g_cgpu": "1",
                              "rdma/hca": "1"
                            }
                          },
                          "securityContext": {
                            "capabilities": {
                              "add": [
                                "IPC_LOCK"
                              ]
                            }
                          },
                          "volumeMounts": [
                            {
                              "mountPath": "/dev/shm",
                              "name": "devshm"
                            },
                            {
                              "mountPath": "/mnt/cluster",
                              "name": "pvc-pfs"
                            },
                            {
                              "mountPath": "/var/bccl/logs",
                              "name": "bccl-logs-volume"
                            }
                          ]
                        },
                        {
                          "env": [
                            {
                              "name": "POD_NAME",
                              "valueFrom": {
                                "fieldRef": {
                                  "apiVersion": "v1",
                                  "fieldPath": "metadata.name"
                                }
                              }
                            },
                            {
                              "name": "POD_UID",
                              "valueFrom": {
                                "fieldRef": {
                                  "apiVersion": "v1",
                                  "fieldPath": "metadata.uid"
                                }
                              }
                            },
                            {
                              "name": "POD_NAMESPACE",
                              "valueFrom": {
                                "fieldRef": {
                                  "apiVersion": "v1",
                                  "fieldPath": "metadata.namespace"
                                }
                              }
                            },
                            {
                              "name": "NODE_NAME",
                              "valueFrom": {
                                "fieldRef": {
                                  "apiVersion": "v1",
                                  "fieldPath": "spec.nodeName"
                                }
                              }
                            },
                            {
                              "name": "JOB_NAME",
                              "value": "testlxq-1"
                            },
                            {
                              "name": "NODE_IP",
                              "valueFrom": {
                                "fieldRef": {
                                  "apiVersion": "v1",
                                  "fieldPath": "status.hostIP"
                                }
                              }
                            },
                            {
                              "name": "ENABLE_ELASTIC",
                              "value": "9"
                            },
                            {
                              "name": "GPUS_PER_NODE",
                              "value": "1"
                            },
                            {
                              "name": "BCCL_LOG_DIR",
                              "value": "/var/bccl/logs"
                            },
                            {
                              "name": "EXPORTER_PORT",
                              "value": "9101"
                            },
                            {
                              "name": "EXPORTER_INTERVAL",
                              "value": "60"
                            },
                            {
                              "name": "EXPORTER_PATH",
                              "value": "/metrics"
                            },
                            {
                              "name": "BCCL_BUS_BW_CALCULATE_MODE",
                              "value": "Agg"
                            },
                            {
                              "name": "BCCL_PROFILING_FILE",
                              "value": "/var/bccl/logs/busbw.cal.%h.%p"
                            }
                          ],
                          "image": "registry.baidubce.com/cce-plugin-dev/ftagent:v1.6-20240713172215",
                          "imagePullPolicy": "Always",
                          "name": "ftagent",
                          "ports": [
                            {
                              "containerPort": 9101,
                              "name": "exporter",
                              "protocol": "TCP"
                            }
                          ],
                          "resources": {},
                          "securityContext": {
                            "capabilities": {
                              "add": [
                                "IPC_LOCK"
                              ]
                            }
                          },
                          "volumeMounts": [
                            {
                              "mountPath": "/var/log/pods",
                              "name": "pod-log-volume"
                            },
                            {
                              "mountPath": "/home/cce",
                              "name": "container-log-volume"
                            },
                            {
                              "mountPath": "/var/bccl/logs",
                              "name": "bccl-logs-volume"
                            }
                          ]
                        }
                      ],
                      "schedulerName": "volcano",
                      "serviceAccountName": "ftagent-sa",
                      "shareProcessNamespace": true,
                      "volumes": [
                        {
                          "emptyDir": {
                            "medium": "Memory",
                            "sizeLimit": "10Gi"
                          },
                          "name": "devshm"
                        },
                        {
                          "name": "pvc-pfs",
                          "persistentVolumeClaim": {
                            "claimName": "pvc-pfs"
                          }
                        },
                        {
                          "emptyDir": {},
                          "name": "bccl-logs-volume"
                        },
                        {
                          "hostPath": {
                            "path": "/var/log/pods",
                            "type": "DirectoryOrCreate"
                          },
                          "name": "pod-log-volume"
                        },
                        {
                          "hostPath": {
                            "path": "/home/cce",
                            "type": "DirectoryOrCreate"
                          },
                          "name": "container-log-volume"
                        }
                      ]
                    }
                  }
                }
              },
              "runPolicy": {
                "cleanPodPolicy": "None",
                "schedulingPolicy": {
                  "priorityClass": "normal",
                  "queue": "default"
                }
              }
            },
            "status": {
              "completionTime": "2024-07-15T07:34:03Z",
              "conditions": [
                {
                  "lastTransitionTime": "2024-07-15T07:19:37Z",
                  "lastUpdateTime": "2024-07-15T07:19:37Z",
                  "message": "PyTorchJob testlxq-1 is created.",
                  "reason": "PyTorchJobCreated",
                  "status": "True",
                  "type": "Created"
                },
                {
                  "lastTransitionTime": "2024-07-15T07:23:28Z",
                  "lastUpdateTime": "2024-07-15T07:23:28Z",
                  "message": "PyTorchJob testlxq-1 is running.",
                  "reason": "JobRunning",
                  "status": "False",
                  "type": "Running"
                },
                {
                  "lastTransitionTime": "2024-07-15T07:34:03Z",
                  "lastUpdateTime": "2024-07-15T07:34:03Z",
                  "message": "PyTorchJob testlxq-1 is failed because 1 Master replica(s) failed.",
                  "reason": "JobFailed",
                  "status": "True",
                  "type": "Failed"
                }
              ],
              "lastReconcileTime": "2024-07-15T07:19:37Z",
              "replicaStatuses": {
                "Master": {
                  "failed": 1,
                  "selector": "training.kubeflow.org/job-name=testlxq-1,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=master"
                }
              },
              "startTime": "2024-07-15T07:19:38Z"
            }
          },
          {
            "apiVersion": "kubeflow.org/v1",
            "kind": "PyTorchJob",
            "metadata": {
              "annotations": {
                "aijob.cce.baidubce.com/barrier-finish": "9ca2c9b5-f186-4fb9-bdf1-44c4c700365e",
                "aijob.cce.baidubce.com/fault-tolerance-enabled": "true",
                "aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": "",
                "aijob.cce.baidubce.com/timeline": "[{\"conditionType\":\"Created\",\"time\":1721668050},{\"conditionType\":\"Scheduled\",\"time\":1721668052},{\"conditionType\":\"Running\",\"time\":1721668246}]",
                "kubectl.kubernetes.io/last-applied-configuration": "{\"apiVersion\":\"kubeflow.org/v1\",\"kind\":\"PyTorchJob\",\"metadata\":{\"annotations\":{},\"name\":\"wangzhuyun-accelerate-open-sora-plan\",\"namespace\":\"default\"},\"spec\":{\"pytorchReplicaSpecs\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"template\":{\"metadata\":null,\"spec\":{\"containers\":[{\"command\":[\"bash\",\"/workspace/Open-Sora-Plan/launch.sh\"],\"env\":[{\"name\":\"CUDA_DEVICE_MAX_CONNECTIONS\",\"value\":\"1\"},{\"name\":\"NCCL_DEBUG\",\"value\":\"INFO\"},{\"name\":\"NCCL_IB_DISABLE\",\"value\":\"0\"},{\"name\":\"MASTER\",\"value\":\"1\"}],\"image\":\"registry.baidubce.com/cce-ai-native/open_sora_plan:v1.1.0\",\"imagePullPolicy\":\"Always\",\"name\":\"pytorch\",\"resources\":{\"limits\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1}},\"securityContext\":{\"capabilities\":{\"add\":[\"IPC_LOCK\"]}},\"volumeMounts\":[{\"mountPath\":\"/dev/shm\",\"name\":\"cache-volume\"},{\"mountPath\":\"/workspace/Open-Sora-Plan/launch.sh\",\"name\":\"config-volume\",\"subPath\":\"launch.sh\"},{\"mountPath\":\"/remote-home1\",\"name\":\"data\"}]}],\"dnsPolicy\":\"ClusterFirstWithHostNet\",\"hostNetwork\":true,\"schedulerName\":\"volcano\",\"tolerations\":[{\"operator\":\"Exists\"}],\"volumes\":[{\"emptyDir\":{\"medium\":\"Memory\"},\"name\":\"cache-volume\"},{\"configMap\":{\"name\":\"launch-cm-open-sora-plan\"},\"name\":\"config-volume\"},{\"name\":\"data\",\"persistentVolumeClaim\":{\"claimName\":\"pvc-pfs\"}}]}}},\"Worker\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"template\":{\"metadata\":null,\"spec\":{\"containers\":[{\"command\":[\"bash\",\"/workspace/Open-Sora-Plan/launch.sh\"],\"env\":[{\"name\":\"CUDA_DEVICE_MAX_CONNECTIONS\",\"value\":\"1\"},{\"name\":\"NCCL_DEBUG\",\"value\":\"INFO\"},{\"name\":\"NCCL_IB_DISABLE\",\"value\":\"0\"}],\"image\":\"registry.baidubce.com/cce-ai-native/open_sora_plan:v1.1.0\",\"imagePullPolicy\":\"Always\",\"name\":\"pytorch\",\"resources\":{\"limits\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1}},\"securityContext\":{\"capabilities\":{\"add\":[\"IPC_LOCK\"]}},\"volumeMounts\":[{\"mountPath\":\"/dev/shm\",\"name\":\"cache-volume\"},{\"mountPath\":\"/workspace/Open-Sora-Plan/launch.sh\",\"name\":\"config-volume\",\"subPath\":\"launch.sh\"},{\"mountPath\":\"/remote-home1\",\"name\":\"data\"}]}],\"dnsPolicy\":\"ClusterFirstWithHostNet\",\"hostNetwork\":true,\"schedulerName\":\"volcano\",\"tolerations\":[{\"operator\":\"Exists\"}],\"volumes\":[{\"emptyDir\":{\"medium\":\"Memory\"},\"name\":\"cache-volume\"},{\"configMap\":{\"name\":\"launch-cm-open-sora-plan\"},\"name\":\"config-volume\"},{\"name\":\"data\",\"persistentVolumeClaim\":{\"claimName\":\"pvc-pfs\"}}]}}}}}}\n"
              },
              "creationTimestamp": "2024-07-22T17:07:30Z",
              "generation": 2,
              "managedFields": [
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        "f:aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": {},
                        "f:aijob.cce.baidubce.com/timeline": {}
                      }
                    }
                  },
                  "manager": "controller",
                  "operation": "Update",
                  "time": "2024-07-22T17:07:30Z"
                },
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        ".": {},
                        "f:kubectl.kubernetes.io/last-applied-configuration": {}
                      }
                    },
                    "f:spec": {
                      ".": {},
                      "f:pytorchReplicaSpecs": {
                        ".": {},
                        "f:Master": {
                          ".": {},
                          "f:replicas": {},
                          "f:restartPolicy": {},
                          "f:template": {
                            ".": {},
                            "f:spec": {
                              ".": {},
                              "f:dnsPolicy": {},
                              "f:hostNetwork": {},
                              "f:schedulerName": {},
                              "f:tolerations": {},
                              "f:volumes": {}
                            }
                          }
                        },
                        "f:Worker": {
                          ".": {},
                          "f:replicas": {},
                          "f:restartPolicy": {},
                          "f:template": {
                            ".": {},
                            "f:spec": {
                              ".": {},
                              "f:dnsPolicy": {},
                              "f:hostNetwork": {},
                              "f:schedulerName": {},
                              "f:tolerations": {},
                              "f:volumes": {}
                            }
                          }
                        }
                      }
                    }
                  },
                  "manager": "kubectl-client-side-apply",
                  "operation": "Update",
                  "time": "2024-07-22T17:07:30Z"
                },
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        "f:aijob.cce.baidubce.com/barrier-finish": {}
                      }
                    }
                  },
                  "manager": "jobbarrier",
                  "operation": "Update",
                  "time": "2024-07-22T17:10:42Z"
                },
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {}
                      }
                    },
                    "f:spec": {
                      "f:pytorchReplicaSpecs": {
                        "f:Master": {
                          "f:template": {
                            "f:metadata": {},
                            "f:spec": {
                              "f:containers": {}
                            }
                          }
                        },
                        "f:Worker": {
                          "f:template": {
                            "f:metadata": {},
                            "f:spec": {
                              "f:containers": {}
                            }
                          }
                        }
                      },
                      "f:runPolicy": {
                        ".": {},
                        "f:cleanPodPolicy": {}
                      }
                    },
                    "f:status": {
                      ".": {},
                      "f:conditions": {},
                      "f:lastReconcileTime": {},
                      "f:replicaStatuses": {
                        ".": {},
                        "f:Master": {
                          ".": {},
                          "f:active": {},
                          "f:selector": {}
                        },
                        "f:Worker": {
                          ".": {},
                          "f:active": {},
                          "f:selector": {}
                        }
                      },
                      "f:startTime": {}
                    }
                  },
                  "manager": "manager",
                  "operation": "Update",
                  "time": "2024-07-22T17:10:51Z"
                }
              ],
              "name": "wangzhuyun-accelerate-open-sora-plan",
              "namespace": "default",
              "resourceVersion": "2376578060",
              "uid": "7b721fc4-9bc9-4206-a741-84439f7ea51b"
            },
            "spec": {
              "pytorchReplicaSpecs": {
                "Master": {
                  "replicas": 1,
                  "restartPolicy": "Never",
                  "template": {
                    "metadata": {},
                    "spec": {
                      "containers": [
                        {
                          "command": [
                            "bash",
                            "/workspace/Open-Sora-Plan/launch.sh"
                          ],
                          "env": [
                            {
                              "name": "CUDA_DEVICE_MAX_CONNECTIONS",
                              "value": "1"
                            },
                            {
                              "name": "NCCL_DEBUG",
                              "value": "INFO"
                            },
                            {
                              "name": "NCCL_IB_DISABLE",
                              "value": "0"
                            },
                            {
                              "name": "MASTER",
                              "value": "1"
                            }
                          ],
                          "image": "registry.baidubce.com/cce-ai-native/open_sora_plan:v1.1.0",
                          "imagePullPolicy": "Always",
                          "name": "pytorch",
                          "ports": [
                            {
                              "containerPort": 23456,
                              "name": "pytorchjob-port",
                              "protocol": "TCP"
                            }
                          ],
                          "resources": {
                            "limits": {
                              "baidu.com/a800_80g_cgpu": "8",
                              "rdma/hca": "1"
                            }
                          },
                          "securityContext": {
                            "capabilities": {
                              "add": [
                                "IPC_LOCK"
                              ]
                            }
                          },
                          "volumeMounts": [
                            {
                              "mountPath": "/dev/shm",
                              "name": "cache-volume"
                            },
                            {
                              "mountPath": "/workspace/Open-Sora-Plan/launch.sh",
                              "name": "config-volume",
                              "subPath": "launch.sh"
                            },
                            {
                              "mountPath": "/remote-home1",
                              "name": "data"
                            }
                          ]
                        }
                      ],
                      "dnsPolicy": "ClusterFirstWithHostNet",
                      "hostNetwork": true,
                      "schedulerName": "volcano",
                      "tolerations": [
                        {
                          "operator": "Exists"
                        }
                      ],
                      "volumes": [
                        {
                          "emptyDir": {
                            "medium": "Memory"
                          },
                          "name": "cache-volume"
                        },
                        {
                          "configMap": {
                            "name": "launch-cm-open-sora-plan"
                          },
                          "name": "config-volume"
                        },
                        {
                          "name": "data",
                          "persistentVolumeClaim": {
                            "claimName": "pvc-pfs"
                          }
                        }
                      ]
                    }
                  }
                },
                "Worker": {
                  "replicas": 1,
                  "restartPolicy": "Never",
                  "template": {
                    "metadata": {},
                    "spec": {
                      "containers": [
                        {
                          "command": [
                            "bash",
                            "/workspace/Open-Sora-Plan/launch.sh"
                          ],
                          "env": [
                            {
                              "name": "CUDA_DEVICE_MAX_CONNECTIONS",
                              "value": "1"
                            },
                            {
                              "name": "NCCL_DEBUG",
                              "value": "INFO"
                            },
                            {
                              "name": "NCCL_IB_DISABLE",
                              "value": "0"
                            }
                          ],
                          "image": "registry.baidubce.com/cce-ai-native/open_sora_plan:v1.1.0",
                          "imagePullPolicy": "Always",
                          "name": "pytorch",
                          "ports": [
                            {
                              "containerPort": 23456,
                              "name": "pytorchjob-port",
                              "protocol": "TCP"
                            }
                          ],
                          "resources": {
                            "limits": {
                              "baidu.com/a800_80g_cgpu": "8",
                              "rdma/hca": "1"
                            }
                          },
                          "securityContext": {
                            "capabilities": {
                              "add": [
                                "IPC_LOCK"
                              ]
                            }
                          },
                          "volumeMounts": [
                            {
                              "mountPath": "/dev/shm",
                              "name": "cache-volume"
                            },
                            {
                              "mountPath": "/workspace/Open-Sora-Plan/launch.sh",
                              "name": "config-volume",
                              "subPath": "launch.sh"
                            },
                            {
                              "mountPath": "/remote-home1",
                              "name": "data"
                            }
                          ]
                        }
                      ],
                      "dnsPolicy": "ClusterFirstWithHostNet",
                      "hostNetwork": true,
                      "schedulerName": "volcano",
                      "tolerations": [
                        {
                          "operator": "Exists"
                        }
                      ],
                      "volumes": [
                        {
                          "emptyDir": {
                            "medium": "Memory"
                          },
                          "name": "cache-volume"
                        },
                        {
                          "configMap": {
                            "name": "launch-cm-open-sora-plan"
                          },
                          "name": "config-volume"
                        },
                        {
                          "name": "data",
                          "persistentVolumeClaim": {
                            "claimName": "pvc-pfs"
                          }
                        }
                      ]
                    }
                  }
                }
              },
              "runPolicy": {
                "cleanPodPolicy": "None"
              }
            },
            "status": {
              "conditions": [
                {
                  "lastTransitionTime": "2024-07-22T17:07:30Z",
                  "lastUpdateTime": "2024-07-22T17:07:30Z",
                  "message": "PyTorchJob wangzhuyun-accelerate-open-sora-plan is created.",
                  "reason": "PyTorchJobCreated",
                  "status": "True",
                  "type": "Created"
                },
                {
                  "lastTransitionTime": "2024-07-22T17:10:46Z",
                  "lastUpdateTime": "2024-07-22T17:10:46Z",
                  "message": "PyTorchJob wangzhuyun-accelerate-open-sora-plan is running.",
                  "reason": "JobRunning",
                  "status": "True",
                  "type": "Running"
                }
              ],
              "lastReconcileTime": "2024-07-22T17:07:30Z",
              "replicaStatuses": {
                "Master": {
                  "active": 1,
                  "selector": "training.kubeflow.org/job-name=wangzhuyun-accelerate-open-sora-plan,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=master"
                },
                "Worker": {
                  "active": 1,
                  "selector": "training.kubeflow.org/job-name=wangzhuyun-accelerate-open-sora-plan,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=worker"
                }
              },
              "startTime": "2024-07-22T17:07:31Z"
            }
          },
          {
            "apiVersion": "kubeflow.org/v1",
            "kind": "PyTorchJob",
            "metadata": {
              "annotations": {
                "aijob.cce.baidubce.com/barrier-finish": "72c47958-95fe-4174-86ce-0ae3e8eba4f5",
                "aijob.cce.baidubce.com/fault-tolerance-enabled": "false",
                "aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": "",
                "aijob.cce.baidubce.com/openapi-jobid": "pytorch-b3c9ce0b-1e76-427d-a2d7-eea086048d3d",
                "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
                "aijob.cce.baidubce.com/raw-request": "{\"name\":\"whx-llama-test-3\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"normal\",\"oversell\":false,\"faultTolerance\":false,\"command\":\"/bin/bash -c\\n#! /bin/bash\\n#rm /workspace/llama/pile_llama_test/*_indexmap*\\n#rm -rf /workspace/llama/pile_llama_test/pile_test_jsonl/\\nROOT_DIR=/workspace/Megatron-LM/examples\\n# 数据集及CHECKPOINT的PATH可按需替换成用户自定义路径\\nDATA_PATH=/mnt/cluster/llama/pile_llama_test/pile-llama_text_document\\nTOKENIZER_PATH=/mnt/cluster/llama/tokenizer/tokenizer.model\\nTENSORBOARD_PATH=/workspace\\n\\nMOUNT_PATH=/mnt/cluster\\nPATH_RESOURCE=/workspace/llama\\n\\n\\n# Ensure the mount path exists\\nmkdir -p ${MOUNT_PATH}\\necho \\\"Contents of MOUNT_PATH before copy:\\\"\\nls -l ${MOUNT_PATH}\\n\\n# Copy data to the mount path\\ncp -r ${PATH_RESOURCE} ${MOUNT_PATH} || { echo \\\"Failed to copy PATH_RESOURCE\\\"; exit 1; }\\n\\necho \\\"Contents of MOUNT_PATH after copy:\\\"\\nls -l ${MOUNT_PATH}\\n\\n\\nGPUS_PER_NODE=8\\n\\nDISTRIBUTED_ARGS=\\\"--nproc_per_node ${GPUS_PER_NODE} --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $MASTER_ADDR --master_port $MASTER_PORT\\\"\\nLLAMA2_7B_ARGS=\\\"--tensor-model-parallel-size 1 \\\\\\n--pipeline-model-parallel-size 2 \\\\\\n--num-layers 32 \\\\\\n--hidden-size 4096 \\\\\\n--ffn-hidden-size 11008 \\\\\\n--num-attention-heads 32 \\\\\\n--micro-batch-size 1 \\\\\\n--global-batch-size 16 \\\\\\n--seq-length 512 \\\\\\n--max-position-embeddings 4096 \\\\\\n--lr 0.0003 \\\\\\n--min-lr 1.0e-5 \\\\\\n--clip-grad 1.0 \\\\\\n--weight-decay 1e-2 \\\\\\n--optimizer adam \\\\\\n--adam-beta1 0.9 \\\\\\n--adam-beta2 0.95 \\\\\\n--adam-eps 1e-05 \\\\\\n--train-iters 5000 \\\\\\n--lr-decay-iters 320000 \\\\\\n--lr-decay-style cosine \\\\\\n--lr-warmup-fraction .01 \\\\\\n--no-async-tensor-model-parallel-allreduce \\\\\\n--tokenizer-type LLaMASentencePieceTokenizer \\\\\\n--tokenizer-model $TOKENIZER_PATH \\\\\\n--activation-func swiglu \\\\\\n--use-rotary-position-embeddings \\\\\\n--rmsnorm-epsilon 1e-5 \\\\\\n--no-position-embedding \\\\\\n--disable-bias-linear \\\\\\n--attention-dropout 0 \\\\\\n--hidden-dropout 0 \\\\\\n--embedding-dropout 0 \\\\\\n--use-distributed-optimizer \\\\\\n--untie-embeddings-and-output-weights \\\\\\n--initial-loss-scale 16 \\\\\\n--sequence-parallel \\\\\\n--fused-rmsnorm \\\\\\n--fp16\\\"\\n\\nOUTPUT_ARGS=\\\"--log-interval 1 \\\\\\n --save-interval 50000 \\\\\\n --eval-interval 1000 \\\\\\n --eval-iters 10\\\"\\n\\nOTHER_ARGS=\\\"--data-path $DATA_PATH \\\\\\n--data-impl mmap \\\\\\n--split 949,50,1 \\\\\\n--tensorboard-dir ${TENSORBOARD_PATH} \\\\\\n--distributed-backend nccl\\\"\\n\\nPYTHONPATH=\\\"$ROOT_DIR/..\\\":\\\"$ROOT_DIR/../megatron/fused_kernels\\\":$PYTHONPATH \\\\\\npython -m torch.distributed.launch $DISTRIBUTED_ARGS \\\\\\n$ROOT_DIR/../pretrain_llama.py \\\\\\n$LLAMA2_7B_ARGS \\\\\\n$OUTPUT_ARGS \\\\\\n$OTHER_ARGS\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":true,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-megatron\",\"tag\":\"ubuntu20.04-cu11.8-torch1.14.0-py38-bccl1.2.3.1_v1.2.7.5_release-test3\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"whx-llama-test-3\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/whx-llama-test-3/output/training_logs\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"},\"Worker\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-megatron\",\"tag\":\"ubuntu20.04-cu11.8-torch1.14.0-py38-bccl1.2.3.1_v1.2.7.5_release-test3\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"whx-llama-test-3\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/whx-llama-test-3/output/training_logs\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":true,\"logPath\":\"/mnt/cluster/whx-llama-test-3/output/training_logs\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":true,\"isCopyJob\":true,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
                "aijob.cce.baidubce.com/timeline": "[{\"conditionType\":\"Created\",\"time\":1721374704},{\"conditionType\":\"Scheduled\",\"time\":1721374706},{\"conditionType\":\"Running\",\"time\":1721375168},{\"conditionType\":\"Succeeded\",\"time\":1721376909}]",
                "scheduling.k8s.io/job-enable-oversell": "false",
                "tensorboard-gc": "true"
              },
              "creationTimestamp": "2024-07-19T07:38:24Z",
              "generation": 2,
              "labels": {
                "aijob.cce.baidubce.com/ai-user-id": "44b2ef4fe15a45a7ab5b1227ae50a261",
                "aijob.cce.baidubce.com/ai-user-name": "wanghouxi",
                "aijob.cce.baidubce.com/create-from-aihcp": "true",
                "aijob.cce.baidubce.com/openapi-jobid": "pytorch-b3c9ce0b-1e76-427d-a2d7-eea086048d3d"
              },
              "managedFields": [
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        ".": {},
                        "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                        "f:aijob.cce.baidubce.com/openapi-jobid": {},
                        "f:aijob.cce.baidubce.com/pfs-id": {},
                        "f:aijob.cce.baidubce.com/raw-request": {},
                        "f:scheduling.k8s.io/job-enable-oversell": {}
                      },
                      "f:labels": {
                        ".": {},
                        "f:aijob.cce.baidubce.com/ai-user-id": {},
                        "f:aijob.cce.baidubce.com/ai-user-name": {},
                        "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                        "f:aijob.cce.baidubce.com/openapi-jobid": {}
                      }
                    },
                    "f:spec": {
                      ".": {},
                      "f:pytorchReplicaSpecs": {
                        ".": {},
                        "f:Master": {
                          ".": {},
                          "f:replicas": {},
                          "f:restartPolicy": {},
                          "f:template": {
                            ".": {},
                            "f:metadata": {
                              ".": {},
                              "f:annotations": {
                                ".": {},
                                "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                                "f:aijob.cce.baidubce.com/openapi-jobid": {},
                                "f:aijob.cce.baidubce.com/pfs-id": {},
                                "f:aijob.cce.baidubce.com/raw-request": {},
                                "f:scheduling.k8s.io/job-enable-oversell": {}
                              },
                              "f:labels": {
                                ".": {},
                                "f:aijob.cce.baidubce.com/ai-user-id": {},
                                "f:aijob.cce.baidubce.com/ai-user-name": {},
                                "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                                "f:aijob.cce.baidubce.com/openapi-jobid": {}
                              }
                            },
                            "f:spec": {
                              ".": {},
                              "f:dnsPolicy": {},
                              "f:hostNetwork": {},
                              "f:schedulerName": {},
                              "f:volumes": {}
                            }
                          }
                        },
                        "f:Worker": {
                          ".": {},
                          "f:replicas": {},
                          "f:restartPolicy": {},
                          "f:template": {
                            ".": {},
                            "f:metadata": {
                              ".": {},
                              "f:annotations": {
                                ".": {},
                                "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                                "f:aijob.cce.baidubce.com/openapi-jobid": {},
                                "f:aijob.cce.baidubce.com/pfs-id": {},
                                "f:aijob.cce.baidubce.com/raw-request": {},
                                "f:scheduling.k8s.io/job-enable-oversell": {}
                              },
                              "f:labels": {
                                ".": {},
                                "f:aijob.cce.baidubce.com/ai-user-id": {},
                                "f:aijob.cce.baidubce.com/ai-user-name": {},
                                "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                                "f:aijob.cce.baidubce.com/openapi-jobid": {}
                              }
                            },
                            "f:spec": {
                              ".": {},
                              "f:dnsPolicy": {},
                              "f:hostNetwork": {},
                              "f:schedulerName": {},
                              "f:volumes": {}
                            }
                          }
                        }
                      },
                      "f:runPolicy": {
                        ".": {},
                        "f:schedulingPolicy": {
                          ".": {},
                          "f:priorityClass": {},
                          "f:queue": {}
                        }
                      }
                    }
                  },
                  "manager": "cce-ai-service",
                  "operation": "Update",
                  "time": "2024-07-19T07:38:24Z"
                },
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        "f:aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": {},
                        "f:aijob.cce.baidubce.com/timeline": {}
                      }
                    },
                    "f:spec": {
                      "f:pytorchReplicaSpecs": {
                        "f:Master": {
                          "f:template": {
                            "f:spec": {
                              "f:containers": {}
                            }
                          }
                        },
                        "f:Worker": {
                          "f:template": {
                            "f:spec": {
                              "f:containers": {}
                            }
                          }
                        }
                      },
                      "f:runPolicy": {
                        "f:cleanPodPolicy": {}
                      }
                    }
                  },
                  "manager": "controller",
                  "operation": "Update",
                  "time": "2024-07-19T07:38:24Z"
                },
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        "f:aijob.cce.baidubce.com/barrier-finish": {}
                      }
                    }
                  },
                  "manager": "jobbarrier",
                  "operation": "Update",
                  "time": "2024-07-19T07:46:03Z"
                },
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        "f:tensorboard-gc": {}
                      }
                    },
                    "f:status": {
                      ".": {},
                      "f:completionTime": {},
                      "f:conditions": {},
                      "f:lastReconcileTime": {},
                      "f:replicaStatuses": {
                        ".": {},
                        "f:Master": {
                          ".": {},
                          "f:selector": {},
                          "f:succeeded": {}
                        },
                        "f:Worker": {
                          ".": {},
                          "f:selector": {},
                          "f:succeeded": {}
                        }
                      },
                      "f:startTime": {}
                    }
                  },
                  "manager": "manager",
                  "operation": "Update",
                  "time": "2024-07-20T07:39:10Z"
                }
              ],
              "name": "whx-llama-test-3",
              "namespace": "default",
              "resourceVersion": "2373784196",
              "uid": "83b2ed94-afe8-40ba-ae91-fc3fe563748d"
            },
            "spec": {
              "pytorchReplicaSpecs": {
                "Master": {
                  "replicas": 1,
                  "restartPolicy": "Never",
                  "template": {
                    "metadata": {
                      "annotations": {
                        "aijob.cce.baidubce.com/fault-tolerance-enabled": "false",
                        "aijob.cce.baidubce.com/openapi-jobid": "pytorch-b3c9ce0b-1e76-427d-a2d7-eea086048d3d",
                        "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
                        "aijob.cce.baidubce.com/raw-request": "{\"name\":\"whx-llama-test-3\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"normal\",\"oversell\":false,\"faultTolerance\":false,\"command\":\"/bin/bash -c\\n#! /bin/bash\\n#rm /workspace/llama/pile_llama_test/*_indexmap*\\n#rm -rf /workspace/llama/pile_llama_test/pile_test_jsonl/\\nROOT_DIR=/workspace/Megatron-LM/examples\\n# 数据集及CHECKPOINT的PATH可按需替换成用户自定义路径\\nDATA_PATH=/mnt/cluster/llama/pile_llama_test/pile-llama_text_document\\nTOKENIZER_PATH=/mnt/cluster/llama/tokenizer/tokenizer.model\\nTENSORBOARD_PATH=/workspace\\n\\nMOUNT_PATH=/mnt/cluster\\nPATH_RESOURCE=/workspace/llama\\n\\n\\n# Ensure the mount path exists\\nmkdir -p ${MOUNT_PATH}\\necho \\\"Contents of MOUNT_PATH before copy:\\\"\\nls -l ${MOUNT_PATH}\\n\\n# Copy data to the mount path\\ncp -r ${PATH_RESOURCE} ${MOUNT_PATH} || { echo \\\"Failed to copy PATH_RESOURCE\\\"; exit 1; }\\n\\necho \\\"Contents of MOUNT_PATH after copy:\\\"\\nls -l ${MOUNT_PATH}\\n\\n\\nGPUS_PER_NODE=8\\n\\nDISTRIBUTED_ARGS=\\\"--nproc_per_node ${GPUS_PER_NODE} --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $MASTER_ADDR --master_port $MASTER_PORT\\\"\\nLLAMA2_7B_ARGS=\\\"--tensor-model-parallel-size 1 \\\\\\n--pipeline-model-parallel-size 2 \\\\\\n--num-layers 32 \\\\\\n--hidden-size 4096 \\\\\\n--ffn-hidden-size 11008 \\\\\\n--num-attention-heads 32 \\\\\\n--micro-batch-size 1 \\\\\\n--global-batch-size 16 \\\\\\n--seq-length 512 \\\\\\n--max-position-embeddings 4096 \\\\\\n--lr 0.0003 \\\\\\n--min-lr 1.0e-5 \\\\\\n--clip-grad 1.0 \\\\\\n--weight-decay 1e-2 \\\\\\n--optimizer adam \\\\\\n--adam-beta1 0.9 \\\\\\n--adam-beta2 0.95 \\\\\\n--adam-eps 1e-05 \\\\\\n--train-iters 5000 \\\\\\n--lr-decay-iters 320000 \\\\\\n--lr-decay-style cosine \\\\\\n--lr-warmup-fraction .01 \\\\\\n--no-async-tensor-model-parallel-allreduce \\\\\\n--tokenizer-type LLaMASentencePieceTokenizer \\\\\\n--tokenizer-model $TOKENIZER_PATH \\\\\\n--activation-func swiglu \\\\\\n--use-rotary-position-embeddings \\\\\\n--rmsnorm-epsilon 1e-5 \\\\\\n--no-position-embedding \\\\\\n--disable-bias-linear \\\\\\n--attention-dropout 0 \\\\\\n--hidden-dropout 0 \\\\\\n--embedding-dropout 0 \\\\\\n--use-distributed-optimizer \\\\\\n--untie-embeddings-and-output-weights \\\\\\n--initial-loss-scale 16 \\\\\\n--sequence-parallel \\\\\\n--fused-rmsnorm \\\\\\n--fp16\\\"\\n\\nOUTPUT_ARGS=\\\"--log-interval 1 \\\\\\n --save-interval 50000 \\\\\\n --eval-interval 1000 \\\\\\n --eval-iters 10\\\"\\n\\nOTHER_ARGS=\\\"--data-path $DATA_PATH \\\\\\n--data-impl mmap \\\\\\n--split 949,50,1 \\\\\\n--tensorboard-dir ${TENSORBOARD_PATH} \\\\\\n--distributed-backend nccl\\\"\\n\\nPYTHONPATH=\\\"$ROOT_DIR/..\\\":\\\"$ROOT_DIR/../megatron/fused_kernels\\\":$PYTHONPATH \\\\\\npython -m torch.distributed.launch $DISTRIBUTED_ARGS \\\\\\n$ROOT_DIR/../pretrain_llama.py \\\\\\n$LLAMA2_7B_ARGS \\\\\\n$OUTPUT_ARGS \\\\\\n$OTHER_ARGS\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":true,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-megatron\",\"tag\":\"ubuntu20.04-cu11.8-torch1.14.0-py38-bccl1.2.3.1_v1.2.7.5_release-test3\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"whx-llama-test-3\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/whx-llama-test-3/output/training_logs\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"},\"Worker\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-megatron\",\"tag\":\"ubuntu20.04-cu11.8-torch1.14.0-py38-bccl1.2.3.1_v1.2.7.5_release-test3\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"whx-llama-test-3\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/whx-llama-test-3/output/training_logs\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":true,\"logPath\":\"/mnt/cluster/whx-llama-test-3/output/training_logs\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":true,\"isCopyJob\":true,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
                        "scheduling.k8s.io/job-enable-oversell": "false"
                      },
                      "labels": {
                        "aijob.cce.baidubce.com/ai-user-id": "44b2ef4fe15a45a7ab5b1227ae50a261",
                        "aijob.cce.baidubce.com/ai-user-name": "wanghouxi",
                        "aijob.cce.baidubce.com/create-from-aihcp": "true",
                        "aijob.cce.baidubce.com/openapi-jobid": "pytorch-b3c9ce0b-1e76-427d-a2d7-eea086048d3d"
                      }
                    },
                    "spec": {
                      "containers": [
                        {
                          "command": [
                            "/bin/bash",
                            "-c",
                            "/bin/bash -c\n#! /bin/bash\n#rm /workspace/llama/pile_llama_test/*_indexmap*\n#rm -rf /workspace/llama/pile_llama_test/pile_test_jsonl/\nROOT_DIR=/workspace/Megatron-LM/examples\n# 数据集及CHECKPOINT的PATH可按需替换成用户自定义路径\nDATA_PATH=/mnt/cluster/llama/pile_llama_test/pile-llama_text_document\nTOKENIZER_PATH=/mnt/cluster/llama/tokenizer/tokenizer.model\nTENSORBOARD_PATH=/workspace\n\nMOUNT_PATH=/mnt/cluster\nPATH_RESOURCE=/workspace/llama\n\n\n# Ensure the mount path exists\nmkdir -p ${MOUNT_PATH}\necho \"Contents of MOUNT_PATH before copy:\"\nls -l ${MOUNT_PATH}\n\n# Copy data to the mount path\ncp -r ${PATH_RESOURCE} ${MOUNT_PATH} || { echo \"Failed to copy PATH_RESOURCE\"; exit 1; }\n\necho \"Contents of MOUNT_PATH after copy:\"\nls -l ${MOUNT_PATH}\n\n\nGPUS_PER_NODE=8\n\nDISTRIBUTED_ARGS=\"--nproc_per_node ${GPUS_PER_NODE} --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $MASTER_ADDR --master_port $MASTER_PORT\"\nLLAMA2_7B_ARGS=\"--tensor-model-parallel-size 1 \\\n--pipeline-model-parallel-size 2 \\\n--num-layers 32 \\\n--hidden-size 4096 \\\n--ffn-hidden-size 11008 \\\n--num-attention-heads 32 \\\n--micro-batch-size 1 \\\n--global-batch-size 16 \\\n--seq-length 512 \\\n--max-position-embeddings 4096 \\\n--lr 0.0003 \\\n--min-lr 1.0e-5 \\\n--clip-grad 1.0 \\\n--weight-decay 1e-2 \\\n--optimizer adam \\\n--adam-beta1 0.9 \\\n--adam-beta2 0.95 \\\n--adam-eps 1e-05 \\\n--train-iters 5000 \\\n--lr-decay-iters 320000 \\\n--lr-decay-style cosine \\\n--lr-warmup-fraction .01 \\\n--no-async-tensor-model-parallel-allreduce \\\n--tokenizer-type LLaMASentencePieceTokenizer \\\n--tokenizer-model $TOKENIZER_PATH \\\n--activation-func swiglu \\\n--use-rotary-position-embeddings \\\n--rmsnorm-epsilon 1e-5 \\\n--no-position-embedding \\\n--disable-bias-linear \\\n--attention-dropout 0 \\\n--hidden-dropout 0 \\\n--embedding-dropout 0 \\\n--use-distributed-optimizer \\\n--untie-embeddings-and-output-weights \\\n--initial-loss-scale 16 \\\n--sequence-parallel \\\n--fused-rmsnorm \\\n--fp16\"\n\nOUTPUT_ARGS=\"--log-interval 1 \\\n --save-interval 50000 \\\n --eval-interval 1000 \\\n --eval-iters 10\"\n\nOTHER_ARGS=\"--data-path $DATA_PATH \\\n--data-impl mmap \\\n--split 949,50,1 \\\n--tensorboard-dir ${TENSORBOARD_PATH} \\\n--distributed-backend nccl\"\n\nPYTHONPATH=\"$ROOT_DIR/..\":\"$ROOT_DIR/../megatron/fused_kernels\":$PYTHONPATH \\\npython -m torch.distributed.launch $DISTRIBUTED_ARGS \\\n$ROOT_DIR/../pretrain_llama.py \\\n$LLAMA2_7B_ARGS \\\n$OUTPUT_ARGS \\\n$OTHER_ARGS"
                          ],
                          "env": [
                            {
                              "name": "AIHC_TENSORBOARD_LOG_PATH",
                              "value": "/mnt/cluster/whx-llama-test-3/output/training_logs"
                            },
                            {
                              "name": "AIHC_JOB_NAME",
                              "value": "whx-llama-test-3"
                            },
                            {
                              "name": "NCCL_IB_DISABLE",
                              "value": "0"
                            }
                          ],
                          "image": "registry.baidubce.com/aihc-aiak/aiak-megatron:ubuntu20.04-cu11.8-torch1.14.0-py38-bccl1.2.3.1_v1.2.7.5_release-test3",
                          "imagePullPolicy": "Always",
                          "name": "pytorch",
                          "ports": [
                            {
                              "containerPort": 23456,
                              "name": "pytorchjob-port",
                              "protocol": "TCP"
                            }
                          ],
                          "resources": {
                            "limits": {
                              "baidu.com/a800_80g_cgpu": "8",
                              "rdma/hca": "1"
                            },
                            "requests": {
                              "baidu.com/a800_80g_cgpu": "8",
                              "rdma/hca": "1"
                            }
                          },
                          "securityContext": {
                            "capabilities": {
                              "add": [
                                "IPC_LOCK"
                              ]
                            }
                          },
                          "volumeMounts": [
                            {
                              "mountPath": "/dev/shm",
                              "name": "devshm"
                            },
                            {
                              "mountPath": "/mnt/cluster",
                              "name": "pvc-pfs"
                            }
                          ]
                        }
                      ],
                      "dnsPolicy": "ClusterFirstWithHostNet",
                      "hostNetwork": true,
                      "schedulerName": "volcano",
                      "volumes": [
                        {
                          "emptyDir": {
                            "medium": "Memory",
                            "sizeLimit": "10Gi"
                          },
                          "name": "devshm"
                        },
                        {
                          "name": "pvc-pfs",
                          "persistentVolumeClaim": {
                            "claimName": "pvc-pfs"
                          }
                        }
                      ]
                    }
                  }
                },
                "Worker": {
                  "replicas": 1,
                  "restartPolicy": "Never",
                  "template": {
                    "metadata": {
                      "annotations": {
                        "aijob.cce.baidubce.com/fault-tolerance-enabled": "false",
                        "aijob.cce.baidubce.com/openapi-jobid": "pytorch-b3c9ce0b-1e76-427d-a2d7-eea086048d3d",
                        "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
                        "aijob.cce.baidubce.com/raw-request": "{\"name\":\"whx-llama-test-3\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"normal\",\"oversell\":false,\"faultTolerance\":false,\"command\":\"/bin/bash -c\\n#! /bin/bash\\n#rm /workspace/llama/pile_llama_test/*_indexmap*\\n#rm -rf /workspace/llama/pile_llama_test/pile_test_jsonl/\\nROOT_DIR=/workspace/Megatron-LM/examples\\n# 数据集及CHECKPOINT的PATH可按需替换成用户自定义路径\\nDATA_PATH=/mnt/cluster/llama/pile_llama_test/pile-llama_text_document\\nTOKENIZER_PATH=/mnt/cluster/llama/tokenizer/tokenizer.model\\nTENSORBOARD_PATH=/workspace\\n\\nMOUNT_PATH=/mnt/cluster\\nPATH_RESOURCE=/workspace/llama\\n\\n\\n# Ensure the mount path exists\\nmkdir -p ${MOUNT_PATH}\\necho \\\"Contents of MOUNT_PATH before copy:\\\"\\nls -l ${MOUNT_PATH}\\n\\n# Copy data to the mount path\\ncp -r ${PATH_RESOURCE} ${MOUNT_PATH} || { echo \\\"Failed to copy PATH_RESOURCE\\\"; exit 1; }\\n\\necho \\\"Contents of MOUNT_PATH after copy:\\\"\\nls -l ${MOUNT_PATH}\\n\\n\\nGPUS_PER_NODE=8\\n\\nDISTRIBUTED_ARGS=\\\"--nproc_per_node ${GPUS_PER_NODE} --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $MASTER_ADDR --master_port $MASTER_PORT\\\"\\nLLAMA2_7B_ARGS=\\\"--tensor-model-parallel-size 1 \\\\\\n--pipeline-model-parallel-size 2 \\\\\\n--num-layers 32 \\\\\\n--hidden-size 4096 \\\\\\n--ffn-hidden-size 11008 \\\\\\n--num-attention-heads 32 \\\\\\n--micro-batch-size 1 \\\\\\n--global-batch-size 16 \\\\\\n--seq-length 512 \\\\\\n--max-position-embeddings 4096 \\\\\\n--lr 0.0003 \\\\\\n--min-lr 1.0e-5 \\\\\\n--clip-grad 1.0 \\\\\\n--weight-decay 1e-2 \\\\\\n--optimizer adam \\\\\\n--adam-beta1 0.9 \\\\\\n--adam-beta2 0.95 \\\\\\n--adam-eps 1e-05 \\\\\\n--train-iters 5000 \\\\\\n--lr-decay-iters 320000 \\\\\\n--lr-decay-style cosine \\\\\\n--lr-warmup-fraction .01 \\\\\\n--no-async-tensor-model-parallel-allreduce \\\\\\n--tokenizer-type LLaMASentencePieceTokenizer \\\\\\n--tokenizer-model $TOKENIZER_PATH \\\\\\n--activation-func swiglu \\\\\\n--use-rotary-position-embeddings \\\\\\n--rmsnorm-epsilon 1e-5 \\\\\\n--no-position-embedding \\\\\\n--disable-bias-linear \\\\\\n--attention-dropout 0 \\\\\\n--hidden-dropout 0 \\\\\\n--embedding-dropout 0 \\\\\\n--use-distributed-optimizer \\\\\\n--untie-embeddings-and-output-weights \\\\\\n--initial-loss-scale 16 \\\\\\n--sequence-parallel \\\\\\n--fused-rmsnorm \\\\\\n--fp16\\\"\\n\\nOUTPUT_ARGS=\\\"--log-interval 1 \\\\\\n --save-interval 50000 \\\\\\n --eval-interval 1000 \\\\\\n --eval-iters 10\\\"\\n\\nOTHER_ARGS=\\\"--data-path $DATA_PATH \\\\\\n--data-impl mmap \\\\\\n--split 949,50,1 \\\\\\n--tensorboard-dir ${TENSORBOARD_PATH} \\\\\\n--distributed-backend nccl\\\"\\n\\nPYTHONPATH=\\\"$ROOT_DIR/..\\\":\\\"$ROOT_DIR/../megatron/fused_kernels\\\":$PYTHONPATH \\\\\\npython -m torch.distributed.launch $DISTRIBUTED_ARGS \\\\\\n$ROOT_DIR/../pretrain_llama.py \\\\\\n$LLAMA2_7B_ARGS \\\\\\n$OUTPUT_ARGS \\\\\\n$OTHER_ARGS\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":true,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-megatron\",\"tag\":\"ubuntu20.04-cu11.8-torch1.14.0-py38-bccl1.2.3.1_v1.2.7.5_release-test3\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"whx-llama-test-3\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/whx-llama-test-3/output/training_logs\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"},\"Worker\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-megatron\",\"tag\":\"ubuntu20.04-cu11.8-torch1.14.0-py38-bccl1.2.3.1_v1.2.7.5_release-test3\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"whx-llama-test-3\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/whx-llama-test-3/output/training_logs\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":true,\"logPath\":\"/mnt/cluster/whx-llama-test-3/output/training_logs\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":true,\"isCopyJob\":true,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
                        "scheduling.k8s.io/job-enable-oversell": "false"
                      },
                      "labels": {
                        "aijob.cce.baidubce.com/ai-user-id": "44b2ef4fe15a45a7ab5b1227ae50a261",
                        "aijob.cce.baidubce.com/ai-user-name": "wanghouxi",
                        "aijob.cce.baidubce.com/create-from-aihcp": "true",
                        "aijob.cce.baidubce.com/openapi-jobid": "pytorch-b3c9ce0b-1e76-427d-a2d7-eea086048d3d"
                      }
                    },
                    "spec": {
                      "containers": [
                        {
                          "command": [
                            "/bin/bash",
                            "-c",
                            "/bin/bash -c\n#! /bin/bash\n#rm /workspace/llama/pile_llama_test/*_indexmap*\n#rm -rf /workspace/llama/pile_llama_test/pile_test_jsonl/\nROOT_DIR=/workspace/Megatron-LM/examples\n# 数据集及CHECKPOINT的PATH可按需替换成用户自定义路径\nDATA_PATH=/mnt/cluster/llama/pile_llama_test/pile-llama_text_document\nTOKENIZER_PATH=/mnt/cluster/llama/tokenizer/tokenizer.model\nTENSORBOARD_PATH=/workspace\n\nMOUNT_PATH=/mnt/cluster\nPATH_RESOURCE=/workspace/llama\n\n\n# Ensure the mount path exists\nmkdir -p ${MOUNT_PATH}\necho \"Contents of MOUNT_PATH before copy:\"\nls -l ${MOUNT_PATH}\n\n# Copy data to the mount path\ncp -r ${PATH_RESOURCE} ${MOUNT_PATH} || { echo \"Failed to copy PATH_RESOURCE\"; exit 1; }\n\necho \"Contents of MOUNT_PATH after copy:\"\nls -l ${MOUNT_PATH}\n\n\nGPUS_PER_NODE=8\n\nDISTRIBUTED_ARGS=\"--nproc_per_node ${GPUS_PER_NODE} --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $MASTER_ADDR --master_port $MASTER_PORT\"\nLLAMA2_7B_ARGS=\"--tensor-model-parallel-size 1 \\\n--pipeline-model-parallel-size 2 \\\n--num-layers 32 \\\n--hidden-size 4096 \\\n--ffn-hidden-size 11008 \\\n--num-attention-heads 32 \\\n--micro-batch-size 1 \\\n--global-batch-size 16 \\\n--seq-length 512 \\\n--max-position-embeddings 4096 \\\n--lr 0.0003 \\\n--min-lr 1.0e-5 \\\n--clip-grad 1.0 \\\n--weight-decay 1e-2 \\\n--optimizer adam \\\n--adam-beta1 0.9 \\\n--adam-beta2 0.95 \\\n--adam-eps 1e-05 \\\n--train-iters 5000 \\\n--lr-decay-iters 320000 \\\n--lr-decay-style cosine \\\n--lr-warmup-fraction .01 \\\n--no-async-tensor-model-parallel-allreduce \\\n--tokenizer-type LLaMASentencePieceTokenizer \\\n--tokenizer-model $TOKENIZER_PATH \\\n--activation-func swiglu \\\n--use-rotary-position-embeddings \\\n--rmsnorm-epsilon 1e-5 \\\n--no-position-embedding \\\n--disable-bias-linear \\\n--attention-dropout 0 \\\n--hidden-dropout 0 \\\n--embedding-dropout 0 \\\n--use-distributed-optimizer \\\n--untie-embeddings-and-output-weights \\\n--initial-loss-scale 16 \\\n--sequence-parallel \\\n--fused-rmsnorm \\\n--fp16\"\n\nOUTPUT_ARGS=\"--log-interval 1 \\\n --save-interval 50000 \\\n --eval-interval 1000 \\\n --eval-iters 10\"\n\nOTHER_ARGS=\"--data-path $DATA_PATH \\\n--data-impl mmap \\\n--split 949,50,1 \\\n--tensorboard-dir ${TENSORBOARD_PATH} \\\n--distributed-backend nccl\"\n\nPYTHONPATH=\"$ROOT_DIR/..\":\"$ROOT_DIR/../megatron/fused_kernels\":$PYTHONPATH \\\npython -m torch.distributed.launch $DISTRIBUTED_ARGS \\\n$ROOT_DIR/../pretrain_llama.py \\\n$LLAMA2_7B_ARGS \\\n$OUTPUT_ARGS \\\n$OTHER_ARGS"
                          ],
                          "env": [
                            {
                              "name": "AIHC_TENSORBOARD_LOG_PATH",
                              "value": "/mnt/cluster/whx-llama-test-3/output/training_logs"
                            },
                            {
                              "name": "AIHC_JOB_NAME",
                              "value": "whx-llama-test-3"
                            },
                            {
                              "name": "NCCL_IB_DISABLE",
                              "value": "0"
                            }
                          ],
                          "image": "registry.baidubce.com/aihc-aiak/aiak-megatron:ubuntu20.04-cu11.8-torch1.14.0-py38-bccl1.2.3.1_v1.2.7.5_release-test3",
                          "imagePullPolicy": "Always",
                          "name": "pytorch",
                          "ports": [
                            {
                              "containerPort": 23456,
                              "name": "pytorchjob-port",
                              "protocol": "TCP"
                            }
                          ],
                          "resources": {
                            "limits": {
                              "baidu.com/a800_80g_cgpu": "8",
                              "rdma/hca": "1"
                            },
                            "requests": {
                              "baidu.com/a800_80g_cgpu": "8",
                              "rdma/hca": "1"
                            }
                          },
                          "securityContext": {
                            "capabilities": {
                              "add": [
                                "IPC_LOCK"
                              ]
                            }
                          },
                          "volumeMounts": [
                            {
                              "mountPath": "/dev/shm",
                              "name": "devshm"
                            },
                            {
                              "mountPath": "/mnt/cluster",
                              "name": "pvc-pfs"
                            }
                          ]
                        }
                      ],
                      "dnsPolicy": "ClusterFirstWithHostNet",
                      "hostNetwork": true,
                      "schedulerName": "volcano",
                      "volumes": [
                        {
                          "emptyDir": {
                            "medium": "Memory",
                            "sizeLimit": "10Gi"
                          },
                          "name": "devshm"
                        },
                        {
                          "name": "pvc-pfs",
                          "persistentVolumeClaim": {
                            "claimName": "pvc-pfs"
                          }
                        }
                      ]
                    }
                  }
                }
              },
              "runPolicy": {
                "cleanPodPolicy": "None",
                "schedulingPolicy": {
                  "priorityClass": "normal",
                  "queue": "default"
                }
              }
            },
            "status": {
              "completionTime": "2024-07-19T08:15:09Z",
              "conditions": [
                {
                  "lastTransitionTime": "2024-07-19T07:38:24Z",
                  "lastUpdateTime": "2024-07-19T07:38:24Z",
                  "message": "PyTorchJob whx-llama-test-3 is created.",
                  "reason": "PyTorchJobCreated",
                  "status": "True",
                  "type": "Created"
                },
                {
                  "lastTransitionTime": "2024-07-19T07:46:08Z",
                  "lastUpdateTime": "2024-07-19T07:46:08Z",
                  "message": "PyTorchJob whx-llama-test-3 is running.",
                  "reason": "JobRunning",
                  "status": "False",
                  "type": "Running"
                },
                {
                  "lastTransitionTime": "2024-07-19T08:15:09Z",
                  "lastUpdateTime": "2024-07-19T08:15:09Z",
                  "message": "PyTorchJob whx-llama-test-3 is successfully completed.",
                  "reason": "JobSucceeded",
                  "status": "True",
                  "type": "Succeeded"
                }
              ],
              "lastReconcileTime": "2024-07-19T07:38:24Z",
              "replicaStatuses": {
                "Master": {
                  "selector": "training.kubeflow.org/job-name=whx-llama-test-3,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=master",
                  "succeeded": 1
                },
                "Worker": {
                  "selector": "training.kubeflow.org/job-name=whx-llama-test-3,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=worker",
                  "succeeded": 1
                }
              },
              "startTime": "2024-07-19T07:38:25Z"
            }
          },
          {
            "apiVersion": "kubeflow.org/v1",
            "kind": "PyTorchJob",
            "metadata": {
              "annotations": {
                "aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": "",
                "aijob.cce.baidubce.com/timeline": "[{\"conditionType\":\"Created\",\"time\":1721375616},{\"conditionType\":\"Scheduled\",\"time\":1721375618},{\"conditionType\":\"Running\",\"time\":1721375628}]",
                "kubectl.kubernetes.io/last-applied-configuration": "{\"apiVersion\":\"kubeflow.org/v1\",\"kind\":\"PyTorchJob\",\"metadata\":{\"annotations\":{},\"name\":\"xiaojunjie-aiak-sora\",\"namespace\":\"default\"},\"spec\":{\"pytorchReplicaSpecs\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"template\":{\"metadata\":null,\"spec\":{\"containers\":[{\"command\":[\"bash\",\"-c\",\"sleep 100d\"],\"env\":[{\"name\":\"CUDA_DEVICE_MAX_CONNECTIONS\",\"value\":\"1\"},{\"name\":\"NCCL_DEBUG\",\"value\":\"INFO\"},{\"name\":\"NCCL_IB_DISABLE\",\"value\":\"0\"},{\"name\":\"MASTER\",\"value\":\"1\"}],\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm:ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"imagePullPolicy\":\"Always\",\"name\":\"pytorch\",\"resources\":{\"limits\":{\"nvidia.com/gpu\":8,\"rdma/hca\":1}},\"securityContext\":{\"capabilities\":{\"add\":[\"IPC_LOCK\"]}},\"volumeMounts\":[{\"mountPath\":\"/dev/shm\",\"name\":\"cache-volume\"},{\"mountPath\":\"/workspace\",\"name\":\"data\",\"subPath\":\"xiaojunjie\"},{\"mountPath\":\"/mnt/pfs\",\"name\":\"data\"}]}],\"schedulerName\":\"volcano\",\"volumes\":[{\"emptyDir\":{\"medium\":\"Memory\"},\"name\":\"cache-volume\"},{\"name\":\"data\",\"persistentVolumeClaim\":{\"claimName\":\"pvc-pfs\"}}]}}}}}}\n"
              },
              "creationTimestamp": "2024-07-19T07:53:36Z",
              "generation": 2,
              "managedFields": [
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        "f:aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": {},
                        "f:aijob.cce.baidubce.com/timeline": {}
                      }
                    },
                    "f:spec": {
                      "f:pytorchReplicaSpecs": {
                        "f:Master": {
                          "f:template": {
                            "f:metadata": {},
                            "f:spec": {
                              "f:containers": {}
                            }
                          }
                        }
                      },
                      "f:runPolicy": {
                        ".": {},
                        "f:cleanPodPolicy": {}
                      }
                    }
                  },
                  "manager": "controller",
                  "operation": "Update",
                  "time": "2024-07-19T07:53:36Z"
                },
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        ".": {},
                        "f:kubectl.kubernetes.io/last-applied-configuration": {}
                      }
                    },
                    "f:spec": {
                      ".": {},
                      "f:pytorchReplicaSpecs": {
                        ".": {},
                        "f:Master": {
                          ".": {},
                          "f:replicas": {},
                          "f:restartPolicy": {},
                          "f:template": {
                            ".": {},
                            "f:spec": {
                              ".": {},
                              "f:schedulerName": {},
                              "f:volumes": {}
                            }
                          }
                        }
                      }
                    }
                  },
                  "manager": "kubectl-client-side-apply",
                  "operation": "Update",
                  "time": "2024-07-19T07:53:36Z"
                },
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:status": {
                      ".": {},
                      "f:conditions": {},
                      "f:lastReconcileTime": {},
                      "f:replicaStatuses": {
                        ".": {},
                        "f:Master": {
                          ".": {},
                          "f:active": {},
                          "f:selector": {}
                        }
                      },
                      "f:startTime": {}
                    }
                  },
                  "manager": "manager",
                  "operation": "Update",
                  "time": "2024-07-19T07:53:48Z"
                }
              ],
              "name": "xiaojunjie-aiak-sora",
              "namespace": "default",
              "resourceVersion": "2372657445",
              "uid": "c78234b2-3b17-483d-8ed0-3bbd7bdd0d7d"
            },
            "spec": {
              "pytorchReplicaSpecs": {
                "Master": {
                  "replicas": 1,
                  "restartPolicy": "Never",
                  "template": {
                    "metadata": {},
                    "spec": {
                      "containers": [
                        {
                          "command": [
                            "bash",
                            "-c",
                            "sleep 100d"
                          ],
                          "env": [
                            {
                              "name": "CUDA_DEVICE_MAX_CONNECTIONS",
                              "value": "1"
                            },
                            {
                              "name": "NCCL_DEBUG",
                              "value": "INFO"
                            },
                            {
                              "name": "NCCL_IB_DISABLE",
                              "value": "0"
                            },
                            {
                              "name": "MASTER",
                              "value": "1"
                            }
                          ],
                          "image": "registry.baidubce.com/aihc-aiak/aiak-training-llm:ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release",
                          "imagePullPolicy": "Always",
                          "name": "pytorch",
                          "ports": [
                            {
                              "containerPort": 23456,
                              "name": "pytorchjob-port",
                              "protocol": "TCP"
                            }
                          ],
                          "resources": {
                            "limits": {
                              "nvidia.com/gpu": "8",
                              "rdma/hca": "1"
                            }
                          },
                          "securityContext": {
                            "capabilities": {
                              "add": [
                                "IPC_LOCK"
                              ]
                            }
                          },
                          "volumeMounts": [
                            {
                              "mountPath": "/dev/shm",
                              "name": "cache-volume"
                            },
                            {
                              "mountPath": "/workspace",
                              "name": "data",
                              "subPath": "xiaojunjie"
                            },
                            {
                              "mountPath": "/mnt/pfs",
                              "name": "data"
                            }
                          ]
                        }
                      ],
                      "schedulerName": "volcano",
                      "volumes": [
                        {
                          "emptyDir": {
                            "medium": "Memory"
                          },
                          "name": "cache-volume"
                        },
                        {
                          "name": "data",
                          "persistentVolumeClaim": {
                            "claimName": "pvc-pfs"
                          }
                        }
                      ]
                    }
                  }
                }
              },
              "runPolicy": {
                "cleanPodPolicy": "None"
              }
            },
            "status": {
              "conditions": [
                {
                  "lastTransitionTime": "2024-07-19T07:53:36Z",
                  "lastUpdateTime": "2024-07-19T07:53:36Z",
                  "message": "PyTorchJob xiaojunjie-aiak-sora is created.",
                  "reason": "PyTorchJobCreated",
                  "status": "True",
                  "type": "Created"
                },
                {
                  "lastTransitionTime": "2024-07-19T07:53:48Z",
                  "lastUpdateTime": "2024-07-19T07:53:48Z",
                  "message": "PyTorchJob xiaojunjie-aiak-sora is running.",
                  "reason": "JobRunning",
                  "status": "True",
                  "type": "Running"
                }
              ],
              "lastReconcileTime": "2024-07-19T07:53:36Z",
              "replicaStatuses": {
                "Master": {
                  "active": 1,
                  "selector": "training.kubeflow.org/job-name=xiaojunjie-aiak-sora,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=master"
                }
              },
              "startTime": "2024-07-19T07:53:37Z"
            }
          },
          {
            "apiVersion": "kubeflow.org/v1",
            "kind": "PyTorchJob",
            "metadata": {
              "annotations": {
                "aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": "",
                "aijob.cce.baidubce.com/timeline": "[{\"conditionType\":\"Created\",\"time\":1721628143},{\"conditionType\":\"Scheduled\",\"time\":1721628145},{\"conditionType\":\"Running\",\"time\":1721628159}]"
              },
              "creationTimestamp": "2024-07-22T06:02:23Z",
              "generation": 2,
              "managedFields": [
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:metadata": {
                      "f:annotations": {
                        ".": {},
                        "f:aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": {},
                        "f:aijob.cce.baidubce.com/timeline": {}
                      }
                    },
                    "f:spec": {
                      "f:pytorchReplicaSpecs": {
                        "f:Master": {
                          "f:template": {
                            "f:metadata": {},
                            "f:spec": {
                              "f:containers": {}
                            }
                          }
                        }
                      },
                      "f:runPolicy": {
                        ".": {},
                        "f:cleanPodPolicy": {}
                      }
                    }
                  },
                  "manager": "controller",
                  "operation": "Update",
                  "time": "2024-07-22T06:02:23Z"
                },
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:spec": {
                      ".": {},
                      "f:pytorchReplicaSpecs": {
                        ".": {},
                        "f:Master": {
                          ".": {},
                          "f:replicas": {},
                          "f:restartPolicy": {},
                          "f:template": {
                            ".": {},
                            "f:spec": {
                              ".": {},
                              "f:schedulerName": {},
                              "f:volumes": {}
                            }
                          }
                        }
                      }
                    }
                  },
                  "manager": "kubectl-create",
                  "operation": "Update",
                  "time": "2024-07-22T06:02:23Z"
                },
                {
                  "apiVersion": "kubeflow.org/v1",
                  "fieldsType": "FieldsV1",
                  "fieldsV1": {
                    "f:status": {
                      ".": {},
                      "f:conditions": {},
                      "f:lastReconcileTime": {},
                      "f:replicaStatuses": {
                        ".": {},
                        "f:Master": {
                          ".": {},
                          "f:active": {},
                          "f:selector": {}
                        }
                      },
                      "f:startTime": {}
                    }
                  },
                  "manager": "manager",
                  "operation": "Update",
                  "time": "2024-07-22T06:02:39Z"
                }
              ],
              "name": "zhanghenghua-llama-factory-qwen14-predict",
              "namespace": "default",
              "resourceVersion": "2375968038",
              "uid": "b299db41-984d-44d3-8aff-349793775437"
            },
            "spec": {
              "pytorchReplicaSpecs": {
                "Master": {
                  "replicas": 1,
                  "restartPolicy": "Never",
                  "template": {
                    "metadata": {},
                    "spec": {
                      "containers": [
                        {
                          "command": [
                            "bash",
                            "-c",
                            "sleep infinity"
                          ],
                          "env": [
                            {
                              "name": "CUDA_DEVICE_MAX_CONNECTIONS",
                              "value": "1"
                            },
                            {
                              "name": "NCCL_DEBUG",
                              "value": "INFO"
                            },
                            {
                              "name": "NCCL_IB_DISABLE",
                              "value": "0"
                            },
                            {
                              "name": "MASTER",
                              "value": "1"
                            }
                          ],
                          "image": "registry.baidubce.com/hac-aiacc/llama-factory:ubuntu22.04-cu12.3-torch2.2.0-py310-deepspeed0.14.4-v0.8.3",
                          "imagePullPolicy": "Always",
                          "name": "pytorch",
                          "ports": [
                            {
                              "containerPort": 23456,
                              "name": "pytorchjob-port",
                              "protocol": "TCP"
                            }
                          ],
                          "resources": {
                            "limits": {
                              "ephemeral-storage": "191680782Ki",
                              "nvidia.com/gpu": "8",
                              "rdma/hca": "1"
                            }
                          },
                          "securityContext": {
                            "capabilities": {
                              "add": [
                                "IPC_LOCK"
                              ]
                            }
                          },
                          "volumeMounts": [
                            {
                              "mountPath": "/dev/shm",
                              "name": "cache-volume"
                            },
                            {
                              "mountPath": "/workspace/LLaMA-Factory/launch.sh",
                              "name": "config-volume",
                              "subPath": "launch.sh"
                            },
                            {
                              "mountPath": "/mnt/cluster",
                              "name": "data"
                            }
                          ]
                        }
                      ],
                      "schedulerName": "volcano",
                      "volumes": [
                        {
                          "emptyDir": {
                            "medium": "Memory"
                          },
                          "name": "cache-volume"
                        },
                        {
                          "configMap": {
                            "name": "launch-llama-factory-qwen14-predict"
                          },
                          "name": "config-volume"
                        },
                        {
                          "name": "data",
                          "persistentVolumeClaim": {
                            "claimName": "pvc-pfs"
                          }
                        }
                      ]
                    }
                  }
                }
              },
              "runPolicy": {
                "cleanPodPolicy": "None"
              }
            },
            "status": {
              "conditions": [
                {
                  "lastTransitionTime": "2024-07-22T06:02:23Z",
                  "lastUpdateTime": "2024-07-22T06:02:23Z",
                  "message": "PyTorchJob zhanghenghua-llama-factory-qwen14-predict is created.",
                  "reason": "PyTorchJobCreated",
                  "status": "True",
                  "type": "Created"
                },
                {
                  "lastTransitionTime": "2024-07-22T06:02:39Z",
                  "lastUpdateTime": "2024-07-22T06:02:39Z",
                  "message": "PyTorchJob zhanghenghua-llama-factory-qwen14-predict is running.",
                  "reason": "JobRunning",
                  "status": "True",
                  "type": "Running"
                }
              ],
              "lastReconcileTime": "2024-07-22T06:02:23Z",
              "replicaStatuses": {
                "Master": {
                  "active": 1,
                  "selector": "training.kubeflow.org/job-name=zhanghenghua-llama-factory-qwen14-predict,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=master"
                }
              },
              "startTime": "2024-07-22T06:02:24Z"
            }
          }
        ],
        "kind": "PyTorchJobList",
        "metadata": {
          "continue": "",
          "resourceVersion": "2377135837"
        }
      },
      "headers": {
        "cache-control": "no-cache, private",
        "content-type": "application/json",
        "x-kubernetes-pf-flowschema-uid": "07814116-c254-4e69-bb49-15ec84480481",
        "x-kubernetes-pf-prioritylevel-uid": "4e7e4972-2fc5-4714-890e-53418dc2bdd0",
        "date": "Tue, 23 Jul 2024 02:10:03 GMT",
        "connection": "close",
        "transfer-encoding": "chunked"
      },
      "request": {
        "uri": {
          "protocol": "https:",
          "slashes": true,
          "auth": null,
          "host": "180.76.164.182:6443",
          "port": "6443",
          "hostname": "180.76.164.182",
          "hash": null,
          "search": null,
          "query": null,
          "pathname": "/apis/kubeflow.org/v1/namespaces/default/pytorchjobs",
          "path": "/apis/kubeflow.org/v1/namespaces/default/pytorchjobs",
          "href": "https://180.76.164.182:6443/apis/kubeflow.org/v1/namespaces/default/pytorchjobs"
        },
        "method": "GET",
        "headers": {
          "Accept": "application/json"
        }
      }
    },
    "body": {
      "apiVersion": "kubeflow.org/v1",
      "items": [
        {
          "apiVersion": "kubeflow.org/v1",
          "kind": "PyTorchJob",
          "metadata": {
            "annotations": {
              "aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": "",
              "aijob.cce.baidubce.com/timeline": "[{\"conditionType\":\"Created\",\"time\":1721652110},{\"conditionType\":\"Scheduled\",\"time\":1721652111},{\"conditionType\":\"Running\",\"time\":1721652144},{\"conditionType\":\"Failed\",\"time\":1721652265}]"
            },
            "creationTimestamp": "2024-07-22T12:41:50Z",
            "generation": 2,
            "managedFields": [
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      ".": {},
                      "f:aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": {},
                      "f:aijob.cce.baidubce.com/timeline": {}
                    }
                  },
                  "f:spec": {
                    "f:pytorchReplicaSpecs": {
                      "f:Master": {
                        "f:template": {
                          "f:metadata": {},
                          "f:spec": {
                            "f:containers": {}
                          }
                        }
                      }
                    },
                    "f:runPolicy": {
                      ".": {},
                      "f:cleanPodPolicy": {}
                    }
                  }
                },
                "manager": "controller",
                "operation": "Update",
                "time": "2024-07-22T12:41:50Z"
              },
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:spec": {
                    ".": {},
                    "f:pytorchReplicaSpecs": {
                      ".": {},
                      "f:Master": {
                        ".": {},
                        "f:replicas": {},
                        "f:restartPolicy": {},
                        "f:template": {
                          ".": {},
                          "f:spec": {
                            ".": {},
                            "f:schedulerName": {},
                            "f:terminationGracePeriodSeconds": {},
                            "f:volumes": {}
                          }
                        }
                      }
                    }
                  }
                },
                "manager": "kubectl-create",
                "operation": "Update",
                "time": "2024-07-22T12:41:50Z"
              },
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:status": {
                    ".": {},
                    "f:completionTime": {},
                    "f:conditions": {},
                    "f:lastReconcileTime": {},
                    "f:replicaStatuses": {
                      ".": {},
                      "f:Master": {
                        ".": {},
                        "f:failed": {},
                        "f:selector": {}
                      }
                    },
                    "f:startTime": {}
                  }
                },
                "manager": "manager",
                "operation": "Update",
                "time": "2024-07-22T12:44:25Z"
              }
            ],
            "name": "agile-aiak-training-llm-pengxiangyu-1721652109",
            "namespace": "default",
            "resourceVersion": "2376292738",
            "uid": "0f0fbd78-3cd4-41f3-84ed-153f615d57fd"
          },
          "spec": {
            "pytorchReplicaSpecs": {
              "Master": {
                "replicas": 1,
                "restartPolicy": "Never",
                "template": {
                  "metadata": {},
                  "spec": {
                    "containers": [
                      {
                        "command": [
                          "/bin/bash",
                          "-c",
                          "\n#! /bin/bash\nset -euo pipefail\nmkdir -p /workspace/logs\n\necho \"开始下载 aiak_training_llm\"\ncd /workspace && rm -rf AIAK-Training-LLM\nwget https://cce-ai-datasets.bj.bcebos.com/hac_test/AIAK-Training-LLM/develop/20240722_1721651386/AIAK-Training-LLM.tar.gz\ntar -zxvf AIAK-Training-LLM.tar.gz\necho \"下载完成 aiak_training_llm\"\n\ncd /workspace/AIAK-Training-LLM/ci/tests/scripts\nextra_param=\"--node_nums 1                              --gpu_nums 8                              --models baichuan2-13b baichuan2-7b llama-2-7b llama-3-8b qwen-7b                              --tasks check_correctness_task check_precess_data_task                              --ckpt_loss_diff 0.01                              --timeout 7200\"\nif [[ \"false\" == \"true\" ]]; then\n    extra_param=\"$extra_param --use_nccl\"\nfi\ncommand=\"python3 main.py $extra_param\"\necho \"任务开始执行: $command\"\neval $command"
                        ],
                        "env": [
                          {
                            "name": "TRAIN_DATA_DIR",
                            "value": "/mnt/pfs/leoli"
                          },
                          {
                            "name": "CUDA_DEVICE_MAX_CONNECTIONS",
                            "value": "1"
                          },
                          {
                            "name": "NCCL_DEBUG",
                            "value": "INFO"
                          },
                          {
                            "name": "timeout",
                            "value": "7200"
                          },
                          {
                            "name": "BOS_SYNC_MEGATRON_SCRIPTS_ADDR"
                          }
                        ],
                        "image": "registry.baidubce.com/hac-aiacc/aiak-training-llm:ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_dev_20240722_203000_encrypt",
                        "imagePullPolicy": "Always",
                        "name": "pytorch",
                        "ports": [
                          {
                            "containerPort": 23456,
                            "name": "pytorchjob-port",
                            "protocol": "TCP"
                          }
                        ],
                        "resources": {
                          "limits": {
                            "baidu.com/a800_80g_cgpu": "8"
                          }
                        },
                        "securityContext": {
                          "capabilities": {
                            "add": [
                              "IPC_LOCK"
                            ]
                          }
                        },
                        "volumeMounts": [
                          {
                            "mountPath": "/mnt/pfs",
                            "name": "pfs"
                          },
                          {
                            "mountPath": "/dev/shm",
                            "name": "cache-volume"
                          }
                        ]
                      }
                    ],
                    "schedulerName": "volcano",
                    "terminationGracePeriodSeconds": 10,
                    "volumes": [
                      {
                        "name": "pfs",
                        "persistentVolumeClaim": {
                          "claimName": "pvc-pfs"
                        }
                      },
                      {
                        "emptyDir": {
                          "medium": "Memory"
                        },
                        "name": "cache-volume"
                      }
                    ]
                  }
                }
              }
            },
            "runPolicy": {
              "cleanPodPolicy": "None"
            }
          },
          "status": {
            "completionTime": "2024-07-22T12:44:25Z",
            "conditions": [
              {
                "lastTransitionTime": "2024-07-22T12:41:50Z",
                "lastUpdateTime": "2024-07-22T12:41:50Z",
                "message": "PyTorchJob agile-aiak-training-llm-pengxiangyu-1721652109 is created.",
                "reason": "PyTorchJobCreated",
                "status": "True",
                "type": "Created"
              },
              {
                "lastTransitionTime": "2024-07-22T12:42:24Z",
                "lastUpdateTime": "2024-07-22T12:42:24Z",
                "message": "PyTorchJob agile-aiak-training-llm-pengxiangyu-1721652109 is running.",
                "reason": "JobRunning",
                "status": "False",
                "type": "Running"
              },
              {
                "lastTransitionTime": "2024-07-22T12:44:25Z",
                "lastUpdateTime": "2024-07-22T12:44:25Z",
                "message": "PyTorchJob agile-aiak-training-llm-pengxiangyu-1721652109 is failed because 1 Master replica(s) failed.",
                "reason": "JobFailed",
                "status": "True",
                "type": "Failed"
              }
            ],
            "lastReconcileTime": "2024-07-22T12:41:50Z",
            "replicaStatuses": {
              "Master": {
                "failed": 1,
                "selector": "training.kubeflow.org/job-name=agile-aiak-training-llm-pengxiangyu-1721652109,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=master"
              }
            },
            "startTime": "2024-07-22T12:41:50Z"
          }
        },
        {
          "apiVersion": "kubeflow.org/v1",
          "kind": "PyTorchJob",
          "metadata": {
            "annotations": {
              "aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": "",
              "aijob.cce.baidubce.com/timeline": "[{\"conditionType\":\"Created\",\"time\":1721615725},{\"conditionType\":\"Scheduled\",\"time\":1721615728},{\"conditionType\":\"Running\",\"time\":1721615738}]",
              "kubectl.kubernetes.io/last-applied-configuration": "{\"apiVersion\":\"kubeflow.org/v1\",\"kind\":\"PyTorchJob\",\"metadata\":{\"annotations\":{},\"name\":\"baidu5-task-for-8gpu\",\"namespace\":\"default\"},\"spec\":{\"pytorchReplicaSpecs\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"template\":{\"metadata\":null,\"spec\":{\"containers\":[{\"command\":[\"bash\",\"/workspace/Megatron-LM/examples/launch.sh\"],\"env\":[{\"name\":\"CUDA_DEVICE_MAX_CONNECTIONS\",\"value\":\"1\"},{\"name\":\"NCCL_DEBUG\",\"value\":\"INFO\"},{\"name\":\"NCCL_IB_DISABLE\",\"value\":\"0\"},{\"name\":\"MASTER\",\"value\":\"1\"}],\"image\":\"registry.baidubce.com/cce-ai-native/aiak-megatron:ubuntu22.04-cu12.2-torch2.1.0-py310_v1.2.4.2\",\"imagePullPolicy\":\"Always\",\"name\":\"pytorch\",\"resources\":{\"limits\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1}},\"securityContext\":{\"capabilities\":{\"add\":[\"IPC_LOCK\"]}},\"volumeMounts\":[{\"mountPath\":\"/dev/shm\",\"name\":\"cache-volume\"},{\"mountPath\":\"/tmp\",\"name\":\"tmp-volume\"},{\"mountPath\":\"/workspace/Megatron-LM/examples/launch.sh\",\"name\":\"config-volume\",\"subPath\":\"launch.sh\"},{\"mountPath\":\"/mnt/cluster\",\"name\":\"data\"}]}],\"schedulerName\":\"volcano\",\"volumes\":[{\"emptyDir\":{\"medium\":\"Memory\"},\"name\":\"cache-volume\"},{\"emptyDir\":{\"medium\":\"Memory\"},\"name\":\"tmp-volume\"},{\"configMap\":{\"name\":\"baidu5-task-for-8gpu\"},\"name\":\"config-volume\"},{\"name\":\"data\",\"persistentVolumeClaim\":{\"claimName\":\"pvc-pfs\"}}]}}}}}}\n"
            },
            "creationTimestamp": "2024-07-22T02:35:25Z",
            "generation": 2,
            "managedFields": [
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      "f:aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": {},
                      "f:aijob.cce.baidubce.com/timeline": {}
                    }
                  },
                  "f:spec": {
                    "f:pytorchReplicaSpecs": {
                      "f:Master": {
                        "f:template": {
                          "f:metadata": {},
                          "f:spec": {
                            "f:containers": {}
                          }
                        }
                      }
                    },
                    "f:runPolicy": {
                      ".": {},
                      "f:cleanPodPolicy": {}
                    }
                  }
                },
                "manager": "controller",
                "operation": "Update",
                "time": "2024-07-22T02:35:25Z"
              },
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      ".": {},
                      "f:kubectl.kubernetes.io/last-applied-configuration": {}
                    }
                  },
                  "f:spec": {
                    ".": {},
                    "f:pytorchReplicaSpecs": {
                      ".": {},
                      "f:Master": {
                        ".": {},
                        "f:replicas": {},
                        "f:restartPolicy": {},
                        "f:template": {
                          ".": {},
                          "f:spec": {
                            ".": {},
                            "f:schedulerName": {},
                            "f:volumes": {}
                          }
                        }
                      }
                    }
                  }
                },
                "manager": "kubectl-client-side-apply",
                "operation": "Update",
                "time": "2024-07-22T02:35:25Z"
              },
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:status": {
                    ".": {},
                    "f:conditions": {},
                    "f:lastReconcileTime": {},
                    "f:replicaStatuses": {
                      ".": {},
                      "f:Master": {
                        ".": {},
                        "f:active": {},
                        "f:selector": {}
                      }
                    },
                    "f:startTime": {}
                  }
                },
                "manager": "manager",
                "operation": "Update",
                "time": "2024-07-22T02:35:38Z"
              }
            ],
            "name": "baidu5-task-for-8gpu",
            "namespace": "default",
            "resourceVersion": "2375802662",
            "uid": "6caf9759-c42b-4e01-8838-bfea936f46a4"
          },
          "spec": {
            "pytorchReplicaSpecs": {
              "Master": {
                "replicas": 1,
                "restartPolicy": "Never",
                "template": {
                  "metadata": {},
                  "spec": {
                    "containers": [
                      {
                        "command": [
                          "bash",
                          "/workspace/Megatron-LM/examples/launch.sh"
                        ],
                        "env": [
                          {
                            "name": "CUDA_DEVICE_MAX_CONNECTIONS",
                            "value": "1"
                          },
                          {
                            "name": "NCCL_DEBUG",
                            "value": "INFO"
                          },
                          {
                            "name": "NCCL_IB_DISABLE",
                            "value": "0"
                          },
                          {
                            "name": "MASTER",
                            "value": "1"
                          }
                        ],
                        "image": "registry.baidubce.com/cce-ai-native/aiak-megatron:ubuntu22.04-cu12.2-torch2.1.0-py310_v1.2.4.2",
                        "imagePullPolicy": "Always",
                        "name": "pytorch",
                        "ports": [
                          {
                            "containerPort": 23456,
                            "name": "pytorchjob-port",
                            "protocol": "TCP"
                          }
                        ],
                        "resources": {
                          "limits": {
                            "baidu.com/a800_80g_cgpu": "8",
                            "rdma/hca": "1"
                          }
                        },
                        "securityContext": {
                          "capabilities": {
                            "add": [
                              "IPC_LOCK"
                            ]
                          }
                        },
                        "volumeMounts": [
                          {
                            "mountPath": "/dev/shm",
                            "name": "cache-volume"
                          },
                          {
                            "mountPath": "/tmp",
                            "name": "tmp-volume"
                          },
                          {
                            "mountPath": "/workspace/Megatron-LM/examples/launch.sh",
                            "name": "config-volume",
                            "subPath": "launch.sh"
                          },
                          {
                            "mountPath": "/mnt/cluster",
                            "name": "data"
                          }
                        ]
                      }
                    ],
                    "schedulerName": "volcano",
                    "volumes": [
                      {
                        "emptyDir": {
                          "medium": "Memory"
                        },
                        "name": "cache-volume"
                      },
                      {
                        "emptyDir": {
                          "medium": "Memory"
                        },
                        "name": "tmp-volume"
                      },
                      {
                        "configMap": {
                          "name": "baidu5-task-for-8gpu"
                        },
                        "name": "config-volume"
                      },
                      {
                        "name": "data",
                        "persistentVolumeClaim": {
                          "claimName": "pvc-pfs"
                        }
                      }
                    ]
                  }
                }
              }
            },
            "runPolicy": {
              "cleanPodPolicy": "None"
            }
          },
          "status": {
            "conditions": [
              {
                "lastTransitionTime": "2024-07-22T02:35:25Z",
                "lastUpdateTime": "2024-07-22T02:35:25Z",
                "message": "PyTorchJob baidu5-task-for-8gpu is created.",
                "reason": "PyTorchJobCreated",
                "status": "True",
                "type": "Created"
              },
              {
                "lastTransitionTime": "2024-07-22T02:35:38Z",
                "lastUpdateTime": "2024-07-22T02:35:38Z",
                "message": "PyTorchJob baidu5-task-for-8gpu is running.",
                "reason": "JobRunning",
                "status": "True",
                "type": "Running"
              }
            ],
            "lastReconcileTime": "2024-07-22T02:35:26Z",
            "replicaStatuses": {
              "Master": {
                "active": 1,
                "selector": "training.kubeflow.org/job-name=baidu5-task-for-8gpu,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=master"
              }
            },
            "startTime": "2024-07-22T02:35:27Z"
          }
        },
        {
          "apiVersion": "kubeflow.org/v1",
          "kind": "PyTorchJob",
          "metadata": {
            "annotations": {
              "aijob.cce.baidubce.com/fault-tolerance-enabled": "true",
              "aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": "",
              "aijob.cce.baidubce.com/timeline": "[{\"conditionType\":\"Created\",\"time\":1721653657}]",
              "kubectl.kubernetes.io/last-applied-configuration": "{\"apiVersion\":\"kubeflow.org/v1\",\"kind\":\"PyTorchJob\",\"metadata\":{\"annotations\":{},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"name\":\"changtao02-llama2-70b-448\",\"namespace\":\"default\"},\"spec\":{\"pytorchReplicaSpecs\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"template\":{\"metadata\":{\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"}},\"spec\":{\"containers\":[{\"command\":[\"bash\",\"/workspace/Megatron-LM/examples/launch.sh\"],\"env\":[{\"name\":\"CUDA_DEVICE_MAX_CONNECTIONS\",\"value\":\"1\"},{\"name\":\"NCCL_DEBUG\",\"value\":\"INFO\"},{\"name\":\"NCCL_IB_DISABLE\",\"value\":\"0\"},{\"name\":\"MASTER\",\"value\":\"1\"}],\"image\":\"registry.baidubce.com/hac-aiacc/aiak-training-llm:ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_dev_20240718_204220\",\"imagePullPolicy\":\"Always\",\"name\":\"pytorch\",\"resources\":{\"limits\":{\"nvidia.com/gpu\":8,\"rdma/hca\":1}},\"securityContext\":{\"capabilities\":{\"add\":[\"IPC_LOCK\"]}},\"volumeMounts\":[{\"mountPath\":\"/dev/shm\",\"name\":\"cache-volume\"},{\"mountPath\":\"/workspace/Megatron-LM/examples/launch.sh\",\"name\":\"config-volume\",\"subPath\":\"launch.sh\"},{\"mountPath\":\"/mnt/cluster\",\"name\":\"data\"}]}],\"hostNetwork\":true,\"schedulerName\":\"volcano\",\"volumes\":[{\"emptyDir\":{\"medium\":\"Memory\"},\"name\":\"cache-volume\"},{\"configMap\":{\"name\":\"launch-changtao02-cm-pytorch-llama2-70b-1\"},\"name\":\"config-volume\"},{\"name\":\"data\",\"persistentVolumeClaim\":{\"claimName\":\"pvc-pfs\"}}]}}},\"Worker\":{\"replicas\":3,\"restartPolicy\":\"Never\",\"template\":{\"spec\":{\"containers\":[{\"command\":[\"bash\",\"/workspace/Megatron-LM/examples/launch.sh\"],\"env\":[{\"name\":\"CUDA_DEVICE_MAX_CONNECTIONS\",\"value\":\"1\"},{\"name\":\"NCCL_DEBUG\",\"value\":\"INFO\"},{\"name\":\"NCCL_IB_DISABLE\",\"value\":\"0\"}],\"image\":\"registry.baidubce.com/hac-aiacc/aiak-training-llm:ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_dev_20240718_204220\",\"imagePullPolicy\":\"Always\",\"name\":\"pytorch\",\"resources\":{\"limits\":{\"nvidia.com/gpu\":8,\"rdma/hca\":1}},\"securityContext\":{\"capabilities\":{\"add\":[\"IPC_LOCK\"]}},\"volumeMounts\":[{\"mountPath\":\"/dev/shm\",\"name\":\"cache-volume\"},{\"mountPath\":\"/workspace/Megatron-LM/examples/launch.sh\",\"name\":\"config-volume\",\"subPath\":\"launch.sh\"},{\"mountPath\":\"/mnt/cluster\",\"name\":\"data\"}]}],\"schedulerName\":\"volcano\",\"volumes\":[{\"emptyDir\":{\"medium\":\"Memory\"},\"name\":\"cache-volume\"},{\"configMap\":{\"name\":\"launch-changtao02-cm-pytorch-llama2-70b-1\"},\"name\":\"config-volume\"},{\"name\":\"data\",\"persistentVolumeClaim\":{\"claimName\":\"pvc-pfs\"}}]}}}}}}\n"
            },
            "creationTimestamp": "2024-07-22T13:07:37Z",
            "generation": 2,
            "labels": {
              "aijob.cce.baidubce.com/create-from-aihcp": "true"
            },
            "managedFields": [
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      "f:aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": {},
                      "f:aijob.cce.baidubce.com/timeline": {}
                    }
                  }
                },
                "manager": "controller",
                "operation": "Update",
                "time": "2024-07-22T13:07:37Z"
              },
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      ".": {},
                      "f:kubectl.kubernetes.io/last-applied-configuration": {}
                    },
                    "f:labels": {
                      ".": {},
                      "f:aijob.cce.baidubce.com/create-from-aihcp": {}
                    }
                  },
                  "f:spec": {
                    ".": {},
                    "f:pytorchReplicaSpecs": {
                      ".": {},
                      "f:Master": {
                        ".": {},
                        "f:replicas": {},
                        "f:restartPolicy": {},
                        "f:template": {
                          ".": {},
                          "f:metadata": {
                            ".": {},
                            "f:labels": {
                              ".": {},
                              "f:aijob.cce.baidubce.com/create-from-aihcp": {}
                            }
                          },
                          "f:spec": {
                            ".": {},
                            "f:hostNetwork": {},
                            "f:schedulerName": {},
                            "f:volumes": {}
                          }
                        }
                      },
                      "f:Worker": {
                        ".": {},
                        "f:replicas": {},
                        "f:restartPolicy": {},
                        "f:template": {
                          ".": {},
                          "f:spec": {
                            ".": {},
                            "f:schedulerName": {},
                            "f:volumes": {}
                          }
                        }
                      }
                    }
                  }
                },
                "manager": "kubectl-client-side-apply",
                "operation": "Update",
                "time": "2024-07-22T13:07:37Z"
              },
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {}
                    }
                  },
                  "f:spec": {
                    "f:pytorchReplicaSpecs": {
                      "f:Master": {
                        "f:template": {
                          "f:spec": {
                            "f:containers": {}
                          }
                        }
                      },
                      "f:Worker": {
                        "f:template": {
                          "f:metadata": {},
                          "f:spec": {
                            "f:containers": {}
                          }
                        }
                      }
                    },
                    "f:runPolicy": {
                      ".": {},
                      "f:cleanPodPolicy": {}
                    }
                  },
                  "f:status": {
                    ".": {},
                    "f:conditions": {},
                    "f:lastReconcileTime": {},
                    "f:replicaStatuses": {
                      ".": {},
                      "f:Master": {
                        ".": {},
                        "f:selector": {}
                      },
                      "f:Worker": {
                        ".": {},
                        "f:selector": {}
                      }
                    },
                    "f:startTime": {}
                  }
                },
                "manager": "manager",
                "operation": "Update",
                "time": "2024-07-22T13:07:37Z"
              }
            ],
            "name": "changtao02-llama2-70b-448",
            "namespace": "default",
            "resourceVersion": "2376311041",
            "uid": "e7917ae4-92b9-42f9-a1ba-2e53d98e392f"
          },
          "spec": {
            "pytorchReplicaSpecs": {
              "Master": {
                "replicas": 1,
                "restartPolicy": "Never",
                "template": {
                  "metadata": {
                    "labels": {
                      "aijob.cce.baidubce.com/create-from-aihcp": "true"
                    }
                  },
                  "spec": {
                    "containers": [
                      {
                        "command": [
                          "bash",
                          "/workspace/Megatron-LM/examples/launch.sh"
                        ],
                        "env": [
                          {
                            "name": "CUDA_DEVICE_MAX_CONNECTIONS",
                            "value": "1"
                          },
                          {
                            "name": "NCCL_DEBUG",
                            "value": "INFO"
                          },
                          {
                            "name": "NCCL_IB_DISABLE",
                            "value": "0"
                          },
                          {
                            "name": "MASTER",
                            "value": "1"
                          }
                        ],
                        "image": "registry.baidubce.com/hac-aiacc/aiak-training-llm:ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_dev_20240718_204220",
                        "imagePullPolicy": "Always",
                        "name": "pytorch",
                        "ports": [
                          {
                            "containerPort": 23456,
                            "name": "pytorchjob-port",
                            "protocol": "TCP"
                          }
                        ],
                        "resources": {
                          "limits": {
                            "nvidia.com/gpu": "8",
                            "rdma/hca": "1"
                          }
                        },
                        "securityContext": {
                          "capabilities": {
                            "add": [
                              "IPC_LOCK"
                            ]
                          }
                        },
                        "volumeMounts": [
                          {
                            "mountPath": "/dev/shm",
                            "name": "cache-volume"
                          },
                          {
                            "mountPath": "/workspace/Megatron-LM/examples/launch.sh",
                            "name": "config-volume",
                            "subPath": "launch.sh"
                          },
                          {
                            "mountPath": "/mnt/cluster",
                            "name": "data"
                          }
                        ]
                      }
                    ],
                    "hostNetwork": true,
                    "schedulerName": "volcano",
                    "volumes": [
                      {
                        "emptyDir": {
                          "medium": "Memory"
                        },
                        "name": "cache-volume"
                      },
                      {
                        "configMap": {
                          "name": "launch-changtao02-cm-pytorch-llama2-70b-1"
                        },
                        "name": "config-volume"
                      },
                      {
                        "name": "data",
                        "persistentVolumeClaim": {
                          "claimName": "pvc-pfs"
                        }
                      }
                    ]
                  }
                }
              },
              "Worker": {
                "replicas": 3,
                "restartPolicy": "Never",
                "template": {
                  "metadata": {},
                  "spec": {
                    "containers": [
                      {
                        "command": [
                          "bash",
                          "/workspace/Megatron-LM/examples/launch.sh"
                        ],
                        "env": [
                          {
                            "name": "CUDA_DEVICE_MAX_CONNECTIONS",
                            "value": "1"
                          },
                          {
                            "name": "NCCL_DEBUG",
                            "value": "INFO"
                          },
                          {
                            "name": "NCCL_IB_DISABLE",
                            "value": "0"
                          }
                        ],
                        "image": "registry.baidubce.com/hac-aiacc/aiak-training-llm:ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_dev_20240718_204220",
                        "imagePullPolicy": "Always",
                        "name": "pytorch",
                        "ports": [
                          {
                            "containerPort": 23456,
                            "name": "pytorchjob-port",
                            "protocol": "TCP"
                          }
                        ],
                        "resources": {
                          "limits": {
                            "nvidia.com/gpu": "8",
                            "rdma/hca": "1"
                          }
                        },
                        "securityContext": {
                          "capabilities": {
                            "add": [
                              "IPC_LOCK"
                            ]
                          }
                        },
                        "volumeMounts": [
                          {
                            "mountPath": "/dev/shm",
                            "name": "cache-volume"
                          },
                          {
                            "mountPath": "/workspace/Megatron-LM/examples/launch.sh",
                            "name": "config-volume",
                            "subPath": "launch.sh"
                          },
                          {
                            "mountPath": "/mnt/cluster",
                            "name": "data"
                          }
                        ]
                      }
                    ],
                    "schedulerName": "volcano",
                    "volumes": [
                      {
                        "emptyDir": {
                          "medium": "Memory"
                        },
                        "name": "cache-volume"
                      },
                      {
                        "configMap": {
                          "name": "launch-changtao02-cm-pytorch-llama2-70b-1"
                        },
                        "name": "config-volume"
                      },
                      {
                        "name": "data",
                        "persistentVolumeClaim": {
                          "claimName": "pvc-pfs"
                        }
                      }
                    ]
                  }
                }
              }
            },
            "runPolicy": {
              "cleanPodPolicy": "None"
            }
          },
          "status": {
            "conditions": [
              {
                "lastTransitionTime": "2024-07-22T13:07:37Z",
                "lastUpdateTime": "2024-07-22T13:07:37Z",
                "message": "PyTorchJob changtao02-llama2-70b-448 is created.",
                "reason": "PyTorchJobCreated",
                "status": "True",
                "type": "Created"
              }
            ],
            "lastReconcileTime": "2024-07-22T13:07:37Z",
            "replicaStatuses": {
              "Master": {
                "selector": "training.kubeflow.org/job-name=changtao02-llama2-70b-448,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=master"
              },
              "Worker": {
                "selector": "training.kubeflow.org/job-name=changtao02-llama2-70b-448,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=worker"
              }
            },
            "startTime": "2024-07-22T13:07:38Z"
          }
        },
        {
          "apiVersion": "kubeflow.org/v1",
          "kind": "PyTorchJob",
          "metadata": {
            "annotations": {
              "aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": "",
              "aijob.cce.baidubce.com/timeline": "[{\"conditionType\":\"Created\",\"time\":1721129463},{\"conditionType\":\"Scheduled\",\"time\":1721129465},{\"conditionType\":\"Running\",\"time\":1721129468},{\"conditionType\":\"Succeeded\",\"time\":1721475093}]",
              "kubectl.kubernetes.io/last-applied-configuration": "{\"apiVersion\":\"kubeflow.org/v1\",\"kind\":\"PyTorchJob\",\"metadata\":{\"annotations\":{},\"name\":\"changtao02-megatron-cpu-sleep-lj\",\"namespace\":\"default\"},\"spec\":{\"pytorchReplicaSpecs\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"template\":{\"metadata\":null,\"spec\":{\"containers\":[{\"command\":[\"bash\",\"-c\",\"sleep 4d\"],\"image\":\"registry.baidubce.com/cce-ai-native/aiak-megatron:multi-accelerators-20240608\",\"imagePullPolicy\":\"Always\",\"name\":\"pytorch\",\"volumeMounts\":[{\"mountPath\":\"/dev/shm\",\"name\":\"cache-volume\"},{\"mountPath\":\"/workspace/Megatron-LM/examples/launch.sh\",\"name\":\"config-volume\",\"subPath\":\"launch.sh\"},{\"mountPath\":\"/mnt/cluster\",\"name\":\"data\"}]}],\"schedulerName\":\"volcano\",\"volumes\":[{\"emptyDir\":{\"medium\":\"Memory\"},\"name\":\"cache-volume\"},{\"configMap\":{\"name\":\"changtao02-cpu-sleep\"},\"name\":\"config-volume\"},{\"name\":\"data\",\"persistentVolumeClaim\":{\"claimName\":\"pvc-pfs\"}}]}}}}}}\n"
            },
            "creationTimestamp": "2024-07-16T11:31:03Z",
            "generation": 5,
            "managedFields": [
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      "f:aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": {},
                      "f:aijob.cce.baidubce.com/timeline": {}
                    }
                  },
                  "f:spec": {
                    "f:pytorchReplicaSpecs": {
                      "f:Master": {
                        "f:template": {
                          "f:metadata": {},
                          "f:spec": {
                            "f:containers": {}
                          }
                        }
                      }
                    },
                    "f:runPolicy": {
                      ".": {},
                      "f:cleanPodPolicy": {}
                    }
                  }
                },
                "manager": "controller",
                "operation": "Update",
                "time": "2024-07-16T11:31:16Z"
              },
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      ".": {},
                      "f:kubectl.kubernetes.io/last-applied-configuration": {}
                    }
                  },
                  "f:spec": {
                    ".": {},
                    "f:pytorchReplicaSpecs": {
                      ".": {},
                      "f:Master": {
                        ".": {},
                        "f:replicas": {},
                        "f:restartPolicy": {},
                        "f:template": {
                          ".": {},
                          "f:spec": {
                            ".": {},
                            "f:schedulerName": {},
                            "f:volumes": {}
                          }
                        }
                      }
                    }
                  }
                },
                "manager": "kubectl-client-side-apply",
                "operation": "Update",
                "time": "2024-07-16T11:31:16Z"
              },
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:status": {
                    ".": {},
                    "f:completionTime": {},
                    "f:conditions": {},
                    "f:lastReconcileTime": {},
                    "f:replicaStatuses": {
                      ".": {},
                      "f:Master": {
                        ".": {},
                        "f:selector": {},
                        "f:succeeded": {}
                      }
                    },
                    "f:startTime": {}
                  }
                },
                "manager": "manager",
                "operation": "Update",
                "time": "2024-07-20T11:31:33Z"
              }
            ],
            "name": "changtao02-megatron-cpu-sleep-lj",
            "namespace": "default",
            "resourceVersion": "2373966056",
            "uid": "dcc732fc-9bc9-4e50-8708-d221e4df63d5"
          },
          "spec": {
            "pytorchReplicaSpecs": {
              "Master": {
                "replicas": 1,
                "restartPolicy": "Never",
                "template": {
                  "metadata": {},
                  "spec": {
                    "containers": [
                      {
                        "command": [
                          "bash",
                          "-c",
                          "sleep 4d"
                        ],
                        "image": "registry.baidubce.com/cce-ai-native/aiak-megatron:multi-accelerators-20240608",
                        "imagePullPolicy": "Always",
                        "name": "pytorch",
                        "ports": [
                          {
                            "containerPort": 23456,
                            "name": "pytorchjob-port",
                            "protocol": "TCP"
                          }
                        ],
                        "resources": {},
                        "volumeMounts": [
                          {
                            "mountPath": "/dev/shm",
                            "name": "cache-volume"
                          },
                          {
                            "mountPath": "/workspace/Megatron-LM/examples/launch.sh",
                            "name": "config-volume",
                            "subPath": "launch.sh"
                          },
                          {
                            "mountPath": "/mnt/cluster",
                            "name": "data"
                          }
                        ]
                      }
                    ],
                    "schedulerName": "volcano",
                    "volumes": [
                      {
                        "emptyDir": {
                          "medium": "Memory"
                        },
                        "name": "cache-volume"
                      },
                      {
                        "configMap": {
                          "name": "changtao02-cpu-sleep"
                        },
                        "name": "config-volume"
                      },
                      {
                        "name": "data",
                        "persistentVolumeClaim": {
                          "claimName": "pvc-pfs"
                        }
                      }
                    ]
                  }
                }
              }
            },
            "runPolicy": {
              "cleanPodPolicy": "None"
            }
          },
          "status": {
            "completionTime": "2024-07-20T11:31:33Z",
            "conditions": [
              {
                "lastTransitionTime": "2024-07-16T11:31:03Z",
                "lastUpdateTime": "2024-07-16T11:31:03Z",
                "message": "PyTorchJob changtao02-megatron-cpu-sleep-lj is created.",
                "reason": "PyTorchJobCreated",
                "status": "True",
                "type": "Created"
              },
              {
                "lastTransitionTime": "2024-07-16T11:31:08Z",
                "lastUpdateTime": "2024-07-16T11:31:08Z",
                "message": "PyTorchJob changtao02-megatron-cpu-sleep-lj is running.",
                "reason": "JobRunning",
                "status": "False",
                "type": "Running"
              },
              {
                "lastTransitionTime": "2024-07-20T11:31:33Z",
                "lastUpdateTime": "2024-07-20T11:31:33Z",
                "message": "PyTorchJob changtao02-megatron-cpu-sleep-lj is successfully completed.",
                "reason": "JobSucceeded",
                "status": "True",
                "type": "Succeeded"
              }
            ],
            "lastReconcileTime": "2024-07-16T11:31:03Z",
            "replicaStatuses": {
              "Master": {
                "selector": "training.kubeflow.org/job-name=changtao02-megatron-cpu-sleep-lj,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=master",
                "succeeded": 1
              }
            },
            "startTime": "2024-07-16T11:31:04Z"
          }
        },
        {
          "apiVersion": "kubeflow.org/v1",
          "kind": "PyTorchJob",
          "metadata": {
            "annotations": {
              "aijob.cce.baidubce.com/barrier-finish": "d0f023d4-59a0-495f-a478-f42104ab5ec5",
              "aijob.cce.baidubce.com/fault-tolerance-enabled": "true",
              "aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": "",
              "aijob.cce.baidubce.com/internal-fault-tolerance-time": "2024-07-18T13:22:29.815441541Z",
              "aijob.cce.baidubce.com/timeline": "[{\"conditionType\":\"Created\",\"time\":1721306309},{\"conditionType\":\"Scheduled\",\"time\":1721308393},{\"conditionType\":\"Running\",\"time\":1721308739},{\"conditionType\":\"Abnormal\",\"time\":1721308949},{\"conditionType\":\"Failed\",\"time\":1721309552}]",
              "kubectl.kubernetes.io/last-applied-configuration": "{\"apiVersion\":\"kubeflow.org/v1\",\"kind\":\"PyTorchJob\",\"metadata\":{\"annotations\":{},\"name\":\"changtao02-megatron-llama3-70b-tp4-pp4\",\"namespace\":\"default\"},\"spec\":{\"pytorchReplicaSpecs\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"template\":{\"metadata\":null,\"spec\":{\"containers\":[{\"command\":[\"bash\",\"/workspace/Megatron-LM/examples/launch.sh\"],\"env\":[{\"name\":\"CUDA_DEVICE_MAX_CONNECTIONS\",\"value\":\"1\"},{\"name\":\"NCCL_IB_DISABLE\",\"value\":\"0\"},{\"name\":\"MASTER\",\"value\":\"1\"}],\"image\":\"registry.baidubce.com/cce-ai-native/aiak-megatron:multi-accelerators-20240608\",\"imagePullPolicy\":\"Always\",\"name\":\"pytorch\",\"resources\":{\"limits\":{\"nvidia.com/gpu\":8,\"rdma/hca\":1}},\"securityContext\":{\"capabilities\":{\"add\":[\"IPC_LOCK\"]}},\"volumeMounts\":[{\"mountPath\":\"/dev/shm\",\"name\":\"cache-volume\"},{\"mountPath\":\"/workspace/Megatron-LM/examples/launch.sh\",\"name\":\"config-volume\",\"subPath\":\"launch.sh\"},{\"mountPath\":\"/mnt/cluster\",\"name\":\"data\"}]}],\"schedulerName\":\"volcano\",\"volumes\":[{\"emptyDir\":{\"medium\":\"Memory\"},\"name\":\"cache-volume\"},{\"configMap\":{\"name\":\"launch-cm-llama3-70b-tp4-pp4\"},\"name\":\"config-volume\"},{\"name\":\"data\",\"persistentVolumeClaim\":{\"claimName\":\"pvc-pfs\"}}]}}},\"Worker\":{\"replicas\":3,\"restartPolicy\":\"Never\",\"template\":{\"spec\":{\"containers\":[{\"command\":[\"bash\",\"/workspace/Megatron-LM/examples/launch.sh\"],\"env\":[{\"name\":\"CUDA_DEVICE_MAX_CONNECTIONS\",\"value\":\"1\"},{\"name\":\"NCCL_IB_DISABLE\",\"value\":\"0\"}],\"image\":\"registry.baidubce.com/cce-ai-native/aiak-megatron:multi-accelerators-20240608\",\"imagePullPolicy\":\"Always\",\"name\":\"pytorch\",\"resources\":{\"limits\":{\"nvidia.com/gpu\":8,\"rdma/hca\":1}},\"securityContext\":{\"capabilities\":{\"add\":[\"IPC_LOCK\"]}},\"volumeMounts\":[{\"mountPath\":\"/dev/shm\",\"name\":\"cache-volume\"},{\"mountPath\":\"/workspace/Megatron-LM/examples/launch.sh\",\"name\":\"config-volume\",\"subPath\":\"launch.sh\"},{\"mountPath\":\"/mnt/cluster\",\"name\":\"data\"}]}],\"schedulerName\":\"volcano\",\"volumes\":[{\"emptyDir\":{\"medium\":\"Memory\"},\"name\":\"cache-volume\"},{\"configMap\":{\"name\":\"launch-cm-llama3-70b-tp4-pp4\"},\"name\":\"config-volume\"},{\"name\":\"data\",\"persistentVolumeClaim\":{\"claimName\":\"pvc-pfs\"}}]}}}}}}\n"
            },
            "creationTimestamp": "2024-07-18T12:38:29Z",
            "generation": 3,
            "managedFields": [
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      "f:aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": {},
                      "f:aijob.cce.baidubce.com/timeline": {}
                    }
                  }
                },
                "manager": "controller",
                "operation": "Update",
                "time": "2024-07-18T12:38:29Z"
              },
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      ".": {},
                      "f:kubectl.kubernetes.io/last-applied-configuration": {}
                    }
                  },
                  "f:spec": {
                    ".": {},
                    "f:pytorchReplicaSpecs": {
                      ".": {},
                      "f:Master": {
                        ".": {},
                        "f:replicas": {},
                        "f:restartPolicy": {},
                        "f:template": {
                          ".": {},
                          "f:spec": {
                            ".": {},
                            "f:schedulerName": {}
                          }
                        }
                      },
                      "f:Worker": {
                        ".": {},
                        "f:replicas": {},
                        "f:restartPolicy": {},
                        "f:template": {
                          ".": {},
                          "f:spec": {
                            ".": {},
                            "f:schedulerName": {}
                          }
                        }
                      }
                    }
                  }
                },
                "manager": "kubectl-client-side-apply",
                "operation": "Update",
                "time": "2024-07-18T12:38:29Z"
              },
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      "f:aijob.cce.baidubce.com/barrier-finish": {}
                    }
                  }
                },
                "manager": "jobbarrier",
                "operation": "Update",
                "time": "2024-07-18T13:18:56Z"
              },
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                      "f:aijob.cce.baidubce.com/internal-fault-tolerance-time": {}
                    }
                  },
                  "f:spec": {
                    "f:pytorchReplicaSpecs": {
                      "f:Master": {
                        "f:template": {
                          "f:metadata": {
                            ".": {},
                            "f:annotations": {
                              ".": {},
                              "f:prometheus.io/path": {},
                              "f:prometheus.io/port": {},
                              "f:prometheus.io/scrape": {}
                            }
                          },
                          "f:spec": {
                            "f:containers": {},
                            "f:serviceAccountName": {},
                            "f:shareProcessNamespace": {},
                            "f:volumes": {}
                          }
                        }
                      },
                      "f:Worker": {
                        "f:template": {
                          "f:metadata": {
                            ".": {},
                            "f:annotations": {
                              ".": {},
                              "f:prometheus.io/path": {},
                              "f:prometheus.io/port": {},
                              "f:prometheus.io/scrape": {}
                            }
                          },
                          "f:spec": {
                            "f:containers": {},
                            "f:serviceAccountName": {},
                            "f:shareProcessNamespace": {},
                            "f:volumes": {}
                          }
                        }
                      }
                    },
                    "f:runPolicy": {
                      ".": {},
                      "f:cleanPodPolicy": {}
                    }
                  },
                  "f:status": {
                    ".": {},
                    "f:completionTime": {},
                    "f:conditions": {},
                    "f:lastReconcileTime": {},
                    "f:replicaStatuses": {
                      ".": {},
                      "f:Master": {
                        ".": {},
                        "f:failed": {},
                        "f:selector": {}
                      },
                      "f:Worker": {
                        ".": {},
                        "f:failed": {},
                        "f:selector": {}
                      }
                    },
                    "f:startTime": {}
                  }
                },
                "manager": "manager",
                "operation": "Update",
                "time": "2024-07-18T13:32:32Z"
              }
            ],
            "name": "changtao02-megatron-llama3-70b-tp4-pp4",
            "namespace": "default",
            "resourceVersion": "2371781262",
            "uid": "bd0f44ca-e715-4565-8bce-4e26051cf5b5"
          },
          "spec": {
            "pytorchReplicaSpecs": {
              "Master": {
                "replicas": 1,
                "restartPolicy": "Never",
                "template": {
                  "metadata": {
                    "annotations": {
                      "prometheus.io/path": "/metrics",
                      "prometheus.io/port": "9101",
                      "prometheus.io/scrape": "true"
                    }
                  },
                  "spec": {
                    "containers": [
                      {
                        "command": [
                          "bash",
                          "/workspace/Megatron-LM/examples/launch.sh"
                        ],
                        "env": [
                          {
                            "name": "CUDA_DEVICE_MAX_CONNECTIONS",
                            "value": "1"
                          },
                          {
                            "name": "NCCL_IB_DISABLE",
                            "value": "0"
                          },
                          {
                            "name": "MASTER",
                            "value": "1"
                          },
                          {
                            "name": "BCCL_BUS_BW_CALCULATE_MODE",
                            "value": "Agg"
                          },
                          {
                            "name": "BCCL_PROFILING_FILE",
                            "value": "/var/bccl/logs/busbw.cal.%h.%p"
                          }
                        ],
                        "image": "registry.baidubce.com/cce-ai-native/aiak-megatron:multi-accelerators-20240608",
                        "imagePullPolicy": "Always",
                        "name": "pytorch",
                        "ports": [
                          {
                            "containerPort": 23456,
                            "name": "pytorchjob-port",
                            "protocol": "TCP"
                          }
                        ],
                        "resources": {
                          "limits": {
                            "nvidia.com/gpu": "8",
                            "rdma/hca": "1"
                          }
                        },
                        "securityContext": {
                          "capabilities": {
                            "add": [
                              "IPC_LOCK"
                            ]
                          }
                        },
                        "volumeMounts": [
                          {
                            "mountPath": "/dev/shm",
                            "name": "cache-volume"
                          },
                          {
                            "mountPath": "/workspace/Megatron-LM/examples/launch.sh",
                            "name": "config-volume",
                            "subPath": "launch.sh"
                          },
                          {
                            "mountPath": "/mnt/cluster",
                            "name": "data"
                          },
                          {
                            "mountPath": "/var/bccl/logs",
                            "name": "bccl-logs-volume"
                          }
                        ]
                      },
                      {
                        "env": [
                          {
                            "name": "POD_NAME",
                            "valueFrom": {
                              "fieldRef": {
                                "apiVersion": "v1",
                                "fieldPath": "metadata.name"
                              }
                            }
                          },
                          {
                            "name": "POD_UID",
                            "valueFrom": {
                              "fieldRef": {
                                "apiVersion": "v1",
                                "fieldPath": "metadata.uid"
                              }
                            }
                          },
                          {
                            "name": "POD_NAMESPACE",
                            "valueFrom": {
                              "fieldRef": {
                                "apiVersion": "v1",
                                "fieldPath": "metadata.namespace"
                              }
                            }
                          },
                          {
                            "name": "NODE_NAME",
                            "valueFrom": {
                              "fieldRef": {
                                "apiVersion": "v1",
                                "fieldPath": "spec.nodeName"
                              }
                            }
                          },
                          {
                            "name": "JOB_NAME",
                            "value": "changtao02-megatron-llama3-70b-tp4-pp4"
                          },
                          {
                            "name": "NODE_IP",
                            "valueFrom": {
                              "fieldRef": {
                                "apiVersion": "v1",
                                "fieldPath": "status.hostIP"
                              }
                            }
                          },
                          {
                            "name": "GPUS_PER_NODE",
                            "value": "8"
                          },
                          {
                            "name": "ENABLE_ELASTIC",
                            "value": "9"
                          },
                          {
                            "name": "BCCL_LOG_DIR",
                            "value": "/var/bccl/logs"
                          },
                          {
                            "name": "EXPORTER_PORT",
                            "value": "9101"
                          },
                          {
                            "name": "EXPORTER_INTERVAL",
                            "value": "60"
                          },
                          {
                            "name": "EXPORTER_PATH",
                            "value": "/metrics"
                          },
                          {
                            "name": "BCCL_BUS_BW_CALCULATE_MODE",
                            "value": "Agg"
                          },
                          {
                            "name": "BCCL_PROFILING_FILE",
                            "value": "/var/bccl/logs/busbw.cal.%h.%p"
                          }
                        ],
                        "image": "registry.baidubce.com/cce-plugin-dev/ftagent:v1.6.21",
                        "imagePullPolicy": "Always",
                        "name": "ftagent",
                        "ports": [
                          {
                            "containerPort": 9101,
                            "name": "exporter",
                            "protocol": "TCP"
                          }
                        ],
                        "resources": {},
                        "securityContext": {
                          "capabilities": {
                            "add": [
                              "IPC_LOCK"
                            ]
                          }
                        },
                        "volumeMounts": [
                          {
                            "mountPath": "/var/log/pods",
                            "name": "pod-log-volume"
                          },
                          {
                            "mountPath": "/home/cce",
                            "name": "container-log-volume"
                          },
                          {
                            "mountPath": "/var/bccl/logs",
                            "name": "bccl-logs-volume"
                          }
                        ]
                      }
                    ],
                    "schedulerName": "volcano",
                    "serviceAccountName": "ftagent-sa",
                    "shareProcessNamespace": true,
                    "volumes": [
                      {
                        "emptyDir": {
                          "medium": "Memory"
                        },
                        "name": "cache-volume"
                      },
                      {
                        "configMap": {
                          "name": "launch-cm-llama3-70b-tp4-pp4"
                        },
                        "name": "config-volume"
                      },
                      {
                        "name": "data",
                        "persistentVolumeClaim": {
                          "claimName": "pvc-pfs"
                        }
                      },
                      {
                        "emptyDir": {},
                        "name": "bccl-logs-volume"
                      },
                      {
                        "hostPath": {
                          "path": "/var/log/pods",
                          "type": "DirectoryOrCreate"
                        },
                        "name": "pod-log-volume"
                      },
                      {
                        "hostPath": {
                          "path": "/home/cce",
                          "type": "DirectoryOrCreate"
                        },
                        "name": "container-log-volume"
                      }
                    ]
                  }
                }
              },
              "Worker": {
                "replicas": 3,
                "restartPolicy": "Never",
                "template": {
                  "metadata": {
                    "annotations": {
                      "prometheus.io/path": "/metrics",
                      "prometheus.io/port": "9101",
                      "prometheus.io/scrape": "true"
                    }
                  },
                  "spec": {
                    "containers": [
                      {
                        "command": [
                          "bash",
                          "/workspace/Megatron-LM/examples/launch.sh"
                        ],
                        "env": [
                          {
                            "name": "CUDA_DEVICE_MAX_CONNECTIONS",
                            "value": "1"
                          },
                          {
                            "name": "NCCL_IB_DISABLE",
                            "value": "0"
                          },
                          {
                            "name": "BCCL_BUS_BW_CALCULATE_MODE",
                            "value": "Agg"
                          },
                          {
                            "name": "BCCL_PROFILING_FILE",
                            "value": "/var/bccl/logs/busbw.cal.%h.%p"
                          }
                        ],
                        "image": "registry.baidubce.com/cce-ai-native/aiak-megatron:multi-accelerators-20240608",
                        "imagePullPolicy": "Always",
                        "name": "pytorch",
                        "ports": [
                          {
                            "containerPort": 23456,
                            "name": "pytorchjob-port",
                            "protocol": "TCP"
                          }
                        ],
                        "resources": {
                          "limits": {
                            "nvidia.com/gpu": "8",
                            "rdma/hca": "1"
                          }
                        },
                        "securityContext": {
                          "capabilities": {
                            "add": [
                              "IPC_LOCK"
                            ]
                          }
                        },
                        "volumeMounts": [
                          {
                            "mountPath": "/dev/shm",
                            "name": "cache-volume"
                          },
                          {
                            "mountPath": "/workspace/Megatron-LM/examples/launch.sh",
                            "name": "config-volume",
                            "subPath": "launch.sh"
                          },
                          {
                            "mountPath": "/mnt/cluster",
                            "name": "data"
                          },
                          {
                            "mountPath": "/var/bccl/logs",
                            "name": "bccl-logs-volume"
                          }
                        ]
                      },
                      {
                        "env": [
                          {
                            "name": "POD_NAME",
                            "valueFrom": {
                              "fieldRef": {
                                "apiVersion": "v1",
                                "fieldPath": "metadata.name"
                              }
                            }
                          },
                          {
                            "name": "POD_UID",
                            "valueFrom": {
                              "fieldRef": {
                                "apiVersion": "v1",
                                "fieldPath": "metadata.uid"
                              }
                            }
                          },
                          {
                            "name": "POD_NAMESPACE",
                            "valueFrom": {
                              "fieldRef": {
                                "apiVersion": "v1",
                                "fieldPath": "metadata.namespace"
                              }
                            }
                          },
                          {
                            "name": "NODE_NAME",
                            "valueFrom": {
                              "fieldRef": {
                                "apiVersion": "v1",
                                "fieldPath": "spec.nodeName"
                              }
                            }
                          },
                          {
                            "name": "JOB_NAME",
                            "value": "changtao02-megatron-llama3-70b-tp4-pp4"
                          },
                          {
                            "name": "NODE_IP",
                            "valueFrom": {
                              "fieldRef": {
                                "apiVersion": "v1",
                                "fieldPath": "status.hostIP"
                              }
                            }
                          },
                          {
                            "name": "GPUS_PER_NODE",
                            "value": "8"
                          },
                          {
                            "name": "ENABLE_ELASTIC",
                            "value": "9"
                          },
                          {
                            "name": "BCCL_LOG_DIR",
                            "value": "/var/bccl/logs"
                          },
                          {
                            "name": "EXPORTER_PORT",
                            "value": "9101"
                          },
                          {
                            "name": "EXPORTER_INTERVAL",
                            "value": "60"
                          },
                          {
                            "name": "EXPORTER_PATH",
                            "value": "/metrics"
                          },
                          {
                            "name": "BCCL_BUS_BW_CALCULATE_MODE",
                            "value": "Agg"
                          },
                          {
                            "name": "BCCL_PROFILING_FILE",
                            "value": "/var/bccl/logs/busbw.cal.%h.%p"
                          }
                        ],
                        "image": "registry.baidubce.com/cce-plugin-dev/ftagent:v1.6.21",
                        "imagePullPolicy": "Always",
                        "name": "ftagent",
                        "ports": [
                          {
                            "containerPort": 9101,
                            "name": "exporter",
                            "protocol": "TCP"
                          }
                        ],
                        "resources": {},
                        "securityContext": {
                          "capabilities": {
                            "add": [
                              "IPC_LOCK"
                            ]
                          }
                        },
                        "volumeMounts": [
                          {
                            "mountPath": "/var/log/pods",
                            "name": "pod-log-volume"
                          },
                          {
                            "mountPath": "/home/cce",
                            "name": "container-log-volume"
                          },
                          {
                            "mountPath": "/var/bccl/logs",
                            "name": "bccl-logs-volume"
                          }
                        ]
                      }
                    ],
                    "schedulerName": "volcano",
                    "serviceAccountName": "ftagent-sa",
                    "shareProcessNamespace": true,
                    "volumes": [
                      {
                        "emptyDir": {
                          "medium": "Memory"
                        },
                        "name": "cache-volume"
                      },
                      {
                        "configMap": {
                          "name": "launch-cm-llama3-70b-tp4-pp4"
                        },
                        "name": "config-volume"
                      },
                      {
                        "name": "data",
                        "persistentVolumeClaim": {
                          "claimName": "pvc-pfs"
                        }
                      },
                      {
                        "emptyDir": {},
                        "name": "bccl-logs-volume"
                      },
                      {
                        "hostPath": {
                          "path": "/var/log/pods",
                          "type": "DirectoryOrCreate"
                        },
                        "name": "pod-log-volume"
                      },
                      {
                        "hostPath": {
                          "path": "/home/cce",
                          "type": "DirectoryOrCreate"
                        },
                        "name": "container-log-volume"
                      }
                    ]
                  }
                }
              }
            },
            "runPolicy": {
              "cleanPodPolicy": "None"
            }
          },
          "status": {
            "completionTime": "2024-07-18T13:32:32Z",
            "conditions": [
              {
                "lastTransitionTime": "2024-07-18T12:38:29Z",
                "lastUpdateTime": "2024-07-18T12:38:29Z",
                "message": "PyTorchJob changtao02-megatron-llama3-70b-tp4-pp4 is created.",
                "reason": "PyTorchJobCreated",
                "status": "True",
                "type": "Created"
              },
              {
                "lastTransitionTime": "2024-07-18T13:18:59Z",
                "lastUpdateTime": "2024-07-18T13:18:59Z",
                "message": "PyTorchJob changtao02-megatron-llama3-70b-tp4-pp4 is running.",
                "reason": "JobRunning",
                "status": "False",
                "type": "Running"
              },
              {
                "lastTransitionTime": "2024-07-18T13:32:32Z",
                "lastUpdateTime": "2024-07-18T13:32:32Z",
                "message": "PyTorchJob changtao02-megatron-llama3-70b-tp4-pp4 is failed because 1 Master replica(s) failed.",
                "reason": "JobFailed",
                "status": "True",
                "type": "Failed"
              }
            ],
            "lastReconcileTime": "2024-07-18T12:38:29Z",
            "replicaStatuses": {
              "Master": {
                "failed": 1,
                "selector": "training.kubeflow.org/job-name=changtao02-megatron-llama3-70b-tp4-pp4,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=master"
              },
              "Worker": {
                "failed": 3,
                "selector": "training.kubeflow.org/job-name=changtao02-megatron-llama3-70b-tp4-pp4,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=worker"
              }
            },
            "startTime": "2024-07-18T12:38:30Z"
          }
        },
        {
          "apiVersion": "kubeflow.org/v1",
          "kind": "PyTorchJob",
          "metadata": {
            "annotations": {
              "aijob.cce.baidubce.com/barrier-finish": "57675ff2-cc51-47e9-856b-e674a7e15ce4",
              "aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": "",
              "aijob.cce.baidubce.com/timeline": "[{\"conditionType\":\"Created\",\"time\":1721299165},{\"conditionType\":\"Scheduled\",\"time\":1721299167},{\"conditionType\":\"Running\",\"time\":1721299180},{\"conditionType\":\"Succeeded\",\"time\":1721299361}]",
              "kubectl.kubernetes.io/last-applied-configuration": "{\"apiVersion\":\"kubeflow.org/v1\",\"kind\":\"PyTorchJob\",\"metadata\":{\"annotations\":{},\"name\":\"changtao02-megatron-llama3-layer20-debug-lj\",\"namespace\":\"default\"},\"spec\":{\"pytorchReplicaSpecs\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"template\":{\"metadata\":null,\"spec\":{\"containers\":[{\"command\":[\"bash\",\"/workspace/Megatron-LM/examples/launch.sh\"],\"env\":[{\"name\":\"CUDA_DEVICE_MAX_CONNECTIONS\",\"value\":\"1\"},{\"name\":\"NCCL_IB_DISABLE\",\"value\":\"0\"},{\"name\":\"MASTER\",\"value\":\"1\"}],\"image\":\"registry.baidubce.com/cce-ai-native/aiak-megatron:multi-accelerators-20240608\",\"imagePullPolicy\":\"Always\",\"name\":\"pytorch\",\"resources\":{\"limits\":{\"nvidia.com/gpu\":8,\"rdma/hca\":1}},\"securityContext\":{\"capabilities\":{\"add\":[\"IPC_LOCK\"]}},\"volumeMounts\":[{\"mountPath\":\"/dev/shm\",\"name\":\"cache-volume\"},{\"mountPath\":\"/workspace/Megatron-LM/examples/launch.sh\",\"name\":\"config-volume\",\"subPath\":\"launch.sh\"},{\"mountPath\":\"/mnt/cluster\",\"name\":\"data\"}]}],\"schedulerName\":\"volcano\",\"volumes\":[{\"emptyDir\":{\"medium\":\"Memory\"},\"name\":\"cache-volume\"},{\"configMap\":{\"name\":\"changtao02-llama3-layer20-debug\"},\"name\":\"config-volume\"},{\"name\":\"data\",\"persistentVolumeClaim\":{\"claimName\":\"pvc-pfs\"}}]}}},\"Worker\":{\"replicas\":0,\"restartPolicy\":\"Never\",\"template\":{\"spec\":{\"containers\":[{\"command\":[\"bash\",\"/workspace/Megatron-LM/examples/launch.sh\"],\"env\":[{\"name\":\"CUDA_DEVICE_MAX_CONNECTIONS\",\"value\":\"1\"},{\"name\":\"NCCL_IB_DISABLE\",\"value\":\"0\"}],\"image\":\"registry.baidubce.com/cce-ai-native/aiak-megatron:multi-accelerators-20240608\",\"imagePullPolicy\":\"Always\",\"name\":\"pytorch\",\"resources\":{\"limits\":{\"nvidia.com/gpu\":8,\"rdma/hca\":1}},\"securityContext\":{\"capabilities\":{\"add\":[\"IPC_LOCK\"]}},\"volumeMounts\":[{\"mountPath\":\"/dev/shm\",\"name\":\"cache-volume\"},{\"mountPath\":\"/workspace/Megatron-LM/examples/launch.sh\",\"name\":\"config-volume\",\"subPath\":\"launch.sh\"},{\"mountPath\":\"/mnt/cluster\",\"name\":\"data\"}]}],\"schedulerName\":\"volcano\",\"volumes\":[{\"emptyDir\":{\"medium\":\"Memory\"},\"name\":\"cache-volume\"},{\"configMap\":{\"name\":\"changtao02-llama3-layer20-debug\"},\"name\":\"config-volume\"},{\"name\":\"data\",\"persistentVolumeClaim\":{\"claimName\":\"pvc-pfs\"}}]}}}}}}\n"
            },
            "creationTimestamp": "2024-07-18T10:39:25Z",
            "generation": 2,
            "managedFields": [
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      "f:aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": {},
                      "f:aijob.cce.baidubce.com/timeline": {}
                    }
                  },
                  "f:spec": {
                    "f:pytorchReplicaSpecs": {
                      "f:Master": {
                        "f:template": {
                          "f:metadata": {},
                          "f:spec": {
                            "f:containers": {}
                          }
                        }
                      },
                      "f:Worker": {
                        "f:template": {
                          "f:metadata": {},
                          "f:spec": {
                            "f:containers": {}
                          }
                        }
                      }
                    },
                    "f:runPolicy": {
                      ".": {},
                      "f:cleanPodPolicy": {}
                    }
                  }
                },
                "manager": "controller",
                "operation": "Update",
                "time": "2024-07-18T10:39:25Z"
              },
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      ".": {},
                      "f:kubectl.kubernetes.io/last-applied-configuration": {}
                    }
                  },
                  "f:spec": {
                    ".": {},
                    "f:pytorchReplicaSpecs": {
                      ".": {},
                      "f:Master": {
                        ".": {},
                        "f:replicas": {},
                        "f:restartPolicy": {},
                        "f:template": {
                          ".": {},
                          "f:spec": {
                            ".": {},
                            "f:schedulerName": {},
                            "f:volumes": {}
                          }
                        }
                      },
                      "f:Worker": {
                        ".": {},
                        "f:replicas": {},
                        "f:restartPolicy": {},
                        "f:template": {
                          ".": {},
                          "f:spec": {
                            ".": {},
                            "f:schedulerName": {},
                            "f:volumes": {}
                          }
                        }
                      }
                    }
                  }
                },
                "manager": "kubectl-client-side-apply",
                "operation": "Update",
                "time": "2024-07-18T10:39:25Z"
              },
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      "f:aijob.cce.baidubce.com/barrier-finish": {}
                    }
                  }
                },
                "manager": "jobbarrier",
                "operation": "Update",
                "time": "2024-07-18T10:39:37Z"
              },
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:status": {
                    ".": {},
                    "f:completionTime": {},
                    "f:conditions": {},
                    "f:lastReconcileTime": {},
                    "f:replicaStatuses": {
                      ".": {},
                      "f:Master": {
                        ".": {},
                        "f:selector": {},
                        "f:succeeded": {}
                      },
                      "f:Worker": {
                        ".": {},
                        "f:selector": {}
                      }
                    },
                    "f:startTime": {}
                  }
                },
                "manager": "manager",
                "operation": "Update",
                "time": "2024-07-18T10:42:41Z"
              }
            ],
            "name": "changtao02-megatron-llama3-layer20-debug-lj",
            "namespace": "default",
            "resourceVersion": "2371637326",
            "uid": "202c61cb-a030-41b5-93b1-8bbdc12f30be"
          },
          "spec": {
            "pytorchReplicaSpecs": {
              "Master": {
                "replicas": 1,
                "restartPolicy": "Never",
                "template": {
                  "metadata": {},
                  "spec": {
                    "containers": [
                      {
                        "command": [
                          "bash",
                          "/workspace/Megatron-LM/examples/launch.sh"
                        ],
                        "env": [
                          {
                            "name": "CUDA_DEVICE_MAX_CONNECTIONS",
                            "value": "1"
                          },
                          {
                            "name": "NCCL_IB_DISABLE",
                            "value": "0"
                          },
                          {
                            "name": "MASTER",
                            "value": "1"
                          }
                        ],
                        "image": "registry.baidubce.com/cce-ai-native/aiak-megatron:multi-accelerators-20240608",
                        "imagePullPolicy": "Always",
                        "name": "pytorch",
                        "ports": [
                          {
                            "containerPort": 23456,
                            "name": "pytorchjob-port",
                            "protocol": "TCP"
                          }
                        ],
                        "resources": {
                          "limits": {
                            "nvidia.com/gpu": "8",
                            "rdma/hca": "1"
                          }
                        },
                        "securityContext": {
                          "capabilities": {
                            "add": [
                              "IPC_LOCK"
                            ]
                          }
                        },
                        "volumeMounts": [
                          {
                            "mountPath": "/dev/shm",
                            "name": "cache-volume"
                          },
                          {
                            "mountPath": "/workspace/Megatron-LM/examples/launch.sh",
                            "name": "config-volume",
                            "subPath": "launch.sh"
                          },
                          {
                            "mountPath": "/mnt/cluster",
                            "name": "data"
                          }
                        ]
                      }
                    ],
                    "schedulerName": "volcano",
                    "volumes": [
                      {
                        "emptyDir": {
                          "medium": "Memory"
                        },
                        "name": "cache-volume"
                      },
                      {
                        "configMap": {
                          "name": "changtao02-llama3-layer20-debug"
                        },
                        "name": "config-volume"
                      },
                      {
                        "name": "data",
                        "persistentVolumeClaim": {
                          "claimName": "pvc-pfs"
                        }
                      }
                    ]
                  }
                }
              },
              "Worker": {
                "replicas": 0,
                "restartPolicy": "Never",
                "template": {
                  "metadata": {},
                  "spec": {
                    "containers": [
                      {
                        "command": [
                          "bash",
                          "/workspace/Megatron-LM/examples/launch.sh"
                        ],
                        "env": [
                          {
                            "name": "CUDA_DEVICE_MAX_CONNECTIONS",
                            "value": "1"
                          },
                          {
                            "name": "NCCL_IB_DISABLE",
                            "value": "0"
                          }
                        ],
                        "image": "registry.baidubce.com/cce-ai-native/aiak-megatron:multi-accelerators-20240608",
                        "imagePullPolicy": "Always",
                        "name": "pytorch",
                        "ports": [
                          {
                            "containerPort": 23456,
                            "name": "pytorchjob-port",
                            "protocol": "TCP"
                          }
                        ],
                        "resources": {
                          "limits": {
                            "nvidia.com/gpu": "8",
                            "rdma/hca": "1"
                          }
                        },
                        "securityContext": {
                          "capabilities": {
                            "add": [
                              "IPC_LOCK"
                            ]
                          }
                        },
                        "volumeMounts": [
                          {
                            "mountPath": "/dev/shm",
                            "name": "cache-volume"
                          },
                          {
                            "mountPath": "/workspace/Megatron-LM/examples/launch.sh",
                            "name": "config-volume",
                            "subPath": "launch.sh"
                          },
                          {
                            "mountPath": "/mnt/cluster",
                            "name": "data"
                          }
                        ]
                      }
                    ],
                    "schedulerName": "volcano",
                    "volumes": [
                      {
                        "emptyDir": {
                          "medium": "Memory"
                        },
                        "name": "cache-volume"
                      },
                      {
                        "configMap": {
                          "name": "changtao02-llama3-layer20-debug"
                        },
                        "name": "config-volume"
                      },
                      {
                        "name": "data",
                        "persistentVolumeClaim": {
                          "claimName": "pvc-pfs"
                        }
                      }
                    ]
                  }
                }
              }
            },
            "runPolicy": {
              "cleanPodPolicy": "None"
            }
          },
          "status": {
            "completionTime": "2024-07-18T10:42:41Z",
            "conditions": [
              {
                "lastTransitionTime": "2024-07-18T10:39:25Z",
                "lastUpdateTime": "2024-07-18T10:39:25Z",
                "message": "PyTorchJob changtao02-megatron-llama3-layer20-debug-lj is created.",
                "reason": "PyTorchJobCreated",
                "status": "True",
                "type": "Created"
              },
              {
                "lastTransitionTime": "2024-07-18T10:39:40Z",
                "lastUpdateTime": "2024-07-18T10:39:40Z",
                "message": "PyTorchJob changtao02-megatron-llama3-layer20-debug-lj is running.",
                "reason": "JobRunning",
                "status": "False",
                "type": "Running"
              },
              {
                "lastTransitionTime": "2024-07-18T10:42:41Z",
                "lastUpdateTime": "2024-07-18T10:42:41Z",
                "message": "PyTorchJob changtao02-megatron-llama3-layer20-debug-lj is successfully completed.",
                "reason": "JobSucceeded",
                "status": "True",
                "type": "Succeeded"
              }
            ],
            "lastReconcileTime": "2024-07-18T10:39:26Z",
            "replicaStatuses": {
              "Master": {
                "selector": "training.kubeflow.org/job-name=changtao02-megatron-llama3-layer20-debug-lj,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=master",
                "succeeded": 1
              },
              "Worker": {
                "selector": "training.kubeflow.org/job-name=changtao02-megatron-llama3-layer20-debug-lj,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=worker"
              }
            },
            "startTime": "2024-07-18T10:39:26Z"
          }
        },
        {
          "apiVersion": "kubeflow.org/v1",
          "kind": "PyTorchJob",
          "metadata": {
            "annotations": {
              "aijob.cce.baidubce.com/barrier-finish": "513c1989-e194-41eb-b1c1-5279a79337a0",
              "aijob.cce.baidubce.com/fault-tolerance-enabled": "true",
              "aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": "",
              "aijob.cce.baidubce.com/openapi-jobid": "pytorch-5f188c2b-a851-4ea8-a62e-dd0b61b8f1e6",
              "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
              "aijob.cce.baidubce.com/raw-request": "{\"name\":\"deepspeed-zhuxiang\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"normal\",\"oversell\":false,\"faultTolerance\":true,\"command\":\" source /root/anaconda3/etc/profile.d/conda.sh\\n    conda activate llama-factory\\n\\n    ROOT_DIR=/workspace/LLaMA-Factory/\\n\\n    CHECKPOINT_LOAD_PATH=/mnt/cluster/ppl/Qwen-14B-Chat\\n    CHECKPOINT_SAVE_PATH=/mnt/cluster/ppl/Qwen-14B-Chat_saved\\n    DEEPSPEED_CONFIG=$ROOT_DIR/examples/deepspeed/ds_z3_offload_config.json\\n\\n    GPUS_PER_NODE=8\\n\\n    is_master=${MASTER-\\\"0\\\"}\\n    if [[ $is_master -eq 1 ]];then\\n      DISTRIBUTED_ARGS=\\\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $HOSTNAME --master_port $MASTER_PORT\\\"\\n    else\\n      DISTRIBUTED_ARGS=\\\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $MASTER_ADDR --master_port $MASTER_PORT\\\"\\n    fi\\n\\n    QWEN_14B_ARGS=\\\"--model_name_or_path $CHECKPOINT_LOAD_PATH \\\\\\n        --stage sft \\\\\\n        --do_train \\\\\\n        --dataset alpaca_en_demo \\\\\\n        --template qwen \\\\\\n        --finetuning_type lora \\\\\\n        --lora_target all \\\\\\n        --overwrite_output_dir \\\\\\n        --dataset_dir $ROOT_DIR/data \\\\\\n        --output_dir $CHECKPOINT_SAVE_PATH \\\\\\n        --preprocessing_num_workers 90 \\\\\\n        --dataloader_num_workers 90 \\\\\\n        --per_device_train_batch_size 1 \\\\\\n        --gradient_accumulation_steps 8 \\\\\\n        --cutoff_len 2048 \\\\\\n        --max_length 2048 \\\\\\n        --deepspeed $DEEPSPEED_CONFIG \\\\\\n        --logging_first_step \\\\\\n        --logging_steps 10 \\\\\\n        --save_strategy steps \\\\\\n        --save_steps 40 \\\\\\n        --num_train_epochs 2.0 \\\\\\n        --lr_scheduler_type cosine \\\\\\n        --learning_rate 1e-5 \\\\\\n        --plot_loss \\\\\\n        --bf16 \\\\\\n        --rope_scaling linear \\\\\\n        --flash_attn auto \\\\\\n        --shift_attn \\\\\\n        --ddp_find_unused_parameters False \\\\\\n        --push_to_hub False\\\"\\n\\n    PYTHONPATH=$ROOT_DIR:$PYTHONPATH \\\\\\n        torchrun $DISTRIBUTED_ARGS \\\\\\n        $ROOT_DIR/src/train.py \\\\\\n        $QWEN_14B_ARGS\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":true,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/cce-ai-native/aiak-algo\",\"tag\":\"0.1\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"deepspeed-zhuxiang\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/deepspeed-zhuxiang/output/training_logs\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"},\"Worker\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/cce-ai-native/aiak-algo\",\"tag\":\"0.1\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"deepspeed-zhuxiang\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/deepspeed-zhuxiang/output/training_logs\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":true,\"logPath\":\"/mnt/cluster/deepspeed-zhuxiang/output/training_logs\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":true,\"isCopyJob\":false,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
              "aijob.cce.baidubce.com/timeline": "[{\"conditionType\":\"Created\",\"time\":1721569996},{\"conditionType\":\"Scheduled\",\"time\":1721569998},{\"conditionType\":\"Running\",\"time\":1721571406},{\"conditionType\":\"Succeeded\",\"time\":1721571826}]",
              "scheduling.k8s.io/job-enable-oversell": "false",
              "tensorboard-gc": "true"
            },
            "creationTimestamp": "2024-07-21T13:53:16Z",
            "generation": 2,
            "labels": {
              "aijob.cce.baidubce.com/ai-user-id": "b89c433a0e884615a4c878ca24e2686e",
              "aijob.cce.baidubce.com/ai-user-name": "zhuxiang05",
              "aijob.cce.baidubce.com/create-from-aihcp": "true",
              "aijob.cce.baidubce.com/openapi-jobid": "pytorch-5f188c2b-a851-4ea8-a62e-dd0b61b8f1e6"
            },
            "managedFields": [
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      ".": {},
                      "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                      "f:aijob.cce.baidubce.com/openapi-jobid": {},
                      "f:aijob.cce.baidubce.com/pfs-id": {},
                      "f:aijob.cce.baidubce.com/raw-request": {},
                      "f:scheduling.k8s.io/job-enable-oversell": {}
                    },
                    "f:labels": {
                      ".": {},
                      "f:aijob.cce.baidubce.com/ai-user-id": {},
                      "f:aijob.cce.baidubce.com/ai-user-name": {},
                      "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                      "f:aijob.cce.baidubce.com/openapi-jobid": {}
                    }
                  },
                  "f:spec": {
                    ".": {},
                    "f:pytorchReplicaSpecs": {
                      ".": {},
                      "f:Master": {
                        ".": {},
                        "f:replicas": {},
                        "f:restartPolicy": {},
                        "f:template": {
                          ".": {},
                          "f:metadata": {
                            ".": {},
                            "f:annotations": {
                              ".": {},
                              "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                              "f:aijob.cce.baidubce.com/openapi-jobid": {},
                              "f:aijob.cce.baidubce.com/pfs-id": {},
                              "f:aijob.cce.baidubce.com/raw-request": {},
                              "f:scheduling.k8s.io/job-enable-oversell": {}
                            },
                            "f:labels": {
                              ".": {},
                              "f:aijob.cce.baidubce.com/ai-user-id": {},
                              "f:aijob.cce.baidubce.com/ai-user-name": {},
                              "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                              "f:aijob.cce.baidubce.com/openapi-jobid": {}
                            }
                          },
                          "f:spec": {
                            ".": {},
                            "f:dnsPolicy": {},
                            "f:hostNetwork": {},
                            "f:schedulerName": {},
                            "f:volumes": {}
                          }
                        }
                      },
                      "f:Worker": {
                        ".": {},
                        "f:replicas": {},
                        "f:restartPolicy": {},
                        "f:template": {
                          ".": {},
                          "f:metadata": {
                            ".": {},
                            "f:annotations": {
                              ".": {},
                              "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                              "f:aijob.cce.baidubce.com/openapi-jobid": {},
                              "f:aijob.cce.baidubce.com/pfs-id": {},
                              "f:aijob.cce.baidubce.com/raw-request": {},
                              "f:scheduling.k8s.io/job-enable-oversell": {}
                            },
                            "f:labels": {
                              ".": {},
                              "f:aijob.cce.baidubce.com/ai-user-id": {},
                              "f:aijob.cce.baidubce.com/ai-user-name": {},
                              "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                              "f:aijob.cce.baidubce.com/openapi-jobid": {}
                            }
                          },
                          "f:spec": {
                            ".": {},
                            "f:dnsPolicy": {},
                            "f:hostNetwork": {},
                            "f:schedulerName": {},
                            "f:volumes": {}
                          }
                        }
                      }
                    },
                    "f:runPolicy": {
                      ".": {},
                      "f:schedulingPolicy": {
                        ".": {},
                        "f:priorityClass": {},
                        "f:queue": {}
                      }
                    }
                  }
                },
                "manager": "cce-ai-service",
                "operation": "Update",
                "time": "2024-07-21T13:53:16Z"
              },
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      "f:aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": {},
                      "f:aijob.cce.baidubce.com/timeline": {}
                    }
                  },
                  "f:spec": {
                    "f:pytorchReplicaSpecs": {
                      "f:Master": {
                        "f:template": {
                          "f:spec": {
                            "f:containers": {}
                          }
                        }
                      },
                      "f:Worker": {
                        "f:template": {
                          "f:spec": {
                            "f:containers": {}
                          }
                        }
                      }
                    },
                    "f:runPolicy": {
                      "f:cleanPodPolicy": {}
                    }
                  }
                },
                "manager": "controller",
                "operation": "Update",
                "time": "2024-07-21T13:53:16Z"
              },
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      "f:aijob.cce.baidubce.com/barrier-finish": {}
                    }
                  }
                },
                "manager": "jobbarrier",
                "operation": "Update",
                "time": "2024-07-21T14:16:37Z"
              },
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      "f:tensorboard-gc": {}
                    }
                  },
                  "f:status": {
                    ".": {},
                    "f:completionTime": {},
                    "f:conditions": {},
                    "f:lastReconcileTime": {},
                    "f:replicaStatuses": {
                      ".": {},
                      "f:Master": {
                        ".": {},
                        "f:selector": {},
                        "f:succeeded": {}
                      },
                      "f:Worker": {
                        ".": {},
                        "f:selector": {},
                        "f:succeeded": {}
                      }
                    },
                    "f:startTime": {}
                  }
                },
                "manager": "manager",
                "operation": "Update",
                "time": "2024-07-22T13:53:34Z"
              }
            ],
            "name": "deepspeed-zhuxiang",
            "namespace": "default",
            "resourceVersion": "2376353037",
            "uid": "9905b1d3-aa53-4500-a38f-85d4e54a3523"
          },
          "spec": {
            "pytorchReplicaSpecs": {
              "Master": {
                "replicas": 1,
                "restartPolicy": "Never",
                "template": {
                  "metadata": {
                    "annotations": {
                      "aijob.cce.baidubce.com/fault-tolerance-enabled": "true",
                      "aijob.cce.baidubce.com/openapi-jobid": "pytorch-5f188c2b-a851-4ea8-a62e-dd0b61b8f1e6",
                      "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
                      "aijob.cce.baidubce.com/raw-request": "{\"name\":\"deepspeed-zhuxiang\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"normal\",\"oversell\":false,\"faultTolerance\":true,\"command\":\" source /root/anaconda3/etc/profile.d/conda.sh\\n    conda activate llama-factory\\n\\n    ROOT_DIR=/workspace/LLaMA-Factory/\\n\\n    CHECKPOINT_LOAD_PATH=/mnt/cluster/ppl/Qwen-14B-Chat\\n    CHECKPOINT_SAVE_PATH=/mnt/cluster/ppl/Qwen-14B-Chat_saved\\n    DEEPSPEED_CONFIG=$ROOT_DIR/examples/deepspeed/ds_z3_offload_config.json\\n\\n    GPUS_PER_NODE=8\\n\\n    is_master=${MASTER-\\\"0\\\"}\\n    if [[ $is_master -eq 1 ]];then\\n      DISTRIBUTED_ARGS=\\\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $HOSTNAME --master_port $MASTER_PORT\\\"\\n    else\\n      DISTRIBUTED_ARGS=\\\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $MASTER_ADDR --master_port $MASTER_PORT\\\"\\n    fi\\n\\n    QWEN_14B_ARGS=\\\"--model_name_or_path $CHECKPOINT_LOAD_PATH \\\\\\n        --stage sft \\\\\\n        --do_train \\\\\\n        --dataset alpaca_en_demo \\\\\\n        --template qwen \\\\\\n        --finetuning_type lora \\\\\\n        --lora_target all \\\\\\n        --overwrite_output_dir \\\\\\n        --dataset_dir $ROOT_DIR/data \\\\\\n        --output_dir $CHECKPOINT_SAVE_PATH \\\\\\n        --preprocessing_num_workers 90 \\\\\\n        --dataloader_num_workers 90 \\\\\\n        --per_device_train_batch_size 1 \\\\\\n        --gradient_accumulation_steps 8 \\\\\\n        --cutoff_len 2048 \\\\\\n        --max_length 2048 \\\\\\n        --deepspeed $DEEPSPEED_CONFIG \\\\\\n        --logging_first_step \\\\\\n        --logging_steps 10 \\\\\\n        --save_strategy steps \\\\\\n        --save_steps 40 \\\\\\n        --num_train_epochs 2.0 \\\\\\n        --lr_scheduler_type cosine \\\\\\n        --learning_rate 1e-5 \\\\\\n        --plot_loss \\\\\\n        --bf16 \\\\\\n        --rope_scaling linear \\\\\\n        --flash_attn auto \\\\\\n        --shift_attn \\\\\\n        --ddp_find_unused_parameters False \\\\\\n        --push_to_hub False\\\"\\n\\n    PYTHONPATH=$ROOT_DIR:$PYTHONPATH \\\\\\n        torchrun $DISTRIBUTED_ARGS \\\\\\n        $ROOT_DIR/src/train.py \\\\\\n        $QWEN_14B_ARGS\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":true,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/cce-ai-native/aiak-algo\",\"tag\":\"0.1\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"deepspeed-zhuxiang\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/deepspeed-zhuxiang/output/training_logs\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"},\"Worker\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/cce-ai-native/aiak-algo\",\"tag\":\"0.1\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"deepspeed-zhuxiang\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/deepspeed-zhuxiang/output/training_logs\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":true,\"logPath\":\"/mnt/cluster/deepspeed-zhuxiang/output/training_logs\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":true,\"isCopyJob\":false,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
                      "scheduling.k8s.io/job-enable-oversell": "false"
                    },
                    "labels": {
                      "aijob.cce.baidubce.com/ai-user-id": "b89c433a0e884615a4c878ca24e2686e",
                      "aijob.cce.baidubce.com/ai-user-name": "zhuxiang05",
                      "aijob.cce.baidubce.com/create-from-aihcp": "true",
                      "aijob.cce.baidubce.com/openapi-jobid": "pytorch-5f188c2b-a851-4ea8-a62e-dd0b61b8f1e6"
                    }
                  },
                  "spec": {
                    "containers": [
                      {
                        "command": [
                          "/bin/bash",
                          "-c",
                          " source /root/anaconda3/etc/profile.d/conda.sh\n    conda activate llama-factory\n\n    ROOT_DIR=/workspace/LLaMA-Factory/\n\n    CHECKPOINT_LOAD_PATH=/mnt/cluster/ppl/Qwen-14B-Chat\n    CHECKPOINT_SAVE_PATH=/mnt/cluster/ppl/Qwen-14B-Chat_saved\n    DEEPSPEED_CONFIG=$ROOT_DIR/examples/deepspeed/ds_z3_offload_config.json\n\n    GPUS_PER_NODE=8\n\n    is_master=${MASTER-\"0\"}\n    if [[ $is_master -eq 1 ]];then\n      DISTRIBUTED_ARGS=\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $HOSTNAME --master_port $MASTER_PORT\"\n    else\n      DISTRIBUTED_ARGS=\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $MASTER_ADDR --master_port $MASTER_PORT\"\n    fi\n\n    QWEN_14B_ARGS=\"--model_name_or_path $CHECKPOINT_LOAD_PATH \\\n        --stage sft \\\n        --do_train \\\n        --dataset alpaca_en_demo \\\n        --template qwen \\\n        --finetuning_type lora \\\n        --lora_target all \\\n        --overwrite_output_dir \\\n        --dataset_dir $ROOT_DIR/data \\\n        --output_dir $CHECKPOINT_SAVE_PATH \\\n        --preprocessing_num_workers 90 \\\n        --dataloader_num_workers 90 \\\n        --per_device_train_batch_size 1 \\\n        --gradient_accumulation_steps 8 \\\n        --cutoff_len 2048 \\\n        --max_length 2048 \\\n        --deepspeed $DEEPSPEED_CONFIG \\\n        --logging_first_step \\\n        --logging_steps 10 \\\n        --save_strategy steps \\\n        --save_steps 40 \\\n        --num_train_epochs 2.0 \\\n        --lr_scheduler_type cosine \\\n        --learning_rate 1e-5 \\\n        --plot_loss \\\n        --bf16 \\\n        --rope_scaling linear \\\n        --flash_attn auto \\\n        --shift_attn \\\n        --ddp_find_unused_parameters False \\\n        --push_to_hub False\"\n\n    PYTHONPATH=$ROOT_DIR:$PYTHONPATH \\\n        torchrun $DISTRIBUTED_ARGS \\\n        $ROOT_DIR/src/train.py \\\n        $QWEN_14B_ARGS"
                        ],
                        "env": [
                          {
                            "name": "AIHC_TENSORBOARD_LOG_PATH",
                            "value": "/mnt/cluster/deepspeed-zhuxiang/output/training_logs"
                          },
                          {
                            "name": "AIHC_JOB_NAME",
                            "value": "deepspeed-zhuxiang"
                          },
                          {
                            "name": "NCCL_IB_DISABLE",
                            "value": "0"
                          }
                        ],
                        "image": "registry.baidubce.com/cce-ai-native/aiak-algo:0.1",
                        "imagePullPolicy": "Always",
                        "name": "pytorch",
                        "ports": [
                          {
                            "containerPort": 23456,
                            "name": "pytorchjob-port",
                            "protocol": "TCP"
                          }
                        ],
                        "resources": {
                          "limits": {
                            "baidu.com/a800_80g_cgpu": "8",
                            "rdma/hca": "1"
                          },
                          "requests": {
                            "baidu.com/a800_80g_cgpu": "8",
                            "rdma/hca": "1"
                          }
                        },
                        "securityContext": {
                          "capabilities": {
                            "add": [
                              "IPC_LOCK"
                            ]
                          }
                        },
                        "volumeMounts": [
                          {
                            "mountPath": "/dev/shm",
                            "name": "devshm"
                          },
                          {
                            "mountPath": "/mnt/cluster",
                            "name": "pvc-pfs"
                          }
                        ]
                      }
                    ],
                    "dnsPolicy": "ClusterFirstWithHostNet",
                    "hostNetwork": true,
                    "schedulerName": "volcano",
                    "volumes": [
                      {
                        "emptyDir": {
                          "medium": "Memory",
                          "sizeLimit": "10Gi"
                        },
                        "name": "devshm"
                      },
                      {
                        "name": "pvc-pfs",
                        "persistentVolumeClaim": {
                          "claimName": "pvc-pfs"
                        }
                      }
                    ]
                  }
                }
              },
              "Worker": {
                "replicas": 1,
                "restartPolicy": "Never",
                "template": {
                  "metadata": {
                    "annotations": {
                      "aijob.cce.baidubce.com/fault-tolerance-enabled": "true",
                      "aijob.cce.baidubce.com/openapi-jobid": "pytorch-5f188c2b-a851-4ea8-a62e-dd0b61b8f1e6",
                      "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
                      "aijob.cce.baidubce.com/raw-request": "{\"name\":\"deepspeed-zhuxiang\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"normal\",\"oversell\":false,\"faultTolerance\":true,\"command\":\" source /root/anaconda3/etc/profile.d/conda.sh\\n    conda activate llama-factory\\n\\n    ROOT_DIR=/workspace/LLaMA-Factory/\\n\\n    CHECKPOINT_LOAD_PATH=/mnt/cluster/ppl/Qwen-14B-Chat\\n    CHECKPOINT_SAVE_PATH=/mnt/cluster/ppl/Qwen-14B-Chat_saved\\n    DEEPSPEED_CONFIG=$ROOT_DIR/examples/deepspeed/ds_z3_offload_config.json\\n\\n    GPUS_PER_NODE=8\\n\\n    is_master=${MASTER-\\\"0\\\"}\\n    if [[ $is_master -eq 1 ]];then\\n      DISTRIBUTED_ARGS=\\\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $HOSTNAME --master_port $MASTER_PORT\\\"\\n    else\\n      DISTRIBUTED_ARGS=\\\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $MASTER_ADDR --master_port $MASTER_PORT\\\"\\n    fi\\n\\n    QWEN_14B_ARGS=\\\"--model_name_or_path $CHECKPOINT_LOAD_PATH \\\\\\n        --stage sft \\\\\\n        --do_train \\\\\\n        --dataset alpaca_en_demo \\\\\\n        --template qwen \\\\\\n        --finetuning_type lora \\\\\\n        --lora_target all \\\\\\n        --overwrite_output_dir \\\\\\n        --dataset_dir $ROOT_DIR/data \\\\\\n        --output_dir $CHECKPOINT_SAVE_PATH \\\\\\n        --preprocessing_num_workers 90 \\\\\\n        --dataloader_num_workers 90 \\\\\\n        --per_device_train_batch_size 1 \\\\\\n        --gradient_accumulation_steps 8 \\\\\\n        --cutoff_len 2048 \\\\\\n        --max_length 2048 \\\\\\n        --deepspeed $DEEPSPEED_CONFIG \\\\\\n        --logging_first_step \\\\\\n        --logging_steps 10 \\\\\\n        --save_strategy steps \\\\\\n        --save_steps 40 \\\\\\n        --num_train_epochs 2.0 \\\\\\n        --lr_scheduler_type cosine \\\\\\n        --learning_rate 1e-5 \\\\\\n        --plot_loss \\\\\\n        --bf16 \\\\\\n        --rope_scaling linear \\\\\\n        --flash_attn auto \\\\\\n        --shift_attn \\\\\\n        --ddp_find_unused_parameters False \\\\\\n        --push_to_hub False\\\"\\n\\n    PYTHONPATH=$ROOT_DIR:$PYTHONPATH \\\\\\n        torchrun $DISTRIBUTED_ARGS \\\\\\n        $ROOT_DIR/src/train.py \\\\\\n        $QWEN_14B_ARGS\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":true,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/cce-ai-native/aiak-algo\",\"tag\":\"0.1\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"deepspeed-zhuxiang\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/deepspeed-zhuxiang/output/training_logs\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"},\"Worker\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/cce-ai-native/aiak-algo\",\"tag\":\"0.1\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"deepspeed-zhuxiang\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/deepspeed-zhuxiang/output/training_logs\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":true,\"logPath\":\"/mnt/cluster/deepspeed-zhuxiang/output/training_logs\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":true,\"isCopyJob\":false,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
                      "scheduling.k8s.io/job-enable-oversell": "false"
                    },
                    "labels": {
                      "aijob.cce.baidubce.com/ai-user-id": "b89c433a0e884615a4c878ca24e2686e",
                      "aijob.cce.baidubce.com/ai-user-name": "zhuxiang05",
                      "aijob.cce.baidubce.com/create-from-aihcp": "true",
                      "aijob.cce.baidubce.com/openapi-jobid": "pytorch-5f188c2b-a851-4ea8-a62e-dd0b61b8f1e6"
                    }
                  },
                  "spec": {
                    "containers": [
                      {
                        "command": [
                          "/bin/bash",
                          "-c",
                          " source /root/anaconda3/etc/profile.d/conda.sh\n    conda activate llama-factory\n\n    ROOT_DIR=/workspace/LLaMA-Factory/\n\n    CHECKPOINT_LOAD_PATH=/mnt/cluster/ppl/Qwen-14B-Chat\n    CHECKPOINT_SAVE_PATH=/mnt/cluster/ppl/Qwen-14B-Chat_saved\n    DEEPSPEED_CONFIG=$ROOT_DIR/examples/deepspeed/ds_z3_offload_config.json\n\n    GPUS_PER_NODE=8\n\n    is_master=${MASTER-\"0\"}\n    if [[ $is_master -eq 1 ]];then\n      DISTRIBUTED_ARGS=\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $HOSTNAME --master_port $MASTER_PORT\"\n    else\n      DISTRIBUTED_ARGS=\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $MASTER_ADDR --master_port $MASTER_PORT\"\n    fi\n\n    QWEN_14B_ARGS=\"--model_name_or_path $CHECKPOINT_LOAD_PATH \\\n        --stage sft \\\n        --do_train \\\n        --dataset alpaca_en_demo \\\n        --template qwen \\\n        --finetuning_type lora \\\n        --lora_target all \\\n        --overwrite_output_dir \\\n        --dataset_dir $ROOT_DIR/data \\\n        --output_dir $CHECKPOINT_SAVE_PATH \\\n        --preprocessing_num_workers 90 \\\n        --dataloader_num_workers 90 \\\n        --per_device_train_batch_size 1 \\\n        --gradient_accumulation_steps 8 \\\n        --cutoff_len 2048 \\\n        --max_length 2048 \\\n        --deepspeed $DEEPSPEED_CONFIG \\\n        --logging_first_step \\\n        --logging_steps 10 \\\n        --save_strategy steps \\\n        --save_steps 40 \\\n        --num_train_epochs 2.0 \\\n        --lr_scheduler_type cosine \\\n        --learning_rate 1e-5 \\\n        --plot_loss \\\n        --bf16 \\\n        --rope_scaling linear \\\n        --flash_attn auto \\\n        --shift_attn \\\n        --ddp_find_unused_parameters False \\\n        --push_to_hub False\"\n\n    PYTHONPATH=$ROOT_DIR:$PYTHONPATH \\\n        torchrun $DISTRIBUTED_ARGS \\\n        $ROOT_DIR/src/train.py \\\n        $QWEN_14B_ARGS"
                        ],
                        "env": [
                          {
                            "name": "AIHC_TENSORBOARD_LOG_PATH",
                            "value": "/mnt/cluster/deepspeed-zhuxiang/output/training_logs"
                          },
                          {
                            "name": "AIHC_JOB_NAME",
                            "value": "deepspeed-zhuxiang"
                          },
                          {
                            "name": "NCCL_IB_DISABLE",
                            "value": "0"
                          }
                        ],
                        "image": "registry.baidubce.com/cce-ai-native/aiak-algo:0.1",
                        "imagePullPolicy": "Always",
                        "name": "pytorch",
                        "ports": [
                          {
                            "containerPort": 23456,
                            "name": "pytorchjob-port",
                            "protocol": "TCP"
                          }
                        ],
                        "resources": {
                          "limits": {
                            "baidu.com/a800_80g_cgpu": "8",
                            "rdma/hca": "1"
                          },
                          "requests": {
                            "baidu.com/a800_80g_cgpu": "8",
                            "rdma/hca": "1"
                          }
                        },
                        "securityContext": {
                          "capabilities": {
                            "add": [
                              "IPC_LOCK"
                            ]
                          }
                        },
                        "volumeMounts": [
                          {
                            "mountPath": "/dev/shm",
                            "name": "devshm"
                          },
                          {
                            "mountPath": "/mnt/cluster",
                            "name": "pvc-pfs"
                          }
                        ]
                      }
                    ],
                    "dnsPolicy": "ClusterFirstWithHostNet",
                    "hostNetwork": true,
                    "schedulerName": "volcano",
                    "volumes": [
                      {
                        "emptyDir": {
                          "medium": "Memory",
                          "sizeLimit": "10Gi"
                        },
                        "name": "devshm"
                      },
                      {
                        "name": "pvc-pfs",
                        "persistentVolumeClaim": {
                          "claimName": "pvc-pfs"
                        }
                      }
                    ]
                  }
                }
              }
            },
            "runPolicy": {
              "cleanPodPolicy": "None",
              "schedulingPolicy": {
                "priorityClass": "normal",
                "queue": "default"
              }
            }
          },
          "status": {
            "completionTime": "2024-07-21T14:23:46Z",
            "conditions": [
              {
                "lastTransitionTime": "2024-07-21T13:53:16Z",
                "lastUpdateTime": "2024-07-21T13:53:16Z",
                "message": "PyTorchJob deepspeed-zhuxiang is created.",
                "reason": "PyTorchJobCreated",
                "status": "True",
                "type": "Created"
              },
              {
                "lastTransitionTime": "2024-07-21T14:16:46Z",
                "lastUpdateTime": "2024-07-21T14:16:46Z",
                "message": "PyTorchJob deepspeed-zhuxiang is running.",
                "reason": "JobRunning",
                "status": "False",
                "type": "Running"
              },
              {
                "lastTransitionTime": "2024-07-21T14:23:46Z",
                "lastUpdateTime": "2024-07-21T14:23:46Z",
                "message": "PyTorchJob deepspeed-zhuxiang is successfully completed.",
                "reason": "JobSucceeded",
                "status": "True",
                "type": "Succeeded"
              }
            ],
            "lastReconcileTime": "2024-07-21T14:23:46Z",
            "replicaStatuses": {
              "Master": {
                "selector": "training.kubeflow.org/job-name=deepspeed-zhuxiang,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=master",
                "succeeded": 1
              },
              "Worker": {
                "selector": "training.kubeflow.org/job-name=deepspeed-zhuxiang,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=worker",
                "succeeded": 1
              }
            },
            "startTime": "2024-07-21T13:53:17Z"
          }
        },
        {
          "apiVersion": "kubeflow.org/v1",
          "kind": "PyTorchJob",
          "metadata": {
            "annotations": {
              "aijob.cce.baidubce.com/barrier-finish": "fc10caac-df62-4783-9710-e515765b632c",
              "aijob.cce.baidubce.com/fault-tolerance-enabled": "false",
              "aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": "",
              "aijob.cce.baidubce.com/openapi-jobid": "pytorch-f6085dc4-cc6e-4dc3-a524-881a8b4e172e",
              "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
              "aijob.cce.baidubce.com/raw-request": "{\"name\":\"deepspeed-zhuxiang-1\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"normal\",\"oversell\":false,\"faultTolerance\":false,\"command\":\" source /root/anaconda3/etc/profile.d/conda.sh\\n    conda activate llama-factory\\n\\n    ROOT_DIR=/workspace/LLaMA-Factory/\\n\\n    CHECKPOINT_LOAD_PATH=/mnt/cluster/ppl/Qwen-14B-Chat\\n    CHECKPOINT_SAVE_PATH=/mnt/cluster/ppl/Qwen-14B-Chat_saved_zhuxiang\\n    DEEPSPEED_CONFIG=$ROOT_DIR/examples/deepspeed/ds_z3_offload_config.json\\n\\n    GPUS_PER_NODE=8\\n\\n    is_master=${MASTER-\\\"0\\\"}\\n    if [[ $is_master -eq 1 ]];then\\n      DISTRIBUTED_ARGS=\\\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $HOSTNAME --master_port $MASTER_PORT\\\"\\n    else\\n      DISTRIBUTED_ARGS=\\\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $MASTER_ADDR --master_port $MASTER_PORT\\\"\\n    fi\\n\\n    QWEN_14B_ARGS=\\\"--model_name_or_path $CHECKPOINT_LOAD_PATH \\\\\\n        --stage sft \\\\\\n        --do_train \\\\\\n        --dataset alpaca_en_demo \\\\\\n        --template qwen \\\\\\n        --finetuning_type lora \\\\\\n        --lora_target all \\\\\\n        --overwrite_output_dir \\\\\\n        --dataset_dir $ROOT_DIR/data \\\\\\n        --output_dir $CHECKPOINT_SAVE_PATH \\\\\\n        --preprocessing_num_workers 90 \\\\\\n        --dataloader_num_workers 90 \\\\\\n        --per_device_train_batch_size 1 \\\\\\n        --gradient_accumulation_steps 8 \\\\\\n        --cutoff_len 2048 \\\\\\n        --max_length 2048 \\\\\\n        --deepspeed $DEEPSPEED_CONFIG \\\\\\n        --logging_first_step \\\\\\n        --logging_steps 10 \\\\\\n        --save_strategy steps \\\\\\n        --save_steps 40 \\\\\\n        --num_train_epochs 2.0 \\\\\\n        --lr_scheduler_type cosine \\\\\\n        --learning_rate 1e-5 \\\\\\n        --plot_loss \\\\\\n        --bf16 \\\\\\n        --rope_scaling linear \\\\\\n        --flash_attn auto \\\\\\n        --shift_attn \\\\\\n        --ddp_find_unused_parameters False \\\\\\n        --push_to_hub False\\\"\\n\\n    PYTHONPATH=$ROOT_DIR:$PYTHONPATH \\\\\\n        torchrun $DISTRIBUTED_ARGS \\\\\\n        $ROOT_DIR/src/train.py \\\\\\n        $QWEN_14B_ARGS\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":true,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/cce-ai-native/aiak-algo\",\"tag\":\"0.1\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"deepspeed-zhuxiang-1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"},\"Worker\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/cce-ai-native/aiak-algo\",\"tag\":\"0.1\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"deepspeed-zhuxiang-1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":false,\"logPath\":\"\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":true,\"isCopyJob\":true,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
              "aijob.cce.baidubce.com/timeline": "[{\"conditionType\":\"Created\",\"time\":1721573623},{\"conditionType\":\"Scheduled\",\"time\":1721573624},{\"conditionType\":\"Running\",\"time\":1721573641},{\"conditionType\":\"Succeeded\",\"time\":1721574002}]",
              "scheduling.k8s.io/job-enable-oversell": "false"
            },
            "creationTimestamp": "2024-07-21T14:53:43Z",
            "generation": 2,
            "labels": {
              "aijob.cce.baidubce.com/ai-user-id": "b89c433a0e884615a4c878ca24e2686e",
              "aijob.cce.baidubce.com/ai-user-name": "zhuxiang05",
              "aijob.cce.baidubce.com/create-from-aihcp": "true",
              "aijob.cce.baidubce.com/openapi-jobid": "pytorch-f6085dc4-cc6e-4dc3-a524-881a8b4e172e"
            },
            "managedFields": [
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      ".": {},
                      "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                      "f:aijob.cce.baidubce.com/openapi-jobid": {},
                      "f:aijob.cce.baidubce.com/pfs-id": {},
                      "f:aijob.cce.baidubce.com/raw-request": {},
                      "f:scheduling.k8s.io/job-enable-oversell": {}
                    },
                    "f:labels": {
                      ".": {},
                      "f:aijob.cce.baidubce.com/ai-user-id": {},
                      "f:aijob.cce.baidubce.com/ai-user-name": {},
                      "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                      "f:aijob.cce.baidubce.com/openapi-jobid": {}
                    }
                  },
                  "f:spec": {
                    ".": {},
                    "f:pytorchReplicaSpecs": {
                      ".": {},
                      "f:Master": {
                        ".": {},
                        "f:replicas": {},
                        "f:restartPolicy": {},
                        "f:template": {
                          ".": {},
                          "f:metadata": {
                            ".": {},
                            "f:annotations": {
                              ".": {},
                              "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                              "f:aijob.cce.baidubce.com/openapi-jobid": {},
                              "f:aijob.cce.baidubce.com/pfs-id": {},
                              "f:aijob.cce.baidubce.com/raw-request": {},
                              "f:scheduling.k8s.io/job-enable-oversell": {}
                            },
                            "f:labels": {
                              ".": {},
                              "f:aijob.cce.baidubce.com/ai-user-id": {},
                              "f:aijob.cce.baidubce.com/ai-user-name": {},
                              "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                              "f:aijob.cce.baidubce.com/openapi-jobid": {}
                            }
                          },
                          "f:spec": {
                            ".": {},
                            "f:dnsPolicy": {},
                            "f:hostNetwork": {},
                            "f:schedulerName": {},
                            "f:volumes": {}
                          }
                        }
                      },
                      "f:Worker": {
                        ".": {},
                        "f:replicas": {},
                        "f:restartPolicy": {},
                        "f:template": {
                          ".": {},
                          "f:metadata": {
                            ".": {},
                            "f:annotations": {
                              ".": {},
                              "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                              "f:aijob.cce.baidubce.com/openapi-jobid": {},
                              "f:aijob.cce.baidubce.com/pfs-id": {},
                              "f:aijob.cce.baidubce.com/raw-request": {},
                              "f:scheduling.k8s.io/job-enable-oversell": {}
                            },
                            "f:labels": {
                              ".": {},
                              "f:aijob.cce.baidubce.com/ai-user-id": {},
                              "f:aijob.cce.baidubce.com/ai-user-name": {},
                              "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                              "f:aijob.cce.baidubce.com/openapi-jobid": {}
                            }
                          },
                          "f:spec": {
                            ".": {},
                            "f:dnsPolicy": {},
                            "f:hostNetwork": {},
                            "f:schedulerName": {},
                            "f:volumes": {}
                          }
                        }
                      }
                    },
                    "f:runPolicy": {
                      ".": {},
                      "f:schedulingPolicy": {
                        ".": {},
                        "f:priorityClass": {},
                        "f:queue": {}
                      }
                    }
                  }
                },
                "manager": "cce-ai-service",
                "operation": "Update",
                "time": "2024-07-21T14:53:43Z"
              },
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      "f:aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": {},
                      "f:aijob.cce.baidubce.com/timeline": {}
                    }
                  },
                  "f:spec": {
                    "f:pytorchReplicaSpecs": {
                      "f:Master": {
                        "f:template": {
                          "f:spec": {
                            "f:containers": {}
                          }
                        }
                      },
                      "f:Worker": {
                        "f:template": {
                          "f:spec": {
                            "f:containers": {}
                          }
                        }
                      }
                    },
                    "f:runPolicy": {
                      "f:cleanPodPolicy": {}
                    }
                  }
                },
                "manager": "controller",
                "operation": "Update",
                "time": "2024-07-21T14:53:43Z"
              },
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      "f:aijob.cce.baidubce.com/barrier-finish": {}
                    }
                  }
                },
                "manager": "jobbarrier",
                "operation": "Update",
                "time": "2024-07-21T14:53:57Z"
              },
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:status": {
                    ".": {},
                    "f:completionTime": {},
                    "f:conditions": {},
                    "f:lastReconcileTime": {},
                    "f:replicaStatuses": {
                      ".": {},
                      "f:Master": {
                        ".": {},
                        "f:selector": {},
                        "f:succeeded": {}
                      },
                      "f:Worker": {
                        ".": {},
                        "f:succeeded": {}
                      }
                    },
                    "f:startTime": {}
                  }
                },
                "manager": "manager",
                "operation": "Update",
                "time": "2024-07-21T15:00:02Z"
              }
            ],
            "name": "deepspeed-zhuxiang-1",
            "namespace": "default",
            "resourceVersion": "2375255404",
            "uid": "2e3133fc-7f1a-4457-bd90-4b791fc806f8"
          },
          "spec": {
            "pytorchReplicaSpecs": {
              "Master": {
                "replicas": 1,
                "restartPolicy": "Never",
                "template": {
                  "metadata": {
                    "annotations": {
                      "aijob.cce.baidubce.com/fault-tolerance-enabled": "false",
                      "aijob.cce.baidubce.com/openapi-jobid": "pytorch-f6085dc4-cc6e-4dc3-a524-881a8b4e172e",
                      "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
                      "aijob.cce.baidubce.com/raw-request": "{\"name\":\"deepspeed-zhuxiang-1\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"normal\",\"oversell\":false,\"faultTolerance\":false,\"command\":\" source /root/anaconda3/etc/profile.d/conda.sh\\n    conda activate llama-factory\\n\\n    ROOT_DIR=/workspace/LLaMA-Factory/\\n\\n    CHECKPOINT_LOAD_PATH=/mnt/cluster/ppl/Qwen-14B-Chat\\n    CHECKPOINT_SAVE_PATH=/mnt/cluster/ppl/Qwen-14B-Chat_saved_zhuxiang\\n    DEEPSPEED_CONFIG=$ROOT_DIR/examples/deepspeed/ds_z3_offload_config.json\\n\\n    GPUS_PER_NODE=8\\n\\n    is_master=${MASTER-\\\"0\\\"}\\n    if [[ $is_master -eq 1 ]];then\\n      DISTRIBUTED_ARGS=\\\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $HOSTNAME --master_port $MASTER_PORT\\\"\\n    else\\n      DISTRIBUTED_ARGS=\\\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $MASTER_ADDR --master_port $MASTER_PORT\\\"\\n    fi\\n\\n    QWEN_14B_ARGS=\\\"--model_name_or_path $CHECKPOINT_LOAD_PATH \\\\\\n        --stage sft \\\\\\n        --do_train \\\\\\n        --dataset alpaca_en_demo \\\\\\n        --template qwen \\\\\\n        --finetuning_type lora \\\\\\n        --lora_target all \\\\\\n        --overwrite_output_dir \\\\\\n        --dataset_dir $ROOT_DIR/data \\\\\\n        --output_dir $CHECKPOINT_SAVE_PATH \\\\\\n        --preprocessing_num_workers 90 \\\\\\n        --dataloader_num_workers 90 \\\\\\n        --per_device_train_batch_size 1 \\\\\\n        --gradient_accumulation_steps 8 \\\\\\n        --cutoff_len 2048 \\\\\\n        --max_length 2048 \\\\\\n        --deepspeed $DEEPSPEED_CONFIG \\\\\\n        --logging_first_step \\\\\\n        --logging_steps 10 \\\\\\n        --save_strategy steps \\\\\\n        --save_steps 40 \\\\\\n        --num_train_epochs 2.0 \\\\\\n        --lr_scheduler_type cosine \\\\\\n        --learning_rate 1e-5 \\\\\\n        --plot_loss \\\\\\n        --bf16 \\\\\\n        --rope_scaling linear \\\\\\n        --flash_attn auto \\\\\\n        --shift_attn \\\\\\n        --ddp_find_unused_parameters False \\\\\\n        --push_to_hub False\\\"\\n\\n    PYTHONPATH=$ROOT_DIR:$PYTHONPATH \\\\\\n        torchrun $DISTRIBUTED_ARGS \\\\\\n        $ROOT_DIR/src/train.py \\\\\\n        $QWEN_14B_ARGS\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":true,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/cce-ai-native/aiak-algo\",\"tag\":\"0.1\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"deepspeed-zhuxiang-1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"},\"Worker\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/cce-ai-native/aiak-algo\",\"tag\":\"0.1\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"deepspeed-zhuxiang-1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":false,\"logPath\":\"\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":true,\"isCopyJob\":true,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
                      "scheduling.k8s.io/job-enable-oversell": "false"
                    },
                    "labels": {
                      "aijob.cce.baidubce.com/ai-user-id": "b89c433a0e884615a4c878ca24e2686e",
                      "aijob.cce.baidubce.com/ai-user-name": "zhuxiang05",
                      "aijob.cce.baidubce.com/create-from-aihcp": "true",
                      "aijob.cce.baidubce.com/openapi-jobid": "pytorch-f6085dc4-cc6e-4dc3-a524-881a8b4e172e"
                    }
                  },
                  "spec": {
                    "containers": [
                      {
                        "command": [
                          "/bin/bash",
                          "-c",
                          " source /root/anaconda3/etc/profile.d/conda.sh\n    conda activate llama-factory\n\n    ROOT_DIR=/workspace/LLaMA-Factory/\n\n    CHECKPOINT_LOAD_PATH=/mnt/cluster/ppl/Qwen-14B-Chat\n    CHECKPOINT_SAVE_PATH=/mnt/cluster/ppl/Qwen-14B-Chat_saved_zhuxiang\n    DEEPSPEED_CONFIG=$ROOT_DIR/examples/deepspeed/ds_z3_offload_config.json\n\n    GPUS_PER_NODE=8\n\n    is_master=${MASTER-\"0\"}\n    if [[ $is_master -eq 1 ]];then\n      DISTRIBUTED_ARGS=\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $HOSTNAME --master_port $MASTER_PORT\"\n    else\n      DISTRIBUTED_ARGS=\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $MASTER_ADDR --master_port $MASTER_PORT\"\n    fi\n\n    QWEN_14B_ARGS=\"--model_name_or_path $CHECKPOINT_LOAD_PATH \\\n        --stage sft \\\n        --do_train \\\n        --dataset alpaca_en_demo \\\n        --template qwen \\\n        --finetuning_type lora \\\n        --lora_target all \\\n        --overwrite_output_dir \\\n        --dataset_dir $ROOT_DIR/data \\\n        --output_dir $CHECKPOINT_SAVE_PATH \\\n        --preprocessing_num_workers 90 \\\n        --dataloader_num_workers 90 \\\n        --per_device_train_batch_size 1 \\\n        --gradient_accumulation_steps 8 \\\n        --cutoff_len 2048 \\\n        --max_length 2048 \\\n        --deepspeed $DEEPSPEED_CONFIG \\\n        --logging_first_step \\\n        --logging_steps 10 \\\n        --save_strategy steps \\\n        --save_steps 40 \\\n        --num_train_epochs 2.0 \\\n        --lr_scheduler_type cosine \\\n        --learning_rate 1e-5 \\\n        --plot_loss \\\n        --bf16 \\\n        --rope_scaling linear \\\n        --flash_attn auto \\\n        --shift_attn \\\n        --ddp_find_unused_parameters False \\\n        --push_to_hub False\"\n\n    PYTHONPATH=$ROOT_DIR:$PYTHONPATH \\\n        torchrun $DISTRIBUTED_ARGS \\\n        $ROOT_DIR/src/train.py \\\n        $QWEN_14B_ARGS"
                        ],
                        "env": [
                          {
                            "name": "AIHC_JOB_NAME",
                            "value": "deepspeed-zhuxiang-1"
                          },
                          {
                            "name": "NCCL_IB_DISABLE",
                            "value": "0"
                          }
                        ],
                        "image": "registry.baidubce.com/cce-ai-native/aiak-algo:0.1",
                        "imagePullPolicy": "Always",
                        "name": "pytorch",
                        "ports": [
                          {
                            "containerPort": 23456,
                            "name": "pytorchjob-port",
                            "protocol": "TCP"
                          }
                        ],
                        "resources": {
                          "limits": {
                            "baidu.com/a800_80g_cgpu": "8",
                            "rdma/hca": "1"
                          },
                          "requests": {
                            "baidu.com/a800_80g_cgpu": "8",
                            "rdma/hca": "1"
                          }
                        },
                        "securityContext": {
                          "capabilities": {
                            "add": [
                              "IPC_LOCK"
                            ]
                          }
                        },
                        "volumeMounts": [
                          {
                            "mountPath": "/dev/shm",
                            "name": "devshm"
                          },
                          {
                            "mountPath": "/mnt/cluster",
                            "name": "pvc-pfs"
                          }
                        ]
                      }
                    ],
                    "dnsPolicy": "ClusterFirstWithHostNet",
                    "hostNetwork": true,
                    "schedulerName": "volcano",
                    "volumes": [
                      {
                        "emptyDir": {
                          "medium": "Memory",
                          "sizeLimit": "10Gi"
                        },
                        "name": "devshm"
                      },
                      {
                        "name": "pvc-pfs",
                        "persistentVolumeClaim": {
                          "claimName": "pvc-pfs"
                        }
                      }
                    ]
                  }
                }
              },
              "Worker": {
                "replicas": 1,
                "restartPolicy": "Never",
                "template": {
                  "metadata": {
                    "annotations": {
                      "aijob.cce.baidubce.com/fault-tolerance-enabled": "false",
                      "aijob.cce.baidubce.com/openapi-jobid": "pytorch-f6085dc4-cc6e-4dc3-a524-881a8b4e172e",
                      "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
                      "aijob.cce.baidubce.com/raw-request": "{\"name\":\"deepspeed-zhuxiang-1\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"normal\",\"oversell\":false,\"faultTolerance\":false,\"command\":\" source /root/anaconda3/etc/profile.d/conda.sh\\n    conda activate llama-factory\\n\\n    ROOT_DIR=/workspace/LLaMA-Factory/\\n\\n    CHECKPOINT_LOAD_PATH=/mnt/cluster/ppl/Qwen-14B-Chat\\n    CHECKPOINT_SAVE_PATH=/mnt/cluster/ppl/Qwen-14B-Chat_saved_zhuxiang\\n    DEEPSPEED_CONFIG=$ROOT_DIR/examples/deepspeed/ds_z3_offload_config.json\\n\\n    GPUS_PER_NODE=8\\n\\n    is_master=${MASTER-\\\"0\\\"}\\n    if [[ $is_master -eq 1 ]];then\\n      DISTRIBUTED_ARGS=\\\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $HOSTNAME --master_port $MASTER_PORT\\\"\\n    else\\n      DISTRIBUTED_ARGS=\\\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $MASTER_ADDR --master_port $MASTER_PORT\\\"\\n    fi\\n\\n    QWEN_14B_ARGS=\\\"--model_name_or_path $CHECKPOINT_LOAD_PATH \\\\\\n        --stage sft \\\\\\n        --do_train \\\\\\n        --dataset alpaca_en_demo \\\\\\n        --template qwen \\\\\\n        --finetuning_type lora \\\\\\n        --lora_target all \\\\\\n        --overwrite_output_dir \\\\\\n        --dataset_dir $ROOT_DIR/data \\\\\\n        --output_dir $CHECKPOINT_SAVE_PATH \\\\\\n        --preprocessing_num_workers 90 \\\\\\n        --dataloader_num_workers 90 \\\\\\n        --per_device_train_batch_size 1 \\\\\\n        --gradient_accumulation_steps 8 \\\\\\n        --cutoff_len 2048 \\\\\\n        --max_length 2048 \\\\\\n        --deepspeed $DEEPSPEED_CONFIG \\\\\\n        --logging_first_step \\\\\\n        --logging_steps 10 \\\\\\n        --save_strategy steps \\\\\\n        --save_steps 40 \\\\\\n        --num_train_epochs 2.0 \\\\\\n        --lr_scheduler_type cosine \\\\\\n        --learning_rate 1e-5 \\\\\\n        --plot_loss \\\\\\n        --bf16 \\\\\\n        --rope_scaling linear \\\\\\n        --flash_attn auto \\\\\\n        --shift_attn \\\\\\n        --ddp_find_unused_parameters False \\\\\\n        --push_to_hub False\\\"\\n\\n    PYTHONPATH=$ROOT_DIR:$PYTHONPATH \\\\\\n        torchrun $DISTRIBUTED_ARGS \\\\\\n        $ROOT_DIR/src/train.py \\\\\\n        $QWEN_14B_ARGS\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":true,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/cce-ai-native/aiak-algo\",\"tag\":\"0.1\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"deepspeed-zhuxiang-1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"},\"Worker\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/cce-ai-native/aiak-algo\",\"tag\":\"0.1\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"deepspeed-zhuxiang-1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":false,\"logPath\":\"\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":true,\"isCopyJob\":true,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
                      "scheduling.k8s.io/job-enable-oversell": "false"
                    },
                    "labels": {
                      "aijob.cce.baidubce.com/ai-user-id": "b89c433a0e884615a4c878ca24e2686e",
                      "aijob.cce.baidubce.com/ai-user-name": "zhuxiang05",
                      "aijob.cce.baidubce.com/create-from-aihcp": "true",
                      "aijob.cce.baidubce.com/openapi-jobid": "pytorch-f6085dc4-cc6e-4dc3-a524-881a8b4e172e"
                    }
                  },
                  "spec": {
                    "containers": [
                      {
                        "command": [
                          "/bin/bash",
                          "-c",
                          " source /root/anaconda3/etc/profile.d/conda.sh\n    conda activate llama-factory\n\n    ROOT_DIR=/workspace/LLaMA-Factory/\n\n    CHECKPOINT_LOAD_PATH=/mnt/cluster/ppl/Qwen-14B-Chat\n    CHECKPOINT_SAVE_PATH=/mnt/cluster/ppl/Qwen-14B-Chat_saved_zhuxiang\n    DEEPSPEED_CONFIG=$ROOT_DIR/examples/deepspeed/ds_z3_offload_config.json\n\n    GPUS_PER_NODE=8\n\n    is_master=${MASTER-\"0\"}\n    if [[ $is_master -eq 1 ]];then\n      DISTRIBUTED_ARGS=\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $HOSTNAME --master_port $MASTER_PORT\"\n    else\n      DISTRIBUTED_ARGS=\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $MASTER_ADDR --master_port $MASTER_PORT\"\n    fi\n\n    QWEN_14B_ARGS=\"--model_name_or_path $CHECKPOINT_LOAD_PATH \\\n        --stage sft \\\n        --do_train \\\n        --dataset alpaca_en_demo \\\n        --template qwen \\\n        --finetuning_type lora \\\n        --lora_target all \\\n        --overwrite_output_dir \\\n        --dataset_dir $ROOT_DIR/data \\\n        --output_dir $CHECKPOINT_SAVE_PATH \\\n        --preprocessing_num_workers 90 \\\n        --dataloader_num_workers 90 \\\n        --per_device_train_batch_size 1 \\\n        --gradient_accumulation_steps 8 \\\n        --cutoff_len 2048 \\\n        --max_length 2048 \\\n        --deepspeed $DEEPSPEED_CONFIG \\\n        --logging_first_step \\\n        --logging_steps 10 \\\n        --save_strategy steps \\\n        --save_steps 40 \\\n        --num_train_epochs 2.0 \\\n        --lr_scheduler_type cosine \\\n        --learning_rate 1e-5 \\\n        --plot_loss \\\n        --bf16 \\\n        --rope_scaling linear \\\n        --flash_attn auto \\\n        --shift_attn \\\n        --ddp_find_unused_parameters False \\\n        --push_to_hub False\"\n\n    PYTHONPATH=$ROOT_DIR:$PYTHONPATH \\\n        torchrun $DISTRIBUTED_ARGS \\\n        $ROOT_DIR/src/train.py \\\n        $QWEN_14B_ARGS"
                        ],
                        "env": [
                          {
                            "name": "AIHC_JOB_NAME",
                            "value": "deepspeed-zhuxiang-1"
                          },
                          {
                            "name": "NCCL_IB_DISABLE",
                            "value": "0"
                          }
                        ],
                        "image": "registry.baidubce.com/cce-ai-native/aiak-algo:0.1",
                        "imagePullPolicy": "Always",
                        "name": "pytorch",
                        "ports": [
                          {
                            "containerPort": 23456,
                            "name": "pytorchjob-port",
                            "protocol": "TCP"
                          }
                        ],
                        "resources": {
                          "limits": {
                            "baidu.com/a800_80g_cgpu": "8",
                            "rdma/hca": "1"
                          },
                          "requests": {
                            "baidu.com/a800_80g_cgpu": "8",
                            "rdma/hca": "1"
                          }
                        },
                        "securityContext": {
                          "capabilities": {
                            "add": [
                              "IPC_LOCK"
                            ]
                          }
                        },
                        "volumeMounts": [
                          {
                            "mountPath": "/dev/shm",
                            "name": "devshm"
                          },
                          {
                            "mountPath": "/mnt/cluster",
                            "name": "pvc-pfs"
                          }
                        ]
                      }
                    ],
                    "dnsPolicy": "ClusterFirstWithHostNet",
                    "hostNetwork": true,
                    "schedulerName": "volcano",
                    "volumes": [
                      {
                        "emptyDir": {
                          "medium": "Memory",
                          "sizeLimit": "10Gi"
                        },
                        "name": "devshm"
                      },
                      {
                        "name": "pvc-pfs",
                        "persistentVolumeClaim": {
                          "claimName": "pvc-pfs"
                        }
                      }
                    ]
                  }
                }
              }
            },
            "runPolicy": {
              "cleanPodPolicy": "None",
              "schedulingPolicy": {
                "priorityClass": "normal",
                "queue": "default"
              }
            }
          },
          "status": {
            "completionTime": "2024-07-21T15:00:02Z",
            "conditions": [
              {
                "lastTransitionTime": "2024-07-21T14:53:43Z",
                "lastUpdateTime": "2024-07-21T14:53:43Z",
                "message": "PyTorchJob deepspeed-zhuxiang-1 is created.",
                "reason": "PyTorchJobCreated",
                "status": "True",
                "type": "Created"
              },
              {
                "lastTransitionTime": "2024-07-21T14:54:01Z",
                "lastUpdateTime": "2024-07-21T14:54:01Z",
                "message": "PyTorchJob deepspeed-zhuxiang-1 is running.",
                "reason": "JobRunning",
                "status": "False",
                "type": "Running"
              },
              {
                "lastTransitionTime": "2024-07-21T15:00:02Z",
                "lastUpdateTime": "2024-07-21T15:00:02Z",
                "message": "PyTorchJob deepspeed-zhuxiang-1 is successfully completed.",
                "reason": "JobSucceeded",
                "status": "True",
                "type": "Succeeded"
              }
            ],
            "lastReconcileTime": "2024-07-21T14:53:43Z",
            "replicaStatuses": {
              "Master": {
                "selector": "training.kubeflow.org/job-name=deepspeed-zhuxiang-1,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=master",
                "succeeded": 1
              },
              "Worker": {
                "succeeded": 1
              }
            },
            "startTime": "2024-07-21T14:53:43Z"
          }
        },
        {
          "apiVersion": "kubeflow.org/v1",
          "kind": "PyTorchJob",
          "metadata": {
            "annotations": {
              "aijob.cce.baidubce.com/barrier-finish": "61dd5907-b076-4163-9f14-b5076bd48803",
              "aijob.cce.baidubce.com/fault-tolerance-enabled": "true",
              "aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": "",
              "aijob.cce.baidubce.com/internal-fault-tolerance-time": "2024-07-21T15:08:09.245321773Z",
              "aijob.cce.baidubce.com/openapi-jobid": "pytorch-17fe505f-168e-4c2e-951d-20c1f8792a1f",
              "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
              "aijob.cce.baidubce.com/raw-request": "{\"name\":\"deepspeed-zhuxiang-2\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"normal\",\"oversell\":false,\"faultTolerance\":true,\"command\":\" source /root/anaconda3/etc/profile.d/conda.sh\\n    conda activate llama-factory\\n\\n    ROOT_DIR=/workspace/LLaMA-Factory/\\n\\n    CHECKPOINT_LOAD_PATH=/mnt/cluster/ppl/Qwen-14B-Chat\\n    CHECKPOINT_SAVE_PATH=/mnt/cluster/ppl/Qwen-14B-Chat_saved_zhuxiang_1\\n    DEEPSPEED_CONFIG=$ROOT_DIR/examples/deepspeed/ds_z3_offload_config.json\\n\\n    GPUS_PER_NODE=8\\n\\n    is_master=${MASTER-\\\"0\\\"}\\n    if [[ $is_master -eq 1 ]];then\\n      DISTRIBUTED_ARGS=\\\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $HOSTNAME --master_port $MASTER_PORT\\\"\\n    else\\n      DISTRIBUTED_ARGS=\\\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $MASTER_ADDR --master_port $MASTER_PORT\\\"\\n    fi\\n\\n    QWEN_14B_ARGS=\\\"--model_name_or_path $CHECKPOINT_LOAD_PATH \\\\\\n        --stage sft \\\\\\n        --do_train \\\\\\n        --dataset alpaca_en_demo \\\\\\n        --template qwen \\\\\\n        --finetuning_type sft \\\\\\n        --overwrite_output_dir \\\\\\n        --dataset_dir $ROOT_DIR/data \\\\\\n        --output_dir $CHECKPOINT_SAVE_PATH \\\\\\n        --preprocessing_num_workers 90 \\\\\\n        --dataloader_num_workers 90 \\\\\\n        --per_device_train_batch_size 1 \\\\\\n        --gradient_accumulation_steps 8 \\\\\\n        --cutoff_len 2048 \\\\\\n        --max_length 2048 \\\\\\n        --deepspeed $DEEPSPEED_CONFIG \\\\\\n        --logging_first_step \\\\\\n        --logging_steps 10 \\\\\\n        --save_strategy steps \\\\\\n        --save_steps 40 \\\\\\n        --num_train_epochs 2.0 \\\\\\n        --lr_scheduler_type cosine \\\\\\n        --learning_rate 1e-5 \\\\\\n        --plot_loss \\\\\\n        --bf16 \\\\\\n        --rope_scaling linear \\\\\\n        --flash_attn auto \\\\\\n        --shift_attn \\\\\\n        --ddp_find_unused_parameters False \\\\\\n        --push_to_hub False\\\"\\n\\n    PYTHONPATH=$ROOT_DIR:$PYTHONPATH \\\\\\n        torchrun $DISTRIBUTED_ARGS \\\\\\n        $ROOT_DIR/src/train.py \\\\\\n        $QWEN_14B_ARGS\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":true,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/cce-ai-native/aiak-algo\",\"tag\":\"0.1\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"deepspeed-zhuxiang-2\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"},\"Worker\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/cce-ai-native/aiak-algo\",\"tag\":\"0.1\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"deepspeed-zhuxiang-2\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":false,\"logPath\":\"\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":true,\"isCopyJob\":true,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
              "aijob.cce.baidubce.com/timeline": "[{\"conditionType\":\"Created\",\"time\":1721574440},{\"conditionType\":\"Scheduled\",\"time\":1721574442},{\"conditionType\":\"Running\",\"time\":1721574458},{\"conditionType\":\"Abnormal\",\"time\":1721574489},{\"conditionType\":\"Failed\",\"time\":1721575092}]",
              "scheduling.k8s.io/job-enable-oversell": "false"
            },
            "creationTimestamp": "2024-07-21T15:07:20Z",
            "generation": 3,
            "labels": {
              "aijob.cce.baidubce.com/ai-user-id": "b89c433a0e884615a4c878ca24e2686e",
              "aijob.cce.baidubce.com/ai-user-name": "zhuxiang05",
              "aijob.cce.baidubce.com/create-from-aihcp": "true",
              "aijob.cce.baidubce.com/openapi-jobid": "pytorch-17fe505f-168e-4c2e-951d-20c1f8792a1f"
            },
            "managedFields": [
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      ".": {},
                      "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                      "f:aijob.cce.baidubce.com/openapi-jobid": {},
                      "f:aijob.cce.baidubce.com/pfs-id": {},
                      "f:aijob.cce.baidubce.com/raw-request": {},
                      "f:scheduling.k8s.io/job-enable-oversell": {}
                    },
                    "f:labels": {
                      ".": {},
                      "f:aijob.cce.baidubce.com/ai-user-id": {},
                      "f:aijob.cce.baidubce.com/ai-user-name": {},
                      "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                      "f:aijob.cce.baidubce.com/openapi-jobid": {}
                    }
                  },
                  "f:spec": {
                    ".": {},
                    "f:pytorchReplicaSpecs": {
                      ".": {},
                      "f:Master": {
                        ".": {},
                        "f:replicas": {},
                        "f:restartPolicy": {},
                        "f:template": {
                          ".": {},
                          "f:metadata": {
                            ".": {},
                            "f:annotations": {
                              ".": {},
                              "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                              "f:aijob.cce.baidubce.com/openapi-jobid": {},
                              "f:aijob.cce.baidubce.com/pfs-id": {},
                              "f:aijob.cce.baidubce.com/raw-request": {},
                              "f:scheduling.k8s.io/job-enable-oversell": {}
                            },
                            "f:labels": {
                              ".": {},
                              "f:aijob.cce.baidubce.com/ai-user-id": {},
                              "f:aijob.cce.baidubce.com/ai-user-name": {},
                              "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                              "f:aijob.cce.baidubce.com/openapi-jobid": {}
                            }
                          },
                          "f:spec": {
                            ".": {},
                            "f:dnsPolicy": {},
                            "f:hostNetwork": {},
                            "f:schedulerName": {}
                          }
                        }
                      },
                      "f:Worker": {
                        ".": {},
                        "f:replicas": {},
                        "f:restartPolicy": {},
                        "f:template": {
                          ".": {},
                          "f:metadata": {
                            ".": {},
                            "f:annotations": {
                              ".": {},
                              "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                              "f:aijob.cce.baidubce.com/openapi-jobid": {},
                              "f:aijob.cce.baidubce.com/pfs-id": {},
                              "f:aijob.cce.baidubce.com/raw-request": {},
                              "f:scheduling.k8s.io/job-enable-oversell": {}
                            },
                            "f:labels": {
                              ".": {},
                              "f:aijob.cce.baidubce.com/ai-user-id": {},
                              "f:aijob.cce.baidubce.com/ai-user-name": {},
                              "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                              "f:aijob.cce.baidubce.com/openapi-jobid": {}
                            }
                          },
                          "f:spec": {
                            ".": {},
                            "f:dnsPolicy": {},
                            "f:hostNetwork": {},
                            "f:schedulerName": {}
                          }
                        }
                      }
                    },
                    "f:runPolicy": {
                      ".": {},
                      "f:schedulingPolicy": {
                        ".": {},
                        "f:priorityClass": {},
                        "f:queue": {}
                      }
                    }
                  }
                },
                "manager": "cce-ai-service",
                "operation": "Update",
                "time": "2024-07-21T15:07:20Z"
              },
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      "f:aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": {},
                      "f:aijob.cce.baidubce.com/timeline": {}
                    }
                  },
                  "f:spec": {
                    "f:runPolicy": {
                      "f:cleanPodPolicy": {}
                    }
                  }
                },
                "manager": "controller",
                "operation": "Update",
                "time": "2024-07-21T15:07:20Z"
              },
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      "f:aijob.cce.baidubce.com/barrier-finish": {}
                    }
                  }
                },
                "manager": "jobbarrier",
                "operation": "Update",
                "time": "2024-07-21T15:07:35Z"
              },
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      "f:aijob.cce.baidubce.com/internal-fault-tolerance-time": {}
                    }
                  },
                  "f:spec": {
                    "f:pytorchReplicaSpecs": {
                      "f:Master": {
                        "f:template": {
                          "f:metadata": {
                            "f:annotations": {
                              "f:prometheus.io/path": {},
                              "f:prometheus.io/port": {},
                              "f:prometheus.io/scrape": {}
                            }
                          },
                          "f:spec": {
                            "f:containers": {},
                            "f:serviceAccountName": {},
                            "f:shareProcessNamespace": {},
                            "f:volumes": {}
                          }
                        }
                      },
                      "f:Worker": {
                        "f:template": {
                          "f:metadata": {
                            "f:annotations": {
                              "f:prometheus.io/path": {},
                              "f:prometheus.io/port": {},
                              "f:prometheus.io/scrape": {}
                            }
                          },
                          "f:spec": {
                            "f:containers": {},
                            "f:serviceAccountName": {},
                            "f:shareProcessNamespace": {},
                            "f:volumes": {}
                          }
                        }
                      }
                    }
                  },
                  "f:status": {
                    ".": {},
                    "f:completionTime": {},
                    "f:conditions": {},
                    "f:lastReconcileTime": {},
                    "f:replicaStatuses": {
                      ".": {},
                      "f:Master": {
                        ".": {},
                        "f:failed": {},
                        "f:selector": {}
                      },
                      "f:Worker": {
                        ".": {},
                        "f:failed": {}
                      }
                    },
                    "f:startTime": {}
                  }
                },
                "manager": "manager",
                "operation": "Update",
                "time": "2024-07-21T15:18:12Z"
              }
            ],
            "name": "deepspeed-zhuxiang-2",
            "namespace": "default",
            "resourceVersion": "2375269930",
            "uid": "cf938174-8fcc-4c7f-a7ef-8418b2d7f967"
          },
          "spec": {
            "pytorchReplicaSpecs": {
              "Master": {
                "replicas": 1,
                "restartPolicy": "Never",
                "template": {
                  "metadata": {
                    "annotations": {
                      "aijob.cce.baidubce.com/fault-tolerance-enabled": "true",
                      "aijob.cce.baidubce.com/openapi-jobid": "pytorch-17fe505f-168e-4c2e-951d-20c1f8792a1f",
                      "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
                      "aijob.cce.baidubce.com/raw-request": "{\"name\":\"deepspeed-zhuxiang-2\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"normal\",\"oversell\":false,\"faultTolerance\":true,\"command\":\" source /root/anaconda3/etc/profile.d/conda.sh\\n    conda activate llama-factory\\n\\n    ROOT_DIR=/workspace/LLaMA-Factory/\\n\\n    CHECKPOINT_LOAD_PATH=/mnt/cluster/ppl/Qwen-14B-Chat\\n    CHECKPOINT_SAVE_PATH=/mnt/cluster/ppl/Qwen-14B-Chat_saved_zhuxiang_1\\n    DEEPSPEED_CONFIG=$ROOT_DIR/examples/deepspeed/ds_z3_offload_config.json\\n\\n    GPUS_PER_NODE=8\\n\\n    is_master=${MASTER-\\\"0\\\"}\\n    if [[ $is_master -eq 1 ]];then\\n      DISTRIBUTED_ARGS=\\\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $HOSTNAME --master_port $MASTER_PORT\\\"\\n    else\\n      DISTRIBUTED_ARGS=\\\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $MASTER_ADDR --master_port $MASTER_PORT\\\"\\n    fi\\n\\n    QWEN_14B_ARGS=\\\"--model_name_or_path $CHECKPOINT_LOAD_PATH \\\\\\n        --stage sft \\\\\\n        --do_train \\\\\\n        --dataset alpaca_en_demo \\\\\\n        --template qwen \\\\\\n        --finetuning_type sft \\\\\\n        --overwrite_output_dir \\\\\\n        --dataset_dir $ROOT_DIR/data \\\\\\n        --output_dir $CHECKPOINT_SAVE_PATH \\\\\\n        --preprocessing_num_workers 90 \\\\\\n        --dataloader_num_workers 90 \\\\\\n        --per_device_train_batch_size 1 \\\\\\n        --gradient_accumulation_steps 8 \\\\\\n        --cutoff_len 2048 \\\\\\n        --max_length 2048 \\\\\\n        --deepspeed $DEEPSPEED_CONFIG \\\\\\n        --logging_first_step \\\\\\n        --logging_steps 10 \\\\\\n        --save_strategy steps \\\\\\n        --save_steps 40 \\\\\\n        --num_train_epochs 2.0 \\\\\\n        --lr_scheduler_type cosine \\\\\\n        --learning_rate 1e-5 \\\\\\n        --plot_loss \\\\\\n        --bf16 \\\\\\n        --rope_scaling linear \\\\\\n        --flash_attn auto \\\\\\n        --shift_attn \\\\\\n        --ddp_find_unused_parameters False \\\\\\n        --push_to_hub False\\\"\\n\\n    PYTHONPATH=$ROOT_DIR:$PYTHONPATH \\\\\\n        torchrun $DISTRIBUTED_ARGS \\\\\\n        $ROOT_DIR/src/train.py \\\\\\n        $QWEN_14B_ARGS\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":true,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/cce-ai-native/aiak-algo\",\"tag\":\"0.1\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"deepspeed-zhuxiang-2\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"},\"Worker\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/cce-ai-native/aiak-algo\",\"tag\":\"0.1\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"deepspeed-zhuxiang-2\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":false,\"logPath\":\"\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":true,\"isCopyJob\":true,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
                      "prometheus.io/path": "/metrics",
                      "prometheus.io/port": "9101",
                      "prometheus.io/scrape": "true",
                      "scheduling.k8s.io/job-enable-oversell": "false"
                    },
                    "labels": {
                      "aijob.cce.baidubce.com/ai-user-id": "b89c433a0e884615a4c878ca24e2686e",
                      "aijob.cce.baidubce.com/ai-user-name": "zhuxiang05",
                      "aijob.cce.baidubce.com/create-from-aihcp": "true",
                      "aijob.cce.baidubce.com/openapi-jobid": "pytorch-17fe505f-168e-4c2e-951d-20c1f8792a1f"
                    }
                  },
                  "spec": {
                    "containers": [
                      {
                        "command": [
                          "/bin/bash",
                          "-c",
                          " source /root/anaconda3/etc/profile.d/conda.sh\n    conda activate llama-factory\n\n    ROOT_DIR=/workspace/LLaMA-Factory/\n\n    CHECKPOINT_LOAD_PATH=/mnt/cluster/ppl/Qwen-14B-Chat\n    CHECKPOINT_SAVE_PATH=/mnt/cluster/ppl/Qwen-14B-Chat_saved_zhuxiang_1\n    DEEPSPEED_CONFIG=$ROOT_DIR/examples/deepspeed/ds_z3_offload_config.json\n\n    GPUS_PER_NODE=8\n\n    is_master=${MASTER-\"0\"}\n    if [[ $is_master -eq 1 ]];then\n      DISTRIBUTED_ARGS=\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $HOSTNAME --master_port $MASTER_PORT\"\n    else\n      DISTRIBUTED_ARGS=\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $MASTER_ADDR --master_port $MASTER_PORT\"\n    fi\n\n    QWEN_14B_ARGS=\"--model_name_or_path $CHECKPOINT_LOAD_PATH \\\n        --stage sft \\\n        --do_train \\\n        --dataset alpaca_en_demo \\\n        --template qwen \\\n        --finetuning_type sft \\\n        --overwrite_output_dir \\\n        --dataset_dir $ROOT_DIR/data \\\n        --output_dir $CHECKPOINT_SAVE_PATH \\\n        --preprocessing_num_workers 90 \\\n        --dataloader_num_workers 90 \\\n        --per_device_train_batch_size 1 \\\n        --gradient_accumulation_steps 8 \\\n        --cutoff_len 2048 \\\n        --max_length 2048 \\\n        --deepspeed $DEEPSPEED_CONFIG \\\n        --logging_first_step \\\n        --logging_steps 10 \\\n        --save_strategy steps \\\n        --save_steps 40 \\\n        --num_train_epochs 2.0 \\\n        --lr_scheduler_type cosine \\\n        --learning_rate 1e-5 \\\n        --plot_loss \\\n        --bf16 \\\n        --rope_scaling linear \\\n        --flash_attn auto \\\n        --shift_attn \\\n        --ddp_find_unused_parameters False \\\n        --push_to_hub False\"\n\n    PYTHONPATH=$ROOT_DIR:$PYTHONPATH \\\n        torchrun $DISTRIBUTED_ARGS \\\n        $ROOT_DIR/src/train.py \\\n        $QWEN_14B_ARGS"
                        ],
                        "env": [
                          {
                            "name": "AIHC_JOB_NAME",
                            "value": "deepspeed-zhuxiang-2"
                          },
                          {
                            "name": "NCCL_IB_DISABLE",
                            "value": "0"
                          },
                          {
                            "name": "BCCL_BUS_BW_CALCULATE_MODE",
                            "value": "Agg"
                          },
                          {
                            "name": "BCCL_PROFILING_FILE",
                            "value": "/var/bccl/logs/busbw.cal.%h.%p"
                          }
                        ],
                        "image": "registry.baidubce.com/cce-ai-native/aiak-algo:0.1",
                        "imagePullPolicy": "Always",
                        "name": "pytorch",
                        "ports": [
                          {
                            "containerPort": 23456,
                            "name": "pytorchjob-port",
                            "protocol": "TCP"
                          }
                        ],
                        "resources": {
                          "limits": {
                            "baidu.com/a800_80g_cgpu": "8",
                            "rdma/hca": "1"
                          },
                          "requests": {
                            "baidu.com/a800_80g_cgpu": "8",
                            "rdma/hca": "1"
                          }
                        },
                        "securityContext": {
                          "capabilities": {
                            "add": [
                              "IPC_LOCK"
                            ]
                          }
                        },
                        "volumeMounts": [
                          {
                            "mountPath": "/dev/shm",
                            "name": "devshm"
                          },
                          {
                            "mountPath": "/mnt/cluster",
                            "name": "pvc-pfs"
                          },
                          {
                            "mountPath": "/var/bccl/logs",
                            "name": "bccl-logs-volume"
                          }
                        ]
                      },
                      {
                        "env": [
                          {
                            "name": "POD_NAME",
                            "valueFrom": {
                              "fieldRef": {
                                "apiVersion": "v1",
                                "fieldPath": "metadata.name"
                              }
                            }
                          },
                          {
                            "name": "POD_UID",
                            "valueFrom": {
                              "fieldRef": {
                                "apiVersion": "v1",
                                "fieldPath": "metadata.uid"
                              }
                            }
                          },
                          {
                            "name": "POD_NAMESPACE",
                            "valueFrom": {
                              "fieldRef": {
                                "apiVersion": "v1",
                                "fieldPath": "metadata.namespace"
                              }
                            }
                          },
                          {
                            "name": "NODE_NAME",
                            "valueFrom": {
                              "fieldRef": {
                                "apiVersion": "v1",
                                "fieldPath": "spec.nodeName"
                              }
                            }
                          },
                          {
                            "name": "JOB_NAME",
                            "value": "deepspeed-zhuxiang-2"
                          },
                          {
                            "name": "NODE_IP",
                            "valueFrom": {
                              "fieldRef": {
                                "apiVersion": "v1",
                                "fieldPath": "status.hostIP"
                              }
                            }
                          },
                          {
                            "name": "GPUS_PER_NODE",
                            "value": "8"
                          },
                          {
                            "name": "ENABLE_ELASTIC",
                            "value": "9"
                          },
                          {
                            "name": "BCCL_LOG_DIR",
                            "value": "/var/bccl/logs"
                          },
                          {
                            "name": "EXPORTER_PORT",
                            "value": "9101"
                          },
                          {
                            "name": "EXPORTER_INTERVAL",
                            "value": "60"
                          },
                          {
                            "name": "EXPORTER_PATH",
                            "value": "/metrics"
                          },
                          {
                            "name": "BCCL_BUS_BW_CALCULATE_MODE",
                            "value": "Agg"
                          },
                          {
                            "name": "BCCL_PROFILING_FILE",
                            "value": "/var/bccl/logs/busbw.cal.%h.%p"
                          }
                        ],
                        "image": "registry.baidubce.com/cce-plugin-dev/ftagent:v1.6.21",
                        "imagePullPolicy": "Always",
                        "name": "ftagent",
                        "ports": [
                          {
                            "containerPort": 9101,
                            "name": "exporter",
                            "protocol": "TCP"
                          }
                        ],
                        "resources": {},
                        "securityContext": {
                          "capabilities": {
                            "add": [
                              "IPC_LOCK"
                            ]
                          }
                        },
                        "volumeMounts": [
                          {
                            "mountPath": "/var/log/pods",
                            "name": "pod-log-volume"
                          },
                          {
                            "mountPath": "/home/cce",
                            "name": "container-log-volume"
                          },
                          {
                            "mountPath": "/var/bccl/logs",
                            "name": "bccl-logs-volume"
                          }
                        ]
                      }
                    ],
                    "dnsPolicy": "ClusterFirstWithHostNet",
                    "hostNetwork": true,
                    "schedulerName": "volcano",
                    "serviceAccountName": "ftagent-sa",
                    "shareProcessNamespace": true,
                    "volumes": [
                      {
                        "emptyDir": {
                          "medium": "Memory",
                          "sizeLimit": "10Gi"
                        },
                        "name": "devshm"
                      },
                      {
                        "name": "pvc-pfs",
                        "persistentVolumeClaim": {
                          "claimName": "pvc-pfs"
                        }
                      },
                      {
                        "emptyDir": {},
                        "name": "bccl-logs-volume"
                      },
                      {
                        "hostPath": {
                          "path": "/var/log/pods",
                          "type": "DirectoryOrCreate"
                        },
                        "name": "pod-log-volume"
                      },
                      {
                        "hostPath": {
                          "path": "/home/cce",
                          "type": "DirectoryOrCreate"
                        },
                        "name": "container-log-volume"
                      }
                    ]
                  }
                }
              },
              "Worker": {
                "replicas": 1,
                "restartPolicy": "Never",
                "template": {
                  "metadata": {
                    "annotations": {
                      "aijob.cce.baidubce.com/fault-tolerance-enabled": "true",
                      "aijob.cce.baidubce.com/openapi-jobid": "pytorch-17fe505f-168e-4c2e-951d-20c1f8792a1f",
                      "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
                      "aijob.cce.baidubce.com/raw-request": "{\"name\":\"deepspeed-zhuxiang-2\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"normal\",\"oversell\":false,\"faultTolerance\":true,\"command\":\" source /root/anaconda3/etc/profile.d/conda.sh\\n    conda activate llama-factory\\n\\n    ROOT_DIR=/workspace/LLaMA-Factory/\\n\\n    CHECKPOINT_LOAD_PATH=/mnt/cluster/ppl/Qwen-14B-Chat\\n    CHECKPOINT_SAVE_PATH=/mnt/cluster/ppl/Qwen-14B-Chat_saved_zhuxiang_1\\n    DEEPSPEED_CONFIG=$ROOT_DIR/examples/deepspeed/ds_z3_offload_config.json\\n\\n    GPUS_PER_NODE=8\\n\\n    is_master=${MASTER-\\\"0\\\"}\\n    if [[ $is_master -eq 1 ]];then\\n      DISTRIBUTED_ARGS=\\\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $HOSTNAME --master_port $MASTER_PORT\\\"\\n    else\\n      DISTRIBUTED_ARGS=\\\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $MASTER_ADDR --master_port $MASTER_PORT\\\"\\n    fi\\n\\n    QWEN_14B_ARGS=\\\"--model_name_or_path $CHECKPOINT_LOAD_PATH \\\\\\n        --stage sft \\\\\\n        --do_train \\\\\\n        --dataset alpaca_en_demo \\\\\\n        --template qwen \\\\\\n        --finetuning_type sft \\\\\\n        --overwrite_output_dir \\\\\\n        --dataset_dir $ROOT_DIR/data \\\\\\n        --output_dir $CHECKPOINT_SAVE_PATH \\\\\\n        --preprocessing_num_workers 90 \\\\\\n        --dataloader_num_workers 90 \\\\\\n        --per_device_train_batch_size 1 \\\\\\n        --gradient_accumulation_steps 8 \\\\\\n        --cutoff_len 2048 \\\\\\n        --max_length 2048 \\\\\\n        --deepspeed $DEEPSPEED_CONFIG \\\\\\n        --logging_first_step \\\\\\n        --logging_steps 10 \\\\\\n        --save_strategy steps \\\\\\n        --save_steps 40 \\\\\\n        --num_train_epochs 2.0 \\\\\\n        --lr_scheduler_type cosine \\\\\\n        --learning_rate 1e-5 \\\\\\n        --plot_loss \\\\\\n        --bf16 \\\\\\n        --rope_scaling linear \\\\\\n        --flash_attn auto \\\\\\n        --shift_attn \\\\\\n        --ddp_find_unused_parameters False \\\\\\n        --push_to_hub False\\\"\\n\\n    PYTHONPATH=$ROOT_DIR:$PYTHONPATH \\\\\\n        torchrun $DISTRIBUTED_ARGS \\\\\\n        $ROOT_DIR/src/train.py \\\\\\n        $QWEN_14B_ARGS\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":true,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/cce-ai-native/aiak-algo\",\"tag\":\"0.1\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"deepspeed-zhuxiang-2\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"},\"Worker\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/cce-ai-native/aiak-algo\",\"tag\":\"0.1\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"deepspeed-zhuxiang-2\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":false,\"logPath\":\"\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":true,\"isCopyJob\":true,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
                      "prometheus.io/path": "/metrics",
                      "prometheus.io/port": "9101",
                      "prometheus.io/scrape": "true",
                      "scheduling.k8s.io/job-enable-oversell": "false"
                    },
                    "labels": {
                      "aijob.cce.baidubce.com/ai-user-id": "b89c433a0e884615a4c878ca24e2686e",
                      "aijob.cce.baidubce.com/ai-user-name": "zhuxiang05",
                      "aijob.cce.baidubce.com/create-from-aihcp": "true",
                      "aijob.cce.baidubce.com/openapi-jobid": "pytorch-17fe505f-168e-4c2e-951d-20c1f8792a1f"
                    }
                  },
                  "spec": {
                    "containers": [
                      {
                        "command": [
                          "/bin/bash",
                          "-c",
                          " source /root/anaconda3/etc/profile.d/conda.sh\n    conda activate llama-factory\n\n    ROOT_DIR=/workspace/LLaMA-Factory/\n\n    CHECKPOINT_LOAD_PATH=/mnt/cluster/ppl/Qwen-14B-Chat\n    CHECKPOINT_SAVE_PATH=/mnt/cluster/ppl/Qwen-14B-Chat_saved_zhuxiang_1\n    DEEPSPEED_CONFIG=$ROOT_DIR/examples/deepspeed/ds_z3_offload_config.json\n\n    GPUS_PER_NODE=8\n\n    is_master=${MASTER-\"0\"}\n    if [[ $is_master -eq 1 ]];then\n      DISTRIBUTED_ARGS=\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $HOSTNAME --master_port $MASTER_PORT\"\n    else\n      DISTRIBUTED_ARGS=\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $MASTER_ADDR --master_port $MASTER_PORT\"\n    fi\n\n    QWEN_14B_ARGS=\"--model_name_or_path $CHECKPOINT_LOAD_PATH \\\n        --stage sft \\\n        --do_train \\\n        --dataset alpaca_en_demo \\\n        --template qwen \\\n        --finetuning_type sft \\\n        --overwrite_output_dir \\\n        --dataset_dir $ROOT_DIR/data \\\n        --output_dir $CHECKPOINT_SAVE_PATH \\\n        --preprocessing_num_workers 90 \\\n        --dataloader_num_workers 90 \\\n        --per_device_train_batch_size 1 \\\n        --gradient_accumulation_steps 8 \\\n        --cutoff_len 2048 \\\n        --max_length 2048 \\\n        --deepspeed $DEEPSPEED_CONFIG \\\n        --logging_first_step \\\n        --logging_steps 10 \\\n        --save_strategy steps \\\n        --save_steps 40 \\\n        --num_train_epochs 2.0 \\\n        --lr_scheduler_type cosine \\\n        --learning_rate 1e-5 \\\n        --plot_loss \\\n        --bf16 \\\n        --rope_scaling linear \\\n        --flash_attn auto \\\n        --shift_attn \\\n        --ddp_find_unused_parameters False \\\n        --push_to_hub False\"\n\n    PYTHONPATH=$ROOT_DIR:$PYTHONPATH \\\n        torchrun $DISTRIBUTED_ARGS \\\n        $ROOT_DIR/src/train.py \\\n        $QWEN_14B_ARGS"
                        ],
                        "env": [
                          {
                            "name": "AIHC_JOB_NAME",
                            "value": "deepspeed-zhuxiang-2"
                          },
                          {
                            "name": "NCCL_IB_DISABLE",
                            "value": "0"
                          },
                          {
                            "name": "BCCL_BUS_BW_CALCULATE_MODE",
                            "value": "Agg"
                          },
                          {
                            "name": "BCCL_PROFILING_FILE",
                            "value": "/var/bccl/logs/busbw.cal.%h.%p"
                          }
                        ],
                        "image": "registry.baidubce.com/cce-ai-native/aiak-algo:0.1",
                        "imagePullPolicy": "Always",
                        "name": "pytorch",
                        "ports": [
                          {
                            "containerPort": 23456,
                            "name": "pytorchjob-port",
                            "protocol": "TCP"
                          }
                        ],
                        "resources": {
                          "limits": {
                            "baidu.com/a800_80g_cgpu": "8",
                            "rdma/hca": "1"
                          },
                          "requests": {
                            "baidu.com/a800_80g_cgpu": "8",
                            "rdma/hca": "1"
                          }
                        },
                        "securityContext": {
                          "capabilities": {
                            "add": [
                              "IPC_LOCK"
                            ]
                          }
                        },
                        "volumeMounts": [
                          {
                            "mountPath": "/dev/shm",
                            "name": "devshm"
                          },
                          {
                            "mountPath": "/mnt/cluster",
                            "name": "pvc-pfs"
                          },
                          {
                            "mountPath": "/var/bccl/logs",
                            "name": "bccl-logs-volume"
                          }
                        ]
                      },
                      {
                        "env": [
                          {
                            "name": "POD_NAME",
                            "valueFrom": {
                              "fieldRef": {
                                "apiVersion": "v1",
                                "fieldPath": "metadata.name"
                              }
                            }
                          },
                          {
                            "name": "POD_UID",
                            "valueFrom": {
                              "fieldRef": {
                                "apiVersion": "v1",
                                "fieldPath": "metadata.uid"
                              }
                            }
                          },
                          {
                            "name": "POD_NAMESPACE",
                            "valueFrom": {
                              "fieldRef": {
                                "apiVersion": "v1",
                                "fieldPath": "metadata.namespace"
                              }
                            }
                          },
                          {
                            "name": "NODE_NAME",
                            "valueFrom": {
                              "fieldRef": {
                                "apiVersion": "v1",
                                "fieldPath": "spec.nodeName"
                              }
                            }
                          },
                          {
                            "name": "JOB_NAME",
                            "value": "deepspeed-zhuxiang-2"
                          },
                          {
                            "name": "NODE_IP",
                            "valueFrom": {
                              "fieldRef": {
                                "apiVersion": "v1",
                                "fieldPath": "status.hostIP"
                              }
                            }
                          },
                          {
                            "name": "GPUS_PER_NODE",
                            "value": "8"
                          },
                          {
                            "name": "ENABLE_ELASTIC",
                            "value": "9"
                          },
                          {
                            "name": "BCCL_LOG_DIR",
                            "value": "/var/bccl/logs"
                          },
                          {
                            "name": "EXPORTER_PORT",
                            "value": "9101"
                          },
                          {
                            "name": "EXPORTER_INTERVAL",
                            "value": "60"
                          },
                          {
                            "name": "EXPORTER_PATH",
                            "value": "/metrics"
                          },
                          {
                            "name": "BCCL_BUS_BW_CALCULATE_MODE",
                            "value": "Agg"
                          },
                          {
                            "name": "BCCL_PROFILING_FILE",
                            "value": "/var/bccl/logs/busbw.cal.%h.%p"
                          }
                        ],
                        "image": "registry.baidubce.com/cce-plugin-dev/ftagent:v1.6.21",
                        "imagePullPolicy": "Always",
                        "name": "ftagent",
                        "ports": [
                          {
                            "containerPort": 9101,
                            "name": "exporter",
                            "protocol": "TCP"
                          }
                        ],
                        "resources": {},
                        "securityContext": {
                          "capabilities": {
                            "add": [
                              "IPC_LOCK"
                            ]
                          }
                        },
                        "volumeMounts": [
                          {
                            "mountPath": "/var/log/pods",
                            "name": "pod-log-volume"
                          },
                          {
                            "mountPath": "/home/cce",
                            "name": "container-log-volume"
                          },
                          {
                            "mountPath": "/var/bccl/logs",
                            "name": "bccl-logs-volume"
                          }
                        ]
                      }
                    ],
                    "dnsPolicy": "ClusterFirstWithHostNet",
                    "hostNetwork": true,
                    "schedulerName": "volcano",
                    "serviceAccountName": "ftagent-sa",
                    "shareProcessNamespace": true,
                    "volumes": [
                      {
                        "emptyDir": {
                          "medium": "Memory",
                          "sizeLimit": "10Gi"
                        },
                        "name": "devshm"
                      },
                      {
                        "name": "pvc-pfs",
                        "persistentVolumeClaim": {
                          "claimName": "pvc-pfs"
                        }
                      },
                      {
                        "emptyDir": {},
                        "name": "bccl-logs-volume"
                      },
                      {
                        "hostPath": {
                          "path": "/var/log/pods",
                          "type": "DirectoryOrCreate"
                        },
                        "name": "pod-log-volume"
                      },
                      {
                        "hostPath": {
                          "path": "/home/cce",
                          "type": "DirectoryOrCreate"
                        },
                        "name": "container-log-volume"
                      }
                    ]
                  }
                }
              }
            },
            "runPolicy": {
              "cleanPodPolicy": "None",
              "schedulingPolicy": {
                "priorityClass": "normal",
                "queue": "default"
              }
            }
          },
          "status": {
            "completionTime": "2024-07-21T15:18:12Z",
            "conditions": [
              {
                "lastTransitionTime": "2024-07-21T15:07:20Z",
                "lastUpdateTime": "2024-07-21T15:07:20Z",
                "message": "PyTorchJob deepspeed-zhuxiang-2 is created.",
                "reason": "PyTorchJobCreated",
                "status": "True",
                "type": "Created"
              },
              {
                "lastTransitionTime": "2024-07-21T15:07:38Z",
                "lastUpdateTime": "2024-07-21T15:07:38Z",
                "message": "PyTorchJob deepspeed-zhuxiang-2 is running.",
                "reason": "JobRunning",
                "status": "False",
                "type": "Running"
              },
              {
                "lastTransitionTime": "2024-07-21T15:18:12Z",
                "lastUpdateTime": "2024-07-21T15:18:12Z",
                "message": "PyTorchJob deepspeed-zhuxiang-2 is failed because 1 Master replica(s) failed.",
                "reason": "JobFailed",
                "status": "True",
                "type": "Failed"
              }
            ],
            "lastReconcileTime": "2024-07-21T15:07:20Z",
            "replicaStatuses": {
              "Master": {
                "failed": 1,
                "selector": "training.kubeflow.org/job-name=deepspeed-zhuxiang-2,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=master"
              },
              "Worker": {
                "failed": 1,
                "selector": "training.kubeflow.org/job-name=deepspeed-zhuxiang-2,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=worker"
              }
            },
            "startTime": "2024-07-21T15:07:21Z"
          }
        },
        {
          "apiVersion": "kubeflow.org/v1",
          "kind": "PyTorchJob",
          "metadata": {
            "annotations": {
              "aijob.cce.baidubce.com/barrier-finish": "f8bf1e5e-2085-4f24-b6fb-75de43615847",
              "aijob.cce.baidubce.com/fault-tolerance-enabled": "true",
              "aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": "",
              "aijob.cce.baidubce.com/openapi-jobid": "pytorch-78c57221-992e-4086-b890-2e9956d4dd8f",
              "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
              "aijob.cce.baidubce.com/raw-request": "{\"name\":\"deepspeed-zhuxiang-3\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"normal\",\"oversell\":false,\"faultTolerance\":true,\"command\":\" source /root/anaconda3/etc/profile.d/conda.sh\\n    conda activate llama-factory\\n\\n    ROOT_DIR=/workspace/LLaMA-Factory/\\n\\n    CHECKPOINT_LOAD_PATH=/mnt/cluster/ppl/Qwen-14B-Chat\\n    CHECKPOINT_SAVE_PATH=/mnt/cluster/ppl/Qwen-14B-Chat_saved_zhuxiang_2\\n    DEEPSPEED_CONFIG=$ROOT_DIR/examples/deepspeed/ds_z3_offload_config.json\\n\\n    GPUS_PER_NODE=8\\n\\n    is_master=${MASTER-\\\"0\\\"}\\n    if [[ $is_master -eq 1 ]];then\\n      DISTRIBUTED_ARGS=\\\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $HOSTNAME --master_port $MASTER_PORT\\\"\\n    else\\n      DISTRIBUTED_ARGS=\\\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $MASTER_ADDR --master_port $MASTER_PORT\\\"\\n    fi\\n\\n    QWEN_14B_ARGS=\\\"--model_name_or_path $CHECKPOINT_LOAD_PATH \\\\\\n        --stage sft \\\\\\n        --do_train \\\\\\n        --dataset alpaca_en_demo \\\\\\n        --template qwen \\\\\\n        --finetuning_type full \\\\\\n        --overwrite_output_dir \\\\\\n        --dataset_dir $ROOT_DIR/data \\\\\\n        --output_dir $CHECKPOINT_SAVE_PATH \\\\\\n        --preprocessing_num_workers 90 \\\\\\n        --dataloader_num_workers 90 \\\\\\n        --per_device_train_batch_size 1 \\\\\\n        --gradient_accumulation_steps 8 \\\\\\n        --cutoff_len 2048 \\\\\\n        --max_length 2048 \\\\\\n        --deepspeed $DEEPSPEED_CONFIG \\\\\\n        --logging_first_step \\\\\\n        --logging_steps 10 \\\\\\n        --save_strategy steps \\\\\\n        --save_steps 40 \\\\\\n        --num_train_epochs 2.0 \\\\\\n        --lr_scheduler_type cosine \\\\\\n        --learning_rate 1e-5 \\\\\\n        --plot_loss \\\\\\n        --bf16 \\\\\\n        --rope_scaling linear \\\\\\n        --flash_attn auto \\\\\\n        --shift_attn \\\\\\n        --ddp_find_unused_parameters False \\\\\\n        --push_to_hub False\\\"\\n\\n    PYTHONPATH=$ROOT_DIR:$PYTHONPATH \\\\\\n        torchrun $DISTRIBUTED_ARGS \\\\\\n        $ROOT_DIR/src/train.py \\\\\\n        $QWEN_14B_ARGS\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":true,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/cce-ai-native/aiak-algo\",\"tag\":\"0.1\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"deepspeed-zhuxiang-3\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"},\"Worker\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/cce-ai-native/aiak-algo\",\"tag\":\"0.1\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"deepspeed-zhuxiang-3\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":false,\"logPath\":\"\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":true,\"isCopyJob\":true,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
              "aijob.cce.baidubce.com/timeline": "[{\"conditionType\":\"Created\",\"time\":1721574643},{\"conditionType\":\"Scheduled\",\"time\":1721574645},{\"conditionType\":\"Running\",\"time\":1721574661},{\"conditionType\":\"Succeeded\",\"time\":1721575112}]",
              "scheduling.k8s.io/job-enable-oversell": "false"
            },
            "creationTimestamp": "2024-07-21T15:10:43Z",
            "generation": 2,
            "labels": {
              "aijob.cce.baidubce.com/ai-user-id": "b89c433a0e884615a4c878ca24e2686e",
              "aijob.cce.baidubce.com/ai-user-name": "zhuxiang05",
              "aijob.cce.baidubce.com/create-from-aihcp": "true",
              "aijob.cce.baidubce.com/openapi-jobid": "pytorch-78c57221-992e-4086-b890-2e9956d4dd8f"
            },
            "managedFields": [
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      ".": {},
                      "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                      "f:aijob.cce.baidubce.com/openapi-jobid": {},
                      "f:aijob.cce.baidubce.com/pfs-id": {},
                      "f:aijob.cce.baidubce.com/raw-request": {},
                      "f:scheduling.k8s.io/job-enable-oversell": {}
                    },
                    "f:labels": {
                      ".": {},
                      "f:aijob.cce.baidubce.com/ai-user-id": {},
                      "f:aijob.cce.baidubce.com/ai-user-name": {},
                      "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                      "f:aijob.cce.baidubce.com/openapi-jobid": {}
                    }
                  },
                  "f:spec": {
                    ".": {},
                    "f:pytorchReplicaSpecs": {
                      ".": {},
                      "f:Master": {
                        ".": {},
                        "f:replicas": {},
                        "f:restartPolicy": {},
                        "f:template": {
                          ".": {},
                          "f:metadata": {
                            ".": {},
                            "f:annotations": {
                              ".": {},
                              "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                              "f:aijob.cce.baidubce.com/openapi-jobid": {},
                              "f:aijob.cce.baidubce.com/pfs-id": {},
                              "f:aijob.cce.baidubce.com/raw-request": {},
                              "f:scheduling.k8s.io/job-enable-oversell": {}
                            },
                            "f:labels": {
                              ".": {},
                              "f:aijob.cce.baidubce.com/ai-user-id": {},
                              "f:aijob.cce.baidubce.com/ai-user-name": {},
                              "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                              "f:aijob.cce.baidubce.com/openapi-jobid": {}
                            }
                          },
                          "f:spec": {
                            ".": {},
                            "f:dnsPolicy": {},
                            "f:hostNetwork": {},
                            "f:schedulerName": {},
                            "f:volumes": {}
                          }
                        }
                      },
                      "f:Worker": {
                        ".": {},
                        "f:replicas": {},
                        "f:restartPolicy": {},
                        "f:template": {
                          ".": {},
                          "f:metadata": {
                            ".": {},
                            "f:annotations": {
                              ".": {},
                              "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                              "f:aijob.cce.baidubce.com/openapi-jobid": {},
                              "f:aijob.cce.baidubce.com/pfs-id": {},
                              "f:aijob.cce.baidubce.com/raw-request": {},
                              "f:scheduling.k8s.io/job-enable-oversell": {}
                            },
                            "f:labels": {
                              ".": {},
                              "f:aijob.cce.baidubce.com/ai-user-id": {},
                              "f:aijob.cce.baidubce.com/ai-user-name": {},
                              "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                              "f:aijob.cce.baidubce.com/openapi-jobid": {}
                            }
                          },
                          "f:spec": {
                            ".": {},
                            "f:dnsPolicy": {},
                            "f:hostNetwork": {},
                            "f:schedulerName": {},
                            "f:volumes": {}
                          }
                        }
                      }
                    },
                    "f:runPolicy": {
                      ".": {},
                      "f:schedulingPolicy": {
                        ".": {},
                        "f:priorityClass": {},
                        "f:queue": {}
                      }
                    }
                  }
                },
                "manager": "cce-ai-service",
                "operation": "Update",
                "time": "2024-07-21T15:10:43Z"
              },
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      "f:aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": {},
                      "f:aijob.cce.baidubce.com/timeline": {}
                    }
                  },
                  "f:spec": {
                    "f:pytorchReplicaSpecs": {
                      "f:Master": {
                        "f:template": {
                          "f:spec": {
                            "f:containers": {}
                          }
                        }
                      },
                      "f:Worker": {
                        "f:template": {
                          "f:spec": {
                            "f:containers": {}
                          }
                        }
                      }
                    },
                    "f:runPolicy": {
                      "f:cleanPodPolicy": {}
                    }
                  }
                },
                "manager": "controller",
                "operation": "Update",
                "time": "2024-07-21T15:10:43Z"
              },
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      "f:aijob.cce.baidubce.com/barrier-finish": {}
                    }
                  }
                },
                "manager": "jobbarrier",
                "operation": "Update",
                "time": "2024-07-21T15:10:58Z"
              },
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:status": {
                    ".": {},
                    "f:completionTime": {},
                    "f:conditions": {},
                    "f:lastReconcileTime": {},
                    "f:replicaStatuses": {
                      ".": {},
                      "f:Master": {
                        ".": {},
                        "f:selector": {},
                        "f:succeeded": {}
                      },
                      "f:Worker": {
                        ".": {},
                        "f:succeeded": {}
                      }
                    },
                    "f:startTime": {}
                  }
                },
                "manager": "manager",
                "operation": "Update",
                "time": "2024-07-21T15:18:32Z"
              }
            ],
            "name": "deepspeed-zhuxiang-3",
            "namespace": "default",
            "resourceVersion": "2375270190",
            "uid": "79f25aa1-63fe-4c7d-bc10-e413306f9e52"
          },
          "spec": {
            "pytorchReplicaSpecs": {
              "Master": {
                "replicas": 1,
                "restartPolicy": "Never",
                "template": {
                  "metadata": {
                    "annotations": {
                      "aijob.cce.baidubce.com/fault-tolerance-enabled": "true",
                      "aijob.cce.baidubce.com/openapi-jobid": "pytorch-78c57221-992e-4086-b890-2e9956d4dd8f",
                      "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
                      "aijob.cce.baidubce.com/raw-request": "{\"name\":\"deepspeed-zhuxiang-3\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"normal\",\"oversell\":false,\"faultTolerance\":true,\"command\":\" source /root/anaconda3/etc/profile.d/conda.sh\\n    conda activate llama-factory\\n\\n    ROOT_DIR=/workspace/LLaMA-Factory/\\n\\n    CHECKPOINT_LOAD_PATH=/mnt/cluster/ppl/Qwen-14B-Chat\\n    CHECKPOINT_SAVE_PATH=/mnt/cluster/ppl/Qwen-14B-Chat_saved_zhuxiang_2\\n    DEEPSPEED_CONFIG=$ROOT_DIR/examples/deepspeed/ds_z3_offload_config.json\\n\\n    GPUS_PER_NODE=8\\n\\n    is_master=${MASTER-\\\"0\\\"}\\n    if [[ $is_master -eq 1 ]];then\\n      DISTRIBUTED_ARGS=\\\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $HOSTNAME --master_port $MASTER_PORT\\\"\\n    else\\n      DISTRIBUTED_ARGS=\\\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $MASTER_ADDR --master_port $MASTER_PORT\\\"\\n    fi\\n\\n    QWEN_14B_ARGS=\\\"--model_name_or_path $CHECKPOINT_LOAD_PATH \\\\\\n        --stage sft \\\\\\n        --do_train \\\\\\n        --dataset alpaca_en_demo \\\\\\n        --template qwen \\\\\\n        --finetuning_type full \\\\\\n        --overwrite_output_dir \\\\\\n        --dataset_dir $ROOT_DIR/data \\\\\\n        --output_dir $CHECKPOINT_SAVE_PATH \\\\\\n        --preprocessing_num_workers 90 \\\\\\n        --dataloader_num_workers 90 \\\\\\n        --per_device_train_batch_size 1 \\\\\\n        --gradient_accumulation_steps 8 \\\\\\n        --cutoff_len 2048 \\\\\\n        --max_length 2048 \\\\\\n        --deepspeed $DEEPSPEED_CONFIG \\\\\\n        --logging_first_step \\\\\\n        --logging_steps 10 \\\\\\n        --save_strategy steps \\\\\\n        --save_steps 40 \\\\\\n        --num_train_epochs 2.0 \\\\\\n        --lr_scheduler_type cosine \\\\\\n        --learning_rate 1e-5 \\\\\\n        --plot_loss \\\\\\n        --bf16 \\\\\\n        --rope_scaling linear \\\\\\n        --flash_attn auto \\\\\\n        --shift_attn \\\\\\n        --ddp_find_unused_parameters False \\\\\\n        --push_to_hub False\\\"\\n\\n    PYTHONPATH=$ROOT_DIR:$PYTHONPATH \\\\\\n        torchrun $DISTRIBUTED_ARGS \\\\\\n        $ROOT_DIR/src/train.py \\\\\\n        $QWEN_14B_ARGS\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":true,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/cce-ai-native/aiak-algo\",\"tag\":\"0.1\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"deepspeed-zhuxiang-3\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"},\"Worker\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/cce-ai-native/aiak-algo\",\"tag\":\"0.1\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"deepspeed-zhuxiang-3\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":false,\"logPath\":\"\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":true,\"isCopyJob\":true,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
                      "scheduling.k8s.io/job-enable-oversell": "false"
                    },
                    "labels": {
                      "aijob.cce.baidubce.com/ai-user-id": "b89c433a0e884615a4c878ca24e2686e",
                      "aijob.cce.baidubce.com/ai-user-name": "zhuxiang05",
                      "aijob.cce.baidubce.com/create-from-aihcp": "true",
                      "aijob.cce.baidubce.com/openapi-jobid": "pytorch-78c57221-992e-4086-b890-2e9956d4dd8f"
                    }
                  },
                  "spec": {
                    "containers": [
                      {
                        "command": [
                          "/bin/bash",
                          "-c",
                          " source /root/anaconda3/etc/profile.d/conda.sh\n    conda activate llama-factory\n\n    ROOT_DIR=/workspace/LLaMA-Factory/\n\n    CHECKPOINT_LOAD_PATH=/mnt/cluster/ppl/Qwen-14B-Chat\n    CHECKPOINT_SAVE_PATH=/mnt/cluster/ppl/Qwen-14B-Chat_saved_zhuxiang_2\n    DEEPSPEED_CONFIG=$ROOT_DIR/examples/deepspeed/ds_z3_offload_config.json\n\n    GPUS_PER_NODE=8\n\n    is_master=${MASTER-\"0\"}\n    if [[ $is_master -eq 1 ]];then\n      DISTRIBUTED_ARGS=\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $HOSTNAME --master_port $MASTER_PORT\"\n    else\n      DISTRIBUTED_ARGS=\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $MASTER_ADDR --master_port $MASTER_PORT\"\n    fi\n\n    QWEN_14B_ARGS=\"--model_name_or_path $CHECKPOINT_LOAD_PATH \\\n        --stage sft \\\n        --do_train \\\n        --dataset alpaca_en_demo \\\n        --template qwen \\\n        --finetuning_type full \\\n        --overwrite_output_dir \\\n        --dataset_dir $ROOT_DIR/data \\\n        --output_dir $CHECKPOINT_SAVE_PATH \\\n        --preprocessing_num_workers 90 \\\n        --dataloader_num_workers 90 \\\n        --per_device_train_batch_size 1 \\\n        --gradient_accumulation_steps 8 \\\n        --cutoff_len 2048 \\\n        --max_length 2048 \\\n        --deepspeed $DEEPSPEED_CONFIG \\\n        --logging_first_step \\\n        --logging_steps 10 \\\n        --save_strategy steps \\\n        --save_steps 40 \\\n        --num_train_epochs 2.0 \\\n        --lr_scheduler_type cosine \\\n        --learning_rate 1e-5 \\\n        --plot_loss \\\n        --bf16 \\\n        --rope_scaling linear \\\n        --flash_attn auto \\\n        --shift_attn \\\n        --ddp_find_unused_parameters False \\\n        --push_to_hub False\"\n\n    PYTHONPATH=$ROOT_DIR:$PYTHONPATH \\\n        torchrun $DISTRIBUTED_ARGS \\\n        $ROOT_DIR/src/train.py \\\n        $QWEN_14B_ARGS"
                        ],
                        "env": [
                          {
                            "name": "NCCL_IB_DISABLE",
                            "value": "0"
                          },
                          {
                            "name": "AIHC_JOB_NAME",
                            "value": "deepspeed-zhuxiang-3"
                          }
                        ],
                        "image": "registry.baidubce.com/cce-ai-native/aiak-algo:0.1",
                        "imagePullPolicy": "Always",
                        "name": "pytorch",
                        "ports": [
                          {
                            "containerPort": 23456,
                            "name": "pytorchjob-port",
                            "protocol": "TCP"
                          }
                        ],
                        "resources": {
                          "limits": {
                            "baidu.com/a800_80g_cgpu": "8",
                            "rdma/hca": "1"
                          },
                          "requests": {
                            "baidu.com/a800_80g_cgpu": "8",
                            "rdma/hca": "1"
                          }
                        },
                        "securityContext": {
                          "capabilities": {
                            "add": [
                              "IPC_LOCK"
                            ]
                          }
                        },
                        "volumeMounts": [
                          {
                            "mountPath": "/dev/shm",
                            "name": "devshm"
                          },
                          {
                            "mountPath": "/mnt/cluster",
                            "name": "pvc-pfs"
                          }
                        ]
                      }
                    ],
                    "dnsPolicy": "ClusterFirstWithHostNet",
                    "hostNetwork": true,
                    "schedulerName": "volcano",
                    "volumes": [
                      {
                        "emptyDir": {
                          "medium": "Memory",
                          "sizeLimit": "10Gi"
                        },
                        "name": "devshm"
                      },
                      {
                        "name": "pvc-pfs",
                        "persistentVolumeClaim": {
                          "claimName": "pvc-pfs"
                        }
                      }
                    ]
                  }
                }
              },
              "Worker": {
                "replicas": 1,
                "restartPolicy": "Never",
                "template": {
                  "metadata": {
                    "annotations": {
                      "aijob.cce.baidubce.com/fault-tolerance-enabled": "true",
                      "aijob.cce.baidubce.com/openapi-jobid": "pytorch-78c57221-992e-4086-b890-2e9956d4dd8f",
                      "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
                      "aijob.cce.baidubce.com/raw-request": "{\"name\":\"deepspeed-zhuxiang-3\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"normal\",\"oversell\":false,\"faultTolerance\":true,\"command\":\" source /root/anaconda3/etc/profile.d/conda.sh\\n    conda activate llama-factory\\n\\n    ROOT_DIR=/workspace/LLaMA-Factory/\\n\\n    CHECKPOINT_LOAD_PATH=/mnt/cluster/ppl/Qwen-14B-Chat\\n    CHECKPOINT_SAVE_PATH=/mnt/cluster/ppl/Qwen-14B-Chat_saved_zhuxiang_2\\n    DEEPSPEED_CONFIG=$ROOT_DIR/examples/deepspeed/ds_z3_offload_config.json\\n\\n    GPUS_PER_NODE=8\\n\\n    is_master=${MASTER-\\\"0\\\"}\\n    if [[ $is_master -eq 1 ]];then\\n      DISTRIBUTED_ARGS=\\\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $HOSTNAME --master_port $MASTER_PORT\\\"\\n    else\\n      DISTRIBUTED_ARGS=\\\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $MASTER_ADDR --master_port $MASTER_PORT\\\"\\n    fi\\n\\n    QWEN_14B_ARGS=\\\"--model_name_or_path $CHECKPOINT_LOAD_PATH \\\\\\n        --stage sft \\\\\\n        --do_train \\\\\\n        --dataset alpaca_en_demo \\\\\\n        --template qwen \\\\\\n        --finetuning_type full \\\\\\n        --overwrite_output_dir \\\\\\n        --dataset_dir $ROOT_DIR/data \\\\\\n        --output_dir $CHECKPOINT_SAVE_PATH \\\\\\n        --preprocessing_num_workers 90 \\\\\\n        --dataloader_num_workers 90 \\\\\\n        --per_device_train_batch_size 1 \\\\\\n        --gradient_accumulation_steps 8 \\\\\\n        --cutoff_len 2048 \\\\\\n        --max_length 2048 \\\\\\n        --deepspeed $DEEPSPEED_CONFIG \\\\\\n        --logging_first_step \\\\\\n        --logging_steps 10 \\\\\\n        --save_strategy steps \\\\\\n        --save_steps 40 \\\\\\n        --num_train_epochs 2.0 \\\\\\n        --lr_scheduler_type cosine \\\\\\n        --learning_rate 1e-5 \\\\\\n        --plot_loss \\\\\\n        --bf16 \\\\\\n        --rope_scaling linear \\\\\\n        --flash_attn auto \\\\\\n        --shift_attn \\\\\\n        --ddp_find_unused_parameters False \\\\\\n        --push_to_hub False\\\"\\n\\n    PYTHONPATH=$ROOT_DIR:$PYTHONPATH \\\\\\n        torchrun $DISTRIBUTED_ARGS \\\\\\n        $ROOT_DIR/src/train.py \\\\\\n        $QWEN_14B_ARGS\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":true,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/cce-ai-native/aiak-algo\",\"tag\":\"0.1\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"deepspeed-zhuxiang-3\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"},\"Worker\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/cce-ai-native/aiak-algo\",\"tag\":\"0.1\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"deepspeed-zhuxiang-3\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":false,\"logPath\":\"\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":true,\"isCopyJob\":true,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
                      "scheduling.k8s.io/job-enable-oversell": "false"
                    },
                    "labels": {
                      "aijob.cce.baidubce.com/ai-user-id": "b89c433a0e884615a4c878ca24e2686e",
                      "aijob.cce.baidubce.com/ai-user-name": "zhuxiang05",
                      "aijob.cce.baidubce.com/create-from-aihcp": "true",
                      "aijob.cce.baidubce.com/openapi-jobid": "pytorch-78c57221-992e-4086-b890-2e9956d4dd8f"
                    }
                  },
                  "spec": {
                    "containers": [
                      {
                        "command": [
                          "/bin/bash",
                          "-c",
                          " source /root/anaconda3/etc/profile.d/conda.sh\n    conda activate llama-factory\n\n    ROOT_DIR=/workspace/LLaMA-Factory/\n\n    CHECKPOINT_LOAD_PATH=/mnt/cluster/ppl/Qwen-14B-Chat\n    CHECKPOINT_SAVE_PATH=/mnt/cluster/ppl/Qwen-14B-Chat_saved_zhuxiang_2\n    DEEPSPEED_CONFIG=$ROOT_DIR/examples/deepspeed/ds_z3_offload_config.json\n\n    GPUS_PER_NODE=8\n\n    is_master=${MASTER-\"0\"}\n    if [[ $is_master -eq 1 ]];then\n      DISTRIBUTED_ARGS=\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $HOSTNAME --master_port $MASTER_PORT\"\n    else\n      DISTRIBUTED_ARGS=\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $MASTER_ADDR --master_port $MASTER_PORT\"\n    fi\n\n    QWEN_14B_ARGS=\"--model_name_or_path $CHECKPOINT_LOAD_PATH \\\n        --stage sft \\\n        --do_train \\\n        --dataset alpaca_en_demo \\\n        --template qwen \\\n        --finetuning_type full \\\n        --overwrite_output_dir \\\n        --dataset_dir $ROOT_DIR/data \\\n        --output_dir $CHECKPOINT_SAVE_PATH \\\n        --preprocessing_num_workers 90 \\\n        --dataloader_num_workers 90 \\\n        --per_device_train_batch_size 1 \\\n        --gradient_accumulation_steps 8 \\\n        --cutoff_len 2048 \\\n        --max_length 2048 \\\n        --deepspeed $DEEPSPEED_CONFIG \\\n        --logging_first_step \\\n        --logging_steps 10 \\\n        --save_strategy steps \\\n        --save_steps 40 \\\n        --num_train_epochs 2.0 \\\n        --lr_scheduler_type cosine \\\n        --learning_rate 1e-5 \\\n        --plot_loss \\\n        --bf16 \\\n        --rope_scaling linear \\\n        --flash_attn auto \\\n        --shift_attn \\\n        --ddp_find_unused_parameters False \\\n        --push_to_hub False\"\n\n    PYTHONPATH=$ROOT_DIR:$PYTHONPATH \\\n        torchrun $DISTRIBUTED_ARGS \\\n        $ROOT_DIR/src/train.py \\\n        $QWEN_14B_ARGS"
                        ],
                        "env": [
                          {
                            "name": "AIHC_JOB_NAME",
                            "value": "deepspeed-zhuxiang-3"
                          },
                          {
                            "name": "NCCL_IB_DISABLE",
                            "value": "0"
                          }
                        ],
                        "image": "registry.baidubce.com/cce-ai-native/aiak-algo:0.1",
                        "imagePullPolicy": "Always",
                        "name": "pytorch",
                        "ports": [
                          {
                            "containerPort": 23456,
                            "name": "pytorchjob-port",
                            "protocol": "TCP"
                          }
                        ],
                        "resources": {
                          "limits": {
                            "baidu.com/a800_80g_cgpu": "8",
                            "rdma/hca": "1"
                          },
                          "requests": {
                            "baidu.com/a800_80g_cgpu": "8",
                            "rdma/hca": "1"
                          }
                        },
                        "securityContext": {
                          "capabilities": {
                            "add": [
                              "IPC_LOCK"
                            ]
                          }
                        },
                        "volumeMounts": [
                          {
                            "mountPath": "/dev/shm",
                            "name": "devshm"
                          },
                          {
                            "mountPath": "/mnt/cluster",
                            "name": "pvc-pfs"
                          }
                        ]
                      }
                    ],
                    "dnsPolicy": "ClusterFirstWithHostNet",
                    "hostNetwork": true,
                    "schedulerName": "volcano",
                    "volumes": [
                      {
                        "emptyDir": {
                          "medium": "Memory",
                          "sizeLimit": "10Gi"
                        },
                        "name": "devshm"
                      },
                      {
                        "name": "pvc-pfs",
                        "persistentVolumeClaim": {
                          "claimName": "pvc-pfs"
                        }
                      }
                    ]
                  }
                }
              }
            },
            "runPolicy": {
              "cleanPodPolicy": "None",
              "schedulingPolicy": {
                "priorityClass": "normal",
                "queue": "default"
              }
            }
          },
          "status": {
            "completionTime": "2024-07-21T15:18:32Z",
            "conditions": [
              {
                "lastTransitionTime": "2024-07-21T15:10:43Z",
                "lastUpdateTime": "2024-07-21T15:10:43Z",
                "message": "PyTorchJob deepspeed-zhuxiang-3 is created.",
                "reason": "PyTorchJobCreated",
                "status": "True",
                "type": "Created"
              },
              {
                "lastTransitionTime": "2024-07-21T15:11:01Z",
                "lastUpdateTime": "2024-07-21T15:11:01Z",
                "message": "PyTorchJob deepspeed-zhuxiang-3 is running.",
                "reason": "JobRunning",
                "status": "False",
                "type": "Running"
              },
              {
                "lastTransitionTime": "2024-07-21T15:18:32Z",
                "lastUpdateTime": "2024-07-21T15:18:32Z",
                "message": "PyTorchJob deepspeed-zhuxiang-3 is successfully completed.",
                "reason": "JobSucceeded",
                "status": "True",
                "type": "Succeeded"
              }
            ],
            "lastReconcileTime": "2024-07-21T15:10:43Z",
            "replicaStatuses": {
              "Master": {
                "selector": "training.kubeflow.org/job-name=deepspeed-zhuxiang-3,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=master",
                "succeeded": 1
              },
              "Worker": {
                "succeeded": 1
              }
            },
            "startTime": "2024-07-21T15:10:45Z"
          }
        },
        {
          "apiVersion": "kubeflow.org/v1",
          "kind": "PyTorchJob",
          "metadata": {
            "annotations": {
              "aijob.cce.baidubce.com/barrier-finish": "33633217-ff37-4710-a9ba-5cf66782e1df",
              "aijob.cce.baidubce.com/fault-tolerance-enabled": "true",
              "aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": "",
              "aijob.cce.baidubce.com/openapi-jobid": "pytorch-5a4216f3-fc78-46b1-89b3-5bae67f3751a",
              "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
              "aijob.cce.baidubce.com/raw-request": "{\"name\":\"deepspeed-zhuxiang-4\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"normal\",\"oversell\":false,\"faultTolerance\":true,\"command\":\" source /root/anaconda3/etc/profile.d/conda.sh\\n    conda activate llama-factory\\n\\n    ROOT_DIR=/workspace/LLaMA-Factory/\\n\\n    CHECKPOINT_LOAD_PATH=/mnt/cluster/ppl/Qwen-14B-Chat\\n    CHECKPOINT_SAVE_PATH=/mnt/cluster/ppl/Qwen-14B-Chat_saved_zhuxiang_4\\n    DEEPSPEED_CONFIG=$ROOT_DIR/examples/deepspeed/ds_z3_offload_config.json\\n\\n    GPUS_PER_NODE=8\\n\\n    is_master=${MASTER-\\\"0\\\"}\\n    if [[ $is_master -eq 1 ]];then\\n      DISTRIBUTED_ARGS=\\\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $HOSTNAME --master_port $MASTER_PORT\\\"\\n    else\\n      DISTRIBUTED_ARGS=\\\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $MASTER_ADDR --master_port $MASTER_PORT\\\"\\n    fi\\n\\n    QWEN_14B_ARGS=\\\"--model_name_or_path $CHECKPOINT_LOAD_PATH \\\\\\n        --stage sft \\\\\\n        --do_train \\\\\\n        --dataset alpaca_en_demo \\\\\\n        --template qwen \\\\\\n        --finetuning_type lora \\\\\\n        --lora_target all \\\\\\n        --overwrite_output_dir \\\\\\n        --dataset_dir $ROOT_DIR/data \\\\\\n        --output_dir $CHECKPOINT_SAVE_PATH \\\\\\n        --preprocessing_num_workers 90 \\\\\\n        --dataloader_num_workers 90 \\\\\\n        --per_device_train_batch_size 1 \\\\\\n        --gradient_accumulation_steps 8 \\\\\\n        --cutoff_len 2048 \\\\\\n        --max_length 2048 \\\\\\n        --deepspeed $DEEPSPEED_CONFIG \\\\\\n        --logging_first_step \\\\\\n        --logging_steps 10 \\\\\\n        --save_strategy steps \\\\\\n        --save_steps 40 \\\\\\n        --num_train_epochs 2.0 \\\\\\n        --lr_scheduler_type cosine \\\\\\n        --learning_rate 1e-5 \\\\\\n        --plot_loss \\\\\\n        --bf16 \\\\\\n        --rope_scaling linear \\\\\\n        --flash_attn auto \\\\\\n        --shift_attn \\\\\\n        --ddp_find_unused_parameters False \\\\\\n        --push_to_hub False\\\"\\n\\n    PYTHONPATH=$ROOT_DIR:$PYTHONPATH \\\\\\n        torchrun $DISTRIBUTED_ARGS \\\\\\n        $ROOT_DIR/src/train.py \\\\\\n        $QWEN_14B_ARGS\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":true,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/cce-ai-native/aiak-algo\",\"tag\":\"0.1\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"deepspeed-zhuxiang-4\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"},\"Worker\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/cce-ai-native/aiak-algo\",\"tag\":\"0.1\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"deepspeed-zhuxiang-4\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":false,\"logPath\":\"\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":true,\"isCopyJob\":true,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
              "aijob.cce.baidubce.com/timeline": "[{\"conditionType\":\"Created\",\"time\":1721577689},{\"conditionType\":\"Scheduled\",\"time\":1721577690},{\"conditionType\":\"Running\",\"time\":1721577744},{\"conditionType\":\"Succeeded\",\"time\":1721578104}]",
              "scheduling.k8s.io/job-enable-oversell": "false"
            },
            "creationTimestamp": "2024-07-21T16:01:29Z",
            "generation": 2,
            "labels": {
              "aijob.cce.baidubce.com/ai-user-id": "b89c433a0e884615a4c878ca24e2686e",
              "aijob.cce.baidubce.com/ai-user-name": "zhuxiang05",
              "aijob.cce.baidubce.com/create-from-aihcp": "true",
              "aijob.cce.baidubce.com/openapi-jobid": "pytorch-5a4216f3-fc78-46b1-89b3-5bae67f3751a"
            },
            "managedFields": [
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      ".": {},
                      "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                      "f:aijob.cce.baidubce.com/openapi-jobid": {},
                      "f:aijob.cce.baidubce.com/pfs-id": {},
                      "f:aijob.cce.baidubce.com/raw-request": {},
                      "f:scheduling.k8s.io/job-enable-oversell": {}
                    },
                    "f:labels": {
                      ".": {},
                      "f:aijob.cce.baidubce.com/ai-user-id": {},
                      "f:aijob.cce.baidubce.com/ai-user-name": {},
                      "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                      "f:aijob.cce.baidubce.com/openapi-jobid": {}
                    }
                  },
                  "f:spec": {
                    ".": {},
                    "f:pytorchReplicaSpecs": {
                      ".": {},
                      "f:Master": {
                        ".": {},
                        "f:replicas": {},
                        "f:restartPolicy": {},
                        "f:template": {
                          ".": {},
                          "f:metadata": {
                            ".": {},
                            "f:annotations": {
                              ".": {},
                              "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                              "f:aijob.cce.baidubce.com/openapi-jobid": {},
                              "f:aijob.cce.baidubce.com/pfs-id": {},
                              "f:aijob.cce.baidubce.com/raw-request": {},
                              "f:scheduling.k8s.io/job-enable-oversell": {}
                            },
                            "f:labels": {
                              ".": {},
                              "f:aijob.cce.baidubce.com/ai-user-id": {},
                              "f:aijob.cce.baidubce.com/ai-user-name": {},
                              "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                              "f:aijob.cce.baidubce.com/openapi-jobid": {}
                            }
                          },
                          "f:spec": {
                            ".": {},
                            "f:dnsPolicy": {},
                            "f:hostNetwork": {},
                            "f:schedulerName": {},
                            "f:volumes": {}
                          }
                        }
                      },
                      "f:Worker": {
                        ".": {},
                        "f:replicas": {},
                        "f:restartPolicy": {},
                        "f:template": {
                          ".": {},
                          "f:metadata": {
                            ".": {},
                            "f:annotations": {
                              ".": {},
                              "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                              "f:aijob.cce.baidubce.com/openapi-jobid": {},
                              "f:aijob.cce.baidubce.com/pfs-id": {},
                              "f:aijob.cce.baidubce.com/raw-request": {},
                              "f:scheduling.k8s.io/job-enable-oversell": {}
                            },
                            "f:labels": {
                              ".": {},
                              "f:aijob.cce.baidubce.com/ai-user-id": {},
                              "f:aijob.cce.baidubce.com/ai-user-name": {},
                              "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                              "f:aijob.cce.baidubce.com/openapi-jobid": {}
                            }
                          },
                          "f:spec": {
                            ".": {},
                            "f:dnsPolicy": {},
                            "f:hostNetwork": {},
                            "f:schedulerName": {},
                            "f:volumes": {}
                          }
                        }
                      }
                    },
                    "f:runPolicy": {
                      ".": {},
                      "f:schedulingPolicy": {
                        ".": {},
                        "f:priorityClass": {},
                        "f:queue": {}
                      }
                    }
                  }
                },
                "manager": "cce-ai-service",
                "operation": "Update",
                "time": "2024-07-21T16:01:29Z"
              },
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      "f:aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": {},
                      "f:aijob.cce.baidubce.com/timeline": {}
                    }
                  },
                  "f:spec": {
                    "f:pytorchReplicaSpecs": {
                      "f:Master": {
                        "f:template": {
                          "f:spec": {
                            "f:containers": {}
                          }
                        }
                      },
                      "f:Worker": {
                        "f:template": {
                          "f:spec": {
                            "f:containers": {}
                          }
                        }
                      }
                    },
                    "f:runPolicy": {
                      "f:cleanPodPolicy": {}
                    }
                  }
                },
                "manager": "controller",
                "operation": "Update",
                "time": "2024-07-21T16:01:29Z"
              },
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      "f:aijob.cce.baidubce.com/barrier-finish": {}
                    }
                  }
                },
                "manager": "jobbarrier",
                "operation": "Update",
                "time": "2024-07-21T16:02:19Z"
              },
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:status": {
                    ".": {},
                    "f:completionTime": {},
                    "f:conditions": {},
                    "f:lastReconcileTime": {},
                    "f:replicaStatuses": {
                      ".": {},
                      "f:Master": {
                        ".": {},
                        "f:selector": {},
                        "f:succeeded": {}
                      },
                      "f:Worker": {
                        ".": {},
                        "f:succeeded": {}
                      }
                    },
                    "f:startTime": {}
                  }
                },
                "manager": "manager",
                "operation": "Update",
                "time": "2024-07-21T16:08:24Z"
              }
            ],
            "name": "deepspeed-zhuxiang-4",
            "namespace": "default",
            "resourceVersion": "2375309550",
            "uid": "db613901-bbdb-48da-bed1-d32f817ee964"
          },
          "spec": {
            "pytorchReplicaSpecs": {
              "Master": {
                "replicas": 1,
                "restartPolicy": "Never",
                "template": {
                  "metadata": {
                    "annotations": {
                      "aijob.cce.baidubce.com/fault-tolerance-enabled": "true",
                      "aijob.cce.baidubce.com/openapi-jobid": "pytorch-5a4216f3-fc78-46b1-89b3-5bae67f3751a",
                      "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
                      "aijob.cce.baidubce.com/raw-request": "{\"name\":\"deepspeed-zhuxiang-4\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"normal\",\"oversell\":false,\"faultTolerance\":true,\"command\":\" source /root/anaconda3/etc/profile.d/conda.sh\\n    conda activate llama-factory\\n\\n    ROOT_DIR=/workspace/LLaMA-Factory/\\n\\n    CHECKPOINT_LOAD_PATH=/mnt/cluster/ppl/Qwen-14B-Chat\\n    CHECKPOINT_SAVE_PATH=/mnt/cluster/ppl/Qwen-14B-Chat_saved_zhuxiang_4\\n    DEEPSPEED_CONFIG=$ROOT_DIR/examples/deepspeed/ds_z3_offload_config.json\\n\\n    GPUS_PER_NODE=8\\n\\n    is_master=${MASTER-\\\"0\\\"}\\n    if [[ $is_master -eq 1 ]];then\\n      DISTRIBUTED_ARGS=\\\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $HOSTNAME --master_port $MASTER_PORT\\\"\\n    else\\n      DISTRIBUTED_ARGS=\\\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $MASTER_ADDR --master_port $MASTER_PORT\\\"\\n    fi\\n\\n    QWEN_14B_ARGS=\\\"--model_name_or_path $CHECKPOINT_LOAD_PATH \\\\\\n        --stage sft \\\\\\n        --do_train \\\\\\n        --dataset alpaca_en_demo \\\\\\n        --template qwen \\\\\\n        --finetuning_type lora \\\\\\n        --lora_target all \\\\\\n        --overwrite_output_dir \\\\\\n        --dataset_dir $ROOT_DIR/data \\\\\\n        --output_dir $CHECKPOINT_SAVE_PATH \\\\\\n        --preprocessing_num_workers 90 \\\\\\n        --dataloader_num_workers 90 \\\\\\n        --per_device_train_batch_size 1 \\\\\\n        --gradient_accumulation_steps 8 \\\\\\n        --cutoff_len 2048 \\\\\\n        --max_length 2048 \\\\\\n        --deepspeed $DEEPSPEED_CONFIG \\\\\\n        --logging_first_step \\\\\\n        --logging_steps 10 \\\\\\n        --save_strategy steps \\\\\\n        --save_steps 40 \\\\\\n        --num_train_epochs 2.0 \\\\\\n        --lr_scheduler_type cosine \\\\\\n        --learning_rate 1e-5 \\\\\\n        --plot_loss \\\\\\n        --bf16 \\\\\\n        --rope_scaling linear \\\\\\n        --flash_attn auto \\\\\\n        --shift_attn \\\\\\n        --ddp_find_unused_parameters False \\\\\\n        --push_to_hub False\\\"\\n\\n    PYTHONPATH=$ROOT_DIR:$PYTHONPATH \\\\\\n        torchrun $DISTRIBUTED_ARGS \\\\\\n        $ROOT_DIR/src/train.py \\\\\\n        $QWEN_14B_ARGS\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":true,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/cce-ai-native/aiak-algo\",\"tag\":\"0.1\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"deepspeed-zhuxiang-4\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"},\"Worker\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/cce-ai-native/aiak-algo\",\"tag\":\"0.1\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"deepspeed-zhuxiang-4\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":false,\"logPath\":\"\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":true,\"isCopyJob\":true,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
                      "scheduling.k8s.io/job-enable-oversell": "false"
                    },
                    "labels": {
                      "aijob.cce.baidubce.com/ai-user-id": "b89c433a0e884615a4c878ca24e2686e",
                      "aijob.cce.baidubce.com/ai-user-name": "zhuxiang05",
                      "aijob.cce.baidubce.com/create-from-aihcp": "true",
                      "aijob.cce.baidubce.com/openapi-jobid": "pytorch-5a4216f3-fc78-46b1-89b3-5bae67f3751a"
                    }
                  },
                  "spec": {
                    "containers": [
                      {
                        "command": [
                          "/bin/bash",
                          "-c",
                          " source /root/anaconda3/etc/profile.d/conda.sh\n    conda activate llama-factory\n\n    ROOT_DIR=/workspace/LLaMA-Factory/\n\n    CHECKPOINT_LOAD_PATH=/mnt/cluster/ppl/Qwen-14B-Chat\n    CHECKPOINT_SAVE_PATH=/mnt/cluster/ppl/Qwen-14B-Chat_saved_zhuxiang_4\n    DEEPSPEED_CONFIG=$ROOT_DIR/examples/deepspeed/ds_z3_offload_config.json\n\n    GPUS_PER_NODE=8\n\n    is_master=${MASTER-\"0\"}\n    if [[ $is_master -eq 1 ]];then\n      DISTRIBUTED_ARGS=\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $HOSTNAME --master_port $MASTER_PORT\"\n    else\n      DISTRIBUTED_ARGS=\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $MASTER_ADDR --master_port $MASTER_PORT\"\n    fi\n\n    QWEN_14B_ARGS=\"--model_name_or_path $CHECKPOINT_LOAD_PATH \\\n        --stage sft \\\n        --do_train \\\n        --dataset alpaca_en_demo \\\n        --template qwen \\\n        --finetuning_type lora \\\n        --lora_target all \\\n        --overwrite_output_dir \\\n        --dataset_dir $ROOT_DIR/data \\\n        --output_dir $CHECKPOINT_SAVE_PATH \\\n        --preprocessing_num_workers 90 \\\n        --dataloader_num_workers 90 \\\n        --per_device_train_batch_size 1 \\\n        --gradient_accumulation_steps 8 \\\n        --cutoff_len 2048 \\\n        --max_length 2048 \\\n        --deepspeed $DEEPSPEED_CONFIG \\\n        --logging_first_step \\\n        --logging_steps 10 \\\n        --save_strategy steps \\\n        --save_steps 40 \\\n        --num_train_epochs 2.0 \\\n        --lr_scheduler_type cosine \\\n        --learning_rate 1e-5 \\\n        --plot_loss \\\n        --bf16 \\\n        --rope_scaling linear \\\n        --flash_attn auto \\\n        --shift_attn \\\n        --ddp_find_unused_parameters False \\\n        --push_to_hub False\"\n\n    PYTHONPATH=$ROOT_DIR:$PYTHONPATH \\\n        torchrun $DISTRIBUTED_ARGS \\\n        $ROOT_DIR/src/train.py \\\n        $QWEN_14B_ARGS"
                        ],
                        "env": [
                          {
                            "name": "AIHC_JOB_NAME",
                            "value": "deepspeed-zhuxiang-4"
                          },
                          {
                            "name": "NCCL_IB_DISABLE",
                            "value": "0"
                          }
                        ],
                        "image": "registry.baidubce.com/cce-ai-native/aiak-algo:0.1",
                        "imagePullPolicy": "Always",
                        "name": "pytorch",
                        "ports": [
                          {
                            "containerPort": 23456,
                            "name": "pytorchjob-port",
                            "protocol": "TCP"
                          }
                        ],
                        "resources": {
                          "limits": {
                            "baidu.com/a800_80g_cgpu": "8",
                            "rdma/hca": "1"
                          },
                          "requests": {
                            "baidu.com/a800_80g_cgpu": "8",
                            "rdma/hca": "1"
                          }
                        },
                        "securityContext": {
                          "capabilities": {
                            "add": [
                              "IPC_LOCK"
                            ]
                          }
                        },
                        "volumeMounts": [
                          {
                            "mountPath": "/dev/shm",
                            "name": "devshm"
                          },
                          {
                            "mountPath": "/mnt/cluster",
                            "name": "pvc-pfs"
                          }
                        ]
                      }
                    ],
                    "dnsPolicy": "ClusterFirstWithHostNet",
                    "hostNetwork": true,
                    "schedulerName": "volcano",
                    "volumes": [
                      {
                        "emptyDir": {
                          "medium": "Memory",
                          "sizeLimit": "10Gi"
                        },
                        "name": "devshm"
                      },
                      {
                        "name": "pvc-pfs",
                        "persistentVolumeClaim": {
                          "claimName": "pvc-pfs"
                        }
                      }
                    ]
                  }
                }
              },
              "Worker": {
                "replicas": 1,
                "restartPolicy": "Never",
                "template": {
                  "metadata": {
                    "annotations": {
                      "aijob.cce.baidubce.com/fault-tolerance-enabled": "true",
                      "aijob.cce.baidubce.com/openapi-jobid": "pytorch-5a4216f3-fc78-46b1-89b3-5bae67f3751a",
                      "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
                      "aijob.cce.baidubce.com/raw-request": "{\"name\":\"deepspeed-zhuxiang-4\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"normal\",\"oversell\":false,\"faultTolerance\":true,\"command\":\" source /root/anaconda3/etc/profile.d/conda.sh\\n    conda activate llama-factory\\n\\n    ROOT_DIR=/workspace/LLaMA-Factory/\\n\\n    CHECKPOINT_LOAD_PATH=/mnt/cluster/ppl/Qwen-14B-Chat\\n    CHECKPOINT_SAVE_PATH=/mnt/cluster/ppl/Qwen-14B-Chat_saved_zhuxiang_4\\n    DEEPSPEED_CONFIG=$ROOT_DIR/examples/deepspeed/ds_z3_offload_config.json\\n\\n    GPUS_PER_NODE=8\\n\\n    is_master=${MASTER-\\\"0\\\"}\\n    if [[ $is_master -eq 1 ]];then\\n      DISTRIBUTED_ARGS=\\\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $HOSTNAME --master_port $MASTER_PORT\\\"\\n    else\\n      DISTRIBUTED_ARGS=\\\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $MASTER_ADDR --master_port $MASTER_PORT\\\"\\n    fi\\n\\n    QWEN_14B_ARGS=\\\"--model_name_or_path $CHECKPOINT_LOAD_PATH \\\\\\n        --stage sft \\\\\\n        --do_train \\\\\\n        --dataset alpaca_en_demo \\\\\\n        --template qwen \\\\\\n        --finetuning_type lora \\\\\\n        --lora_target all \\\\\\n        --overwrite_output_dir \\\\\\n        --dataset_dir $ROOT_DIR/data \\\\\\n        --output_dir $CHECKPOINT_SAVE_PATH \\\\\\n        --preprocessing_num_workers 90 \\\\\\n        --dataloader_num_workers 90 \\\\\\n        --per_device_train_batch_size 1 \\\\\\n        --gradient_accumulation_steps 8 \\\\\\n        --cutoff_len 2048 \\\\\\n        --max_length 2048 \\\\\\n        --deepspeed $DEEPSPEED_CONFIG \\\\\\n        --logging_first_step \\\\\\n        --logging_steps 10 \\\\\\n        --save_strategy steps \\\\\\n        --save_steps 40 \\\\\\n        --num_train_epochs 2.0 \\\\\\n        --lr_scheduler_type cosine \\\\\\n        --learning_rate 1e-5 \\\\\\n        --plot_loss \\\\\\n        --bf16 \\\\\\n        --rope_scaling linear \\\\\\n        --flash_attn auto \\\\\\n        --shift_attn \\\\\\n        --ddp_find_unused_parameters False \\\\\\n        --push_to_hub False\\\"\\n\\n    PYTHONPATH=$ROOT_DIR:$PYTHONPATH \\\\\\n        torchrun $DISTRIBUTED_ARGS \\\\\\n        $ROOT_DIR/src/train.py \\\\\\n        $QWEN_14B_ARGS\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":true,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/cce-ai-native/aiak-algo\",\"tag\":\"0.1\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"deepspeed-zhuxiang-4\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"},\"Worker\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/cce-ai-native/aiak-algo\",\"tag\":\"0.1\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"deepspeed-zhuxiang-4\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":false,\"logPath\":\"\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":true,\"isCopyJob\":true,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
                      "scheduling.k8s.io/job-enable-oversell": "false"
                    },
                    "labels": {
                      "aijob.cce.baidubce.com/ai-user-id": "b89c433a0e884615a4c878ca24e2686e",
                      "aijob.cce.baidubce.com/ai-user-name": "zhuxiang05",
                      "aijob.cce.baidubce.com/create-from-aihcp": "true",
                      "aijob.cce.baidubce.com/openapi-jobid": "pytorch-5a4216f3-fc78-46b1-89b3-5bae67f3751a"
                    }
                  },
                  "spec": {
                    "containers": [
                      {
                        "command": [
                          "/bin/bash",
                          "-c",
                          " source /root/anaconda3/etc/profile.d/conda.sh\n    conda activate llama-factory\n\n    ROOT_DIR=/workspace/LLaMA-Factory/\n\n    CHECKPOINT_LOAD_PATH=/mnt/cluster/ppl/Qwen-14B-Chat\n    CHECKPOINT_SAVE_PATH=/mnt/cluster/ppl/Qwen-14B-Chat_saved_zhuxiang_4\n    DEEPSPEED_CONFIG=$ROOT_DIR/examples/deepspeed/ds_z3_offload_config.json\n\n    GPUS_PER_NODE=8\n\n    is_master=${MASTER-\"0\"}\n    if [[ $is_master -eq 1 ]];then\n      DISTRIBUTED_ARGS=\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $HOSTNAME --master_port $MASTER_PORT\"\n    else\n      DISTRIBUTED_ARGS=\"--nproc_per_node $GPUS_PER_NODE --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $MASTER_ADDR --master_port $MASTER_PORT\"\n    fi\n\n    QWEN_14B_ARGS=\"--model_name_or_path $CHECKPOINT_LOAD_PATH \\\n        --stage sft \\\n        --do_train \\\n        --dataset alpaca_en_demo \\\n        --template qwen \\\n        --finetuning_type lora \\\n        --lora_target all \\\n        --overwrite_output_dir \\\n        --dataset_dir $ROOT_DIR/data \\\n        --output_dir $CHECKPOINT_SAVE_PATH \\\n        --preprocessing_num_workers 90 \\\n        --dataloader_num_workers 90 \\\n        --per_device_train_batch_size 1 \\\n        --gradient_accumulation_steps 8 \\\n        --cutoff_len 2048 \\\n        --max_length 2048 \\\n        --deepspeed $DEEPSPEED_CONFIG \\\n        --logging_first_step \\\n        --logging_steps 10 \\\n        --save_strategy steps \\\n        --save_steps 40 \\\n        --num_train_epochs 2.0 \\\n        --lr_scheduler_type cosine \\\n        --learning_rate 1e-5 \\\n        --plot_loss \\\n        --bf16 \\\n        --rope_scaling linear \\\n        --flash_attn auto \\\n        --shift_attn \\\n        --ddp_find_unused_parameters False \\\n        --push_to_hub False\"\n\n    PYTHONPATH=$ROOT_DIR:$PYTHONPATH \\\n        torchrun $DISTRIBUTED_ARGS \\\n        $ROOT_DIR/src/train.py \\\n        $QWEN_14B_ARGS"
                        ],
                        "env": [
                          {
                            "name": "AIHC_JOB_NAME",
                            "value": "deepspeed-zhuxiang-4"
                          },
                          {
                            "name": "NCCL_IB_DISABLE",
                            "value": "0"
                          }
                        ],
                        "image": "registry.baidubce.com/cce-ai-native/aiak-algo:0.1",
                        "imagePullPolicy": "Always",
                        "name": "pytorch",
                        "ports": [
                          {
                            "containerPort": 23456,
                            "name": "pytorchjob-port",
                            "protocol": "TCP"
                          }
                        ],
                        "resources": {
                          "limits": {
                            "baidu.com/a800_80g_cgpu": "8",
                            "rdma/hca": "1"
                          },
                          "requests": {
                            "baidu.com/a800_80g_cgpu": "8",
                            "rdma/hca": "1"
                          }
                        },
                        "securityContext": {
                          "capabilities": {
                            "add": [
                              "IPC_LOCK"
                            ]
                          }
                        },
                        "volumeMounts": [
                          {
                            "mountPath": "/dev/shm",
                            "name": "devshm"
                          },
                          {
                            "mountPath": "/mnt/cluster",
                            "name": "pvc-pfs"
                          }
                        ]
                      }
                    ],
                    "dnsPolicy": "ClusterFirstWithHostNet",
                    "hostNetwork": true,
                    "schedulerName": "volcano",
                    "volumes": [
                      {
                        "emptyDir": {
                          "medium": "Memory",
                          "sizeLimit": "10Gi"
                        },
                        "name": "devshm"
                      },
                      {
                        "name": "pvc-pfs",
                        "persistentVolumeClaim": {
                          "claimName": "pvc-pfs"
                        }
                      }
                    ]
                  }
                }
              }
            },
            "runPolicy": {
              "cleanPodPolicy": "None",
              "schedulingPolicy": {
                "priorityClass": "normal",
                "queue": "default"
              }
            }
          },
          "status": {
            "completionTime": "2024-07-21T16:08:24Z",
            "conditions": [
              {
                "lastTransitionTime": "2024-07-21T16:01:29Z",
                "lastUpdateTime": "2024-07-21T16:01:29Z",
                "message": "PyTorchJob deepspeed-zhuxiang-4 is created.",
                "reason": "PyTorchJobCreated",
                "status": "True",
                "type": "Created"
              },
              {
                "lastTransitionTime": "2024-07-21T16:02:24Z",
                "lastUpdateTime": "2024-07-21T16:02:24Z",
                "message": "PyTorchJob deepspeed-zhuxiang-4 is running.",
                "reason": "JobRunning",
                "status": "False",
                "type": "Running"
              },
              {
                "lastTransitionTime": "2024-07-21T16:08:24Z",
                "lastUpdateTime": "2024-07-21T16:08:24Z",
                "message": "PyTorchJob deepspeed-zhuxiang-4 is successfully completed.",
                "reason": "JobSucceeded",
                "status": "True",
                "type": "Succeeded"
              }
            ],
            "lastReconcileTime": "2024-07-21T16:01:29Z",
            "replicaStatuses": {
              "Master": {
                "selector": "training.kubeflow.org/job-name=deepspeed-zhuxiang-4,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=master",
                "succeeded": 1
              },
              "Worker": {
                "succeeded": 1
              }
            },
            "startTime": "2024-07-21T16:01:29Z"
          }
        },
        {
          "apiVersion": "kubeflow.org/v1",
          "kind": "PyTorchJob",
          "metadata": {
            "annotations": {
              "aijob.cce.baidubce.com/barrier-finish": "7cfa2c4c-680b-4351-815a-0c6f560ae580",
              "aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": "",
              "aijob.cce.baidubce.com/timeline": "[{\"conditionType\":\"Created\",\"time\":1721271291},{\"conditionType\":\"Scheduled\",\"time\":1721271292},{\"conditionType\":\"Running\",\"time\":1721271304},{\"conditionType\":\"Succeeded\",\"time\":1721271664}]",
              "kubectl.kubernetes.io/last-applied-configuration": "{\"apiVersion\":\"kubeflow.org/v1\",\"kind\":\"PyTorchJob\",\"metadata\":{\"annotations\":{},\"name\":\"guoyaning-pytorch-communication-config-test\",\"namespace\":\"default\"},\"spec\":{\"pytorchReplicaSpecs\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"template\":{\"metadata\":null,\"spec\":{\"containers\":[{\"command\":[\"/bin/bash\",\"-c\",\"#! /bin/bash\\npython -m torch.distributed.launch --use_env --nproc_per_node 8 --nnodes 1 --node_rank $RANK --master_addr $MASTER_ADDR --master_port $MASTER_PORT communication.py -n 10 -b 8G -tp 4 -dp 2 -pp 1 -order 1 -d float32 -l debug -interbw 100 -intrabw 200\"],\"env\":[{\"name\":\"NCCL_DEBUG\",\"value\":\"INFO\"},{\"name\":\"NCCL_ALGO\",\"value\":\"RING\"},{\"name\":\"NCCL_IB_DISABLE\",\"value\":\"0\"}],\"image\":\"registry.baidubce.com/cce-ai-native/pytorch:gyn-torch\",\"imagePullPolicy\":\"Always\",\"name\":\"pytorch\",\"resources\":{\"limits\":{\"baidu.com/a800_80g_cgpu\":\"8\",\"rdma/hca\":1},\"requests\":{\"baidu.com/a800_80g_cgpu\":\"8\",\"rdma/hca\":1}},\"securityContext\":{\"capabilities\":{\"add\":[\"IPC_LOCK\"]}},\"volumeMounts\":[{\"mountPath\":\"/dev/shm\",\"name\":\"cache-volume\"}]}],\"schedulerName\":\"volcano\",\"volumes\":[{\"emptyDir\":{\"medium\":\"Memory\"},\"name\":\"cache-volume\"}]}}},\"Worker\":{\"replicas\":0,\"restartPolicy\":\"Never\",\"template\":{\"metadata\":null,\"spec\":{\"containers\":[{\"command\":[\"/bin/bash\",\"-c\",\"#! /bin/bash\\npython -m torch.distributed.launch --use_env --nproc_per_node 8 --nnodes 1 --node_rank $RANK --master_addr $MASTER_ADDR --master_port $MASTER_PORT communication.py -n 10 -b 8G -tp 4 -dp 2 -pp 1 -order 1 -d float32 -l debug -interbw 100 -intrabw 200\"],\"env\":[{\"name\":\"NCCL_DEBUG\",\"value\":\"INFO\"},{\"name\":\"NCCL_ALGO\",\"value\":\"RING\"},{\"name\":\"NCCL_IB_DISABLE\",\"value\":\"0\"}],\"image\":\"registry.baidubce.com/cce-ai-native/pytorch:gyn-torch\",\"imagePullPolicy\":\"Always\",\"name\":\"pytorch\",\"resources\":{\"limits\":{\"baidu.com/a800_80g_cgpu\":\"8\",\"rdma/hca\":1},\"requests\":{\"baidu.com/a800_80g_cgpu\":\"8\",\"rdma/hca\":1}},\"securityContext\":{\"capabilities\":{\"add\":[\"IPC_LOCK\"]}},\"volumeMounts\":[{\"mountPath\":\"/dev/shm\",\"name\":\"cache-volume\"}]}],\"schedulerName\":\"volcano\",\"volumes\":[{\"emptyDir\":{\"medium\":\"Memory\"},\"name\":\"cache-volume\"}]}}}},\"runPolicy\":{\"schedulingPolicy\":{\"queue\":\"default\"}}}}\n"
            },
            "creationTimestamp": "2024-07-18T02:54:51Z",
            "generation": 2,
            "managedFields": [
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      "f:aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": {},
                      "f:aijob.cce.baidubce.com/timeline": {}
                    }
                  },
                  "f:spec": {
                    "f:pytorchReplicaSpecs": {
                      "f:Master": {
                        "f:template": {
                          "f:metadata": {},
                          "f:spec": {
                            "f:containers": {}
                          }
                        }
                      },
                      "f:Worker": {
                        "f:template": {
                          "f:metadata": {},
                          "f:spec": {
                            "f:containers": {}
                          }
                        }
                      }
                    },
                    "f:runPolicy": {
                      "f:cleanPodPolicy": {}
                    }
                  }
                },
                "manager": "controller",
                "operation": "Update",
                "time": "2024-07-18T02:54:51Z"
              },
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      ".": {},
                      "f:kubectl.kubernetes.io/last-applied-configuration": {}
                    }
                  },
                  "f:spec": {
                    ".": {},
                    "f:pytorchReplicaSpecs": {
                      ".": {},
                      "f:Master": {
                        ".": {},
                        "f:replicas": {},
                        "f:restartPolicy": {},
                        "f:template": {
                          ".": {},
                          "f:spec": {
                            ".": {},
                            "f:schedulerName": {},
                            "f:volumes": {}
                          }
                        }
                      },
                      "f:Worker": {
                        ".": {},
                        "f:replicas": {},
                        "f:restartPolicy": {},
                        "f:template": {
                          ".": {},
                          "f:spec": {
                            ".": {},
                            "f:schedulerName": {},
                            "f:volumes": {}
                          }
                        }
                      }
                    },
                    "f:runPolicy": {
                      ".": {},
                      "f:schedulingPolicy": {
                        ".": {},
                        "f:queue": {}
                      }
                    }
                  }
                },
                "manager": "kubectl-client-side-apply",
                "operation": "Update",
                "time": "2024-07-18T02:54:51Z"
              },
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      "f:aijob.cce.baidubce.com/barrier-finish": {}
                    }
                  }
                },
                "manager": "jobbarrier",
                "operation": "Update",
                "time": "2024-07-18T02:55:01Z"
              },
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:status": {
                    ".": {},
                    "f:completionTime": {},
                    "f:conditions": {},
                    "f:lastReconcileTime": {},
                    "f:replicaStatuses": {
                      ".": {},
                      "f:Master": {
                        ".": {},
                        "f:selector": {},
                        "f:succeeded": {}
                      },
                      "f:Worker": {}
                    },
                    "f:startTime": {}
                  }
                },
                "manager": "manager",
                "operation": "Update",
                "time": "2024-07-18T03:01:04Z"
              }
            ],
            "name": "guoyaning-pytorch-communication-config-test",
            "namespace": "default",
            "resourceVersion": "2371222980",
            "uid": "4601f4a6-70cb-484f-9eea-f976b0b66898"
          },
          "spec": {
            "pytorchReplicaSpecs": {
              "Master": {
                "replicas": 1,
                "restartPolicy": "Never",
                "template": {
                  "metadata": {},
                  "spec": {
                    "containers": [
                      {
                        "command": [
                          "/bin/bash",
                          "-c",
                          "#! /bin/bash\npython -m torch.distributed.launch --use_env --nproc_per_node 8 --nnodes 1 --node_rank $RANK --master_addr $MASTER_ADDR --master_port $MASTER_PORT communication.py -n 10 -b 8G -tp 4 -dp 2 -pp 1 -order 1 -d float32 -l debug -interbw 100 -intrabw 200"
                        ],
                        "env": [
                          {
                            "name": "NCCL_DEBUG",
                            "value": "INFO"
                          },
                          {
                            "name": "NCCL_ALGO",
                            "value": "RING"
                          },
                          {
                            "name": "NCCL_IB_DISABLE",
                            "value": "0"
                          }
                        ],
                        "image": "registry.baidubce.com/cce-ai-native/pytorch:gyn-torch",
                        "imagePullPolicy": "Always",
                        "name": "pytorch",
                        "ports": [
                          {
                            "containerPort": 23456,
                            "name": "pytorchjob-port",
                            "protocol": "TCP"
                          }
                        ],
                        "resources": {
                          "limits": {
                            "baidu.com/a800_80g_cgpu": "8",
                            "rdma/hca": "1"
                          },
                          "requests": {
                            "baidu.com/a800_80g_cgpu": "8",
                            "rdma/hca": "1"
                          }
                        },
                        "securityContext": {
                          "capabilities": {
                            "add": [
                              "IPC_LOCK"
                            ]
                          }
                        },
                        "volumeMounts": [
                          {
                            "mountPath": "/dev/shm",
                            "name": "cache-volume"
                          }
                        ]
                      }
                    ],
                    "schedulerName": "volcano",
                    "volumes": [
                      {
                        "emptyDir": {
                          "medium": "Memory"
                        },
                        "name": "cache-volume"
                      }
                    ]
                  }
                }
              },
              "Worker": {
                "replicas": 0,
                "restartPolicy": "Never",
                "template": {
                  "metadata": {},
                  "spec": {
                    "containers": [
                      {
                        "command": [
                          "/bin/bash",
                          "-c",
                          "#! /bin/bash\npython -m torch.distributed.launch --use_env --nproc_per_node 8 --nnodes 1 --node_rank $RANK --master_addr $MASTER_ADDR --master_port $MASTER_PORT communication.py -n 10 -b 8G -tp 4 -dp 2 -pp 1 -order 1 -d float32 -l debug -interbw 100 -intrabw 200"
                        ],
                        "env": [
                          {
                            "name": "NCCL_DEBUG",
                            "value": "INFO"
                          },
                          {
                            "name": "NCCL_ALGO",
                            "value": "RING"
                          },
                          {
                            "name": "NCCL_IB_DISABLE",
                            "value": "0"
                          }
                        ],
                        "image": "registry.baidubce.com/cce-ai-native/pytorch:gyn-torch",
                        "imagePullPolicy": "Always",
                        "name": "pytorch",
                        "ports": [
                          {
                            "containerPort": 23456,
                            "name": "pytorchjob-port",
                            "protocol": "TCP"
                          }
                        ],
                        "resources": {
                          "limits": {
                            "baidu.com/a800_80g_cgpu": "8",
                            "rdma/hca": "1"
                          },
                          "requests": {
                            "baidu.com/a800_80g_cgpu": "8",
                            "rdma/hca": "1"
                          }
                        },
                        "securityContext": {
                          "capabilities": {
                            "add": [
                              "IPC_LOCK"
                            ]
                          }
                        },
                        "volumeMounts": [
                          {
                            "mountPath": "/dev/shm",
                            "name": "cache-volume"
                          }
                        ]
                      }
                    ],
                    "schedulerName": "volcano",
                    "volumes": [
                      {
                        "emptyDir": {
                          "medium": "Memory"
                        },
                        "name": "cache-volume"
                      }
                    ]
                  }
                }
              }
            },
            "runPolicy": {
              "cleanPodPolicy": "None",
              "schedulingPolicy": {
                "queue": "default"
              }
            }
          },
          "status": {
            "completionTime": "2024-07-18T03:01:04Z",
            "conditions": [
              {
                "lastTransitionTime": "2024-07-18T02:54:51Z",
                "lastUpdateTime": "2024-07-18T02:54:51Z",
                "message": "PyTorchJob guoyaning-pytorch-communication-config-test is created.",
                "reason": "PyTorchJobCreated",
                "status": "True",
                "type": "Created"
              },
              {
                "lastTransitionTime": "2024-07-18T02:55:04Z",
                "lastUpdateTime": "2024-07-18T02:55:04Z",
                "message": "PyTorchJob guoyaning-pytorch-communication-config-test is running.",
                "reason": "JobRunning",
                "status": "False",
                "type": "Running"
              },
              {
                "lastTransitionTime": "2024-07-18T03:01:04Z",
                "lastUpdateTime": "2024-07-18T03:01:04Z",
                "message": "PyTorchJob guoyaning-pytorch-communication-config-test is successfully completed.",
                "reason": "JobSucceeded",
                "status": "True",
                "type": "Succeeded"
              }
            ],
            "lastReconcileTime": "2024-07-18T02:54:51Z",
            "replicaStatuses": {
              "Master": {
                "selector": "training.kubeflow.org/job-name=guoyaning-pytorch-communication-config-test,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=master",
                "succeeded": 1
              },
              "Worker": {}
            },
            "startTime": "2024-07-18T02:54:51Z"
          }
        },
        {
          "apiVersion": "kubeflow.org/v1",
          "kind": "PyTorchJob",
          "metadata": {
            "annotations": {
              "aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": "",
              "aijob.cce.baidubce.com/timeline": "[{\"conditionType\":\"Created\",\"time\":1721637753},{\"conditionType\":\"Scheduled\",\"time\":1721637755},{\"conditionType\":\"Running\",\"time\":1721637765}]",
              "kubectl.kubernetes.io/last-applied-configuration": "{\"apiVersion\":\"kubeflow.org/v1\",\"kind\":\"PyTorchJob\",\"metadata\":{\"annotations\":{},\"name\":\"gushilei-72hours-llama2-test2\",\"namespace\":\"default\"},\"spec\":{\"pytorchReplicaSpecs\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"template\":{\"metadata\":null,\"spec\":{\"containers\":[{\"command\":[\"bash\",\"/workspace/launch.sh\"],\"env\":[{\"name\":\"CUDA_DEVICE_MAX_CONNECTIONS\",\"value\":\"1\"},{\"name\":\"NCCL_DEBUG\",\"value\":\"INFO\"},{\"name\":\"NCCL_IB_DISABLE\",\"value\":\"0\"},{\"name\":\"MASTER\",\"value\":\"1\"}],\"image\":\"registry.baidubce.com/cce-ai-native/gsl-deepspeed-sq:05\",\"imagePullPolicy\":\"Always\",\"name\":\"pytorch\",\"resources\":{\"limits\":{\"nvidia.com/gpu\":8,\"rdma/hca\":1}},\"securityContext\":{\"capabilities\":{\"add\":[\"IPC_LOCK\"]}},\"volumeMounts\":[{\"mountPath\":\"/dev/shm\",\"name\":\"cache-volume\"},{\"mountPath\":\"/workspace/launch.sh\",\"name\":\"config-volume\",\"subPath\":\"launch.sh\"},{\"mountPath\":\"/mnt/cluster\",\"name\":\"data\"}]}],\"schedulerName\":\"volcano\",\"volumes\":[{\"emptyDir\":{\"medium\":\"Memory\"},\"name\":\"cache-volume\"},{\"configMap\":{\"name\":\"gsl-launch-cm-7b-test2-d2\"},\"name\":\"config-volume\"},{\"name\":\"data\",\"persistentVolumeClaim\":{\"claimName\":\"pvc-pfs\"}}]}}}}}}\n"
            },
            "creationTimestamp": "2024-07-22T08:42:33Z",
            "generation": 2,
            "managedFields": [
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      "f:aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": {},
                      "f:aijob.cce.baidubce.com/timeline": {}
                    }
                  },
                  "f:spec": {
                    "f:pytorchReplicaSpecs": {
                      "f:Master": {
                        "f:template": {
                          "f:metadata": {},
                          "f:spec": {
                            "f:containers": {}
                          }
                        }
                      }
                    },
                    "f:runPolicy": {
                      ".": {},
                      "f:cleanPodPolicy": {}
                    }
                  }
                },
                "manager": "controller",
                "operation": "Update",
                "time": "2024-07-22T08:42:33Z"
              },
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      ".": {},
                      "f:kubectl.kubernetes.io/last-applied-configuration": {}
                    }
                  },
                  "f:spec": {
                    ".": {},
                    "f:pytorchReplicaSpecs": {
                      ".": {},
                      "f:Master": {
                        ".": {},
                        "f:replicas": {},
                        "f:restartPolicy": {},
                        "f:template": {
                          ".": {},
                          "f:spec": {
                            ".": {},
                            "f:schedulerName": {},
                            "f:volumes": {}
                          }
                        }
                      }
                    }
                  }
                },
                "manager": "kubectl-client-side-apply",
                "operation": "Update",
                "time": "2024-07-22T08:42:33Z"
              },
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:status": {
                    ".": {},
                    "f:conditions": {},
                    "f:lastReconcileTime": {},
                    "f:replicaStatuses": {
                      ".": {},
                      "f:Master": {
                        ".": {},
                        "f:active": {},
                        "f:selector": {}
                      }
                    },
                    "f:startTime": {}
                  }
                },
                "manager": "manager",
                "operation": "Update",
                "time": "2024-07-22T08:42:45Z"
              }
            ],
            "name": "gushilei-72hours-llama2-test2",
            "namespace": "default",
            "resourceVersion": "2376098975",
            "uid": "24515d31-9df9-4ccb-8848-01b7083145d2"
          },
          "spec": {
            "pytorchReplicaSpecs": {
              "Master": {
                "replicas": 1,
                "restartPolicy": "Never",
                "template": {
                  "metadata": {},
                  "spec": {
                    "containers": [
                      {
                        "command": [
                          "bash",
                          "/workspace/launch.sh"
                        ],
                        "env": [
                          {
                            "name": "CUDA_DEVICE_MAX_CONNECTIONS",
                            "value": "1"
                          },
                          {
                            "name": "NCCL_DEBUG",
                            "value": "INFO"
                          },
                          {
                            "name": "NCCL_IB_DISABLE",
                            "value": "0"
                          },
                          {
                            "name": "MASTER",
                            "value": "1"
                          }
                        ],
                        "image": "registry.baidubce.com/cce-ai-native/gsl-deepspeed-sq:05",
                        "imagePullPolicy": "Always",
                        "name": "pytorch",
                        "ports": [
                          {
                            "containerPort": 23456,
                            "name": "pytorchjob-port",
                            "protocol": "TCP"
                          }
                        ],
                        "resources": {
                          "limits": {
                            "nvidia.com/gpu": "8",
                            "rdma/hca": "1"
                          }
                        },
                        "securityContext": {
                          "capabilities": {
                            "add": [
                              "IPC_LOCK"
                            ]
                          }
                        },
                        "volumeMounts": [
                          {
                            "mountPath": "/dev/shm",
                            "name": "cache-volume"
                          },
                          {
                            "mountPath": "/workspace/launch.sh",
                            "name": "config-volume",
                            "subPath": "launch.sh"
                          },
                          {
                            "mountPath": "/mnt/cluster",
                            "name": "data"
                          }
                        ]
                      }
                    ],
                    "schedulerName": "volcano",
                    "volumes": [
                      {
                        "emptyDir": {
                          "medium": "Memory"
                        },
                        "name": "cache-volume"
                      },
                      {
                        "configMap": {
                          "name": "gsl-launch-cm-7b-test2-d2"
                        },
                        "name": "config-volume"
                      },
                      {
                        "name": "data",
                        "persistentVolumeClaim": {
                          "claimName": "pvc-pfs"
                        }
                      }
                    ]
                  }
                }
              }
            },
            "runPolicy": {
              "cleanPodPolicy": "None"
            }
          },
          "status": {
            "conditions": [
              {
                "lastTransitionTime": "2024-07-22T08:42:33Z",
                "lastUpdateTime": "2024-07-22T08:42:33Z",
                "message": "PyTorchJob gushilei-72hours-llama2-test2 is created.",
                "reason": "PyTorchJobCreated",
                "status": "True",
                "type": "Created"
              },
              {
                "lastTransitionTime": "2024-07-22T08:42:45Z",
                "lastUpdateTime": "2024-07-22T08:42:45Z",
                "message": "PyTorchJob gushilei-72hours-llama2-test2 is running.",
                "reason": "JobRunning",
                "status": "True",
                "type": "Running"
              }
            ],
            "lastReconcileTime": "2024-07-22T08:42:33Z",
            "replicaStatuses": {
              "Master": {
                "active": 1,
                "selector": "training.kubeflow.org/job-name=gushilei-72hours-llama2-test2,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=master"
              }
            },
            "startTime": "2024-07-22T08:42:34Z"
          }
        },
        {
          "apiVersion": "kubeflow.org/v1",
          "kind": "PyTorchJob",
          "metadata": {
            "annotations": {
              "aijob.cce.baidubce.com/barrier-finish": "2e07e965-0cfd-41c0-86d0-19d2092780d0",
              "aijob.cce.baidubce.com/fault-tolerance-enabled": "true",
              "aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": "",
              "aijob.cce.baidubce.com/internal-fault-tolerance-time": "2024-07-18T02:17:39.225207493Z",
              "aijob.cce.baidubce.com/openapi-jobid": "pytorch-5961a180-13bb-49a1-8c5d-58ad07e652e4",
              "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
              "aijob.cce.baidubce.com/raw-request": "{\"name\":\"llamatest0718forxiaomi\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"high\",\"oversell\":false,\"faultTolerance\":true,\"command\":\"\\n#! /bin/bash\\n\\nMEGATRON_PATH=${MEGATRON_PATH:-\\\"/workspace/AIAK-Megatron\\\"}\\nAIAK_TRAINING_PATH=${AIAK_TRAINING_PATH:-\\\"/workspace/AIAK-Training-LLM\\\"}\\n\\nDATA_PATH=${DATA_PATH:-\\\"/mnt/cluster/llama2/pile/pile-llama_text_document\\\"}\\nTOKENIZER_PATH=${TOKENIZER_PATH:-\\\"/mnt/cluster/llama2/Llama-2-70b-hf/\\\"}\\n\\nCHECKPOINT_PATH=${CHECKPOINT_PATH:-\\\"/mnt/cluster/llama2/mcore_llama2_70b_tp4_pp4\\\"}\\n\\nTENSORBOARD_PATH=${TENSORBOARD_PATH:-\\\"/mnt/cluster/aiak-training-llm/tensorboard-log/llama2-70b-tp4pp4\\\"}\\n\\nGPUS_PER_NODE=8\\n\\n# Change for multinode config\\nMASTER_ADDR=${MASTER_ADDR:-\\\"localhost\\\"}\\nMASTER_PORT=${MASTER_PORT:-\\\"6000\\\"}\\nNNODES=${WORLD_SIZE:-\\\"1\\\"}\\nNODE_RANK=${RANK:-\\\"0\\\"}\\n\\nDISTRIBUTED_ARGS=(\\n    --nproc_per_node $GPUS_PER_NODE\\n    --nnodes $NNODES\\n    --node_rank $NODE_RANK\\n    --master_addr $MASTER_ADDR\\n    --master_port $MASTER_PORT\\n)\\n\\n# you can setup llama2-70b maunally\\n#MODEL_ARGS=(\\n#    --model-name llama2\\n#    --num-layers 80\\n#    --hidden-size 8192\\n#    --ffn-hidden-size 28672\\n#    --num-attention-heads 64\\n#    --position-embedding-type rope\\n#    --normalization RMSNorm\\n#    --swiglu\\n#    --attention-dropout 0\\n#    --hidden-dropout 0\\n#    --disable-bias-linear\\n#    --untie-embeddings-and-output-weights\\n#    --group-query-attention\\n#    --num-query-groups 8\\n#)\\n\\n# or you can setup llama2-70b by using the following command\\nMODEL_ARGS=(\\n    --model-name llama2-70b # options: llama2-7b, llama2-13b, llama2-70b\\n)\\n\\nDATA_ARGS=(\\n    --tokenizer-type HFTokenizer\\n    --hf-tokenizer-path $TOKENIZER_PATH\\n    --data-path $DATA_PATH\\n    --split 949,50,1\\n)\\n\\nTRAINING_ARGS=(\\n    --training-phase pretrain # options: pretrain, sft\\n    --seq-length 4096\\n    --max-position-embeddings 4096\\n    --init-method-std 0.01\\n    --micro-batch-size 1\\n    --global-batch-size 1024\\n    --lr 0.0002\\n    --min-lr 1.0e-5\\n    --clip-grad 1.0\\n    --weight-decay 0.01\\n    --optimizer adam\\n    --adam-beta1 0.9\\n    --adam-beta2 0.95\\n    --adam-eps 1e-05\\n    --norm-epsilon 1e-6\\n    --train-iters 500000\\n    --lr-decay-iters 500000\\n    --lr-decay-style cosine\\n    --lr-warmup-fraction 0.002\\n    --initial-loss-scale 65536\\n    --fp16\\n    --save-interval 5000\\n    --eval-interval 1000\\n    --eval-iters 10\\n    #--ckpt-step 0\\n    #--no-load-optim\\n    #--no-load-rng\\n)\\n\\nMODEL_PARALLEL_ARGS=(\\n    --tensor-model-parallel-size 4\\n    --pipeline-model-parallel-size 4\\n    --use-distributed-optimizer\\n    --overlap-grad-reduce\\n    --overlap-param-gather\\n    --distributed-backend nccl\\n    --sequence-parallel\\n    #--tp-comm-overlap # require mpi envrionment\\n)\\n\\nLOGGING_ARGS=(\\n    --log-interval 1\\n    --tensorboard-dir ${TENSORBOARD_PATH}\\n    --log-timers-to-tensorboard\\n)\\n\\nif [ -n \\\"${WANDB_API_KEY}\\\" ]; then\\n    LOGGING_ARGS+=(\\n        --wandb-project ${WANDB_PROJECT}\\n        --wandb-exp-name ${WANDB_NAME} \\n    )\\nfi\\n\\nPYTHONPATH=$MEGATRON_PATH:$AIAK_TRAINING_PATH:$PYTHONPATH     torchrun ${DISTRIBUTED_ARGS[@]}     $AIAK_TRAINING_PATH/aiak_training_llm/train.py     ${MODEL_ARGS[@]}     ${DATA_ARGS[@]}     ${TRAINING_ARGS[@]}     ${MODEL_PARALLEL_ARGS[@]}     ${LOGGING_ARGS[@]}\\n\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":true,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi/output/training_logs\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"},\"Worker\":{\"replicas\":3,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi/output/training_logs\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":true,\"logPath\":\"/mnt/cluster/llamatest0718forxiaomi/output/training_logs\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":true,\"isCopyJob\":false,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
              "aijob.cce.baidubce.com/timeline": "[{\"conditionType\":\"Created\",\"time\":1721268630},{\"conditionType\":\"Scheduled\",\"time\":1721268981},{\"conditionType\":\"Running\",\"time\":1721269028},{\"conditionType\":\"Abnormal\",\"time\":1721269059},{\"conditionType\":\"ManualTermination\",\"time\":1721269176}]",
              "job-manager/action": "stop",
              "scheduling.k8s.io/job-enable-oversell": "false",
              "tensorboard-gc": "true"
            },
            "creationTimestamp": "2024-07-18T02:10:30Z",
            "generation": 4,
            "labels": {
              "aijob.cce.baidubce.com/ai-user-id": "b5a24aa26e4d4f55bc3acf68edc4b051",
              "aijob.cce.baidubce.com/ai-user-name": "zhangmuhua",
              "aijob.cce.baidubce.com/create-from-aihcp": "true",
              "aijob.cce.baidubce.com/openapi-jobid": "pytorch-5961a180-13bb-49a1-8c5d-58ad07e652e4"
            },
            "managedFields": [
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      "f:aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": {},
                      "f:aijob.cce.baidubce.com/timeline": {}
                    }
                  },
                  "f:spec": {
                    "f:runPolicy": {
                      "f:cleanPodPolicy": {}
                    }
                  }
                },
                "manager": "controller",
                "operation": "Update",
                "time": "2024-07-18T02:10:30Z"
              },
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      "f:aijob.cce.baidubce.com/barrier-finish": {}
                    }
                  }
                },
                "manager": "jobbarrier",
                "operation": "Update",
                "time": "2024-07-18T02:17:04Z"
              },
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      ".": {},
                      "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                      "f:aijob.cce.baidubce.com/openapi-jobid": {},
                      "f:aijob.cce.baidubce.com/pfs-id": {},
                      "f:aijob.cce.baidubce.com/raw-request": {},
                      "f:job-manager/action": {},
                      "f:scheduling.k8s.io/job-enable-oversell": {}
                    },
                    "f:labels": {
                      ".": {},
                      "f:aijob.cce.baidubce.com/ai-user-id": {},
                      "f:aijob.cce.baidubce.com/ai-user-name": {},
                      "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                      "f:aijob.cce.baidubce.com/openapi-jobid": {}
                    }
                  },
                  "f:spec": {
                    ".": {},
                    "f:pytorchReplicaSpecs": {
                      ".": {},
                      "f:Master": {
                        ".": {},
                        "f:replicas": {},
                        "f:restartPolicy": {},
                        "f:template": {
                          ".": {},
                          "f:metadata": {
                            ".": {},
                            "f:annotations": {
                              ".": {},
                              "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                              "f:aijob.cce.baidubce.com/openapi-jobid": {},
                              "f:aijob.cce.baidubce.com/pfs-id": {},
                              "f:aijob.cce.baidubce.com/raw-request": {},
                              "f:scheduling.k8s.io/job-enable-oversell": {}
                            },
                            "f:labels": {
                              ".": {},
                              "f:aijob.cce.baidubce.com/ai-user-id": {},
                              "f:aijob.cce.baidubce.com/ai-user-name": {},
                              "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                              "f:aijob.cce.baidubce.com/openapi-jobid": {}
                            }
                          },
                          "f:spec": {
                            ".": {},
                            "f:dnsPolicy": {},
                            "f:hostNetwork": {},
                            "f:schedulerName": {}
                          }
                        }
                      },
                      "f:Worker": {
                        ".": {},
                        "f:replicas": {},
                        "f:restartPolicy": {},
                        "f:template": {
                          ".": {},
                          "f:metadata": {
                            ".": {},
                            "f:annotations": {
                              ".": {},
                              "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                              "f:aijob.cce.baidubce.com/openapi-jobid": {},
                              "f:aijob.cce.baidubce.com/pfs-id": {},
                              "f:aijob.cce.baidubce.com/raw-request": {},
                              "f:scheduling.k8s.io/job-enable-oversell": {}
                            },
                            "f:labels": {
                              ".": {},
                              "f:aijob.cce.baidubce.com/ai-user-id": {},
                              "f:aijob.cce.baidubce.com/ai-user-name": {},
                              "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                              "f:aijob.cce.baidubce.com/openapi-jobid": {}
                            }
                          },
                          "f:spec": {
                            ".": {},
                            "f:dnsPolicy": {},
                            "f:hostNetwork": {},
                            "f:schedulerName": {}
                          }
                        }
                      }
                    },
                    "f:runPolicy": {
                      ".": {},
                      "f:schedulingPolicy": {
                        ".": {},
                        "f:priorityClass": {},
                        "f:queue": {}
                      }
                    }
                  }
                },
                "manager": "cce-ai-service",
                "operation": "Update",
                "time": "2024-07-18T02:19:36Z"
              },
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      "f:aijob.cce.baidubce.com/internal-fault-tolerance-time": {},
                      "f:tensorboard-gc": {}
                    }
                  },
                  "f:spec": {
                    "f:pytorchReplicaSpecs": {
                      "f:Master": {
                        "f:template": {
                          "f:metadata": {
                            "f:annotations": {
                              "f:prometheus.io/path": {},
                              "f:prometheus.io/port": {},
                              "f:prometheus.io/scrape": {}
                            }
                          },
                          "f:spec": {
                            "f:containers": {},
                            "f:serviceAccountName": {},
                            "f:shareProcessNamespace": {},
                            "f:volumes": {}
                          }
                        }
                      },
                      "f:Worker": {
                        "f:template": {
                          "f:metadata": {
                            "f:annotations": {
                              "f:prometheus.io/path": {},
                              "f:prometheus.io/port": {},
                              "f:prometheus.io/scrape": {}
                            }
                          },
                          "f:spec": {
                            "f:containers": {},
                            "f:serviceAccountName": {},
                            "f:shareProcessNamespace": {},
                            "f:volumes": {}
                          }
                        }
                      }
                    }
                  },
                  "f:status": {
                    ".": {},
                    "f:completionTime": {},
                    "f:conditions": {},
                    "f:lastReconcileTime": {},
                    "f:replicaStatuses": {
                      ".": {},
                      "f:Master": {
                        ".": {},
                        "f:failed": {}
                      },
                      "f:Worker": {
                        ".": {},
                        "f:failed": {}
                      }
                    },
                    "f:startTime": {}
                  }
                },
                "manager": "manager",
                "operation": "Update",
                "time": "2024-07-19T02:10:55Z"
              }
            ],
            "name": "llamatest0718forxiaomi",
            "namespace": "default",
            "resourceVersion": "2372379743",
            "uid": "37163e59-3e0b-4d85-94a9-093619062227"
          },
          "spec": {
            "pytorchReplicaSpecs": {
              "Master": {
                "replicas": 1,
                "restartPolicy": "Never",
                "template": {
                  "metadata": {
                    "annotations": {
                      "aijob.cce.baidubce.com/fault-tolerance-enabled": "true",
                      "aijob.cce.baidubce.com/openapi-jobid": "pytorch-5961a180-13bb-49a1-8c5d-58ad07e652e4",
                      "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
                      "aijob.cce.baidubce.com/raw-request": "{\"name\":\"llamatest0718forxiaomi\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"normal\",\"oversell\":false,\"faultTolerance\":true,\"command\":\"\\n#! /bin/bash\\n\\nMEGATRON_PATH=${MEGATRON_PATH:-\\\"/workspace/AIAK-Megatron\\\"}\\nAIAK_TRAINING_PATH=${AIAK_TRAINING_PATH:-\\\"/workspace/AIAK-Training-LLM\\\"}\\n\\nDATA_PATH=${DATA_PATH:-\\\"/mnt/cluster/llama2/pile/pile-llama_text_document\\\"}\\nTOKENIZER_PATH=${TOKENIZER_PATH:-\\\"/mnt/cluster/llama2/Llama-2-70b-hf/\\\"}\\n\\nCHECKPOINT_PATH=${CHECKPOINT_PATH:-\\\"/mnt/cluster/llama2/mcore_llama2_70b_tp4_pp4\\\"}\\n\\nTENSORBOARD_PATH=${TENSORBOARD_PATH:-\\\"/mnt/cluster/aiak-training-llm/tensorboard-log/llama2-70b-tp4pp4\\\"}\\n\\nGPUS_PER_NODE=8\\n\\n# Change for multinode config\\nMASTER_ADDR=${MASTER_ADDR:-\\\"localhost\\\"}\\nMASTER_PORT=${MASTER_PORT:-\\\"6000\\\"}\\nNNODES=${WORLD_SIZE:-\\\"1\\\"}\\nNODE_RANK=${RANK:-\\\"0\\\"}\\n\\nDISTRIBUTED_ARGS=(\\n    --nproc_per_node $GPUS_PER_NODE\\n    --nnodes $NNODES\\n    --node_rank $NODE_RANK\\n    --master_addr $MASTER_ADDR\\n    --master_port $MASTER_PORT\\n)\\n\\n# you can setup llama2-70b maunally\\n#MODEL_ARGS=(\\n#    --model-name llama2\\n#    --num-layers 80\\n#    --hidden-size 8192\\n#    --ffn-hidden-size 28672\\n#    --num-attention-heads 64\\n#    --position-embedding-type rope\\n#    --normalization RMSNorm\\n#    --swiglu\\n#    --attention-dropout 0\\n#    --hidden-dropout 0\\n#    --disable-bias-linear\\n#    --untie-embeddings-and-output-weights\\n#    --group-query-attention\\n#    --num-query-groups 8\\n#)\\n\\n# or you can setup llama2-70b by using the following command\\nMODEL_ARGS=(\\n    --model-name llama2-70b # options: llama2-7b, llama2-13b, llama2-70b\\n)\\n\\nDATA_ARGS=(\\n    --tokenizer-type HFTokenizer\\n    --hf-tokenizer-path $TOKENIZER_PATH\\n    --data-path $DATA_PATH\\n    --split 949,50,1\\n)\\n\\nTRAINING_ARGS=(\\n    --training-phase pretrain # options: pretrain, sft\\n    --seq-length 4096\\n    --max-position-embeddings 4096\\n    --init-method-std 0.01\\n    --micro-batch-size 1\\n    --global-batch-size 1024\\n    --lr 0.0002\\n    --min-lr 1.0e-5\\n    --clip-grad 1.0\\n    --weight-decay 0.01\\n    --optimizer adam\\n    --adam-beta1 0.9\\n    --adam-beta2 0.95\\n    --adam-eps 1e-05\\n    --norm-epsilon 1e-6\\n    --train-iters 500000\\n    --lr-decay-iters 500000\\n    --lr-decay-style cosine\\n    --lr-warmup-fraction 0.002\\n    --initial-loss-scale 65536\\n    --fp16\\n    --save-interval 5000\\n    --eval-interval 1000\\n    --eval-iters 10\\n    #--ckpt-step 0\\n    #--no-load-optim\\n    #--no-load-rng\\n)\\n\\nMODEL_PARALLEL_ARGS=(\\n    --tensor-model-parallel-size 4\\n    --pipeline-model-parallel-size 4\\n    --use-distributed-optimizer\\n    --overlap-grad-reduce\\n    --overlap-param-gather\\n    --distributed-backend nccl\\n    --sequence-parallel\\n    #--tp-comm-overlap # require mpi envrionment\\n)\\n\\nLOGGING_ARGS=(\\n    --log-interval 1\\n    --tensorboard-dir ${TENSORBOARD_PATH}\\n    --log-timers-to-tensorboard\\n)\\n\\nif [ -n \\\"${WANDB_API_KEY}\\\" ]; then\\n    LOGGING_ARGS+=(\\n        --wandb-project ${WANDB_PROJECT}\\n        --wandb-exp-name ${WANDB_NAME} \\n    )\\nfi\\n\\nPYTHONPATH=$MEGATRON_PATH:$AIAK_TRAINING_PATH:$PYTHONPATH     torchrun ${DISTRIBUTED_ARGS[@]}     $AIAK_TRAINING_PATH/aiak_training_llm/train.py     ${MODEL_ARGS[@]}     ${DATA_ARGS[@]}     ${TRAINING_ARGS[@]}     ${MODEL_PARALLEL_ARGS[@]}     ${LOGGING_ARGS[@]}\\n\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":true,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi/output/training_logs\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"},\"Worker\":{\"replicas\":3,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi/output/training_logs\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":true,\"logPath\":\"/mnt/cluster/llamatest0718forxiaomi/output/training_logs\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":true,\"isCopyJob\":false,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
                      "prometheus.io/path": "/metrics",
                      "prometheus.io/port": "9101",
                      "prometheus.io/scrape": "true",
                      "scheduling.k8s.io/job-enable-oversell": "false"
                    },
                    "labels": {
                      "aijob.cce.baidubce.com/ai-user-id": "b5a24aa26e4d4f55bc3acf68edc4b051",
                      "aijob.cce.baidubce.com/ai-user-name": "zhangmuhua",
                      "aijob.cce.baidubce.com/create-from-aihcp": "true",
                      "aijob.cce.baidubce.com/openapi-jobid": "pytorch-5961a180-13bb-49a1-8c5d-58ad07e652e4"
                    }
                  },
                  "spec": {
                    "containers": [
                      {
                        "command": [
                          "/bin/bash",
                          "-c",
                          "\n#! /bin/bash\n\nMEGATRON_PATH=${MEGATRON_PATH:-\"/workspace/AIAK-Megatron\"}\nAIAK_TRAINING_PATH=${AIAK_TRAINING_PATH:-\"/workspace/AIAK-Training-LLM\"}\n\nDATA_PATH=${DATA_PATH:-\"/mnt/cluster/llama2/pile/pile-llama_text_document\"}\nTOKENIZER_PATH=${TOKENIZER_PATH:-\"/mnt/cluster/llama2/Llama-2-70b-hf/\"}\n\nCHECKPOINT_PATH=${CHECKPOINT_PATH:-\"/mnt/cluster/llama2/mcore_llama2_70b_tp4_pp4\"}\n\nTENSORBOARD_PATH=${TENSORBOARD_PATH:-\"/mnt/cluster/aiak-training-llm/tensorboard-log/llama2-70b-tp4pp4\"}\n\nGPUS_PER_NODE=8\n\n# Change for multinode config\nMASTER_ADDR=${MASTER_ADDR:-\"localhost\"}\nMASTER_PORT=${MASTER_PORT:-\"6000\"}\nNNODES=${WORLD_SIZE:-\"1\"}\nNODE_RANK=${RANK:-\"0\"}\n\nDISTRIBUTED_ARGS=(\n    --nproc_per_node $GPUS_PER_NODE\n    --nnodes $NNODES\n    --node_rank $NODE_RANK\n    --master_addr $MASTER_ADDR\n    --master_port $MASTER_PORT\n)\n\n# you can setup llama2-70b maunally\n#MODEL_ARGS=(\n#    --model-name llama2\n#    --num-layers 80\n#    --hidden-size 8192\n#    --ffn-hidden-size 28672\n#    --num-attention-heads 64\n#    --position-embedding-type rope\n#    --normalization RMSNorm\n#    --swiglu\n#    --attention-dropout 0\n#    --hidden-dropout 0\n#    --disable-bias-linear\n#    --untie-embeddings-and-output-weights\n#    --group-query-attention\n#    --num-query-groups 8\n#)\n\n# or you can setup llama2-70b by using the following command\nMODEL_ARGS=(\n    --model-name llama2-70b # options: llama2-7b, llama2-13b, llama2-70b\n)\n\nDATA_ARGS=(\n    --tokenizer-type HFTokenizer\n    --hf-tokenizer-path $TOKENIZER_PATH\n    --data-path $DATA_PATH\n    --split 949,50,1\n)\n\nTRAINING_ARGS=(\n    --training-phase pretrain # options: pretrain, sft\n    --seq-length 4096\n    --max-position-embeddings 4096\n    --init-method-std 0.01\n    --micro-batch-size 1\n    --global-batch-size 1024\n    --lr 0.0002\n    --min-lr 1.0e-5\n    --clip-grad 1.0\n    --weight-decay 0.01\n    --optimizer adam\n    --adam-beta1 0.9\n    --adam-beta2 0.95\n    --adam-eps 1e-05\n    --norm-epsilon 1e-6\n    --train-iters 500000\n    --lr-decay-iters 500000\n    --lr-decay-style cosine\n    --lr-warmup-fraction 0.002\n    --initial-loss-scale 65536\n    --fp16\n    --save-interval 5000\n    --eval-interval 1000\n    --eval-iters 10\n    #--ckpt-step 0\n    #--no-load-optim\n    #--no-load-rng\n)\n\nMODEL_PARALLEL_ARGS=(\n    --tensor-model-parallel-size 4\n    --pipeline-model-parallel-size 4\n    --use-distributed-optimizer\n    --overlap-grad-reduce\n    --overlap-param-gather\n    --distributed-backend nccl\n    --sequence-parallel\n    #--tp-comm-overlap # require mpi envrionment\n)\n\nLOGGING_ARGS=(\n    --log-interval 1\n    --tensorboard-dir ${TENSORBOARD_PATH}\n    --log-timers-to-tensorboard\n)\n\nif [ -n \"${WANDB_API_KEY}\" ]; then\n    LOGGING_ARGS+=(\n        --wandb-project ${WANDB_PROJECT}\n        --wandb-exp-name ${WANDB_NAME} \n    )\nfi\n\nPYTHONPATH=$MEGATRON_PATH:$AIAK_TRAINING_PATH:$PYTHONPATH     torchrun ${DISTRIBUTED_ARGS[@]}     $AIAK_TRAINING_PATH/aiak_training_llm/train.py     ${MODEL_ARGS[@]}     ${DATA_ARGS[@]}     ${TRAINING_ARGS[@]}     ${MODEL_PARALLEL_ARGS[@]}     ${LOGGING_ARGS[@]}\n"
                        ],
                        "env": [
                          {
                            "name": "AIHC_TENSORBOARD_LOG_PATH",
                            "value": "/mnt/cluster/llamatest0718forxiaomi/output/training_logs"
                          },
                          {
                            "name": "AIHC_JOB_NAME",
                            "value": "llamatest0718forxiaomi"
                          },
                          {
                            "name": "NCCL_IB_DISABLE",
                            "value": "0"
                          },
                          {
                            "name": "BCCL_BUS_BW_CALCULATE_MODE",
                            "value": "Agg"
                          },
                          {
                            "name": "BCCL_PROFILING_FILE",
                            "value": "/var/bccl/logs/busbw.cal.%h.%p"
                          }
                        ],
                        "image": "registry.baidubce.com/aihc-aiak/aiak-training-llm:ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release",
                        "imagePullPolicy": "Always",
                        "name": "pytorch",
                        "ports": [
                          {
                            "containerPort": 23456,
                            "name": "pytorchjob-port",
                            "protocol": "TCP"
                          }
                        ],
                        "resources": {
                          "limits": {
                            "baidu.com/a800_80g_cgpu": "8",
                            "rdma/hca": "1"
                          },
                          "requests": {
                            "baidu.com/a800_80g_cgpu": "8",
                            "rdma/hca": "1"
                          }
                        },
                        "securityContext": {
                          "capabilities": {
                            "add": [
                              "IPC_LOCK"
                            ]
                          }
                        },
                        "volumeMounts": [
                          {
                            "mountPath": "/dev/shm",
                            "name": "devshm"
                          },
                          {
                            "mountPath": "/mnt/cluster",
                            "name": "pvc-pfs"
                          },
                          {
                            "mountPath": "/var/bccl/logs",
                            "name": "bccl-logs-volume"
                          }
                        ]
                      },
                      {
                        "env": [
                          {
                            "name": "POD_NAME",
                            "valueFrom": {
                              "fieldRef": {
                                "apiVersion": "v1",
                                "fieldPath": "metadata.name"
                              }
                            }
                          },
                          {
                            "name": "POD_UID",
                            "valueFrom": {
                              "fieldRef": {
                                "apiVersion": "v1",
                                "fieldPath": "metadata.uid"
                              }
                            }
                          },
                          {
                            "name": "POD_NAMESPACE",
                            "valueFrom": {
                              "fieldRef": {
                                "apiVersion": "v1",
                                "fieldPath": "metadata.namespace"
                              }
                            }
                          },
                          {
                            "name": "NODE_NAME",
                            "valueFrom": {
                              "fieldRef": {
                                "apiVersion": "v1",
                                "fieldPath": "spec.nodeName"
                              }
                            }
                          },
                          {
                            "name": "JOB_NAME",
                            "value": "llamatest0718forxiaomi"
                          },
                          {
                            "name": "NODE_IP",
                            "valueFrom": {
                              "fieldRef": {
                                "apiVersion": "v1",
                                "fieldPath": "status.hostIP"
                              }
                            }
                          },
                          {
                            "name": "ENABLE_ELASTIC",
                            "value": "9"
                          },
                          {
                            "name": "GPUS_PER_NODE",
                            "value": "8"
                          },
                          {
                            "name": "BCCL_LOG_DIR",
                            "value": "/var/bccl/logs"
                          },
                          {
                            "name": "EXPORTER_PORT",
                            "value": "9101"
                          },
                          {
                            "name": "EXPORTER_INTERVAL",
                            "value": "60"
                          },
                          {
                            "name": "EXPORTER_PATH",
                            "value": "/metrics"
                          },
                          {
                            "name": "BCCL_BUS_BW_CALCULATE_MODE",
                            "value": "Agg"
                          },
                          {
                            "name": "BCCL_PROFILING_FILE",
                            "value": "/var/bccl/logs/busbw.cal.%h.%p"
                          }
                        ],
                        "image": "registry.baidubce.com/cce-plugin-dev/ftagent:v1.6-20240713172215",
                        "imagePullPolicy": "Always",
                        "name": "ftagent",
                        "ports": [
                          {
                            "containerPort": 9101,
                            "name": "exporter",
                            "protocol": "TCP"
                          }
                        ],
                        "resources": {},
                        "securityContext": {
                          "capabilities": {
                            "add": [
                              "IPC_LOCK"
                            ]
                          }
                        },
                        "volumeMounts": [
                          {
                            "mountPath": "/var/log/pods",
                            "name": "pod-log-volume"
                          },
                          {
                            "mountPath": "/home/cce",
                            "name": "container-log-volume"
                          },
                          {
                            "mountPath": "/var/bccl/logs",
                            "name": "bccl-logs-volume"
                          }
                        ]
                      }
                    ],
                    "dnsPolicy": "ClusterFirstWithHostNet",
                    "hostNetwork": true,
                    "schedulerName": "volcano",
                    "serviceAccountName": "ftagent-sa",
                    "shareProcessNamespace": true,
                    "volumes": [
                      {
                        "emptyDir": {
                          "medium": "Memory",
                          "sizeLimit": "10Gi"
                        },
                        "name": "devshm"
                      },
                      {
                        "name": "pvc-pfs",
                        "persistentVolumeClaim": {
                          "claimName": "pvc-pfs"
                        }
                      },
                      {
                        "emptyDir": {},
                        "name": "bccl-logs-volume"
                      },
                      {
                        "hostPath": {
                          "path": "/var/log/pods",
                          "type": "DirectoryOrCreate"
                        },
                        "name": "pod-log-volume"
                      },
                      {
                        "hostPath": {
                          "path": "/home/cce",
                          "type": "DirectoryOrCreate"
                        },
                        "name": "container-log-volume"
                      }
                    ]
                  }
                }
              },
              "Worker": {
                "replicas": 3,
                "restartPolicy": "Never",
                "template": {
                  "metadata": {
                    "annotations": {
                      "aijob.cce.baidubce.com/fault-tolerance-enabled": "true",
                      "aijob.cce.baidubce.com/openapi-jobid": "pytorch-5961a180-13bb-49a1-8c5d-58ad07e652e4",
                      "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
                      "aijob.cce.baidubce.com/raw-request": "{\"name\":\"llamatest0718forxiaomi\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"normal\",\"oversell\":false,\"faultTolerance\":true,\"command\":\"\\n#! /bin/bash\\n\\nMEGATRON_PATH=${MEGATRON_PATH:-\\\"/workspace/AIAK-Megatron\\\"}\\nAIAK_TRAINING_PATH=${AIAK_TRAINING_PATH:-\\\"/workspace/AIAK-Training-LLM\\\"}\\n\\nDATA_PATH=${DATA_PATH:-\\\"/mnt/cluster/llama2/pile/pile-llama_text_document\\\"}\\nTOKENIZER_PATH=${TOKENIZER_PATH:-\\\"/mnt/cluster/llama2/Llama-2-70b-hf/\\\"}\\n\\nCHECKPOINT_PATH=${CHECKPOINT_PATH:-\\\"/mnt/cluster/llama2/mcore_llama2_70b_tp4_pp4\\\"}\\n\\nTENSORBOARD_PATH=${TENSORBOARD_PATH:-\\\"/mnt/cluster/aiak-training-llm/tensorboard-log/llama2-70b-tp4pp4\\\"}\\n\\nGPUS_PER_NODE=8\\n\\n# Change for multinode config\\nMASTER_ADDR=${MASTER_ADDR:-\\\"localhost\\\"}\\nMASTER_PORT=${MASTER_PORT:-\\\"6000\\\"}\\nNNODES=${WORLD_SIZE:-\\\"1\\\"}\\nNODE_RANK=${RANK:-\\\"0\\\"}\\n\\nDISTRIBUTED_ARGS=(\\n    --nproc_per_node $GPUS_PER_NODE\\n    --nnodes $NNODES\\n    --node_rank $NODE_RANK\\n    --master_addr $MASTER_ADDR\\n    --master_port $MASTER_PORT\\n)\\n\\n# you can setup llama2-70b maunally\\n#MODEL_ARGS=(\\n#    --model-name llama2\\n#    --num-layers 80\\n#    --hidden-size 8192\\n#    --ffn-hidden-size 28672\\n#    --num-attention-heads 64\\n#    --position-embedding-type rope\\n#    --normalization RMSNorm\\n#    --swiglu\\n#    --attention-dropout 0\\n#    --hidden-dropout 0\\n#    --disable-bias-linear\\n#    --untie-embeddings-and-output-weights\\n#    --group-query-attention\\n#    --num-query-groups 8\\n#)\\n\\n# or you can setup llama2-70b by using the following command\\nMODEL_ARGS=(\\n    --model-name llama2-70b # options: llama2-7b, llama2-13b, llama2-70b\\n)\\n\\nDATA_ARGS=(\\n    --tokenizer-type HFTokenizer\\n    --hf-tokenizer-path $TOKENIZER_PATH\\n    --data-path $DATA_PATH\\n    --split 949,50,1\\n)\\n\\nTRAINING_ARGS=(\\n    --training-phase pretrain # options: pretrain, sft\\n    --seq-length 4096\\n    --max-position-embeddings 4096\\n    --init-method-std 0.01\\n    --micro-batch-size 1\\n    --global-batch-size 1024\\n    --lr 0.0002\\n    --min-lr 1.0e-5\\n    --clip-grad 1.0\\n    --weight-decay 0.01\\n    --optimizer adam\\n    --adam-beta1 0.9\\n    --adam-beta2 0.95\\n    --adam-eps 1e-05\\n    --norm-epsilon 1e-6\\n    --train-iters 500000\\n    --lr-decay-iters 500000\\n    --lr-decay-style cosine\\n    --lr-warmup-fraction 0.002\\n    --initial-loss-scale 65536\\n    --fp16\\n    --save-interval 5000\\n    --eval-interval 1000\\n    --eval-iters 10\\n    #--ckpt-step 0\\n    #--no-load-optim\\n    #--no-load-rng\\n)\\n\\nMODEL_PARALLEL_ARGS=(\\n    --tensor-model-parallel-size 4\\n    --pipeline-model-parallel-size 4\\n    --use-distributed-optimizer\\n    --overlap-grad-reduce\\n    --overlap-param-gather\\n    --distributed-backend nccl\\n    --sequence-parallel\\n    #--tp-comm-overlap # require mpi envrionment\\n)\\n\\nLOGGING_ARGS=(\\n    --log-interval 1\\n    --tensorboard-dir ${TENSORBOARD_PATH}\\n    --log-timers-to-tensorboard\\n)\\n\\nif [ -n \\\"${WANDB_API_KEY}\\\" ]; then\\n    LOGGING_ARGS+=(\\n        --wandb-project ${WANDB_PROJECT}\\n        --wandb-exp-name ${WANDB_NAME} \\n    )\\nfi\\n\\nPYTHONPATH=$MEGATRON_PATH:$AIAK_TRAINING_PATH:$PYTHONPATH     torchrun ${DISTRIBUTED_ARGS[@]}     $AIAK_TRAINING_PATH/aiak_training_llm/train.py     ${MODEL_ARGS[@]}     ${DATA_ARGS[@]}     ${TRAINING_ARGS[@]}     ${MODEL_PARALLEL_ARGS[@]}     ${LOGGING_ARGS[@]}\\n\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":true,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi/output/training_logs\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"},\"Worker\":{\"replicas\":3,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi/output/training_logs\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":true,\"logPath\":\"/mnt/cluster/llamatest0718forxiaomi/output/training_logs\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":true,\"isCopyJob\":false,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
                      "prometheus.io/path": "/metrics",
                      "prometheus.io/port": "9101",
                      "prometheus.io/scrape": "true",
                      "scheduling.k8s.io/job-enable-oversell": "false"
                    },
                    "labels": {
                      "aijob.cce.baidubce.com/ai-user-id": "b5a24aa26e4d4f55bc3acf68edc4b051",
                      "aijob.cce.baidubce.com/ai-user-name": "zhangmuhua",
                      "aijob.cce.baidubce.com/create-from-aihcp": "true",
                      "aijob.cce.baidubce.com/openapi-jobid": "pytorch-5961a180-13bb-49a1-8c5d-58ad07e652e4"
                    }
                  },
                  "spec": {
                    "containers": [
                      {
                        "command": [
                          "/bin/bash",
                          "-c",
                          "\n#! /bin/bash\n\nMEGATRON_PATH=${MEGATRON_PATH:-\"/workspace/AIAK-Megatron\"}\nAIAK_TRAINING_PATH=${AIAK_TRAINING_PATH:-\"/workspace/AIAK-Training-LLM\"}\n\nDATA_PATH=${DATA_PATH:-\"/mnt/cluster/llama2/pile/pile-llama_text_document\"}\nTOKENIZER_PATH=${TOKENIZER_PATH:-\"/mnt/cluster/llama2/Llama-2-70b-hf/\"}\n\nCHECKPOINT_PATH=${CHECKPOINT_PATH:-\"/mnt/cluster/llama2/mcore_llama2_70b_tp4_pp4\"}\n\nTENSORBOARD_PATH=${TENSORBOARD_PATH:-\"/mnt/cluster/aiak-training-llm/tensorboard-log/llama2-70b-tp4pp4\"}\n\nGPUS_PER_NODE=8\n\n# Change for multinode config\nMASTER_ADDR=${MASTER_ADDR:-\"localhost\"}\nMASTER_PORT=${MASTER_PORT:-\"6000\"}\nNNODES=${WORLD_SIZE:-\"1\"}\nNODE_RANK=${RANK:-\"0\"}\n\nDISTRIBUTED_ARGS=(\n    --nproc_per_node $GPUS_PER_NODE\n    --nnodes $NNODES\n    --node_rank $NODE_RANK\n    --master_addr $MASTER_ADDR\n    --master_port $MASTER_PORT\n)\n\n# you can setup llama2-70b maunally\n#MODEL_ARGS=(\n#    --model-name llama2\n#    --num-layers 80\n#    --hidden-size 8192\n#    --ffn-hidden-size 28672\n#    --num-attention-heads 64\n#    --position-embedding-type rope\n#    --normalization RMSNorm\n#    --swiglu\n#    --attention-dropout 0\n#    --hidden-dropout 0\n#    --disable-bias-linear\n#    --untie-embeddings-and-output-weights\n#    --group-query-attention\n#    --num-query-groups 8\n#)\n\n# or you can setup llama2-70b by using the following command\nMODEL_ARGS=(\n    --model-name llama2-70b # options: llama2-7b, llama2-13b, llama2-70b\n)\n\nDATA_ARGS=(\n    --tokenizer-type HFTokenizer\n    --hf-tokenizer-path $TOKENIZER_PATH\n    --data-path $DATA_PATH\n    --split 949,50,1\n)\n\nTRAINING_ARGS=(\n    --training-phase pretrain # options: pretrain, sft\n    --seq-length 4096\n    --max-position-embeddings 4096\n    --init-method-std 0.01\n    --micro-batch-size 1\n    --global-batch-size 1024\n    --lr 0.0002\n    --min-lr 1.0e-5\n    --clip-grad 1.0\n    --weight-decay 0.01\n    --optimizer adam\n    --adam-beta1 0.9\n    --adam-beta2 0.95\n    --adam-eps 1e-05\n    --norm-epsilon 1e-6\n    --train-iters 500000\n    --lr-decay-iters 500000\n    --lr-decay-style cosine\n    --lr-warmup-fraction 0.002\n    --initial-loss-scale 65536\n    --fp16\n    --save-interval 5000\n    --eval-interval 1000\n    --eval-iters 10\n    #--ckpt-step 0\n    #--no-load-optim\n    #--no-load-rng\n)\n\nMODEL_PARALLEL_ARGS=(\n    --tensor-model-parallel-size 4\n    --pipeline-model-parallel-size 4\n    --use-distributed-optimizer\n    --overlap-grad-reduce\n    --overlap-param-gather\n    --distributed-backend nccl\n    --sequence-parallel\n    #--tp-comm-overlap # require mpi envrionment\n)\n\nLOGGING_ARGS=(\n    --log-interval 1\n    --tensorboard-dir ${TENSORBOARD_PATH}\n    --log-timers-to-tensorboard\n)\n\nif [ -n \"${WANDB_API_KEY}\" ]; then\n    LOGGING_ARGS+=(\n        --wandb-project ${WANDB_PROJECT}\n        --wandb-exp-name ${WANDB_NAME} \n    )\nfi\n\nPYTHONPATH=$MEGATRON_PATH:$AIAK_TRAINING_PATH:$PYTHONPATH     torchrun ${DISTRIBUTED_ARGS[@]}     $AIAK_TRAINING_PATH/aiak_training_llm/train.py     ${MODEL_ARGS[@]}     ${DATA_ARGS[@]}     ${TRAINING_ARGS[@]}     ${MODEL_PARALLEL_ARGS[@]}     ${LOGGING_ARGS[@]}\n"
                        ],
                        "env": [
                          {
                            "name": "AIHC_TENSORBOARD_LOG_PATH",
                            "value": "/mnt/cluster/llamatest0718forxiaomi/output/training_logs"
                          },
                          {
                            "name": "AIHC_JOB_NAME",
                            "value": "llamatest0718forxiaomi"
                          },
                          {
                            "name": "NCCL_IB_DISABLE",
                            "value": "0"
                          },
                          {
                            "name": "BCCL_BUS_BW_CALCULATE_MODE",
                            "value": "Agg"
                          },
                          {
                            "name": "BCCL_PROFILING_FILE",
                            "value": "/var/bccl/logs/busbw.cal.%h.%p"
                          }
                        ],
                        "image": "registry.baidubce.com/aihc-aiak/aiak-training-llm:ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release",
                        "imagePullPolicy": "Always",
                        "name": "pytorch",
                        "ports": [
                          {
                            "containerPort": 23456,
                            "name": "pytorchjob-port",
                            "protocol": "TCP"
                          }
                        ],
                        "resources": {
                          "limits": {
                            "baidu.com/a800_80g_cgpu": "8",
                            "rdma/hca": "1"
                          },
                          "requests": {
                            "baidu.com/a800_80g_cgpu": "8",
                            "rdma/hca": "1"
                          }
                        },
                        "securityContext": {
                          "capabilities": {
                            "add": [
                              "IPC_LOCK"
                            ]
                          }
                        },
                        "volumeMounts": [
                          {
                            "mountPath": "/dev/shm",
                            "name": "devshm"
                          },
                          {
                            "mountPath": "/mnt/cluster",
                            "name": "pvc-pfs"
                          },
                          {
                            "mountPath": "/var/bccl/logs",
                            "name": "bccl-logs-volume"
                          }
                        ]
                      },
                      {
                        "env": [
                          {
                            "name": "POD_NAME",
                            "valueFrom": {
                              "fieldRef": {
                                "apiVersion": "v1",
                                "fieldPath": "metadata.name"
                              }
                            }
                          },
                          {
                            "name": "POD_UID",
                            "valueFrom": {
                              "fieldRef": {
                                "apiVersion": "v1",
                                "fieldPath": "metadata.uid"
                              }
                            }
                          },
                          {
                            "name": "POD_NAMESPACE",
                            "valueFrom": {
                              "fieldRef": {
                                "apiVersion": "v1",
                                "fieldPath": "metadata.namespace"
                              }
                            }
                          },
                          {
                            "name": "NODE_NAME",
                            "valueFrom": {
                              "fieldRef": {
                                "apiVersion": "v1",
                                "fieldPath": "spec.nodeName"
                              }
                            }
                          },
                          {
                            "name": "JOB_NAME",
                            "value": "llamatest0718forxiaomi"
                          },
                          {
                            "name": "NODE_IP",
                            "valueFrom": {
                              "fieldRef": {
                                "apiVersion": "v1",
                                "fieldPath": "status.hostIP"
                              }
                            }
                          },
                          {
                            "name": "ENABLE_ELASTIC",
                            "value": "9"
                          },
                          {
                            "name": "GPUS_PER_NODE",
                            "value": "8"
                          },
                          {
                            "name": "BCCL_LOG_DIR",
                            "value": "/var/bccl/logs"
                          },
                          {
                            "name": "EXPORTER_PORT",
                            "value": "9101"
                          },
                          {
                            "name": "EXPORTER_INTERVAL",
                            "value": "60"
                          },
                          {
                            "name": "EXPORTER_PATH",
                            "value": "/metrics"
                          },
                          {
                            "name": "BCCL_BUS_BW_CALCULATE_MODE",
                            "value": "Agg"
                          },
                          {
                            "name": "BCCL_PROFILING_FILE",
                            "value": "/var/bccl/logs/busbw.cal.%h.%p"
                          }
                        ],
                        "image": "registry.baidubce.com/cce-plugin-dev/ftagent:v1.6-20240713172215",
                        "imagePullPolicy": "Always",
                        "name": "ftagent",
                        "ports": [
                          {
                            "containerPort": 9101,
                            "name": "exporter",
                            "protocol": "TCP"
                          }
                        ],
                        "resources": {},
                        "securityContext": {
                          "capabilities": {
                            "add": [
                              "IPC_LOCK"
                            ]
                          }
                        },
                        "volumeMounts": [
                          {
                            "mountPath": "/var/log/pods",
                            "name": "pod-log-volume"
                          },
                          {
                            "mountPath": "/home/cce",
                            "name": "container-log-volume"
                          },
                          {
                            "mountPath": "/var/bccl/logs",
                            "name": "bccl-logs-volume"
                          }
                        ]
                      }
                    ],
                    "dnsPolicy": "ClusterFirstWithHostNet",
                    "hostNetwork": true,
                    "schedulerName": "volcano",
                    "serviceAccountName": "ftagent-sa",
                    "shareProcessNamespace": true,
                    "volumes": [
                      {
                        "emptyDir": {
                          "medium": "Memory",
                          "sizeLimit": "10Gi"
                        },
                        "name": "devshm"
                      },
                      {
                        "name": "pvc-pfs",
                        "persistentVolumeClaim": {
                          "claimName": "pvc-pfs"
                        }
                      },
                      {
                        "emptyDir": {},
                        "name": "bccl-logs-volume"
                      },
                      {
                        "hostPath": {
                          "path": "/var/log/pods",
                          "type": "DirectoryOrCreate"
                        },
                        "name": "pod-log-volume"
                      },
                      {
                        "hostPath": {
                          "path": "/home/cce",
                          "type": "DirectoryOrCreate"
                        },
                        "name": "container-log-volume"
                      }
                    ]
                  }
                }
              }
            },
            "runPolicy": {
              "cleanPodPolicy": "None",
              "schedulingPolicy": {
                "priorityClass": "high",
                "queue": "default"
              }
            }
          },
          "status": {
            "completionTime": "2024-07-18T02:19:36Z",
            "conditions": [
              {
                "lastTransitionTime": "2024-07-18T02:10:30Z",
                "lastUpdateTime": "2024-07-18T02:10:30Z",
                "message": "PyTorchJob llamatest0718forxiaomi is created.",
                "reason": "PyTorchJobCreated",
                "status": "True",
                "type": "Created"
              },
              {
                "lastTransitionTime": "2024-07-18T02:17:08Z",
                "lastUpdateTime": "2024-07-18T02:17:08Z",
                "message": "PyTorchJob llamatest0718forxiaomi is running.",
                "reason": "JobRunning",
                "status": "False",
                "type": "Running"
              },
              {
                "lastTransitionTime": "2024-07-18T02:19:36Z",
                "lastUpdateTime": "2024-07-18T02:19:36Z",
                "message": "PytorchJob default/llamatest0718forxiaomi is stopped",
                "reason": "PyTorchJobStopped",
                "status": "True",
                "type": "Stopped"
              },
              {
                "lastTransitionTime": "2024-07-18T02:19:36Z",
                "lastUpdateTime": "2024-07-18T02:19:36Z",
                "message": "PyTorchJob llamatest0718forxiaomi is failed because 3 Worker replica(s) failed.",
                "reason": "JobFailed",
                "status": "True",
                "type": "Failed"
              }
            ],
            "lastReconcileTime": "2024-07-18T02:10:31Z",
            "replicaStatuses": {
              "Master": {
                "failed": 1,
                "selector": "training.kubeflow.org/job-name=llamatest0718forxiaomi,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=master"
              },
              "Worker": {
                "failed": 3,
                "selector": "training.kubeflow.org/job-name=llamatest0718forxiaomi,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=worker"
              }
            },
            "startTime": "2024-07-18T02:10:32Z"
          }
        },
        {
          "apiVersion": "kubeflow.org/v1",
          "kind": "PyTorchJob",
          "metadata": {
            "annotations": {
              "aijob.cce.baidubce.com/barrier-finish": "1d8a5926-1916-4dc1-a8ad-f45ed67f6a5e",
              "aijob.cce.baidubce.com/fault-tolerance-enabled": "true",
              "aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": "",
              "aijob.cce.baidubce.com/internal-fault-tolerance-time": "2024-07-18T02:20:19.474955307Z",
              "aijob.cce.baidubce.com/openapi-jobid": "pytorch-bb0b516a-22c8-4a4f-a0cd-6cf33b80120f",
              "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
              "aijob.cce.baidubce.com/raw-request": "{\"name\":\"llamatest0718forxiaomi2\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"high\",\"oversell\":false,\"faultTolerance\":true,\"command\":\"\\n#! /bin/bash\\n\\nMEGATRON_PATH=${MEGATRON_PATH:-\\\"/workspace/AIAK-Megatron\\\"}\\nAIAK_TRAINING_PATH=${AIAK_TRAINING_PATH:-\\\"/workspace/AIAK-Training-LLM\\\"}\\n\\nDATA_PATH=${DATA_PATH:-\\\"/mnt/cluster/llama2/pile/pile-llama_text_document\\\"}\\nTOKENIZER_PATH=${TOKENIZER_PATH:-\\\"/mnt/cluster/llama2/Llama-2-70b-hf/\\\"}\\n\\nCHECKPOINT_PATH=${CHECKPOINT_PATH:-\\\"/mnt/cluster/llama2/mcore_llama2_70b_tp4_pp4\\\"}\\n\\nTENSORBOARD_PATH=${TENSORBOARD_PATH:-\\\"/mnt/cluster/aiak-training-llm/tensorboard-log/llama2-70b-tp4pp4\\\"}\\n\\nGPUS_PER_NODE=8\\n\\n# Change for multinode config\\nMASTER_ADDR=${MASTER_ADDR:-\\\"localhost\\\"}\\nMASTER_PORT=${MASTER_PORT:-\\\"6000\\\"}\\nNNODES=${WORLD_SIZE:-\\\"1\\\"}\\nNODE_RANK=${RANK:-\\\"0\\\"}\\n\\nDISTRIBUTED_ARGS=(\\n    --nproc_per_node $GPUS_PER_NODE\\n    --nnodes $NNODES\\n    --node_rank $NODE_RANK\\n    --master_addr $MASTER_ADDR\\n    --master_port $MASTER_PORT\\n)\\n\\n# you can setup llama2-70b maunally\\n#MODEL_ARGS=(\\n#    --model-name llama2\\n#    --num-layers 80\\n#    --hidden-size 8192\\n#    --ffn-hidden-size 28672\\n#    --num-attention-heads 64\\n#    --position-embedding-type rope\\n#    --normalization RMSNorm\\n#    --swiglu\\n#    --attention-dropout 0\\n#    --hidden-dropout 0\\n#    --disable-bias-linear\\n#    --untie-embeddings-and-output-weights\\n#    --group-query-attention\\n#    --num-query-groups 8\\n#)\\n\\n# or you can setup llama2-70b by using the following command\\nMODEL_ARGS=(\\n    --model-name llama2-70b # options: llama2-7b, llama2-13b, llama2-70b\\n)\\n\\nDATA_ARGS=(\\n    --tokenizer-type HFTokenizer\\n    --hf-tokenizer-path $TOKENIZER_PATH\\n    --data-path $DATA_PATH\\n    --split 949,50,1\\n)\\n\\nTRAINING_ARGS=(\\n    --training-phase pretrain # options: pretrain, sft\\n    --seq-length 4096\\n    --max-position-embeddings 4096\\n    --init-method-std 0.01\\n    --micro-batch-size 1\\n    --global-batch-size 1024\\n    --lr 0.0002\\n    --min-lr 1.0e-5\\n    --clip-grad 1.0\\n    --weight-decay 0.01\\n    --optimizer adam\\n    --adam-beta1 0.9\\n    --adam-beta2 0.95\\n    --adam-eps 1e-05\\n    --norm-epsilon 1e-6\\n    --train-iters 500000\\n    --lr-decay-iters 500000\\n    --lr-decay-style cosine\\n    --lr-warmup-fraction 0.002\\n    --initial-loss-scale 65536\\n    --fp16\\n    --save-interval 5000\\n    --eval-interval 1000\\n    --eval-iters 10\\n    #--ckpt-step 0\\n    #--no-load-optim\\n    #--no-load-rng\\n)\\n\\nMODEL_PARALLEL_ARGS=(\\n    --tensor-model-parallel-size 4\\n    --pipeline-model-parallel-size 4\\n    --use-distributed-optimizer\\n    --overlap-grad-reduce\\n    --overlap-param-gather\\n    --distributed-backend nccl\\n    --sequence-parallel\\n    #--tp-comm-overlap # require mpi envrionment\\n)\\n\\nLOGGING_ARGS=(\\n    --log-interval 1\\n    --tensorboard-dir ${TENSORBOARD_PATH}\\n    --log-timers-to-tensorboard\\n)\\n\\nif [ -n \\\"${WANDB_API_KEY}\\\" ]; then\\n    LOGGING_ARGS+=(\\n        --wandb-project ${WANDB_PROJECT}\\n        --wandb-exp-name ${WANDB_NAME} \\n    )\\nfi\\n\\nPYTHONPATH=$MEGATRON_PATH:$AIAK_TRAINING_PATH:$PYTHONPATH     torchrun ${DISTRIBUTED_ARGS[@]}     $AIAK_TRAINING_PATH/aiak_training_llm/train.py     ${MODEL_ARGS[@]}     ${DATA_ARGS[@]}     ${TRAINING_ARGS[@]}     ${MODEL_PARALLEL_ARGS[@]}     ${LOGGING_ARGS[@]}\\n\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":true,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi2\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi2/output/training_logs\",\"CUDA_DEVICE_MAX_CONNECTIONS\":\"1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"},\"Worker\":{\"replicas\":3,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi2\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi2/output/training_logs\",\"CUDA_DEVICE_MAX_CONNECTIONS\":\"1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":true,\"logPath\":\"/mnt/cluster/llamatest0718forxiaomi2/output/training_logs\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":true,\"isCopyJob\":true,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
              "aijob.cce.baidubce.com/timeline": "[{\"conditionType\":\"Created\",\"time\":1721269167},{\"conditionType\":\"Scheduled\",\"time\":1721269169},{\"conditionType\":\"Running\",\"time\":1721269189},{\"conditionType\":\"Abnormal\",\"time\":1721269219},{\"conditionType\":\"ManualTermination\",\"time\":1721269316}]",
              "job-manager/action": "stop",
              "scheduling.k8s.io/job-enable-oversell": "false",
              "tensorboard-gc": "true"
            },
            "creationTimestamp": "2024-07-18T02:19:27Z",
            "generation": 3,
            "labels": {
              "aijob.cce.baidubce.com/ai-user-id": "b5a24aa26e4d4f55bc3acf68edc4b051",
              "aijob.cce.baidubce.com/ai-user-name": "zhangmuhua",
              "aijob.cce.baidubce.com/create-from-aihcp": "true",
              "aijob.cce.baidubce.com/openapi-jobid": "pytorch-bb0b516a-22c8-4a4f-a0cd-6cf33b80120f"
            },
            "managedFields": [
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      "f:aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": {},
                      "f:aijob.cce.baidubce.com/timeline": {}
                    }
                  },
                  "f:spec": {
                    "f:runPolicy": {
                      "f:cleanPodPolicy": {}
                    }
                  }
                },
                "manager": "controller",
                "operation": "Update",
                "time": "2024-07-18T02:19:27Z"
              },
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      "f:aijob.cce.baidubce.com/barrier-finish": {}
                    }
                  }
                },
                "manager": "jobbarrier",
                "operation": "Update",
                "time": "2024-07-18T02:19:46Z"
              },
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      ".": {},
                      "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                      "f:aijob.cce.baidubce.com/openapi-jobid": {},
                      "f:aijob.cce.baidubce.com/pfs-id": {},
                      "f:aijob.cce.baidubce.com/raw-request": {},
                      "f:job-manager/action": {},
                      "f:scheduling.k8s.io/job-enable-oversell": {}
                    },
                    "f:labels": {
                      ".": {},
                      "f:aijob.cce.baidubce.com/ai-user-id": {},
                      "f:aijob.cce.baidubce.com/ai-user-name": {},
                      "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                      "f:aijob.cce.baidubce.com/openapi-jobid": {}
                    }
                  },
                  "f:spec": {
                    ".": {},
                    "f:pytorchReplicaSpecs": {
                      ".": {},
                      "f:Master": {
                        ".": {},
                        "f:replicas": {},
                        "f:restartPolicy": {},
                        "f:template": {
                          ".": {},
                          "f:metadata": {
                            ".": {},
                            "f:annotations": {
                              ".": {},
                              "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                              "f:aijob.cce.baidubce.com/openapi-jobid": {},
                              "f:aijob.cce.baidubce.com/pfs-id": {},
                              "f:aijob.cce.baidubce.com/raw-request": {},
                              "f:scheduling.k8s.io/job-enable-oversell": {}
                            },
                            "f:labels": {
                              ".": {},
                              "f:aijob.cce.baidubce.com/ai-user-id": {},
                              "f:aijob.cce.baidubce.com/ai-user-name": {},
                              "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                              "f:aijob.cce.baidubce.com/openapi-jobid": {}
                            }
                          },
                          "f:spec": {
                            ".": {},
                            "f:dnsPolicy": {},
                            "f:hostNetwork": {},
                            "f:schedulerName": {}
                          }
                        }
                      },
                      "f:Worker": {
                        ".": {},
                        "f:replicas": {},
                        "f:restartPolicy": {},
                        "f:template": {
                          ".": {},
                          "f:metadata": {
                            ".": {},
                            "f:annotations": {
                              ".": {},
                              "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                              "f:aijob.cce.baidubce.com/openapi-jobid": {},
                              "f:aijob.cce.baidubce.com/pfs-id": {},
                              "f:aijob.cce.baidubce.com/raw-request": {},
                              "f:scheduling.k8s.io/job-enable-oversell": {}
                            },
                            "f:labels": {
                              ".": {},
                              "f:aijob.cce.baidubce.com/ai-user-id": {},
                              "f:aijob.cce.baidubce.com/ai-user-name": {},
                              "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                              "f:aijob.cce.baidubce.com/openapi-jobid": {}
                            }
                          },
                          "f:spec": {
                            ".": {},
                            "f:dnsPolicy": {},
                            "f:hostNetwork": {},
                            "f:schedulerName": {}
                          }
                        }
                      }
                    },
                    "f:runPolicy": {
                      ".": {},
                      "f:schedulingPolicy": {
                        ".": {},
                        "f:priorityClass": {},
                        "f:queue": {}
                      }
                    }
                  }
                },
                "manager": "cce-ai-service",
                "operation": "Update",
                "time": "2024-07-18T02:21:56Z"
              },
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      "f:aijob.cce.baidubce.com/internal-fault-tolerance-time": {},
                      "f:tensorboard-gc": {}
                    }
                  },
                  "f:spec": {
                    "f:pytorchReplicaSpecs": {
                      "f:Master": {
                        "f:template": {
                          "f:metadata": {
                            "f:annotations": {
                              "f:prometheus.io/path": {},
                              "f:prometheus.io/port": {},
                              "f:prometheus.io/scrape": {}
                            }
                          },
                          "f:spec": {
                            "f:containers": {},
                            "f:serviceAccountName": {},
                            "f:shareProcessNamespace": {},
                            "f:volumes": {}
                          }
                        }
                      },
                      "f:Worker": {
                        "f:template": {
                          "f:metadata": {
                            "f:annotations": {
                              "f:prometheus.io/path": {},
                              "f:prometheus.io/port": {},
                              "f:prometheus.io/scrape": {}
                            }
                          },
                          "f:spec": {
                            "f:containers": {},
                            "f:serviceAccountName": {},
                            "f:shareProcessNamespace": {},
                            "f:volumes": {}
                          }
                        }
                      }
                    }
                  },
                  "f:status": {
                    ".": {},
                    "f:completionTime": {},
                    "f:conditions": {},
                    "f:lastReconcileTime": {},
                    "f:replicaStatuses": {
                      ".": {},
                      "f:Master": {
                        ".": {},
                        "f:failed": {}
                      },
                      "f:Worker": {
                        ".": {},
                        "f:failed": {}
                      }
                    },
                    "f:startTime": {}
                  }
                },
                "manager": "manager",
                "operation": "Update",
                "time": "2024-07-19T02:19:55Z"
              }
            ],
            "name": "llamatest0718forxiaomi2",
            "namespace": "default",
            "resourceVersion": "2372387205",
            "uid": "e47f6034-7100-4e2f-9e3d-e800a2017161"
          },
          "spec": {
            "pytorchReplicaSpecs": {
              "Master": {
                "replicas": 1,
                "restartPolicy": "Never",
                "template": {
                  "metadata": {
                    "annotations": {
                      "aijob.cce.baidubce.com/fault-tolerance-enabled": "true",
                      "aijob.cce.baidubce.com/openapi-jobid": "pytorch-bb0b516a-22c8-4a4f-a0cd-6cf33b80120f",
                      "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
                      "aijob.cce.baidubce.com/raw-request": "{\"name\":\"llamatest0718forxiaomi2\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"high\",\"oversell\":false,\"faultTolerance\":true,\"command\":\"\\n#! /bin/bash\\n\\nMEGATRON_PATH=${MEGATRON_PATH:-\\\"/workspace/AIAK-Megatron\\\"}\\nAIAK_TRAINING_PATH=${AIAK_TRAINING_PATH:-\\\"/workspace/AIAK-Training-LLM\\\"}\\n\\nDATA_PATH=${DATA_PATH:-\\\"/mnt/cluster/llama2/pile/pile-llama_text_document\\\"}\\nTOKENIZER_PATH=${TOKENIZER_PATH:-\\\"/mnt/cluster/llama2/Llama-2-70b-hf/\\\"}\\n\\nCHECKPOINT_PATH=${CHECKPOINT_PATH:-\\\"/mnt/cluster/llama2/mcore_llama2_70b_tp4_pp4\\\"}\\n\\nTENSORBOARD_PATH=${TENSORBOARD_PATH:-\\\"/mnt/cluster/aiak-training-llm/tensorboard-log/llama2-70b-tp4pp4\\\"}\\n\\nGPUS_PER_NODE=8\\n\\n# Change for multinode config\\nMASTER_ADDR=${MASTER_ADDR:-\\\"localhost\\\"}\\nMASTER_PORT=${MASTER_PORT:-\\\"6000\\\"}\\nNNODES=${WORLD_SIZE:-\\\"1\\\"}\\nNODE_RANK=${RANK:-\\\"0\\\"}\\n\\nDISTRIBUTED_ARGS=(\\n    --nproc_per_node $GPUS_PER_NODE\\n    --nnodes $NNODES\\n    --node_rank $NODE_RANK\\n    --master_addr $MASTER_ADDR\\n    --master_port $MASTER_PORT\\n)\\n\\n# you can setup llama2-70b maunally\\n#MODEL_ARGS=(\\n#    --model-name llama2\\n#    --num-layers 80\\n#    --hidden-size 8192\\n#    --ffn-hidden-size 28672\\n#    --num-attention-heads 64\\n#    --position-embedding-type rope\\n#    --normalization RMSNorm\\n#    --swiglu\\n#    --attention-dropout 0\\n#    --hidden-dropout 0\\n#    --disable-bias-linear\\n#    --untie-embeddings-and-output-weights\\n#    --group-query-attention\\n#    --num-query-groups 8\\n#)\\n\\n# or you can setup llama2-70b by using the following command\\nMODEL_ARGS=(\\n    --model-name llama2-70b # options: llama2-7b, llama2-13b, llama2-70b\\n)\\n\\nDATA_ARGS=(\\n    --tokenizer-type HFTokenizer\\n    --hf-tokenizer-path $TOKENIZER_PATH\\n    --data-path $DATA_PATH\\n    --split 949,50,1\\n)\\n\\nTRAINING_ARGS=(\\n    --training-phase pretrain # options: pretrain, sft\\n    --seq-length 4096\\n    --max-position-embeddings 4096\\n    --init-method-std 0.01\\n    --micro-batch-size 1\\n    --global-batch-size 1024\\n    --lr 0.0002\\n    --min-lr 1.0e-5\\n    --clip-grad 1.0\\n    --weight-decay 0.01\\n    --optimizer adam\\n    --adam-beta1 0.9\\n    --adam-beta2 0.95\\n    --adam-eps 1e-05\\n    --norm-epsilon 1e-6\\n    --train-iters 500000\\n    --lr-decay-iters 500000\\n    --lr-decay-style cosine\\n    --lr-warmup-fraction 0.002\\n    --initial-loss-scale 65536\\n    --fp16\\n    --save-interval 5000\\n    --eval-interval 1000\\n    --eval-iters 10\\n    #--ckpt-step 0\\n    #--no-load-optim\\n    #--no-load-rng\\n)\\n\\nMODEL_PARALLEL_ARGS=(\\n    --tensor-model-parallel-size 4\\n    --pipeline-model-parallel-size 4\\n    --use-distributed-optimizer\\n    --overlap-grad-reduce\\n    --overlap-param-gather\\n    --distributed-backend nccl\\n    --sequence-parallel\\n    #--tp-comm-overlap # require mpi envrionment\\n)\\n\\nLOGGING_ARGS=(\\n    --log-interval 1\\n    --tensorboard-dir ${TENSORBOARD_PATH}\\n    --log-timers-to-tensorboard\\n)\\n\\nif [ -n \\\"${WANDB_API_KEY}\\\" ]; then\\n    LOGGING_ARGS+=(\\n        --wandb-project ${WANDB_PROJECT}\\n        --wandb-exp-name ${WANDB_NAME} \\n    )\\nfi\\n\\nPYTHONPATH=$MEGATRON_PATH:$AIAK_TRAINING_PATH:$PYTHONPATH     torchrun ${DISTRIBUTED_ARGS[@]}     $AIAK_TRAINING_PATH/aiak_training_llm/train.py     ${MODEL_ARGS[@]}     ${DATA_ARGS[@]}     ${TRAINING_ARGS[@]}     ${MODEL_PARALLEL_ARGS[@]}     ${LOGGING_ARGS[@]}\\n\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":true,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi2\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi2/output/training_logs\",\"CUDA_DEVICE_MAX_CONNECTIONS\":\"1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"},\"Worker\":{\"replicas\":3,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi2\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi2/output/training_logs\",\"CUDA_DEVICE_MAX_CONNECTIONS\":\"1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":true,\"logPath\":\"/mnt/cluster/llamatest0718forxiaomi2/output/training_logs\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":true,\"isCopyJob\":true,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
                      "prometheus.io/path": "/metrics",
                      "prometheus.io/port": "9101",
                      "prometheus.io/scrape": "true",
                      "scheduling.k8s.io/job-enable-oversell": "false"
                    },
                    "labels": {
                      "aijob.cce.baidubce.com/ai-user-id": "b5a24aa26e4d4f55bc3acf68edc4b051",
                      "aijob.cce.baidubce.com/ai-user-name": "zhangmuhua",
                      "aijob.cce.baidubce.com/create-from-aihcp": "true",
                      "aijob.cce.baidubce.com/openapi-jobid": "pytorch-bb0b516a-22c8-4a4f-a0cd-6cf33b80120f"
                    }
                  },
                  "spec": {
                    "containers": [
                      {
                        "command": [
                          "/bin/bash",
                          "-c",
                          "\n#! /bin/bash\n\nMEGATRON_PATH=${MEGATRON_PATH:-\"/workspace/AIAK-Megatron\"}\nAIAK_TRAINING_PATH=${AIAK_TRAINING_PATH:-\"/workspace/AIAK-Training-LLM\"}\n\nDATA_PATH=${DATA_PATH:-\"/mnt/cluster/llama2/pile/pile-llama_text_document\"}\nTOKENIZER_PATH=${TOKENIZER_PATH:-\"/mnt/cluster/llama2/Llama-2-70b-hf/\"}\n\nCHECKPOINT_PATH=${CHECKPOINT_PATH:-\"/mnt/cluster/llama2/mcore_llama2_70b_tp4_pp4\"}\n\nTENSORBOARD_PATH=${TENSORBOARD_PATH:-\"/mnt/cluster/aiak-training-llm/tensorboard-log/llama2-70b-tp4pp4\"}\n\nGPUS_PER_NODE=8\n\n# Change for multinode config\nMASTER_ADDR=${MASTER_ADDR:-\"localhost\"}\nMASTER_PORT=${MASTER_PORT:-\"6000\"}\nNNODES=${WORLD_SIZE:-\"1\"}\nNODE_RANK=${RANK:-\"0\"}\n\nDISTRIBUTED_ARGS=(\n    --nproc_per_node $GPUS_PER_NODE\n    --nnodes $NNODES\n    --node_rank $NODE_RANK\n    --master_addr $MASTER_ADDR\n    --master_port $MASTER_PORT\n)\n\n# you can setup llama2-70b maunally\n#MODEL_ARGS=(\n#    --model-name llama2\n#    --num-layers 80\n#    --hidden-size 8192\n#    --ffn-hidden-size 28672\n#    --num-attention-heads 64\n#    --position-embedding-type rope\n#    --normalization RMSNorm\n#    --swiglu\n#    --attention-dropout 0\n#    --hidden-dropout 0\n#    --disable-bias-linear\n#    --untie-embeddings-and-output-weights\n#    --group-query-attention\n#    --num-query-groups 8\n#)\n\n# or you can setup llama2-70b by using the following command\nMODEL_ARGS=(\n    --model-name llama2-70b # options: llama2-7b, llama2-13b, llama2-70b\n)\n\nDATA_ARGS=(\n    --tokenizer-type HFTokenizer\n    --hf-tokenizer-path $TOKENIZER_PATH\n    --data-path $DATA_PATH\n    --split 949,50,1\n)\n\nTRAINING_ARGS=(\n    --training-phase pretrain # options: pretrain, sft\n    --seq-length 4096\n    --max-position-embeddings 4096\n    --init-method-std 0.01\n    --micro-batch-size 1\n    --global-batch-size 1024\n    --lr 0.0002\n    --min-lr 1.0e-5\n    --clip-grad 1.0\n    --weight-decay 0.01\n    --optimizer adam\n    --adam-beta1 0.9\n    --adam-beta2 0.95\n    --adam-eps 1e-05\n    --norm-epsilon 1e-6\n    --train-iters 500000\n    --lr-decay-iters 500000\n    --lr-decay-style cosine\n    --lr-warmup-fraction 0.002\n    --initial-loss-scale 65536\n    --fp16\n    --save-interval 5000\n    --eval-interval 1000\n    --eval-iters 10\n    #--ckpt-step 0\n    #--no-load-optim\n    #--no-load-rng\n)\n\nMODEL_PARALLEL_ARGS=(\n    --tensor-model-parallel-size 4\n    --pipeline-model-parallel-size 4\n    --use-distributed-optimizer\n    --overlap-grad-reduce\n    --overlap-param-gather\n    --distributed-backend nccl\n    --sequence-parallel\n    #--tp-comm-overlap # require mpi envrionment\n)\n\nLOGGING_ARGS=(\n    --log-interval 1\n    --tensorboard-dir ${TENSORBOARD_PATH}\n    --log-timers-to-tensorboard\n)\n\nif [ -n \"${WANDB_API_KEY}\" ]; then\n    LOGGING_ARGS+=(\n        --wandb-project ${WANDB_PROJECT}\n        --wandb-exp-name ${WANDB_NAME} \n    )\nfi\n\nPYTHONPATH=$MEGATRON_PATH:$AIAK_TRAINING_PATH:$PYTHONPATH     torchrun ${DISTRIBUTED_ARGS[@]}     $AIAK_TRAINING_PATH/aiak_training_llm/train.py     ${MODEL_ARGS[@]}     ${DATA_ARGS[@]}     ${TRAINING_ARGS[@]}     ${MODEL_PARALLEL_ARGS[@]}     ${LOGGING_ARGS[@]}\n"
                        ],
                        "env": [
                          {
                            "name": "CUDA_DEVICE_MAX_CONNECTIONS",
                            "value": "1"
                          },
                          {
                            "name": "AIHC_TENSORBOARD_LOG_PATH",
                            "value": "/mnt/cluster/llamatest0718forxiaomi2/output/training_logs"
                          },
                          {
                            "name": "AIHC_JOB_NAME",
                            "value": "llamatest0718forxiaomi2"
                          },
                          {
                            "name": "NCCL_IB_DISABLE",
                            "value": "0"
                          },
                          {
                            "name": "BCCL_BUS_BW_CALCULATE_MODE",
                            "value": "Agg"
                          },
                          {
                            "name": "BCCL_PROFILING_FILE",
                            "value": "/var/bccl/logs/busbw.cal.%h.%p"
                          }
                        ],
                        "image": "registry.baidubce.com/aihc-aiak/aiak-training-llm:ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release",
                        "imagePullPolicy": "Always",
                        "name": "pytorch",
                        "ports": [
                          {
                            "containerPort": 23456,
                            "name": "pytorchjob-port",
                            "protocol": "TCP"
                          }
                        ],
                        "resources": {
                          "limits": {
                            "baidu.com/a800_80g_cgpu": "8",
                            "rdma/hca": "1"
                          },
                          "requests": {
                            "baidu.com/a800_80g_cgpu": "8",
                            "rdma/hca": "1"
                          }
                        },
                        "securityContext": {
                          "capabilities": {
                            "add": [
                              "IPC_LOCK"
                            ]
                          }
                        },
                        "volumeMounts": [
                          {
                            "mountPath": "/dev/shm",
                            "name": "devshm"
                          },
                          {
                            "mountPath": "/mnt/cluster",
                            "name": "pvc-pfs"
                          },
                          {
                            "mountPath": "/var/bccl/logs",
                            "name": "bccl-logs-volume"
                          }
                        ]
                      },
                      {
                        "env": [
                          {
                            "name": "POD_NAME",
                            "valueFrom": {
                              "fieldRef": {
                                "apiVersion": "v1",
                                "fieldPath": "metadata.name"
                              }
                            }
                          },
                          {
                            "name": "POD_UID",
                            "valueFrom": {
                              "fieldRef": {
                                "apiVersion": "v1",
                                "fieldPath": "metadata.uid"
                              }
                            }
                          },
                          {
                            "name": "POD_NAMESPACE",
                            "valueFrom": {
                              "fieldRef": {
                                "apiVersion": "v1",
                                "fieldPath": "metadata.namespace"
                              }
                            }
                          },
                          {
                            "name": "NODE_NAME",
                            "valueFrom": {
                              "fieldRef": {
                                "apiVersion": "v1",
                                "fieldPath": "spec.nodeName"
                              }
                            }
                          },
                          {
                            "name": "JOB_NAME",
                            "value": "llamatest0718forxiaomi2"
                          },
                          {
                            "name": "NODE_IP",
                            "valueFrom": {
                              "fieldRef": {
                                "apiVersion": "v1",
                                "fieldPath": "status.hostIP"
                              }
                            }
                          },
                          {
                            "name": "ENABLE_ELASTIC",
                            "value": "9"
                          },
                          {
                            "name": "GPUS_PER_NODE",
                            "value": "8"
                          },
                          {
                            "name": "BCCL_LOG_DIR",
                            "value": "/var/bccl/logs"
                          },
                          {
                            "name": "EXPORTER_PORT",
                            "value": "9101"
                          },
                          {
                            "name": "EXPORTER_INTERVAL",
                            "value": "60"
                          },
                          {
                            "name": "EXPORTER_PATH",
                            "value": "/metrics"
                          },
                          {
                            "name": "BCCL_BUS_BW_CALCULATE_MODE",
                            "value": "Agg"
                          },
                          {
                            "name": "BCCL_PROFILING_FILE",
                            "value": "/var/bccl/logs/busbw.cal.%h.%p"
                          }
                        ],
                        "image": "registry.baidubce.com/cce-plugin-dev/ftagent:v1.6-20240713172215",
                        "imagePullPolicy": "Always",
                        "name": "ftagent",
                        "ports": [
                          {
                            "containerPort": 9101,
                            "name": "exporter",
                            "protocol": "TCP"
                          }
                        ],
                        "resources": {},
                        "securityContext": {
                          "capabilities": {
                            "add": [
                              "IPC_LOCK"
                            ]
                          }
                        },
                        "volumeMounts": [
                          {
                            "mountPath": "/var/log/pods",
                            "name": "pod-log-volume"
                          },
                          {
                            "mountPath": "/home/cce",
                            "name": "container-log-volume"
                          },
                          {
                            "mountPath": "/var/bccl/logs",
                            "name": "bccl-logs-volume"
                          }
                        ]
                      }
                    ],
                    "dnsPolicy": "ClusterFirstWithHostNet",
                    "hostNetwork": true,
                    "schedulerName": "volcano",
                    "serviceAccountName": "ftagent-sa",
                    "shareProcessNamespace": true,
                    "volumes": [
                      {
                        "emptyDir": {
                          "medium": "Memory",
                          "sizeLimit": "10Gi"
                        },
                        "name": "devshm"
                      },
                      {
                        "name": "pvc-pfs",
                        "persistentVolumeClaim": {
                          "claimName": "pvc-pfs"
                        }
                      },
                      {
                        "emptyDir": {},
                        "name": "bccl-logs-volume"
                      },
                      {
                        "hostPath": {
                          "path": "/var/log/pods",
                          "type": "DirectoryOrCreate"
                        },
                        "name": "pod-log-volume"
                      },
                      {
                        "hostPath": {
                          "path": "/home/cce",
                          "type": "DirectoryOrCreate"
                        },
                        "name": "container-log-volume"
                      }
                    ]
                  }
                }
              },
              "Worker": {
                "replicas": 3,
                "restartPolicy": "Never",
                "template": {
                  "metadata": {
                    "annotations": {
                      "aijob.cce.baidubce.com/fault-tolerance-enabled": "true",
                      "aijob.cce.baidubce.com/openapi-jobid": "pytorch-bb0b516a-22c8-4a4f-a0cd-6cf33b80120f",
                      "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
                      "aijob.cce.baidubce.com/raw-request": "{\"name\":\"llamatest0718forxiaomi2\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"high\",\"oversell\":false,\"faultTolerance\":true,\"command\":\"\\n#! /bin/bash\\n\\nMEGATRON_PATH=${MEGATRON_PATH:-\\\"/workspace/AIAK-Megatron\\\"}\\nAIAK_TRAINING_PATH=${AIAK_TRAINING_PATH:-\\\"/workspace/AIAK-Training-LLM\\\"}\\n\\nDATA_PATH=${DATA_PATH:-\\\"/mnt/cluster/llama2/pile/pile-llama_text_document\\\"}\\nTOKENIZER_PATH=${TOKENIZER_PATH:-\\\"/mnt/cluster/llama2/Llama-2-70b-hf/\\\"}\\n\\nCHECKPOINT_PATH=${CHECKPOINT_PATH:-\\\"/mnt/cluster/llama2/mcore_llama2_70b_tp4_pp4\\\"}\\n\\nTENSORBOARD_PATH=${TENSORBOARD_PATH:-\\\"/mnt/cluster/aiak-training-llm/tensorboard-log/llama2-70b-tp4pp4\\\"}\\n\\nGPUS_PER_NODE=8\\n\\n# Change for multinode config\\nMASTER_ADDR=${MASTER_ADDR:-\\\"localhost\\\"}\\nMASTER_PORT=${MASTER_PORT:-\\\"6000\\\"}\\nNNODES=${WORLD_SIZE:-\\\"1\\\"}\\nNODE_RANK=${RANK:-\\\"0\\\"}\\n\\nDISTRIBUTED_ARGS=(\\n    --nproc_per_node $GPUS_PER_NODE\\n    --nnodes $NNODES\\n    --node_rank $NODE_RANK\\n    --master_addr $MASTER_ADDR\\n    --master_port $MASTER_PORT\\n)\\n\\n# you can setup llama2-70b maunally\\n#MODEL_ARGS=(\\n#    --model-name llama2\\n#    --num-layers 80\\n#    --hidden-size 8192\\n#    --ffn-hidden-size 28672\\n#    --num-attention-heads 64\\n#    --position-embedding-type rope\\n#    --normalization RMSNorm\\n#    --swiglu\\n#    --attention-dropout 0\\n#    --hidden-dropout 0\\n#    --disable-bias-linear\\n#    --untie-embeddings-and-output-weights\\n#    --group-query-attention\\n#    --num-query-groups 8\\n#)\\n\\n# or you can setup llama2-70b by using the following command\\nMODEL_ARGS=(\\n    --model-name llama2-70b # options: llama2-7b, llama2-13b, llama2-70b\\n)\\n\\nDATA_ARGS=(\\n    --tokenizer-type HFTokenizer\\n    --hf-tokenizer-path $TOKENIZER_PATH\\n    --data-path $DATA_PATH\\n    --split 949,50,1\\n)\\n\\nTRAINING_ARGS=(\\n    --training-phase pretrain # options: pretrain, sft\\n    --seq-length 4096\\n    --max-position-embeddings 4096\\n    --init-method-std 0.01\\n    --micro-batch-size 1\\n    --global-batch-size 1024\\n    --lr 0.0002\\n    --min-lr 1.0e-5\\n    --clip-grad 1.0\\n    --weight-decay 0.01\\n    --optimizer adam\\n    --adam-beta1 0.9\\n    --adam-beta2 0.95\\n    --adam-eps 1e-05\\n    --norm-epsilon 1e-6\\n    --train-iters 500000\\n    --lr-decay-iters 500000\\n    --lr-decay-style cosine\\n    --lr-warmup-fraction 0.002\\n    --initial-loss-scale 65536\\n    --fp16\\n    --save-interval 5000\\n    --eval-interval 1000\\n    --eval-iters 10\\n    #--ckpt-step 0\\n    #--no-load-optim\\n    #--no-load-rng\\n)\\n\\nMODEL_PARALLEL_ARGS=(\\n    --tensor-model-parallel-size 4\\n    --pipeline-model-parallel-size 4\\n    --use-distributed-optimizer\\n    --overlap-grad-reduce\\n    --overlap-param-gather\\n    --distributed-backend nccl\\n    --sequence-parallel\\n    #--tp-comm-overlap # require mpi envrionment\\n)\\n\\nLOGGING_ARGS=(\\n    --log-interval 1\\n    --tensorboard-dir ${TENSORBOARD_PATH}\\n    --log-timers-to-tensorboard\\n)\\n\\nif [ -n \\\"${WANDB_API_KEY}\\\" ]; then\\n    LOGGING_ARGS+=(\\n        --wandb-project ${WANDB_PROJECT}\\n        --wandb-exp-name ${WANDB_NAME} \\n    )\\nfi\\n\\nPYTHONPATH=$MEGATRON_PATH:$AIAK_TRAINING_PATH:$PYTHONPATH     torchrun ${DISTRIBUTED_ARGS[@]}     $AIAK_TRAINING_PATH/aiak_training_llm/train.py     ${MODEL_ARGS[@]}     ${DATA_ARGS[@]}     ${TRAINING_ARGS[@]}     ${MODEL_PARALLEL_ARGS[@]}     ${LOGGING_ARGS[@]}\\n\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":true,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi2\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi2/output/training_logs\",\"CUDA_DEVICE_MAX_CONNECTIONS\":\"1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"},\"Worker\":{\"replicas\":3,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi2\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi2/output/training_logs\",\"CUDA_DEVICE_MAX_CONNECTIONS\":\"1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":true,\"logPath\":\"/mnt/cluster/llamatest0718forxiaomi2/output/training_logs\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":true,\"isCopyJob\":true,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
                      "prometheus.io/path": "/metrics",
                      "prometheus.io/port": "9101",
                      "prometheus.io/scrape": "true",
                      "scheduling.k8s.io/job-enable-oversell": "false"
                    },
                    "labels": {
                      "aijob.cce.baidubce.com/ai-user-id": "b5a24aa26e4d4f55bc3acf68edc4b051",
                      "aijob.cce.baidubce.com/ai-user-name": "zhangmuhua",
                      "aijob.cce.baidubce.com/create-from-aihcp": "true",
                      "aijob.cce.baidubce.com/openapi-jobid": "pytorch-bb0b516a-22c8-4a4f-a0cd-6cf33b80120f"
                    }
                  },
                  "spec": {
                    "containers": [
                      {
                        "command": [
                          "/bin/bash",
                          "-c",
                          "\n#! /bin/bash\n\nMEGATRON_PATH=${MEGATRON_PATH:-\"/workspace/AIAK-Megatron\"}\nAIAK_TRAINING_PATH=${AIAK_TRAINING_PATH:-\"/workspace/AIAK-Training-LLM\"}\n\nDATA_PATH=${DATA_PATH:-\"/mnt/cluster/llama2/pile/pile-llama_text_document\"}\nTOKENIZER_PATH=${TOKENIZER_PATH:-\"/mnt/cluster/llama2/Llama-2-70b-hf/\"}\n\nCHECKPOINT_PATH=${CHECKPOINT_PATH:-\"/mnt/cluster/llama2/mcore_llama2_70b_tp4_pp4\"}\n\nTENSORBOARD_PATH=${TENSORBOARD_PATH:-\"/mnt/cluster/aiak-training-llm/tensorboard-log/llama2-70b-tp4pp4\"}\n\nGPUS_PER_NODE=8\n\n# Change for multinode config\nMASTER_ADDR=${MASTER_ADDR:-\"localhost\"}\nMASTER_PORT=${MASTER_PORT:-\"6000\"}\nNNODES=${WORLD_SIZE:-\"1\"}\nNODE_RANK=${RANK:-\"0\"}\n\nDISTRIBUTED_ARGS=(\n    --nproc_per_node $GPUS_PER_NODE\n    --nnodes $NNODES\n    --node_rank $NODE_RANK\n    --master_addr $MASTER_ADDR\n    --master_port $MASTER_PORT\n)\n\n# you can setup llama2-70b maunally\n#MODEL_ARGS=(\n#    --model-name llama2\n#    --num-layers 80\n#    --hidden-size 8192\n#    --ffn-hidden-size 28672\n#    --num-attention-heads 64\n#    --position-embedding-type rope\n#    --normalization RMSNorm\n#    --swiglu\n#    --attention-dropout 0\n#    --hidden-dropout 0\n#    --disable-bias-linear\n#    --untie-embeddings-and-output-weights\n#    --group-query-attention\n#    --num-query-groups 8\n#)\n\n# or you can setup llama2-70b by using the following command\nMODEL_ARGS=(\n    --model-name llama2-70b # options: llama2-7b, llama2-13b, llama2-70b\n)\n\nDATA_ARGS=(\n    --tokenizer-type HFTokenizer\n    --hf-tokenizer-path $TOKENIZER_PATH\n    --data-path $DATA_PATH\n    --split 949,50,1\n)\n\nTRAINING_ARGS=(\n    --training-phase pretrain # options: pretrain, sft\n    --seq-length 4096\n    --max-position-embeddings 4096\n    --init-method-std 0.01\n    --micro-batch-size 1\n    --global-batch-size 1024\n    --lr 0.0002\n    --min-lr 1.0e-5\n    --clip-grad 1.0\n    --weight-decay 0.01\n    --optimizer adam\n    --adam-beta1 0.9\n    --adam-beta2 0.95\n    --adam-eps 1e-05\n    --norm-epsilon 1e-6\n    --train-iters 500000\n    --lr-decay-iters 500000\n    --lr-decay-style cosine\n    --lr-warmup-fraction 0.002\n    --initial-loss-scale 65536\n    --fp16\n    --save-interval 5000\n    --eval-interval 1000\n    --eval-iters 10\n    #--ckpt-step 0\n    #--no-load-optim\n    #--no-load-rng\n)\n\nMODEL_PARALLEL_ARGS=(\n    --tensor-model-parallel-size 4\n    --pipeline-model-parallel-size 4\n    --use-distributed-optimizer\n    --overlap-grad-reduce\n    --overlap-param-gather\n    --distributed-backend nccl\n    --sequence-parallel\n    #--tp-comm-overlap # require mpi envrionment\n)\n\nLOGGING_ARGS=(\n    --log-interval 1\n    --tensorboard-dir ${TENSORBOARD_PATH}\n    --log-timers-to-tensorboard\n)\n\nif [ -n \"${WANDB_API_KEY}\" ]; then\n    LOGGING_ARGS+=(\n        --wandb-project ${WANDB_PROJECT}\n        --wandb-exp-name ${WANDB_NAME} \n    )\nfi\n\nPYTHONPATH=$MEGATRON_PATH:$AIAK_TRAINING_PATH:$PYTHONPATH     torchrun ${DISTRIBUTED_ARGS[@]}     $AIAK_TRAINING_PATH/aiak_training_llm/train.py     ${MODEL_ARGS[@]}     ${DATA_ARGS[@]}     ${TRAINING_ARGS[@]}     ${MODEL_PARALLEL_ARGS[@]}     ${LOGGING_ARGS[@]}\n"
                        ],
                        "env": [
                          {
                            "name": "CUDA_DEVICE_MAX_CONNECTIONS",
                            "value": "1"
                          },
                          {
                            "name": "AIHC_TENSORBOARD_LOG_PATH",
                            "value": "/mnt/cluster/llamatest0718forxiaomi2/output/training_logs"
                          },
                          {
                            "name": "AIHC_JOB_NAME",
                            "value": "llamatest0718forxiaomi2"
                          },
                          {
                            "name": "NCCL_IB_DISABLE",
                            "value": "0"
                          },
                          {
                            "name": "BCCL_BUS_BW_CALCULATE_MODE",
                            "value": "Agg"
                          },
                          {
                            "name": "BCCL_PROFILING_FILE",
                            "value": "/var/bccl/logs/busbw.cal.%h.%p"
                          }
                        ],
                        "image": "registry.baidubce.com/aihc-aiak/aiak-training-llm:ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release",
                        "imagePullPolicy": "Always",
                        "name": "pytorch",
                        "ports": [
                          {
                            "containerPort": 23456,
                            "name": "pytorchjob-port",
                            "protocol": "TCP"
                          }
                        ],
                        "resources": {
                          "limits": {
                            "baidu.com/a800_80g_cgpu": "8",
                            "rdma/hca": "1"
                          },
                          "requests": {
                            "baidu.com/a800_80g_cgpu": "8",
                            "rdma/hca": "1"
                          }
                        },
                        "securityContext": {
                          "capabilities": {
                            "add": [
                              "IPC_LOCK"
                            ]
                          }
                        },
                        "volumeMounts": [
                          {
                            "mountPath": "/dev/shm",
                            "name": "devshm"
                          },
                          {
                            "mountPath": "/mnt/cluster",
                            "name": "pvc-pfs"
                          },
                          {
                            "mountPath": "/var/bccl/logs",
                            "name": "bccl-logs-volume"
                          }
                        ]
                      },
                      {
                        "env": [
                          {
                            "name": "POD_NAME",
                            "valueFrom": {
                              "fieldRef": {
                                "apiVersion": "v1",
                                "fieldPath": "metadata.name"
                              }
                            }
                          },
                          {
                            "name": "POD_UID",
                            "valueFrom": {
                              "fieldRef": {
                                "apiVersion": "v1",
                                "fieldPath": "metadata.uid"
                              }
                            }
                          },
                          {
                            "name": "POD_NAMESPACE",
                            "valueFrom": {
                              "fieldRef": {
                                "apiVersion": "v1",
                                "fieldPath": "metadata.namespace"
                              }
                            }
                          },
                          {
                            "name": "NODE_NAME",
                            "valueFrom": {
                              "fieldRef": {
                                "apiVersion": "v1",
                                "fieldPath": "spec.nodeName"
                              }
                            }
                          },
                          {
                            "name": "JOB_NAME",
                            "value": "llamatest0718forxiaomi2"
                          },
                          {
                            "name": "NODE_IP",
                            "valueFrom": {
                              "fieldRef": {
                                "apiVersion": "v1",
                                "fieldPath": "status.hostIP"
                              }
                            }
                          },
                          {
                            "name": "ENABLE_ELASTIC",
                            "value": "9"
                          },
                          {
                            "name": "GPUS_PER_NODE",
                            "value": "8"
                          },
                          {
                            "name": "BCCL_LOG_DIR",
                            "value": "/var/bccl/logs"
                          },
                          {
                            "name": "EXPORTER_PORT",
                            "value": "9101"
                          },
                          {
                            "name": "EXPORTER_INTERVAL",
                            "value": "60"
                          },
                          {
                            "name": "EXPORTER_PATH",
                            "value": "/metrics"
                          },
                          {
                            "name": "BCCL_BUS_BW_CALCULATE_MODE",
                            "value": "Agg"
                          },
                          {
                            "name": "BCCL_PROFILING_FILE",
                            "value": "/var/bccl/logs/busbw.cal.%h.%p"
                          }
                        ],
                        "image": "registry.baidubce.com/cce-plugin-dev/ftagent:v1.6-20240713172215",
                        "imagePullPolicy": "Always",
                        "name": "ftagent",
                        "ports": [
                          {
                            "containerPort": 9101,
                            "name": "exporter",
                            "protocol": "TCP"
                          }
                        ],
                        "resources": {},
                        "securityContext": {
                          "capabilities": {
                            "add": [
                              "IPC_LOCK"
                            ]
                          }
                        },
                        "volumeMounts": [
                          {
                            "mountPath": "/var/log/pods",
                            "name": "pod-log-volume"
                          },
                          {
                            "mountPath": "/home/cce",
                            "name": "container-log-volume"
                          },
                          {
                            "mountPath": "/var/bccl/logs",
                            "name": "bccl-logs-volume"
                          }
                        ]
                      }
                    ],
                    "dnsPolicy": "ClusterFirstWithHostNet",
                    "hostNetwork": true,
                    "schedulerName": "volcano",
                    "serviceAccountName": "ftagent-sa",
                    "shareProcessNamespace": true,
                    "volumes": [
                      {
                        "emptyDir": {
                          "medium": "Memory",
                          "sizeLimit": "10Gi"
                        },
                        "name": "devshm"
                      },
                      {
                        "name": "pvc-pfs",
                        "persistentVolumeClaim": {
                          "claimName": "pvc-pfs"
                        }
                      },
                      {
                        "emptyDir": {},
                        "name": "bccl-logs-volume"
                      },
                      {
                        "hostPath": {
                          "path": "/var/log/pods",
                          "type": "DirectoryOrCreate"
                        },
                        "name": "pod-log-volume"
                      },
                      {
                        "hostPath": {
                          "path": "/home/cce",
                          "type": "DirectoryOrCreate"
                        },
                        "name": "container-log-volume"
                      }
                    ]
                  }
                }
              }
            },
            "runPolicy": {
              "cleanPodPolicy": "None",
              "schedulingPolicy": {
                "priorityClass": "high",
                "queue": "default"
              }
            }
          },
          "status": {
            "completionTime": "2024-07-18T02:21:56Z",
            "conditions": [
              {
                "lastTransitionTime": "2024-07-18T02:19:27Z",
                "lastUpdateTime": "2024-07-18T02:19:27Z",
                "message": "PyTorchJob llamatest0718forxiaomi2 is created.",
                "reason": "PyTorchJobCreated",
                "status": "True",
                "type": "Created"
              },
              {
                "lastTransitionTime": "2024-07-18T02:19:49Z",
                "lastUpdateTime": "2024-07-18T02:19:49Z",
                "message": "PyTorchJob llamatest0718forxiaomi2 is running.",
                "reason": "JobRunning",
                "status": "False",
                "type": "Running"
              },
              {
                "lastTransitionTime": "2024-07-18T02:21:56Z",
                "lastUpdateTime": "2024-07-18T02:21:56Z",
                "message": "PytorchJob default/llamatest0718forxiaomi2 is stopped",
                "reason": "PyTorchJobStopped",
                "status": "True",
                "type": "Stopped"
              },
              {
                "lastTransitionTime": "2024-07-18T02:21:56Z",
                "lastUpdateTime": "2024-07-18T02:21:56Z",
                "message": "PyTorchJob llamatest0718forxiaomi2 is failed because 1 Master replica(s) failed.",
                "reason": "JobFailed",
                "status": "True",
                "type": "Failed"
              }
            ],
            "lastReconcileTime": "2024-07-18T02:19:27Z",
            "replicaStatuses": {
              "Master": {
                "failed": 1,
                "selector": "training.kubeflow.org/job-name=llamatest0718forxiaomi2,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=master"
              },
              "Worker": {
                "failed": 3,
                "selector": "training.kubeflow.org/job-name=llamatest0718forxiaomi2,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=worker"
              }
            },
            "startTime": "2024-07-18T02:19:29Z"
          }
        },
        {
          "apiVersion": "kubeflow.org/v1",
          "kind": "PyTorchJob",
          "metadata": {
            "annotations": {
              "aijob.cce.baidubce.com/barrier-finish": "b95a6974-ce32-4734-8aa8-fe75aeea9668",
              "aijob.cce.baidubce.com/fault-tolerance-enabled": "true",
              "aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": "",
              "aijob.cce.baidubce.com/internal-fault-tolerance-time": "2024-07-18T02:22:31.688504306Z",
              "aijob.cce.baidubce.com/openapi-jobid": "pytorch-e973d356-59b6-4652-8e58-9e9605e1c0d8",
              "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
              "aijob.cce.baidubce.com/raw-request": "{\"name\":\"llamatest0718forxiaomi3\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"high\",\"oversell\":false,\"faultTolerance\":true,\"command\":\"\\n#! /bin/bash\\n\\nMEGATRON_PATH=${MEGATRON_PATH:-\\\"/workspace/AIAK-Megatron\\\"}\\nAIAK_TRAINING_PATH=${AIAK_TRAINING_PATH:-\\\"/workspace/AIAK-Training-LLM\\\"}\\n\\nDATA_PATH=${DATA_PATH:-\\\"/mnt/cluster/llama2/pile/pile-llama_text_document\\\"}\\nTOKENIZER_PATH=${TOKENIZER_PATH:-\\\"/mnt/cluster/llama2/Llama-2-70b-hf/tokenizer.model\\\"}\\n\\nCHECKPOINT_PATH=${CHECKPOINT_PATH:-\\\"/mnt/cluster/llama2/mcore_llama2_70b_tp4_pp4\\\"}\\n\\nTENSORBOARD_PATH=${TENSORBOARD_PATH:-\\\"/mnt/cluster/aiak-training-llm/tensorboard-log/llama2-70b-tp4pp4\\\"}\\n\\nGPUS_PER_NODE=8\\n\\n# Change for multinode config\\nMASTER_ADDR=${MASTER_ADDR:-\\\"localhost\\\"}\\nMASTER_PORT=${MASTER_PORT:-\\\"6000\\\"}\\nNNODES=${WORLD_SIZE:-\\\"1\\\"}\\nNODE_RANK=${RANK:-\\\"0\\\"}\\n\\nDISTRIBUTED_ARGS=(\\n    --nproc_per_node $GPUS_PER_NODE\\n    --nnodes $NNODES\\n    --node_rank $NODE_RANK\\n    --master_addr $MASTER_ADDR\\n    --master_port $MASTER_PORT\\n)\\n\\n# you can setup llama2-70b maunally\\n#MODEL_ARGS=(\\n#    --model-name llama2\\n#    --num-layers 80\\n#    --hidden-size 8192\\n#    --ffn-hidden-size 28672\\n#    --num-attention-heads 64\\n#    --position-embedding-type rope\\n#    --normalization RMSNorm\\n#    --swiglu\\n#    --attention-dropout 0\\n#    --hidden-dropout 0\\n#    --disable-bias-linear\\n#    --untie-embeddings-and-output-weights\\n#    --group-query-attention\\n#    --num-query-groups 8\\n#)\\n\\n# or you can setup llama2-70b by using the following command\\nMODEL_ARGS=(\\n    --model-name llama2-70b # options: llama2-7b, llama2-13b, llama2-70b\\n)\\n\\nDATA_ARGS=(\\n    --tokenizer-type HFTokenizer\\n    --hf-tokenizer-path $TOKENIZER_PATH\\n    --data-path $DATA_PATH\\n    --split 949,50,1\\n)\\n\\nTRAINING_ARGS=(\\n    --training-phase pretrain # options: pretrain, sft\\n    --seq-length 4096\\n    --max-position-embeddings 4096\\n    --init-method-std 0.01\\n    --micro-batch-size 1\\n    --global-batch-size 1024\\n    --lr 0.0002\\n    --min-lr 1.0e-5\\n    --clip-grad 1.0\\n    --weight-decay 0.01\\n    --optimizer adam\\n    --adam-beta1 0.9\\n    --adam-beta2 0.95\\n    --adam-eps 1e-05\\n    --norm-epsilon 1e-6\\n    --train-iters 500000\\n    --lr-decay-iters 500000\\n    --lr-decay-style cosine\\n    --lr-warmup-fraction 0.002\\n    --initial-loss-scale 65536\\n    --fp16\\n    --save-interval 5000\\n    --eval-interval 1000\\n    --eval-iters 10\\n    #--ckpt-step 0\\n    #--no-load-optim\\n    #--no-load-rng\\n)\\n\\nMODEL_PARALLEL_ARGS=(\\n    --tensor-model-parallel-size 4\\n    --pipeline-model-parallel-size 4\\n    --use-distributed-optimizer\\n    --overlap-grad-reduce\\n    --overlap-param-gather\\n    --distributed-backend nccl\\n    --sequence-parallel\\n    #--tp-comm-overlap # require mpi envrionment\\n)\\n\\nLOGGING_ARGS=(\\n    --log-interval 1\\n    --tensorboard-dir ${TENSORBOARD_PATH}\\n    --log-timers-to-tensorboard\\n)\\n\\nif [ -n \\\"${WANDB_API_KEY}\\\" ]; then\\n    LOGGING_ARGS+=(\\n        --wandb-project ${WANDB_PROJECT}\\n        --wandb-exp-name ${WANDB_NAME} \\n    )\\nfi\\n\\nPYTHONPATH=$MEGATRON_PATH:$AIAK_TRAINING_PATH:$PYTHONPATH     torchrun ${DISTRIBUTED_ARGS[@]}     $AIAK_TRAINING_PATH/aiak_training_llm/train.py     ${MODEL_ARGS[@]}     ${DATA_ARGS[@]}     ${TRAINING_ARGS[@]}     ${MODEL_PARALLEL_ARGS[@]}     ${LOGGING_ARGS[@]}\\n\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":true,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi3\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi3/output/training_logs\",\"CUDA_DEVICE_MAX_CONNECTIONS\":\"1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"},\"Worker\":{\"replicas\":3,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi3\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi3/output/training_logs\",\"CUDA_DEVICE_MAX_CONNECTIONS\":\"1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":true,\"logPath\":\"/mnt/cluster/llamatest0718forxiaomi3/output/training_logs\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":true,\"isCopyJob\":true,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
              "aijob.cce.baidubce.com/timeline": "[{\"conditionType\":\"Created\",\"time\":1721269309},{\"conditionType\":\"Scheduled\",\"time\":1721269311},{\"conditionType\":\"Running\",\"time\":1721269322},{\"conditionType\":\"Abnormal\",\"time\":1721269351},{\"conditionType\":\"ManualTermination\",\"time\":1721269602}]",
              "job-manager/action": "stop",
              "scheduling.k8s.io/job-enable-oversell": "false",
              "tensorboard-gc": "true"
            },
            "creationTimestamp": "2024-07-18T02:21:49Z",
            "generation": 3,
            "labels": {
              "aijob.cce.baidubce.com/ai-user-id": "b5a24aa26e4d4f55bc3acf68edc4b051",
              "aijob.cce.baidubce.com/ai-user-name": "zhangmuhua",
              "aijob.cce.baidubce.com/create-from-aihcp": "true",
              "aijob.cce.baidubce.com/openapi-jobid": "pytorch-e973d356-59b6-4652-8e58-9e9605e1c0d8"
            },
            "managedFields": [
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      "f:aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": {},
                      "f:aijob.cce.baidubce.com/timeline": {}
                    }
                  },
                  "f:spec": {
                    "f:runPolicy": {
                      "f:cleanPodPolicy": {}
                    }
                  }
                },
                "manager": "controller",
                "operation": "Update",
                "time": "2024-07-18T02:21:49Z"
              },
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      "f:aijob.cce.baidubce.com/barrier-finish": {}
                    }
                  }
                },
                "manager": "jobbarrier",
                "operation": "Update",
                "time": "2024-07-18T02:21:58Z"
              },
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      ".": {},
                      "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                      "f:aijob.cce.baidubce.com/openapi-jobid": {},
                      "f:aijob.cce.baidubce.com/pfs-id": {},
                      "f:aijob.cce.baidubce.com/raw-request": {},
                      "f:job-manager/action": {},
                      "f:scheduling.k8s.io/job-enable-oversell": {}
                    },
                    "f:labels": {
                      ".": {},
                      "f:aijob.cce.baidubce.com/ai-user-id": {},
                      "f:aijob.cce.baidubce.com/ai-user-name": {},
                      "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                      "f:aijob.cce.baidubce.com/openapi-jobid": {}
                    }
                  },
                  "f:spec": {
                    ".": {},
                    "f:pytorchReplicaSpecs": {
                      ".": {},
                      "f:Master": {
                        ".": {},
                        "f:replicas": {},
                        "f:restartPolicy": {},
                        "f:template": {
                          ".": {},
                          "f:metadata": {
                            ".": {},
                            "f:annotations": {
                              ".": {},
                              "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                              "f:aijob.cce.baidubce.com/openapi-jobid": {},
                              "f:aijob.cce.baidubce.com/pfs-id": {},
                              "f:aijob.cce.baidubce.com/raw-request": {},
                              "f:scheduling.k8s.io/job-enable-oversell": {}
                            },
                            "f:labels": {
                              ".": {},
                              "f:aijob.cce.baidubce.com/ai-user-id": {},
                              "f:aijob.cce.baidubce.com/ai-user-name": {},
                              "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                              "f:aijob.cce.baidubce.com/openapi-jobid": {}
                            }
                          },
                          "f:spec": {
                            ".": {},
                            "f:dnsPolicy": {},
                            "f:hostNetwork": {},
                            "f:schedulerName": {}
                          }
                        }
                      },
                      "f:Worker": {
                        ".": {},
                        "f:replicas": {},
                        "f:restartPolicy": {},
                        "f:template": {
                          ".": {},
                          "f:metadata": {
                            ".": {},
                            "f:annotations": {
                              ".": {},
                              "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                              "f:aijob.cce.baidubce.com/openapi-jobid": {},
                              "f:aijob.cce.baidubce.com/pfs-id": {},
                              "f:aijob.cce.baidubce.com/raw-request": {},
                              "f:scheduling.k8s.io/job-enable-oversell": {}
                            },
                            "f:labels": {
                              ".": {},
                              "f:aijob.cce.baidubce.com/ai-user-id": {},
                              "f:aijob.cce.baidubce.com/ai-user-name": {},
                              "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                              "f:aijob.cce.baidubce.com/openapi-jobid": {}
                            }
                          },
                          "f:spec": {
                            ".": {},
                            "f:dnsPolicy": {},
                            "f:hostNetwork": {},
                            "f:schedulerName": {}
                          }
                        }
                      }
                    },
                    "f:runPolicy": {
                      ".": {},
                      "f:schedulingPolicy": {
                        ".": {},
                        "f:priorityClass": {},
                        "f:queue": {}
                      }
                    }
                  }
                },
                "manager": "cce-ai-service",
                "operation": "Update",
                "time": "2024-07-18T02:26:42Z"
              },
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      "f:aijob.cce.baidubce.com/internal-fault-tolerance-time": {},
                      "f:tensorboard-gc": {}
                    }
                  },
                  "f:spec": {
                    "f:pytorchReplicaSpecs": {
                      "f:Master": {
                        "f:template": {
                          "f:metadata": {
                            "f:annotations": {
                              "f:prometheus.io/path": {},
                              "f:prometheus.io/port": {},
                              "f:prometheus.io/scrape": {}
                            }
                          },
                          "f:spec": {
                            "f:containers": {},
                            "f:serviceAccountName": {},
                            "f:shareProcessNamespace": {},
                            "f:volumes": {}
                          }
                        }
                      },
                      "f:Worker": {
                        "f:template": {
                          "f:metadata": {
                            "f:annotations": {
                              "f:prometheus.io/path": {},
                              "f:prometheus.io/port": {},
                              "f:prometheus.io/scrape": {}
                            }
                          },
                          "f:spec": {
                            "f:containers": {},
                            "f:serviceAccountName": {},
                            "f:shareProcessNamespace": {},
                            "f:volumes": {}
                          }
                        }
                      }
                    }
                  },
                  "f:status": {
                    ".": {},
                    "f:completionTime": {},
                    "f:conditions": {},
                    "f:lastReconcileTime": {},
                    "f:replicaStatuses": {
                      ".": {},
                      "f:Master": {
                        ".": {},
                        "f:failed": {}
                      },
                      "f:Worker": {
                        ".": {},
                        "f:failed": {}
                      }
                    },
                    "f:startTime": {}
                  }
                },
                "manager": "manager",
                "operation": "Update",
                "time": "2024-07-19T02:21:55Z"
              }
            ],
            "name": "llamatest0718forxiaomi3",
            "namespace": "default",
            "resourceVersion": "2372388747",
            "uid": "95cfae3c-cecc-4c60-b86b-25f654bd39ca"
          },
          "spec": {
            "pytorchReplicaSpecs": {
              "Master": {
                "replicas": 1,
                "restartPolicy": "Never",
                "template": {
                  "metadata": {
                    "annotations": {
                      "aijob.cce.baidubce.com/fault-tolerance-enabled": "true",
                      "aijob.cce.baidubce.com/openapi-jobid": "pytorch-e973d356-59b6-4652-8e58-9e9605e1c0d8",
                      "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
                      "aijob.cce.baidubce.com/raw-request": "{\"name\":\"llamatest0718forxiaomi3\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"high\",\"oversell\":false,\"faultTolerance\":true,\"command\":\"\\n#! /bin/bash\\n\\nMEGATRON_PATH=${MEGATRON_PATH:-\\\"/workspace/AIAK-Megatron\\\"}\\nAIAK_TRAINING_PATH=${AIAK_TRAINING_PATH:-\\\"/workspace/AIAK-Training-LLM\\\"}\\n\\nDATA_PATH=${DATA_PATH:-\\\"/mnt/cluster/llama2/pile/pile-llama_text_document\\\"}\\nTOKENIZER_PATH=${TOKENIZER_PATH:-\\\"/mnt/cluster/llama2/Llama-2-70b-hf/tokenizer.model\\\"}\\n\\nCHECKPOINT_PATH=${CHECKPOINT_PATH:-\\\"/mnt/cluster/llama2/mcore_llama2_70b_tp4_pp4\\\"}\\n\\nTENSORBOARD_PATH=${TENSORBOARD_PATH:-\\\"/mnt/cluster/aiak-training-llm/tensorboard-log/llama2-70b-tp4pp4\\\"}\\n\\nGPUS_PER_NODE=8\\n\\n# Change for multinode config\\nMASTER_ADDR=${MASTER_ADDR:-\\\"localhost\\\"}\\nMASTER_PORT=${MASTER_PORT:-\\\"6000\\\"}\\nNNODES=${WORLD_SIZE:-\\\"1\\\"}\\nNODE_RANK=${RANK:-\\\"0\\\"}\\n\\nDISTRIBUTED_ARGS=(\\n    --nproc_per_node $GPUS_PER_NODE\\n    --nnodes $NNODES\\n    --node_rank $NODE_RANK\\n    --master_addr $MASTER_ADDR\\n    --master_port $MASTER_PORT\\n)\\n\\n# you can setup llama2-70b maunally\\n#MODEL_ARGS=(\\n#    --model-name llama2\\n#    --num-layers 80\\n#    --hidden-size 8192\\n#    --ffn-hidden-size 28672\\n#    --num-attention-heads 64\\n#    --position-embedding-type rope\\n#    --normalization RMSNorm\\n#    --swiglu\\n#    --attention-dropout 0\\n#    --hidden-dropout 0\\n#    --disable-bias-linear\\n#    --untie-embeddings-and-output-weights\\n#    --group-query-attention\\n#    --num-query-groups 8\\n#)\\n\\n# or you can setup llama2-70b by using the following command\\nMODEL_ARGS=(\\n    --model-name llama2-70b # options: llama2-7b, llama2-13b, llama2-70b\\n)\\n\\nDATA_ARGS=(\\n    --tokenizer-type HFTokenizer\\n    --hf-tokenizer-path $TOKENIZER_PATH\\n    --data-path $DATA_PATH\\n    --split 949,50,1\\n)\\n\\nTRAINING_ARGS=(\\n    --training-phase pretrain # options: pretrain, sft\\n    --seq-length 4096\\n    --max-position-embeddings 4096\\n    --init-method-std 0.01\\n    --micro-batch-size 1\\n    --global-batch-size 1024\\n    --lr 0.0002\\n    --min-lr 1.0e-5\\n    --clip-grad 1.0\\n    --weight-decay 0.01\\n    --optimizer adam\\n    --adam-beta1 0.9\\n    --adam-beta2 0.95\\n    --adam-eps 1e-05\\n    --norm-epsilon 1e-6\\n    --train-iters 500000\\n    --lr-decay-iters 500000\\n    --lr-decay-style cosine\\n    --lr-warmup-fraction 0.002\\n    --initial-loss-scale 65536\\n    --fp16\\n    --save-interval 5000\\n    --eval-interval 1000\\n    --eval-iters 10\\n    #--ckpt-step 0\\n    #--no-load-optim\\n    #--no-load-rng\\n)\\n\\nMODEL_PARALLEL_ARGS=(\\n    --tensor-model-parallel-size 4\\n    --pipeline-model-parallel-size 4\\n    --use-distributed-optimizer\\n    --overlap-grad-reduce\\n    --overlap-param-gather\\n    --distributed-backend nccl\\n    --sequence-parallel\\n    #--tp-comm-overlap # require mpi envrionment\\n)\\n\\nLOGGING_ARGS=(\\n    --log-interval 1\\n    --tensorboard-dir ${TENSORBOARD_PATH}\\n    --log-timers-to-tensorboard\\n)\\n\\nif [ -n \\\"${WANDB_API_KEY}\\\" ]; then\\n    LOGGING_ARGS+=(\\n        --wandb-project ${WANDB_PROJECT}\\n        --wandb-exp-name ${WANDB_NAME} \\n    )\\nfi\\n\\nPYTHONPATH=$MEGATRON_PATH:$AIAK_TRAINING_PATH:$PYTHONPATH     torchrun ${DISTRIBUTED_ARGS[@]}     $AIAK_TRAINING_PATH/aiak_training_llm/train.py     ${MODEL_ARGS[@]}     ${DATA_ARGS[@]}     ${TRAINING_ARGS[@]}     ${MODEL_PARALLEL_ARGS[@]}     ${LOGGING_ARGS[@]}\\n\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":true,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi3\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi3/output/training_logs\",\"CUDA_DEVICE_MAX_CONNECTIONS\":\"1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"},\"Worker\":{\"replicas\":3,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi3\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi3/output/training_logs\",\"CUDA_DEVICE_MAX_CONNECTIONS\":\"1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":true,\"logPath\":\"/mnt/cluster/llamatest0718forxiaomi3/output/training_logs\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":true,\"isCopyJob\":true,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
                      "prometheus.io/path": "/metrics",
                      "prometheus.io/port": "9101",
                      "prometheus.io/scrape": "true",
                      "scheduling.k8s.io/job-enable-oversell": "false"
                    },
                    "labels": {
                      "aijob.cce.baidubce.com/ai-user-id": "b5a24aa26e4d4f55bc3acf68edc4b051",
                      "aijob.cce.baidubce.com/ai-user-name": "zhangmuhua",
                      "aijob.cce.baidubce.com/create-from-aihcp": "true",
                      "aijob.cce.baidubce.com/openapi-jobid": "pytorch-e973d356-59b6-4652-8e58-9e9605e1c0d8"
                    }
                  },
                  "spec": {
                    "containers": [
                      {
                        "command": [
                          "/bin/bash",
                          "-c",
                          "\n#! /bin/bash\n\nMEGATRON_PATH=${MEGATRON_PATH:-\"/workspace/AIAK-Megatron\"}\nAIAK_TRAINING_PATH=${AIAK_TRAINING_PATH:-\"/workspace/AIAK-Training-LLM\"}\n\nDATA_PATH=${DATA_PATH:-\"/mnt/cluster/llama2/pile/pile-llama_text_document\"}\nTOKENIZER_PATH=${TOKENIZER_PATH:-\"/mnt/cluster/llama2/Llama-2-70b-hf/tokenizer.model\"}\n\nCHECKPOINT_PATH=${CHECKPOINT_PATH:-\"/mnt/cluster/llama2/mcore_llama2_70b_tp4_pp4\"}\n\nTENSORBOARD_PATH=${TENSORBOARD_PATH:-\"/mnt/cluster/aiak-training-llm/tensorboard-log/llama2-70b-tp4pp4\"}\n\nGPUS_PER_NODE=8\n\n# Change for multinode config\nMASTER_ADDR=${MASTER_ADDR:-\"localhost\"}\nMASTER_PORT=${MASTER_PORT:-\"6000\"}\nNNODES=${WORLD_SIZE:-\"1\"}\nNODE_RANK=${RANK:-\"0\"}\n\nDISTRIBUTED_ARGS=(\n    --nproc_per_node $GPUS_PER_NODE\n    --nnodes $NNODES\n    --node_rank $NODE_RANK\n    --master_addr $MASTER_ADDR\n    --master_port $MASTER_PORT\n)\n\n# you can setup llama2-70b maunally\n#MODEL_ARGS=(\n#    --model-name llama2\n#    --num-layers 80\n#    --hidden-size 8192\n#    --ffn-hidden-size 28672\n#    --num-attention-heads 64\n#    --position-embedding-type rope\n#    --normalization RMSNorm\n#    --swiglu\n#    --attention-dropout 0\n#    --hidden-dropout 0\n#    --disable-bias-linear\n#    --untie-embeddings-and-output-weights\n#    --group-query-attention\n#    --num-query-groups 8\n#)\n\n# or you can setup llama2-70b by using the following command\nMODEL_ARGS=(\n    --model-name llama2-70b # options: llama2-7b, llama2-13b, llama2-70b\n)\n\nDATA_ARGS=(\n    --tokenizer-type HFTokenizer\n    --hf-tokenizer-path $TOKENIZER_PATH\n    --data-path $DATA_PATH\n    --split 949,50,1\n)\n\nTRAINING_ARGS=(\n    --training-phase pretrain # options: pretrain, sft\n    --seq-length 4096\n    --max-position-embeddings 4096\n    --init-method-std 0.01\n    --micro-batch-size 1\n    --global-batch-size 1024\n    --lr 0.0002\n    --min-lr 1.0e-5\n    --clip-grad 1.0\n    --weight-decay 0.01\n    --optimizer adam\n    --adam-beta1 0.9\n    --adam-beta2 0.95\n    --adam-eps 1e-05\n    --norm-epsilon 1e-6\n    --train-iters 500000\n    --lr-decay-iters 500000\n    --lr-decay-style cosine\n    --lr-warmup-fraction 0.002\n    --initial-loss-scale 65536\n    --fp16\n    --save-interval 5000\n    --eval-interval 1000\n    --eval-iters 10\n    #--ckpt-step 0\n    #--no-load-optim\n    #--no-load-rng\n)\n\nMODEL_PARALLEL_ARGS=(\n    --tensor-model-parallel-size 4\n    --pipeline-model-parallel-size 4\n    --use-distributed-optimizer\n    --overlap-grad-reduce\n    --overlap-param-gather\n    --distributed-backend nccl\n    --sequence-parallel\n    #--tp-comm-overlap # require mpi envrionment\n)\n\nLOGGING_ARGS=(\n    --log-interval 1\n    --tensorboard-dir ${TENSORBOARD_PATH}\n    --log-timers-to-tensorboard\n)\n\nif [ -n \"${WANDB_API_KEY}\" ]; then\n    LOGGING_ARGS+=(\n        --wandb-project ${WANDB_PROJECT}\n        --wandb-exp-name ${WANDB_NAME} \n    )\nfi\n\nPYTHONPATH=$MEGATRON_PATH:$AIAK_TRAINING_PATH:$PYTHONPATH     torchrun ${DISTRIBUTED_ARGS[@]}     $AIAK_TRAINING_PATH/aiak_training_llm/train.py     ${MODEL_ARGS[@]}     ${DATA_ARGS[@]}     ${TRAINING_ARGS[@]}     ${MODEL_PARALLEL_ARGS[@]}     ${LOGGING_ARGS[@]}\n"
                        ],
                        "env": [
                          {
                            "name": "CUDA_DEVICE_MAX_CONNECTIONS",
                            "value": "1"
                          },
                          {
                            "name": "AIHC_TENSORBOARD_LOG_PATH",
                            "value": "/mnt/cluster/llamatest0718forxiaomi3/output/training_logs"
                          },
                          {
                            "name": "AIHC_JOB_NAME",
                            "value": "llamatest0718forxiaomi3"
                          },
                          {
                            "name": "NCCL_IB_DISABLE",
                            "value": "0"
                          },
                          {
                            "name": "BCCL_BUS_BW_CALCULATE_MODE",
                            "value": "Agg"
                          },
                          {
                            "name": "BCCL_PROFILING_FILE",
                            "value": "/var/bccl/logs/busbw.cal.%h.%p"
                          }
                        ],
                        "image": "registry.baidubce.com/aihc-aiak/aiak-training-llm:ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release",
                        "imagePullPolicy": "Always",
                        "name": "pytorch",
                        "ports": [
                          {
                            "containerPort": 23456,
                            "name": "pytorchjob-port",
                            "protocol": "TCP"
                          }
                        ],
                        "resources": {
                          "limits": {
                            "baidu.com/a800_80g_cgpu": "8",
                            "rdma/hca": "1"
                          },
                          "requests": {
                            "baidu.com/a800_80g_cgpu": "8",
                            "rdma/hca": "1"
                          }
                        },
                        "securityContext": {
                          "capabilities": {
                            "add": [
                              "IPC_LOCK"
                            ]
                          }
                        },
                        "volumeMounts": [
                          {
                            "mountPath": "/dev/shm",
                            "name": "devshm"
                          },
                          {
                            "mountPath": "/mnt/cluster",
                            "name": "pvc-pfs"
                          },
                          {
                            "mountPath": "/var/bccl/logs",
                            "name": "bccl-logs-volume"
                          }
                        ]
                      },
                      {
                        "env": [
                          {
                            "name": "POD_NAME",
                            "valueFrom": {
                              "fieldRef": {
                                "apiVersion": "v1",
                                "fieldPath": "metadata.name"
                              }
                            }
                          },
                          {
                            "name": "POD_UID",
                            "valueFrom": {
                              "fieldRef": {
                                "apiVersion": "v1",
                                "fieldPath": "metadata.uid"
                              }
                            }
                          },
                          {
                            "name": "POD_NAMESPACE",
                            "valueFrom": {
                              "fieldRef": {
                                "apiVersion": "v1",
                                "fieldPath": "metadata.namespace"
                              }
                            }
                          },
                          {
                            "name": "NODE_NAME",
                            "valueFrom": {
                              "fieldRef": {
                                "apiVersion": "v1",
                                "fieldPath": "spec.nodeName"
                              }
                            }
                          },
                          {
                            "name": "JOB_NAME",
                            "value": "llamatest0718forxiaomi3"
                          },
                          {
                            "name": "NODE_IP",
                            "valueFrom": {
                              "fieldRef": {
                                "apiVersion": "v1",
                                "fieldPath": "status.hostIP"
                              }
                            }
                          },
                          {
                            "name": "ENABLE_ELASTIC",
                            "value": "9"
                          },
                          {
                            "name": "GPUS_PER_NODE",
                            "value": "8"
                          },
                          {
                            "name": "BCCL_LOG_DIR",
                            "value": "/var/bccl/logs"
                          },
                          {
                            "name": "EXPORTER_PORT",
                            "value": "9101"
                          },
                          {
                            "name": "EXPORTER_INTERVAL",
                            "value": "60"
                          },
                          {
                            "name": "EXPORTER_PATH",
                            "value": "/metrics"
                          },
                          {
                            "name": "BCCL_BUS_BW_CALCULATE_MODE",
                            "value": "Agg"
                          },
                          {
                            "name": "BCCL_PROFILING_FILE",
                            "value": "/var/bccl/logs/busbw.cal.%h.%p"
                          }
                        ],
                        "image": "registry.baidubce.com/cce-plugin-dev/ftagent:v1.6-20240713172215",
                        "imagePullPolicy": "Always",
                        "name": "ftagent",
                        "ports": [
                          {
                            "containerPort": 9101,
                            "name": "exporter",
                            "protocol": "TCP"
                          }
                        ],
                        "resources": {},
                        "securityContext": {
                          "capabilities": {
                            "add": [
                              "IPC_LOCK"
                            ]
                          }
                        },
                        "volumeMounts": [
                          {
                            "mountPath": "/var/log/pods",
                            "name": "pod-log-volume"
                          },
                          {
                            "mountPath": "/home/cce",
                            "name": "container-log-volume"
                          },
                          {
                            "mountPath": "/var/bccl/logs",
                            "name": "bccl-logs-volume"
                          }
                        ]
                      }
                    ],
                    "dnsPolicy": "ClusterFirstWithHostNet",
                    "hostNetwork": true,
                    "schedulerName": "volcano",
                    "serviceAccountName": "ftagent-sa",
                    "shareProcessNamespace": true,
                    "volumes": [
                      {
                        "emptyDir": {
                          "medium": "Memory",
                          "sizeLimit": "10Gi"
                        },
                        "name": "devshm"
                      },
                      {
                        "name": "pvc-pfs",
                        "persistentVolumeClaim": {
                          "claimName": "pvc-pfs"
                        }
                      },
                      {
                        "emptyDir": {},
                        "name": "bccl-logs-volume"
                      },
                      {
                        "hostPath": {
                          "path": "/var/log/pods",
                          "type": "DirectoryOrCreate"
                        },
                        "name": "pod-log-volume"
                      },
                      {
                        "hostPath": {
                          "path": "/home/cce",
                          "type": "DirectoryOrCreate"
                        },
                        "name": "container-log-volume"
                      }
                    ]
                  }
                }
              },
              "Worker": {
                "replicas": 3,
                "restartPolicy": "Never",
                "template": {
                  "metadata": {
                    "annotations": {
                      "aijob.cce.baidubce.com/fault-tolerance-enabled": "true",
                      "aijob.cce.baidubce.com/openapi-jobid": "pytorch-e973d356-59b6-4652-8e58-9e9605e1c0d8",
                      "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
                      "aijob.cce.baidubce.com/raw-request": "{\"name\":\"llamatest0718forxiaomi3\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"high\",\"oversell\":false,\"faultTolerance\":true,\"command\":\"\\n#! /bin/bash\\n\\nMEGATRON_PATH=${MEGATRON_PATH:-\\\"/workspace/AIAK-Megatron\\\"}\\nAIAK_TRAINING_PATH=${AIAK_TRAINING_PATH:-\\\"/workspace/AIAK-Training-LLM\\\"}\\n\\nDATA_PATH=${DATA_PATH:-\\\"/mnt/cluster/llama2/pile/pile-llama_text_document\\\"}\\nTOKENIZER_PATH=${TOKENIZER_PATH:-\\\"/mnt/cluster/llama2/Llama-2-70b-hf/tokenizer.model\\\"}\\n\\nCHECKPOINT_PATH=${CHECKPOINT_PATH:-\\\"/mnt/cluster/llama2/mcore_llama2_70b_tp4_pp4\\\"}\\n\\nTENSORBOARD_PATH=${TENSORBOARD_PATH:-\\\"/mnt/cluster/aiak-training-llm/tensorboard-log/llama2-70b-tp4pp4\\\"}\\n\\nGPUS_PER_NODE=8\\n\\n# Change for multinode config\\nMASTER_ADDR=${MASTER_ADDR:-\\\"localhost\\\"}\\nMASTER_PORT=${MASTER_PORT:-\\\"6000\\\"}\\nNNODES=${WORLD_SIZE:-\\\"1\\\"}\\nNODE_RANK=${RANK:-\\\"0\\\"}\\n\\nDISTRIBUTED_ARGS=(\\n    --nproc_per_node $GPUS_PER_NODE\\n    --nnodes $NNODES\\n    --node_rank $NODE_RANK\\n    --master_addr $MASTER_ADDR\\n    --master_port $MASTER_PORT\\n)\\n\\n# you can setup llama2-70b maunally\\n#MODEL_ARGS=(\\n#    --model-name llama2\\n#    --num-layers 80\\n#    --hidden-size 8192\\n#    --ffn-hidden-size 28672\\n#    --num-attention-heads 64\\n#    --position-embedding-type rope\\n#    --normalization RMSNorm\\n#    --swiglu\\n#    --attention-dropout 0\\n#    --hidden-dropout 0\\n#    --disable-bias-linear\\n#    --untie-embeddings-and-output-weights\\n#    --group-query-attention\\n#    --num-query-groups 8\\n#)\\n\\n# or you can setup llama2-70b by using the following command\\nMODEL_ARGS=(\\n    --model-name llama2-70b # options: llama2-7b, llama2-13b, llama2-70b\\n)\\n\\nDATA_ARGS=(\\n    --tokenizer-type HFTokenizer\\n    --hf-tokenizer-path $TOKENIZER_PATH\\n    --data-path $DATA_PATH\\n    --split 949,50,1\\n)\\n\\nTRAINING_ARGS=(\\n    --training-phase pretrain # options: pretrain, sft\\n    --seq-length 4096\\n    --max-position-embeddings 4096\\n    --init-method-std 0.01\\n    --micro-batch-size 1\\n    --global-batch-size 1024\\n    --lr 0.0002\\n    --min-lr 1.0e-5\\n    --clip-grad 1.0\\n    --weight-decay 0.01\\n    --optimizer adam\\n    --adam-beta1 0.9\\n    --adam-beta2 0.95\\n    --adam-eps 1e-05\\n    --norm-epsilon 1e-6\\n    --train-iters 500000\\n    --lr-decay-iters 500000\\n    --lr-decay-style cosine\\n    --lr-warmup-fraction 0.002\\n    --initial-loss-scale 65536\\n    --fp16\\n    --save-interval 5000\\n    --eval-interval 1000\\n    --eval-iters 10\\n    #--ckpt-step 0\\n    #--no-load-optim\\n    #--no-load-rng\\n)\\n\\nMODEL_PARALLEL_ARGS=(\\n    --tensor-model-parallel-size 4\\n    --pipeline-model-parallel-size 4\\n    --use-distributed-optimizer\\n    --overlap-grad-reduce\\n    --overlap-param-gather\\n    --distributed-backend nccl\\n    --sequence-parallel\\n    #--tp-comm-overlap # require mpi envrionment\\n)\\n\\nLOGGING_ARGS=(\\n    --log-interval 1\\n    --tensorboard-dir ${TENSORBOARD_PATH}\\n    --log-timers-to-tensorboard\\n)\\n\\nif [ -n \\\"${WANDB_API_KEY}\\\" ]; then\\n    LOGGING_ARGS+=(\\n        --wandb-project ${WANDB_PROJECT}\\n        --wandb-exp-name ${WANDB_NAME} \\n    )\\nfi\\n\\nPYTHONPATH=$MEGATRON_PATH:$AIAK_TRAINING_PATH:$PYTHONPATH     torchrun ${DISTRIBUTED_ARGS[@]}     $AIAK_TRAINING_PATH/aiak_training_llm/train.py     ${MODEL_ARGS[@]}     ${DATA_ARGS[@]}     ${TRAINING_ARGS[@]}     ${MODEL_PARALLEL_ARGS[@]}     ${LOGGING_ARGS[@]}\\n\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":true,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi3\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi3/output/training_logs\",\"CUDA_DEVICE_MAX_CONNECTIONS\":\"1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"},\"Worker\":{\"replicas\":3,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi3\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi3/output/training_logs\",\"CUDA_DEVICE_MAX_CONNECTIONS\":\"1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":true,\"logPath\":\"/mnt/cluster/llamatest0718forxiaomi3/output/training_logs\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":true,\"isCopyJob\":true,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
                      "prometheus.io/path": "/metrics",
                      "prometheus.io/port": "9101",
                      "prometheus.io/scrape": "true",
                      "scheduling.k8s.io/job-enable-oversell": "false"
                    },
                    "labels": {
                      "aijob.cce.baidubce.com/ai-user-id": "b5a24aa26e4d4f55bc3acf68edc4b051",
                      "aijob.cce.baidubce.com/ai-user-name": "zhangmuhua",
                      "aijob.cce.baidubce.com/create-from-aihcp": "true",
                      "aijob.cce.baidubce.com/openapi-jobid": "pytorch-e973d356-59b6-4652-8e58-9e9605e1c0d8"
                    }
                  },
                  "spec": {
                    "containers": [
                      {
                        "command": [
                          "/bin/bash",
                          "-c",
                          "\n#! /bin/bash\n\nMEGATRON_PATH=${MEGATRON_PATH:-\"/workspace/AIAK-Megatron\"}\nAIAK_TRAINING_PATH=${AIAK_TRAINING_PATH:-\"/workspace/AIAK-Training-LLM\"}\n\nDATA_PATH=${DATA_PATH:-\"/mnt/cluster/llama2/pile/pile-llama_text_document\"}\nTOKENIZER_PATH=${TOKENIZER_PATH:-\"/mnt/cluster/llama2/Llama-2-70b-hf/tokenizer.model\"}\n\nCHECKPOINT_PATH=${CHECKPOINT_PATH:-\"/mnt/cluster/llama2/mcore_llama2_70b_tp4_pp4\"}\n\nTENSORBOARD_PATH=${TENSORBOARD_PATH:-\"/mnt/cluster/aiak-training-llm/tensorboard-log/llama2-70b-tp4pp4\"}\n\nGPUS_PER_NODE=8\n\n# Change for multinode config\nMASTER_ADDR=${MASTER_ADDR:-\"localhost\"}\nMASTER_PORT=${MASTER_PORT:-\"6000\"}\nNNODES=${WORLD_SIZE:-\"1\"}\nNODE_RANK=${RANK:-\"0\"}\n\nDISTRIBUTED_ARGS=(\n    --nproc_per_node $GPUS_PER_NODE\n    --nnodes $NNODES\n    --node_rank $NODE_RANK\n    --master_addr $MASTER_ADDR\n    --master_port $MASTER_PORT\n)\n\n# you can setup llama2-70b maunally\n#MODEL_ARGS=(\n#    --model-name llama2\n#    --num-layers 80\n#    --hidden-size 8192\n#    --ffn-hidden-size 28672\n#    --num-attention-heads 64\n#    --position-embedding-type rope\n#    --normalization RMSNorm\n#    --swiglu\n#    --attention-dropout 0\n#    --hidden-dropout 0\n#    --disable-bias-linear\n#    --untie-embeddings-and-output-weights\n#    --group-query-attention\n#    --num-query-groups 8\n#)\n\n# or you can setup llama2-70b by using the following command\nMODEL_ARGS=(\n    --model-name llama2-70b # options: llama2-7b, llama2-13b, llama2-70b\n)\n\nDATA_ARGS=(\n    --tokenizer-type HFTokenizer\n    --hf-tokenizer-path $TOKENIZER_PATH\n    --data-path $DATA_PATH\n    --split 949,50,1\n)\n\nTRAINING_ARGS=(\n    --training-phase pretrain # options: pretrain, sft\n    --seq-length 4096\n    --max-position-embeddings 4096\n    --init-method-std 0.01\n    --micro-batch-size 1\n    --global-batch-size 1024\n    --lr 0.0002\n    --min-lr 1.0e-5\n    --clip-grad 1.0\n    --weight-decay 0.01\n    --optimizer adam\n    --adam-beta1 0.9\n    --adam-beta2 0.95\n    --adam-eps 1e-05\n    --norm-epsilon 1e-6\n    --train-iters 500000\n    --lr-decay-iters 500000\n    --lr-decay-style cosine\n    --lr-warmup-fraction 0.002\n    --initial-loss-scale 65536\n    --fp16\n    --save-interval 5000\n    --eval-interval 1000\n    --eval-iters 10\n    #--ckpt-step 0\n    #--no-load-optim\n    #--no-load-rng\n)\n\nMODEL_PARALLEL_ARGS=(\n    --tensor-model-parallel-size 4\n    --pipeline-model-parallel-size 4\n    --use-distributed-optimizer\n    --overlap-grad-reduce\n    --overlap-param-gather\n    --distributed-backend nccl\n    --sequence-parallel\n    #--tp-comm-overlap # require mpi envrionment\n)\n\nLOGGING_ARGS=(\n    --log-interval 1\n    --tensorboard-dir ${TENSORBOARD_PATH}\n    --log-timers-to-tensorboard\n)\n\nif [ -n \"${WANDB_API_KEY}\" ]; then\n    LOGGING_ARGS+=(\n        --wandb-project ${WANDB_PROJECT}\n        --wandb-exp-name ${WANDB_NAME} \n    )\nfi\n\nPYTHONPATH=$MEGATRON_PATH:$AIAK_TRAINING_PATH:$PYTHONPATH     torchrun ${DISTRIBUTED_ARGS[@]}     $AIAK_TRAINING_PATH/aiak_training_llm/train.py     ${MODEL_ARGS[@]}     ${DATA_ARGS[@]}     ${TRAINING_ARGS[@]}     ${MODEL_PARALLEL_ARGS[@]}     ${LOGGING_ARGS[@]}\n"
                        ],
                        "env": [
                          {
                            "name": "AIHC_JOB_NAME",
                            "value": "llamatest0718forxiaomi3"
                          },
                          {
                            "name": "NCCL_IB_DISABLE",
                            "value": "0"
                          },
                          {
                            "name": "CUDA_DEVICE_MAX_CONNECTIONS",
                            "value": "1"
                          },
                          {
                            "name": "AIHC_TENSORBOARD_LOG_PATH",
                            "value": "/mnt/cluster/llamatest0718forxiaomi3/output/training_logs"
                          },
                          {
                            "name": "BCCL_BUS_BW_CALCULATE_MODE",
                            "value": "Agg"
                          },
                          {
                            "name": "BCCL_PROFILING_FILE",
                            "value": "/var/bccl/logs/busbw.cal.%h.%p"
                          }
                        ],
                        "image": "registry.baidubce.com/aihc-aiak/aiak-training-llm:ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release",
                        "imagePullPolicy": "Always",
                        "name": "pytorch",
                        "ports": [
                          {
                            "containerPort": 23456,
                            "name": "pytorchjob-port",
                            "protocol": "TCP"
                          }
                        ],
                        "resources": {
                          "limits": {
                            "baidu.com/a800_80g_cgpu": "8",
                            "rdma/hca": "1"
                          },
                          "requests": {
                            "baidu.com/a800_80g_cgpu": "8",
                            "rdma/hca": "1"
                          }
                        },
                        "securityContext": {
                          "capabilities": {
                            "add": [
                              "IPC_LOCK"
                            ]
                          }
                        },
                        "volumeMounts": [
                          {
                            "mountPath": "/dev/shm",
                            "name": "devshm"
                          },
                          {
                            "mountPath": "/mnt/cluster",
                            "name": "pvc-pfs"
                          },
                          {
                            "mountPath": "/var/bccl/logs",
                            "name": "bccl-logs-volume"
                          }
                        ]
                      },
                      {
                        "env": [
                          {
                            "name": "POD_NAME",
                            "valueFrom": {
                              "fieldRef": {
                                "apiVersion": "v1",
                                "fieldPath": "metadata.name"
                              }
                            }
                          },
                          {
                            "name": "POD_UID",
                            "valueFrom": {
                              "fieldRef": {
                                "apiVersion": "v1",
                                "fieldPath": "metadata.uid"
                              }
                            }
                          },
                          {
                            "name": "POD_NAMESPACE",
                            "valueFrom": {
                              "fieldRef": {
                                "apiVersion": "v1",
                                "fieldPath": "metadata.namespace"
                              }
                            }
                          },
                          {
                            "name": "NODE_NAME",
                            "valueFrom": {
                              "fieldRef": {
                                "apiVersion": "v1",
                                "fieldPath": "spec.nodeName"
                              }
                            }
                          },
                          {
                            "name": "JOB_NAME",
                            "value": "llamatest0718forxiaomi3"
                          },
                          {
                            "name": "NODE_IP",
                            "valueFrom": {
                              "fieldRef": {
                                "apiVersion": "v1",
                                "fieldPath": "status.hostIP"
                              }
                            }
                          },
                          {
                            "name": "ENABLE_ELASTIC",
                            "value": "9"
                          },
                          {
                            "name": "GPUS_PER_NODE",
                            "value": "8"
                          },
                          {
                            "name": "BCCL_LOG_DIR",
                            "value": "/var/bccl/logs"
                          },
                          {
                            "name": "EXPORTER_PORT",
                            "value": "9101"
                          },
                          {
                            "name": "EXPORTER_INTERVAL",
                            "value": "60"
                          },
                          {
                            "name": "EXPORTER_PATH",
                            "value": "/metrics"
                          },
                          {
                            "name": "BCCL_BUS_BW_CALCULATE_MODE",
                            "value": "Agg"
                          },
                          {
                            "name": "BCCL_PROFILING_FILE",
                            "value": "/var/bccl/logs/busbw.cal.%h.%p"
                          }
                        ],
                        "image": "registry.baidubce.com/cce-plugin-dev/ftagent:v1.6-20240713172215",
                        "imagePullPolicy": "Always",
                        "name": "ftagent",
                        "ports": [
                          {
                            "containerPort": 9101,
                            "name": "exporter",
                            "protocol": "TCP"
                          }
                        ],
                        "resources": {},
                        "securityContext": {
                          "capabilities": {
                            "add": [
                              "IPC_LOCK"
                            ]
                          }
                        },
                        "volumeMounts": [
                          {
                            "mountPath": "/var/log/pods",
                            "name": "pod-log-volume"
                          },
                          {
                            "mountPath": "/home/cce",
                            "name": "container-log-volume"
                          },
                          {
                            "mountPath": "/var/bccl/logs",
                            "name": "bccl-logs-volume"
                          }
                        ]
                      }
                    ],
                    "dnsPolicy": "ClusterFirstWithHostNet",
                    "hostNetwork": true,
                    "schedulerName": "volcano",
                    "serviceAccountName": "ftagent-sa",
                    "shareProcessNamespace": true,
                    "volumes": [
                      {
                        "emptyDir": {
                          "medium": "Memory",
                          "sizeLimit": "10Gi"
                        },
                        "name": "devshm"
                      },
                      {
                        "name": "pvc-pfs",
                        "persistentVolumeClaim": {
                          "claimName": "pvc-pfs"
                        }
                      },
                      {
                        "emptyDir": {},
                        "name": "bccl-logs-volume"
                      },
                      {
                        "hostPath": {
                          "path": "/var/log/pods",
                          "type": "DirectoryOrCreate"
                        },
                        "name": "pod-log-volume"
                      },
                      {
                        "hostPath": {
                          "path": "/home/cce",
                          "type": "DirectoryOrCreate"
                        },
                        "name": "container-log-volume"
                      }
                    ]
                  }
                }
              }
            },
            "runPolicy": {
              "cleanPodPolicy": "None",
              "schedulingPolicy": {
                "priorityClass": "high",
                "queue": "default"
              }
            }
          },
          "status": {
            "completionTime": "2024-07-18T02:26:42Z",
            "conditions": [
              {
                "lastTransitionTime": "2024-07-18T02:21:49Z",
                "lastUpdateTime": "2024-07-18T02:21:49Z",
                "message": "PyTorchJob llamatest0718forxiaomi3 is created.",
                "reason": "PyTorchJobCreated",
                "status": "True",
                "type": "Created"
              },
              {
                "lastTransitionTime": "2024-07-18T02:22:02Z",
                "lastUpdateTime": "2024-07-18T02:22:02Z",
                "message": "PyTorchJob llamatest0718forxiaomi3 is running.",
                "reason": "JobRunning",
                "status": "False",
                "type": "Running"
              },
              {
                "lastTransitionTime": "2024-07-18T02:26:42Z",
                "lastUpdateTime": "2024-07-18T02:26:42Z",
                "message": "PytorchJob default/llamatest0718forxiaomi3 is stopped",
                "reason": "PyTorchJobStopped",
                "status": "True",
                "type": "Stopped"
              },
              {
                "lastTransitionTime": "2024-07-18T02:26:42Z",
                "lastUpdateTime": "2024-07-18T02:26:42Z",
                "message": "PyTorchJob llamatest0718forxiaomi3 is failed because 1 Master replica(s) failed.",
                "reason": "JobFailed",
                "status": "True",
                "type": "Failed"
              }
            ],
            "lastReconcileTime": "2024-07-18T02:21:50Z",
            "replicaStatuses": {
              "Master": {
                "failed": 1,
                "selector": "training.kubeflow.org/job-name=llamatest0718forxiaomi3,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=master"
              },
              "Worker": {
                "failed": 3,
                "selector": "training.kubeflow.org/job-name=llamatest0718forxiaomi3,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=worker"
              }
            },
            "startTime": "2024-07-18T02:21:50Z"
          }
        },
        {
          "apiVersion": "kubeflow.org/v1",
          "kind": "PyTorchJob",
          "metadata": {
            "annotations": {
              "aijob.cce.baidubce.com/barrier-finish": "dd6fc2af-82c1-4e46-9b76-035b4e3edcbb",
              "aijob.cce.baidubce.com/fault-tolerance-enabled": "true",
              "aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": "",
              "aijob.cce.baidubce.com/internal-fault-tolerance-time": "2024-07-18T02:27:46.670969774Z",
              "aijob.cce.baidubce.com/openapi-jobid": "pytorch-27acfb1c-f6ea-4a51-93eb-24d0ee3413ac",
              "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
              "aijob.cce.baidubce.com/raw-request": "{\"name\":\"llamatest0718forxiaomi4\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"high\",\"oversell\":false,\"faultTolerance\":true,\"command\":\"\\n#! /bin/bash\\n\\nMEGATRON_PATH=${MEGATRON_PATH:-\\\"/workspace/AIAK-Megatron\\\"}\\nAIAK_TRAINING_PATH=${AIAK_TRAINING_PATH:-\\\"/workspace/AIAK-Training-LLM\\\"}\\n\\nDATA_PATH=${DATA_PATH:-\\\"/mnt/cluster/llama2/pile/pile-llama_text_document\\\"}\\nTOKENIZER_PATH=${TOKENIZER_PATH:-\\\"/mnt/cluster/llama2/Llama-2-70b-hf/\\\"}\\n\\nCHECKPOINT_PATH=${CHECKPOINT_PATH:-\\\"/mnt/cluster/llama2/mcore_llama2_70b_tp4_pp4\\\"}\\n\\nTENSORBOARD_PATH=${TENSORBOARD_PATH:-\\\"/mnt/cluster/aiak-training-llm/tensorboard-log/llama2-70b-tp4pp4\\\"}\\n\\nGPUS_PER_NODE=8\\n\\n# Change for multinode config\\nMASTER_ADDR=${MASTER_ADDR:-\\\"localhost\\\"}\\nMASTER_PORT=${MASTER_PORT:-\\\"6000\\\"}\\nNNODES=${WORLD_SIZE:-\\\"1\\\"}\\nNODE_RANK=${RANK:-\\\"0\\\"}\\n\\nDISTRIBUTED_ARGS=(\\n    --nproc_per_node $GPUS_PER_NODE\\n    --nnodes $NNODES\\n    --node_rank $NODE_RANK\\n    --master_addr $MASTER_ADDR\\n    --master_port $MASTER_PORT\\n)\\n\\n# you can setup llama2-70b maunally\\n#MODEL_ARGS=(\\n#    --model-name llama2\\n#    --num-layers 80\\n#    --hidden-size 8192\\n#    --ffn-hidden-size 28672\\n#    --num-attention-heads 64\\n#    --position-embedding-type rope\\n#    --normalization RMSNorm\\n#    --swiglu\\n#    --attention-dropout 0\\n#    --hidden-dropout 0\\n#    --disable-bias-linear\\n#    --untie-embeddings-and-output-weights\\n#    --group-query-attention\\n#    --num-query-groups 8\\n#)\\n\\n# or you can setup llama2-70b by using the following command\\nMODEL_ARGS=(\\n    --model-name llama2-70b # options: llama2-7b, llama2-13b, llama2-70b\\n)\\n\\nDATA_ARGS=(\\n    --tokenizer-type HFTokenizer\\n    --hf-tokenizer-path $TOKENIZER_PATH\\n    --data-path $DATA_PATH\\n    --split 949,50,1\\n)\\n\\nTRAINING_ARGS=(\\n    --training-phase pretrain # options: pretrain, sft\\n    --seq-length 4096\\n    --max-position-embeddings 4096\\n    --init-method-std 0.01\\n    --micro-batch-size 1\\n    --global-batch-size 1024\\n    --lr 0.0002\\n    --min-lr 1.0e-5\\n    --clip-grad 1.0\\n    --weight-decay 0.01\\n    --optimizer adam\\n    --adam-beta1 0.9\\n    --adam-beta2 0.95\\n    --adam-eps 1e-05\\n    --norm-epsilon 1e-6\\n    --train-iters 500000\\n    --lr-decay-iters 500000\\n    --lr-decay-style cosine\\n    --lr-warmup-fraction 0.002\\n    --initial-loss-scale 65536\\n    --fp16\\n    --save-interval 5000\\n    --eval-interval 1000\\n    --eval-iters 10\\n    #--ckpt-step 0\\n    #--no-load-optim\\n    #--no-load-rng\\n)\\n\\nMODEL_PARALLEL_ARGS=(\\n    --tensor-model-parallel-size 4\\n    --pipeline-model-parallel-size 4\\n    --use-distributed-optimizer\\n    --overlap-grad-reduce\\n    --overlap-param-gather\\n    --distributed-backend nccl\\n    --sequence-parallel\\n    #--tp-comm-overlap # require mpi envrionment\\n)\\n\\nLOGGING_ARGS=(\\n    --log-interval 1\\n    --tensorboard-dir ${TENSORBOARD_PATH}\\n    --log-timers-to-tensorboard\\n)\\n\\nif [ -n \\\"${WANDB_API_KEY}\\\" ]; then\\n    LOGGING_ARGS+=(\\n        --wandb-project ${WANDB_PROJECT}\\n        --wandb-exp-name ${WANDB_NAME} \\n    )\\nfi\\n\\nPYTHONPATH=$MEGATRON_PATH:$AIAK_TRAINING_PATH:$PYTHONPATH     torchrun ${DISTRIBUTED_ARGS[@]}     $AIAK_TRAINING_PATH/aiak_training_llm/train.py     ${MODEL_ARGS[@]}     ${DATA_ARGS[@]}     ${TRAINING_ARGS[@]}     ${MODEL_PARALLEL_ARGS[@]}     ${LOGGING_ARGS[@]}\\n\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":true,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi4\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi4/output/training_logs\",\"CUDA_DEVICE_MAX_CONNECTIONS\":\"1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"},\"Worker\":{\"replicas\":3,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi4\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi4/output/training_logs\",\"CUDA_DEVICE_MAX_CONNECTIONS\":\"1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":true,\"logPath\":\"/mnt/cluster/llamatest0718forxiaomi4/output/training_logs\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":true,\"isCopyJob\":true,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
              "aijob.cce.baidubce.com/timeline": "[{\"conditionType\":\"Created\",\"time\":1721269594},{\"conditionType\":\"Scheduled\",\"time\":1721269596},{\"conditionType\":\"Running\",\"time\":1721269606},{\"conditionType\":\"Abnormal\",\"time\":1721269666},{\"conditionType\":\"ManualTermination\",\"time\":1721269834}]",
              "job-manager/action": "stop",
              "scheduling.k8s.io/job-enable-oversell": "false",
              "tensorboard-gc": "true"
            },
            "creationTimestamp": "2024-07-18T02:26:34Z",
            "generation": 3,
            "labels": {
              "aijob.cce.baidubce.com/ai-user-id": "b5a24aa26e4d4f55bc3acf68edc4b051",
              "aijob.cce.baidubce.com/ai-user-name": "zhangmuhua",
              "aijob.cce.baidubce.com/create-from-aihcp": "true",
              "aijob.cce.baidubce.com/openapi-jobid": "pytorch-27acfb1c-f6ea-4a51-93eb-24d0ee3413ac"
            },
            "managedFields": [
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      "f:aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": {},
                      "f:aijob.cce.baidubce.com/timeline": {}
                    }
                  },
                  "f:spec": {
                    "f:runPolicy": {
                      "f:cleanPodPolicy": {}
                    }
                  }
                },
                "manager": "controller",
                "operation": "Update",
                "time": "2024-07-18T02:26:34Z"
              },
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      "f:aijob.cce.baidubce.com/barrier-finish": {}
                    }
                  }
                },
                "manager": "jobbarrier",
                "operation": "Update",
                "time": "2024-07-18T02:26:43Z"
              },
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      ".": {},
                      "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                      "f:aijob.cce.baidubce.com/openapi-jobid": {},
                      "f:aijob.cce.baidubce.com/pfs-id": {},
                      "f:aijob.cce.baidubce.com/raw-request": {},
                      "f:job-manager/action": {},
                      "f:scheduling.k8s.io/job-enable-oversell": {}
                    },
                    "f:labels": {
                      ".": {},
                      "f:aijob.cce.baidubce.com/ai-user-id": {},
                      "f:aijob.cce.baidubce.com/ai-user-name": {},
                      "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                      "f:aijob.cce.baidubce.com/openapi-jobid": {}
                    }
                  },
                  "f:spec": {
                    ".": {},
                    "f:pytorchReplicaSpecs": {
                      ".": {},
                      "f:Master": {
                        ".": {},
                        "f:replicas": {},
                        "f:restartPolicy": {},
                        "f:template": {
                          ".": {},
                          "f:metadata": {
                            ".": {},
                            "f:annotations": {
                              ".": {},
                              "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                              "f:aijob.cce.baidubce.com/openapi-jobid": {},
                              "f:aijob.cce.baidubce.com/pfs-id": {},
                              "f:aijob.cce.baidubce.com/raw-request": {},
                              "f:scheduling.k8s.io/job-enable-oversell": {}
                            },
                            "f:labels": {
                              ".": {},
                              "f:aijob.cce.baidubce.com/ai-user-id": {},
                              "f:aijob.cce.baidubce.com/ai-user-name": {},
                              "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                              "f:aijob.cce.baidubce.com/openapi-jobid": {}
                            }
                          },
                          "f:spec": {
                            ".": {},
                            "f:dnsPolicy": {},
                            "f:hostNetwork": {},
                            "f:schedulerName": {}
                          }
                        }
                      },
                      "f:Worker": {
                        ".": {},
                        "f:replicas": {},
                        "f:restartPolicy": {},
                        "f:template": {
                          ".": {},
                          "f:metadata": {
                            ".": {},
                            "f:annotations": {
                              ".": {},
                              "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                              "f:aijob.cce.baidubce.com/openapi-jobid": {},
                              "f:aijob.cce.baidubce.com/pfs-id": {},
                              "f:aijob.cce.baidubce.com/raw-request": {},
                              "f:scheduling.k8s.io/job-enable-oversell": {}
                            },
                            "f:labels": {
                              ".": {},
                              "f:aijob.cce.baidubce.com/ai-user-id": {},
                              "f:aijob.cce.baidubce.com/ai-user-name": {},
                              "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                              "f:aijob.cce.baidubce.com/openapi-jobid": {}
                            }
                          },
                          "f:spec": {
                            ".": {},
                            "f:dnsPolicy": {},
                            "f:hostNetwork": {},
                            "f:schedulerName": {}
                          }
                        }
                      }
                    },
                    "f:runPolicy": {
                      ".": {},
                      "f:schedulingPolicy": {
                        ".": {},
                        "f:priorityClass": {},
                        "f:queue": {}
                      }
                    }
                  }
                },
                "manager": "cce-ai-service",
                "operation": "Update",
                "time": "2024-07-18T02:30:34Z"
              },
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      "f:aijob.cce.baidubce.com/internal-fault-tolerance-time": {},
                      "f:tensorboard-gc": {}
                    }
                  },
                  "f:spec": {
                    "f:pytorchReplicaSpecs": {
                      "f:Master": {
                        "f:template": {
                          "f:metadata": {
                            "f:annotations": {
                              "f:prometheus.io/path": {},
                              "f:prometheus.io/port": {},
                              "f:prometheus.io/scrape": {}
                            }
                          },
                          "f:spec": {
                            "f:containers": {},
                            "f:serviceAccountName": {},
                            "f:shareProcessNamespace": {},
                            "f:volumes": {}
                          }
                        }
                      },
                      "f:Worker": {
                        "f:template": {
                          "f:metadata": {
                            "f:annotations": {
                              "f:prometheus.io/path": {},
                              "f:prometheus.io/port": {},
                              "f:prometheus.io/scrape": {}
                            }
                          },
                          "f:spec": {
                            "f:containers": {},
                            "f:serviceAccountName": {},
                            "f:shareProcessNamespace": {},
                            "f:volumes": {}
                          }
                        }
                      }
                    }
                  },
                  "f:status": {
                    ".": {},
                    "f:completionTime": {},
                    "f:conditions": {},
                    "f:lastReconcileTime": {},
                    "f:replicaStatuses": {
                      ".": {},
                      "f:Master": {
                        ".": {},
                        "f:failed": {}
                      },
                      "f:Worker": {
                        ".": {},
                        "f:failed": {}
                      }
                    },
                    "f:startTime": {}
                  }
                },
                "manager": "manager",
                "operation": "Update",
                "time": "2024-07-19T02:26:55Z"
              }
            ],
            "name": "llamatest0718forxiaomi4",
            "namespace": "default",
            "resourceVersion": "2372392872",
            "uid": "58c8d30d-ea83-41d1-bbb0-b3657be888dd"
          },
          "spec": {
            "pytorchReplicaSpecs": {
              "Master": {
                "replicas": 1,
                "restartPolicy": "Never",
                "template": {
                  "metadata": {
                    "annotations": {
                      "aijob.cce.baidubce.com/fault-tolerance-enabled": "true",
                      "aijob.cce.baidubce.com/openapi-jobid": "pytorch-27acfb1c-f6ea-4a51-93eb-24d0ee3413ac",
                      "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
                      "aijob.cce.baidubce.com/raw-request": "{\"name\":\"llamatest0718forxiaomi4\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"high\",\"oversell\":false,\"faultTolerance\":true,\"command\":\"\\n#! /bin/bash\\n\\nMEGATRON_PATH=${MEGATRON_PATH:-\\\"/workspace/AIAK-Megatron\\\"}\\nAIAK_TRAINING_PATH=${AIAK_TRAINING_PATH:-\\\"/workspace/AIAK-Training-LLM\\\"}\\n\\nDATA_PATH=${DATA_PATH:-\\\"/mnt/cluster/llama2/pile/pile-llama_text_document\\\"}\\nTOKENIZER_PATH=${TOKENIZER_PATH:-\\\"/mnt/cluster/llama2/Llama-2-70b-hf/\\\"}\\n\\nCHECKPOINT_PATH=${CHECKPOINT_PATH:-\\\"/mnt/cluster/llama2/mcore_llama2_70b_tp4_pp4\\\"}\\n\\nTENSORBOARD_PATH=${TENSORBOARD_PATH:-\\\"/mnt/cluster/aiak-training-llm/tensorboard-log/llama2-70b-tp4pp4\\\"}\\n\\nGPUS_PER_NODE=8\\n\\n# Change for multinode config\\nMASTER_ADDR=${MASTER_ADDR:-\\\"localhost\\\"}\\nMASTER_PORT=${MASTER_PORT:-\\\"6000\\\"}\\nNNODES=${WORLD_SIZE:-\\\"1\\\"}\\nNODE_RANK=${RANK:-\\\"0\\\"}\\n\\nDISTRIBUTED_ARGS=(\\n    --nproc_per_node $GPUS_PER_NODE\\n    --nnodes $NNODES\\n    --node_rank $NODE_RANK\\n    --master_addr $MASTER_ADDR\\n    --master_port $MASTER_PORT\\n)\\n\\n# you can setup llama2-70b maunally\\n#MODEL_ARGS=(\\n#    --model-name llama2\\n#    --num-layers 80\\n#    --hidden-size 8192\\n#    --ffn-hidden-size 28672\\n#    --num-attention-heads 64\\n#    --position-embedding-type rope\\n#    --normalization RMSNorm\\n#    --swiglu\\n#    --attention-dropout 0\\n#    --hidden-dropout 0\\n#    --disable-bias-linear\\n#    --untie-embeddings-and-output-weights\\n#    --group-query-attention\\n#    --num-query-groups 8\\n#)\\n\\n# or you can setup llama2-70b by using the following command\\nMODEL_ARGS=(\\n    --model-name llama2-70b # options: llama2-7b, llama2-13b, llama2-70b\\n)\\n\\nDATA_ARGS=(\\n    --tokenizer-type HFTokenizer\\n    --hf-tokenizer-path $TOKENIZER_PATH\\n    --data-path $DATA_PATH\\n    --split 949,50,1\\n)\\n\\nTRAINING_ARGS=(\\n    --training-phase pretrain # options: pretrain, sft\\n    --seq-length 4096\\n    --max-position-embeddings 4096\\n    --init-method-std 0.01\\n    --micro-batch-size 1\\n    --global-batch-size 1024\\n    --lr 0.0002\\n    --min-lr 1.0e-5\\n    --clip-grad 1.0\\n    --weight-decay 0.01\\n    --optimizer adam\\n    --adam-beta1 0.9\\n    --adam-beta2 0.95\\n    --adam-eps 1e-05\\n    --norm-epsilon 1e-6\\n    --train-iters 500000\\n    --lr-decay-iters 500000\\n    --lr-decay-style cosine\\n    --lr-warmup-fraction 0.002\\n    --initial-loss-scale 65536\\n    --fp16\\n    --save-interval 5000\\n    --eval-interval 1000\\n    --eval-iters 10\\n    #--ckpt-step 0\\n    #--no-load-optim\\n    #--no-load-rng\\n)\\n\\nMODEL_PARALLEL_ARGS=(\\n    --tensor-model-parallel-size 4\\n    --pipeline-model-parallel-size 4\\n    --use-distributed-optimizer\\n    --overlap-grad-reduce\\n    --overlap-param-gather\\n    --distributed-backend nccl\\n    --sequence-parallel\\n    #--tp-comm-overlap # require mpi envrionment\\n)\\n\\nLOGGING_ARGS=(\\n    --log-interval 1\\n    --tensorboard-dir ${TENSORBOARD_PATH}\\n    --log-timers-to-tensorboard\\n)\\n\\nif [ -n \\\"${WANDB_API_KEY}\\\" ]; then\\n    LOGGING_ARGS+=(\\n        --wandb-project ${WANDB_PROJECT}\\n        --wandb-exp-name ${WANDB_NAME} \\n    )\\nfi\\n\\nPYTHONPATH=$MEGATRON_PATH:$AIAK_TRAINING_PATH:$PYTHONPATH     torchrun ${DISTRIBUTED_ARGS[@]}     $AIAK_TRAINING_PATH/aiak_training_llm/train.py     ${MODEL_ARGS[@]}     ${DATA_ARGS[@]}     ${TRAINING_ARGS[@]}     ${MODEL_PARALLEL_ARGS[@]}     ${LOGGING_ARGS[@]}\\n\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":true,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi4\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi4/output/training_logs\",\"CUDA_DEVICE_MAX_CONNECTIONS\":\"1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"},\"Worker\":{\"replicas\":3,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi4\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi4/output/training_logs\",\"CUDA_DEVICE_MAX_CONNECTIONS\":\"1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":true,\"logPath\":\"/mnt/cluster/llamatest0718forxiaomi4/output/training_logs\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":true,\"isCopyJob\":true,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
                      "prometheus.io/path": "/metrics",
                      "prometheus.io/port": "9101",
                      "prometheus.io/scrape": "true",
                      "scheduling.k8s.io/job-enable-oversell": "false"
                    },
                    "labels": {
                      "aijob.cce.baidubce.com/ai-user-id": "b5a24aa26e4d4f55bc3acf68edc4b051",
                      "aijob.cce.baidubce.com/ai-user-name": "zhangmuhua",
                      "aijob.cce.baidubce.com/create-from-aihcp": "true",
                      "aijob.cce.baidubce.com/openapi-jobid": "pytorch-27acfb1c-f6ea-4a51-93eb-24d0ee3413ac"
                    }
                  },
                  "spec": {
                    "containers": [
                      {
                        "command": [
                          "/bin/bash",
                          "-c",
                          "\n#! /bin/bash\n\nMEGATRON_PATH=${MEGATRON_PATH:-\"/workspace/AIAK-Megatron\"}\nAIAK_TRAINING_PATH=${AIAK_TRAINING_PATH:-\"/workspace/AIAK-Training-LLM\"}\n\nDATA_PATH=${DATA_PATH:-\"/mnt/cluster/llama2/pile/pile-llama_text_document\"}\nTOKENIZER_PATH=${TOKENIZER_PATH:-\"/mnt/cluster/llama2/Llama-2-70b-hf/\"}\n\nCHECKPOINT_PATH=${CHECKPOINT_PATH:-\"/mnt/cluster/llama2/mcore_llama2_70b_tp4_pp4\"}\n\nTENSORBOARD_PATH=${TENSORBOARD_PATH:-\"/mnt/cluster/aiak-training-llm/tensorboard-log/llama2-70b-tp4pp4\"}\n\nGPUS_PER_NODE=8\n\n# Change for multinode config\nMASTER_ADDR=${MASTER_ADDR:-\"localhost\"}\nMASTER_PORT=${MASTER_PORT:-\"6000\"}\nNNODES=${WORLD_SIZE:-\"1\"}\nNODE_RANK=${RANK:-\"0\"}\n\nDISTRIBUTED_ARGS=(\n    --nproc_per_node $GPUS_PER_NODE\n    --nnodes $NNODES\n    --node_rank $NODE_RANK\n    --master_addr $MASTER_ADDR\n    --master_port $MASTER_PORT\n)\n\n# you can setup llama2-70b maunally\n#MODEL_ARGS=(\n#    --model-name llama2\n#    --num-layers 80\n#    --hidden-size 8192\n#    --ffn-hidden-size 28672\n#    --num-attention-heads 64\n#    --position-embedding-type rope\n#    --normalization RMSNorm\n#    --swiglu\n#    --attention-dropout 0\n#    --hidden-dropout 0\n#    --disable-bias-linear\n#    --untie-embeddings-and-output-weights\n#    --group-query-attention\n#    --num-query-groups 8\n#)\n\n# or you can setup llama2-70b by using the following command\nMODEL_ARGS=(\n    --model-name llama2-70b # options: llama2-7b, llama2-13b, llama2-70b\n)\n\nDATA_ARGS=(\n    --tokenizer-type HFTokenizer\n    --hf-tokenizer-path $TOKENIZER_PATH\n    --data-path $DATA_PATH\n    --split 949,50,1\n)\n\nTRAINING_ARGS=(\n    --training-phase pretrain # options: pretrain, sft\n    --seq-length 4096\n    --max-position-embeddings 4096\n    --init-method-std 0.01\n    --micro-batch-size 1\n    --global-batch-size 1024\n    --lr 0.0002\n    --min-lr 1.0e-5\n    --clip-grad 1.0\n    --weight-decay 0.01\n    --optimizer adam\n    --adam-beta1 0.9\n    --adam-beta2 0.95\n    --adam-eps 1e-05\n    --norm-epsilon 1e-6\n    --train-iters 500000\n    --lr-decay-iters 500000\n    --lr-decay-style cosine\n    --lr-warmup-fraction 0.002\n    --initial-loss-scale 65536\n    --fp16\n    --save-interval 5000\n    --eval-interval 1000\n    --eval-iters 10\n    #--ckpt-step 0\n    #--no-load-optim\n    #--no-load-rng\n)\n\nMODEL_PARALLEL_ARGS=(\n    --tensor-model-parallel-size 4\n    --pipeline-model-parallel-size 4\n    --use-distributed-optimizer\n    --overlap-grad-reduce\n    --overlap-param-gather\n    --distributed-backend nccl\n    --sequence-parallel\n    #--tp-comm-overlap # require mpi envrionment\n)\n\nLOGGING_ARGS=(\n    --log-interval 1\n    --tensorboard-dir ${TENSORBOARD_PATH}\n    --log-timers-to-tensorboard\n)\n\nif [ -n \"${WANDB_API_KEY}\" ]; then\n    LOGGING_ARGS+=(\n        --wandb-project ${WANDB_PROJECT}\n        --wandb-exp-name ${WANDB_NAME} \n    )\nfi\n\nPYTHONPATH=$MEGATRON_PATH:$AIAK_TRAINING_PATH:$PYTHONPATH     torchrun ${DISTRIBUTED_ARGS[@]}     $AIAK_TRAINING_PATH/aiak_training_llm/train.py     ${MODEL_ARGS[@]}     ${DATA_ARGS[@]}     ${TRAINING_ARGS[@]}     ${MODEL_PARALLEL_ARGS[@]}     ${LOGGING_ARGS[@]}\n"
                        ],
                        "env": [
                          {
                            "name": "CUDA_DEVICE_MAX_CONNECTIONS",
                            "value": "1"
                          },
                          {
                            "name": "AIHC_TENSORBOARD_LOG_PATH",
                            "value": "/mnt/cluster/llamatest0718forxiaomi4/output/training_logs"
                          },
                          {
                            "name": "AIHC_JOB_NAME",
                            "value": "llamatest0718forxiaomi4"
                          },
                          {
                            "name": "NCCL_IB_DISABLE",
                            "value": "0"
                          },
                          {
                            "name": "BCCL_BUS_BW_CALCULATE_MODE",
                            "value": "Agg"
                          },
                          {
                            "name": "BCCL_PROFILING_FILE",
                            "value": "/var/bccl/logs/busbw.cal.%h.%p"
                          }
                        ],
                        "image": "registry.baidubce.com/aihc-aiak/aiak-training-llm:ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release",
                        "imagePullPolicy": "Always",
                        "name": "pytorch",
                        "ports": [
                          {
                            "containerPort": 23456,
                            "name": "pytorchjob-port",
                            "protocol": "TCP"
                          }
                        ],
                        "resources": {
                          "limits": {
                            "baidu.com/a800_80g_cgpu": "8",
                            "rdma/hca": "1"
                          },
                          "requests": {
                            "baidu.com/a800_80g_cgpu": "8",
                            "rdma/hca": "1"
                          }
                        },
                        "securityContext": {
                          "capabilities": {
                            "add": [
                              "IPC_LOCK"
                            ]
                          }
                        },
                        "volumeMounts": [
                          {
                            "mountPath": "/dev/shm",
                            "name": "devshm"
                          },
                          {
                            "mountPath": "/mnt/cluster",
                            "name": "pvc-pfs"
                          },
                          {
                            "mountPath": "/var/bccl/logs",
                            "name": "bccl-logs-volume"
                          }
                        ]
                      },
                      {
                        "env": [
                          {
                            "name": "POD_NAME",
                            "valueFrom": {
                              "fieldRef": {
                                "apiVersion": "v1",
                                "fieldPath": "metadata.name"
                              }
                            }
                          },
                          {
                            "name": "POD_UID",
                            "valueFrom": {
                              "fieldRef": {
                                "apiVersion": "v1",
                                "fieldPath": "metadata.uid"
                              }
                            }
                          },
                          {
                            "name": "POD_NAMESPACE",
                            "valueFrom": {
                              "fieldRef": {
                                "apiVersion": "v1",
                                "fieldPath": "metadata.namespace"
                              }
                            }
                          },
                          {
                            "name": "NODE_NAME",
                            "valueFrom": {
                              "fieldRef": {
                                "apiVersion": "v1",
                                "fieldPath": "spec.nodeName"
                              }
                            }
                          },
                          {
                            "name": "JOB_NAME",
                            "value": "llamatest0718forxiaomi4"
                          },
                          {
                            "name": "NODE_IP",
                            "valueFrom": {
                              "fieldRef": {
                                "apiVersion": "v1",
                                "fieldPath": "status.hostIP"
                              }
                            }
                          },
                          {
                            "name": "ENABLE_ELASTIC",
                            "value": "9"
                          },
                          {
                            "name": "GPUS_PER_NODE",
                            "value": "8"
                          },
                          {
                            "name": "BCCL_LOG_DIR",
                            "value": "/var/bccl/logs"
                          },
                          {
                            "name": "EXPORTER_PORT",
                            "value": "9101"
                          },
                          {
                            "name": "EXPORTER_INTERVAL",
                            "value": "60"
                          },
                          {
                            "name": "EXPORTER_PATH",
                            "value": "/metrics"
                          },
                          {
                            "name": "BCCL_BUS_BW_CALCULATE_MODE",
                            "value": "Agg"
                          },
                          {
                            "name": "BCCL_PROFILING_FILE",
                            "value": "/var/bccl/logs/busbw.cal.%h.%p"
                          }
                        ],
                        "image": "registry.baidubce.com/cce-plugin-dev/ftagent:v1.6-20240713172215",
                        "imagePullPolicy": "Always",
                        "name": "ftagent",
                        "ports": [
                          {
                            "containerPort": 9101,
                            "name": "exporter",
                            "protocol": "TCP"
                          }
                        ],
                        "resources": {},
                        "securityContext": {
                          "capabilities": {
                            "add": [
                              "IPC_LOCK"
                            ]
                          }
                        },
                        "volumeMounts": [
                          {
                            "mountPath": "/var/log/pods",
                            "name": "pod-log-volume"
                          },
                          {
                            "mountPath": "/home/cce",
                            "name": "container-log-volume"
                          },
                          {
                            "mountPath": "/var/bccl/logs",
                            "name": "bccl-logs-volume"
                          }
                        ]
                      }
                    ],
                    "dnsPolicy": "ClusterFirstWithHostNet",
                    "hostNetwork": true,
                    "schedulerName": "volcano",
                    "serviceAccountName": "ftagent-sa",
                    "shareProcessNamespace": true,
                    "volumes": [
                      {
                        "emptyDir": {
                          "medium": "Memory",
                          "sizeLimit": "10Gi"
                        },
                        "name": "devshm"
                      },
                      {
                        "name": "pvc-pfs",
                        "persistentVolumeClaim": {
                          "claimName": "pvc-pfs"
                        }
                      },
                      {
                        "emptyDir": {},
                        "name": "bccl-logs-volume"
                      },
                      {
                        "hostPath": {
                          "path": "/var/log/pods",
                          "type": "DirectoryOrCreate"
                        },
                        "name": "pod-log-volume"
                      },
                      {
                        "hostPath": {
                          "path": "/home/cce",
                          "type": "DirectoryOrCreate"
                        },
                        "name": "container-log-volume"
                      }
                    ]
                  }
                }
              },
              "Worker": {
                "replicas": 3,
                "restartPolicy": "Never",
                "template": {
                  "metadata": {
                    "annotations": {
                      "aijob.cce.baidubce.com/fault-tolerance-enabled": "true",
                      "aijob.cce.baidubce.com/openapi-jobid": "pytorch-27acfb1c-f6ea-4a51-93eb-24d0ee3413ac",
                      "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
                      "aijob.cce.baidubce.com/raw-request": "{\"name\":\"llamatest0718forxiaomi4\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"high\",\"oversell\":false,\"faultTolerance\":true,\"command\":\"\\n#! /bin/bash\\n\\nMEGATRON_PATH=${MEGATRON_PATH:-\\\"/workspace/AIAK-Megatron\\\"}\\nAIAK_TRAINING_PATH=${AIAK_TRAINING_PATH:-\\\"/workspace/AIAK-Training-LLM\\\"}\\n\\nDATA_PATH=${DATA_PATH:-\\\"/mnt/cluster/llama2/pile/pile-llama_text_document\\\"}\\nTOKENIZER_PATH=${TOKENIZER_PATH:-\\\"/mnt/cluster/llama2/Llama-2-70b-hf/\\\"}\\n\\nCHECKPOINT_PATH=${CHECKPOINT_PATH:-\\\"/mnt/cluster/llama2/mcore_llama2_70b_tp4_pp4\\\"}\\n\\nTENSORBOARD_PATH=${TENSORBOARD_PATH:-\\\"/mnt/cluster/aiak-training-llm/tensorboard-log/llama2-70b-tp4pp4\\\"}\\n\\nGPUS_PER_NODE=8\\n\\n# Change for multinode config\\nMASTER_ADDR=${MASTER_ADDR:-\\\"localhost\\\"}\\nMASTER_PORT=${MASTER_PORT:-\\\"6000\\\"}\\nNNODES=${WORLD_SIZE:-\\\"1\\\"}\\nNODE_RANK=${RANK:-\\\"0\\\"}\\n\\nDISTRIBUTED_ARGS=(\\n    --nproc_per_node $GPUS_PER_NODE\\n    --nnodes $NNODES\\n    --node_rank $NODE_RANK\\n    --master_addr $MASTER_ADDR\\n    --master_port $MASTER_PORT\\n)\\n\\n# you can setup llama2-70b maunally\\n#MODEL_ARGS=(\\n#    --model-name llama2\\n#    --num-layers 80\\n#    --hidden-size 8192\\n#    --ffn-hidden-size 28672\\n#    --num-attention-heads 64\\n#    --position-embedding-type rope\\n#    --normalization RMSNorm\\n#    --swiglu\\n#    --attention-dropout 0\\n#    --hidden-dropout 0\\n#    --disable-bias-linear\\n#    --untie-embeddings-and-output-weights\\n#    --group-query-attention\\n#    --num-query-groups 8\\n#)\\n\\n# or you can setup llama2-70b by using the following command\\nMODEL_ARGS=(\\n    --model-name llama2-70b # options: llama2-7b, llama2-13b, llama2-70b\\n)\\n\\nDATA_ARGS=(\\n    --tokenizer-type HFTokenizer\\n    --hf-tokenizer-path $TOKENIZER_PATH\\n    --data-path $DATA_PATH\\n    --split 949,50,1\\n)\\n\\nTRAINING_ARGS=(\\n    --training-phase pretrain # options: pretrain, sft\\n    --seq-length 4096\\n    --max-position-embeddings 4096\\n    --init-method-std 0.01\\n    --micro-batch-size 1\\n    --global-batch-size 1024\\n    --lr 0.0002\\n    --min-lr 1.0e-5\\n    --clip-grad 1.0\\n    --weight-decay 0.01\\n    --optimizer adam\\n    --adam-beta1 0.9\\n    --adam-beta2 0.95\\n    --adam-eps 1e-05\\n    --norm-epsilon 1e-6\\n    --train-iters 500000\\n    --lr-decay-iters 500000\\n    --lr-decay-style cosine\\n    --lr-warmup-fraction 0.002\\n    --initial-loss-scale 65536\\n    --fp16\\n    --save-interval 5000\\n    --eval-interval 1000\\n    --eval-iters 10\\n    #--ckpt-step 0\\n    #--no-load-optim\\n    #--no-load-rng\\n)\\n\\nMODEL_PARALLEL_ARGS=(\\n    --tensor-model-parallel-size 4\\n    --pipeline-model-parallel-size 4\\n    --use-distributed-optimizer\\n    --overlap-grad-reduce\\n    --overlap-param-gather\\n    --distributed-backend nccl\\n    --sequence-parallel\\n    #--tp-comm-overlap # require mpi envrionment\\n)\\n\\nLOGGING_ARGS=(\\n    --log-interval 1\\n    --tensorboard-dir ${TENSORBOARD_PATH}\\n    --log-timers-to-tensorboard\\n)\\n\\nif [ -n \\\"${WANDB_API_KEY}\\\" ]; then\\n    LOGGING_ARGS+=(\\n        --wandb-project ${WANDB_PROJECT}\\n        --wandb-exp-name ${WANDB_NAME} \\n    )\\nfi\\n\\nPYTHONPATH=$MEGATRON_PATH:$AIAK_TRAINING_PATH:$PYTHONPATH     torchrun ${DISTRIBUTED_ARGS[@]}     $AIAK_TRAINING_PATH/aiak_training_llm/train.py     ${MODEL_ARGS[@]}     ${DATA_ARGS[@]}     ${TRAINING_ARGS[@]}     ${MODEL_PARALLEL_ARGS[@]}     ${LOGGING_ARGS[@]}\\n\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":true,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi4\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi4/output/training_logs\",\"CUDA_DEVICE_MAX_CONNECTIONS\":\"1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"},\"Worker\":{\"replicas\":3,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi4\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi4/output/training_logs\",\"CUDA_DEVICE_MAX_CONNECTIONS\":\"1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":true,\"logPath\":\"/mnt/cluster/llamatest0718forxiaomi4/output/training_logs\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":true,\"isCopyJob\":true,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
                      "prometheus.io/path": "/metrics",
                      "prometheus.io/port": "9101",
                      "prometheus.io/scrape": "true",
                      "scheduling.k8s.io/job-enable-oversell": "false"
                    },
                    "labels": {
                      "aijob.cce.baidubce.com/ai-user-id": "b5a24aa26e4d4f55bc3acf68edc4b051",
                      "aijob.cce.baidubce.com/ai-user-name": "zhangmuhua",
                      "aijob.cce.baidubce.com/create-from-aihcp": "true",
                      "aijob.cce.baidubce.com/openapi-jobid": "pytorch-27acfb1c-f6ea-4a51-93eb-24d0ee3413ac"
                    }
                  },
                  "spec": {
                    "containers": [
                      {
                        "command": [
                          "/bin/bash",
                          "-c",
                          "\n#! /bin/bash\n\nMEGATRON_PATH=${MEGATRON_PATH:-\"/workspace/AIAK-Megatron\"}\nAIAK_TRAINING_PATH=${AIAK_TRAINING_PATH:-\"/workspace/AIAK-Training-LLM\"}\n\nDATA_PATH=${DATA_PATH:-\"/mnt/cluster/llama2/pile/pile-llama_text_document\"}\nTOKENIZER_PATH=${TOKENIZER_PATH:-\"/mnt/cluster/llama2/Llama-2-70b-hf/\"}\n\nCHECKPOINT_PATH=${CHECKPOINT_PATH:-\"/mnt/cluster/llama2/mcore_llama2_70b_tp4_pp4\"}\n\nTENSORBOARD_PATH=${TENSORBOARD_PATH:-\"/mnt/cluster/aiak-training-llm/tensorboard-log/llama2-70b-tp4pp4\"}\n\nGPUS_PER_NODE=8\n\n# Change for multinode config\nMASTER_ADDR=${MASTER_ADDR:-\"localhost\"}\nMASTER_PORT=${MASTER_PORT:-\"6000\"}\nNNODES=${WORLD_SIZE:-\"1\"}\nNODE_RANK=${RANK:-\"0\"}\n\nDISTRIBUTED_ARGS=(\n    --nproc_per_node $GPUS_PER_NODE\n    --nnodes $NNODES\n    --node_rank $NODE_RANK\n    --master_addr $MASTER_ADDR\n    --master_port $MASTER_PORT\n)\n\n# you can setup llama2-70b maunally\n#MODEL_ARGS=(\n#    --model-name llama2\n#    --num-layers 80\n#    --hidden-size 8192\n#    --ffn-hidden-size 28672\n#    --num-attention-heads 64\n#    --position-embedding-type rope\n#    --normalization RMSNorm\n#    --swiglu\n#    --attention-dropout 0\n#    --hidden-dropout 0\n#    --disable-bias-linear\n#    --untie-embeddings-and-output-weights\n#    --group-query-attention\n#    --num-query-groups 8\n#)\n\n# or you can setup llama2-70b by using the following command\nMODEL_ARGS=(\n    --model-name llama2-70b # options: llama2-7b, llama2-13b, llama2-70b\n)\n\nDATA_ARGS=(\n    --tokenizer-type HFTokenizer\n    --hf-tokenizer-path $TOKENIZER_PATH\n    --data-path $DATA_PATH\n    --split 949,50,1\n)\n\nTRAINING_ARGS=(\n    --training-phase pretrain # options: pretrain, sft\n    --seq-length 4096\n    --max-position-embeddings 4096\n    --init-method-std 0.01\n    --micro-batch-size 1\n    --global-batch-size 1024\n    --lr 0.0002\n    --min-lr 1.0e-5\n    --clip-grad 1.0\n    --weight-decay 0.01\n    --optimizer adam\n    --adam-beta1 0.9\n    --adam-beta2 0.95\n    --adam-eps 1e-05\n    --norm-epsilon 1e-6\n    --train-iters 500000\n    --lr-decay-iters 500000\n    --lr-decay-style cosine\n    --lr-warmup-fraction 0.002\n    --initial-loss-scale 65536\n    --fp16\n    --save-interval 5000\n    --eval-interval 1000\n    --eval-iters 10\n    #--ckpt-step 0\n    #--no-load-optim\n    #--no-load-rng\n)\n\nMODEL_PARALLEL_ARGS=(\n    --tensor-model-parallel-size 4\n    --pipeline-model-parallel-size 4\n    --use-distributed-optimizer\n    --overlap-grad-reduce\n    --overlap-param-gather\n    --distributed-backend nccl\n    --sequence-parallel\n    #--tp-comm-overlap # require mpi envrionment\n)\n\nLOGGING_ARGS=(\n    --log-interval 1\n    --tensorboard-dir ${TENSORBOARD_PATH}\n    --log-timers-to-tensorboard\n)\n\nif [ -n \"${WANDB_API_KEY}\" ]; then\n    LOGGING_ARGS+=(\n        --wandb-project ${WANDB_PROJECT}\n        --wandb-exp-name ${WANDB_NAME} \n    )\nfi\n\nPYTHONPATH=$MEGATRON_PATH:$AIAK_TRAINING_PATH:$PYTHONPATH     torchrun ${DISTRIBUTED_ARGS[@]}     $AIAK_TRAINING_PATH/aiak_training_llm/train.py     ${MODEL_ARGS[@]}     ${DATA_ARGS[@]}     ${TRAINING_ARGS[@]}     ${MODEL_PARALLEL_ARGS[@]}     ${LOGGING_ARGS[@]}\n"
                        ],
                        "env": [
                          {
                            "name": "NCCL_IB_DISABLE",
                            "value": "0"
                          },
                          {
                            "name": "CUDA_DEVICE_MAX_CONNECTIONS",
                            "value": "1"
                          },
                          {
                            "name": "AIHC_TENSORBOARD_LOG_PATH",
                            "value": "/mnt/cluster/llamatest0718forxiaomi4/output/training_logs"
                          },
                          {
                            "name": "AIHC_JOB_NAME",
                            "value": "llamatest0718forxiaomi4"
                          },
                          {
                            "name": "BCCL_BUS_BW_CALCULATE_MODE",
                            "value": "Agg"
                          },
                          {
                            "name": "BCCL_PROFILING_FILE",
                            "value": "/var/bccl/logs/busbw.cal.%h.%p"
                          }
                        ],
                        "image": "registry.baidubce.com/aihc-aiak/aiak-training-llm:ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release",
                        "imagePullPolicy": "Always",
                        "name": "pytorch",
                        "ports": [
                          {
                            "containerPort": 23456,
                            "name": "pytorchjob-port",
                            "protocol": "TCP"
                          }
                        ],
                        "resources": {
                          "limits": {
                            "baidu.com/a800_80g_cgpu": "8",
                            "rdma/hca": "1"
                          },
                          "requests": {
                            "baidu.com/a800_80g_cgpu": "8",
                            "rdma/hca": "1"
                          }
                        },
                        "securityContext": {
                          "capabilities": {
                            "add": [
                              "IPC_LOCK"
                            ]
                          }
                        },
                        "volumeMounts": [
                          {
                            "mountPath": "/dev/shm",
                            "name": "devshm"
                          },
                          {
                            "mountPath": "/mnt/cluster",
                            "name": "pvc-pfs"
                          },
                          {
                            "mountPath": "/var/bccl/logs",
                            "name": "bccl-logs-volume"
                          }
                        ]
                      },
                      {
                        "env": [
                          {
                            "name": "POD_NAME",
                            "valueFrom": {
                              "fieldRef": {
                                "apiVersion": "v1",
                                "fieldPath": "metadata.name"
                              }
                            }
                          },
                          {
                            "name": "POD_UID",
                            "valueFrom": {
                              "fieldRef": {
                                "apiVersion": "v1",
                                "fieldPath": "metadata.uid"
                              }
                            }
                          },
                          {
                            "name": "POD_NAMESPACE",
                            "valueFrom": {
                              "fieldRef": {
                                "apiVersion": "v1",
                                "fieldPath": "metadata.namespace"
                              }
                            }
                          },
                          {
                            "name": "NODE_NAME",
                            "valueFrom": {
                              "fieldRef": {
                                "apiVersion": "v1",
                                "fieldPath": "spec.nodeName"
                              }
                            }
                          },
                          {
                            "name": "JOB_NAME",
                            "value": "llamatest0718forxiaomi4"
                          },
                          {
                            "name": "NODE_IP",
                            "valueFrom": {
                              "fieldRef": {
                                "apiVersion": "v1",
                                "fieldPath": "status.hostIP"
                              }
                            }
                          },
                          {
                            "name": "ENABLE_ELASTIC",
                            "value": "9"
                          },
                          {
                            "name": "GPUS_PER_NODE",
                            "value": "8"
                          },
                          {
                            "name": "BCCL_LOG_DIR",
                            "value": "/var/bccl/logs"
                          },
                          {
                            "name": "EXPORTER_PORT",
                            "value": "9101"
                          },
                          {
                            "name": "EXPORTER_INTERVAL",
                            "value": "60"
                          },
                          {
                            "name": "EXPORTER_PATH",
                            "value": "/metrics"
                          },
                          {
                            "name": "BCCL_BUS_BW_CALCULATE_MODE",
                            "value": "Agg"
                          },
                          {
                            "name": "BCCL_PROFILING_FILE",
                            "value": "/var/bccl/logs/busbw.cal.%h.%p"
                          }
                        ],
                        "image": "registry.baidubce.com/cce-plugin-dev/ftagent:v1.6-20240713172215",
                        "imagePullPolicy": "Always",
                        "name": "ftagent",
                        "ports": [
                          {
                            "containerPort": 9101,
                            "name": "exporter",
                            "protocol": "TCP"
                          }
                        ],
                        "resources": {},
                        "securityContext": {
                          "capabilities": {
                            "add": [
                              "IPC_LOCK"
                            ]
                          }
                        },
                        "volumeMounts": [
                          {
                            "mountPath": "/var/log/pods",
                            "name": "pod-log-volume"
                          },
                          {
                            "mountPath": "/home/cce",
                            "name": "container-log-volume"
                          },
                          {
                            "mountPath": "/var/bccl/logs",
                            "name": "bccl-logs-volume"
                          }
                        ]
                      }
                    ],
                    "dnsPolicy": "ClusterFirstWithHostNet",
                    "hostNetwork": true,
                    "schedulerName": "volcano",
                    "serviceAccountName": "ftagent-sa",
                    "shareProcessNamespace": true,
                    "volumes": [
                      {
                        "emptyDir": {
                          "medium": "Memory",
                          "sizeLimit": "10Gi"
                        },
                        "name": "devshm"
                      },
                      {
                        "name": "pvc-pfs",
                        "persistentVolumeClaim": {
                          "claimName": "pvc-pfs"
                        }
                      },
                      {
                        "emptyDir": {},
                        "name": "bccl-logs-volume"
                      },
                      {
                        "hostPath": {
                          "path": "/var/log/pods",
                          "type": "DirectoryOrCreate"
                        },
                        "name": "pod-log-volume"
                      },
                      {
                        "hostPath": {
                          "path": "/home/cce",
                          "type": "DirectoryOrCreate"
                        },
                        "name": "container-log-volume"
                      }
                    ]
                  }
                }
              }
            },
            "runPolicy": {
              "cleanPodPolicy": "None",
              "schedulingPolicy": {
                "priorityClass": "high",
                "queue": "default"
              }
            }
          },
          "status": {
            "completionTime": "2024-07-18T02:30:34Z",
            "conditions": [
              {
                "lastTransitionTime": "2024-07-18T02:26:34Z",
                "lastUpdateTime": "2024-07-18T02:26:34Z",
                "message": "PyTorchJob llamatest0718forxiaomi4 is created.",
                "reason": "PyTorchJobCreated",
                "status": "True",
                "type": "Created"
              },
              {
                "lastTransitionTime": "2024-07-18T02:26:46Z",
                "lastUpdateTime": "2024-07-18T02:26:46Z",
                "message": "PyTorchJob llamatest0718forxiaomi4 is running.",
                "reason": "JobRunning",
                "status": "False",
                "type": "Running"
              },
              {
                "lastTransitionTime": "2024-07-18T02:30:34Z",
                "lastUpdateTime": "2024-07-18T02:30:34Z",
                "message": "PytorchJob default/llamatest0718forxiaomi4 is stopped",
                "reason": "PyTorchJobStopped",
                "status": "True",
                "type": "Stopped"
              },
              {
                "lastTransitionTime": "2024-07-18T02:30:34Z",
                "lastUpdateTime": "2024-07-18T02:30:34Z",
                "message": "PyTorchJob llamatest0718forxiaomi4 is failed because 1 Master replica(s) failed.",
                "reason": "JobFailed",
                "status": "True",
                "type": "Failed"
              }
            ],
            "lastReconcileTime": "2024-07-18T02:26:51Z",
            "replicaStatuses": {
              "Master": {
                "failed": 1,
                "selector": "training.kubeflow.org/job-name=llamatest0718forxiaomi4,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=master"
              },
              "Worker": {
                "failed": 3,
                "selector": "training.kubeflow.org/job-name=llamatest0718forxiaomi4,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=worker"
              }
            },
            "startTime": "2024-07-18T02:26:35Z"
          }
        },
        {
          "apiVersion": "kubeflow.org/v1",
          "kind": "PyTorchJob",
          "metadata": {
            "annotations": {
              "aijob.cce.baidubce.com/barrier-finish": "c5be9974-295c-403b-9b2f-a2188de562cd",
              "aijob.cce.baidubce.com/fault-tolerance-enabled": "true",
              "aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": "",
              "aijob.cce.baidubce.com/openapi-jobid": "pytorch-fcb2193b-60e3-4459-a23e-e97124d11c5b",
              "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
              "aijob.cce.baidubce.com/raw-request": "{\"name\":\"llamatest0718forxiaomi5\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"high\",\"oversell\":false,\"faultTolerance\":true,\"command\":\"\\n#! /bin/bash\\n\\nMEGATRON_PATH=${MEGATRON_PATH:-\\\"/workspace/AIAK-Megatron\\\"}\\nAIAK_TRAINING_PATH=${AIAK_TRAINING_PATH:-\\\"/workspace/AIAK-Training-LLM\\\"}\\n\\nDATA_PATH=${DATA_PATH:-\\\"/mnt/cluster/llama2/pile_llama_test/pile-llama_text_document\\\"}\\nTOKENIZER_PATH=${TOKENIZER_PATH:-\\\"/mnt/cluster/llama2/Llama-2-70b-hf/\\\"}\\n\\nCHECKPOINT_PATH=${CHECKPOINT_PATH:-\\\"/mnt/cluster/llama2/mcore_llama2_70b_tp4_pp4\\\"}\\n\\nTENSORBOARD_PATH=${TENSORBOARD_PATH:-\\\"/mnt/cluster/aiak-training-llm/tensorboard-log/llama2-70b-tp4pp4\\\"}\\n\\nGPUS_PER_NODE=8\\n\\n# Change for multinode config\\nMASTER_ADDR=${MASTER_ADDR:-\\\"localhost\\\"}\\nMASTER_PORT=${MASTER_PORT:-\\\"6000\\\"}\\nNNODES=${WORLD_SIZE:-\\\"1\\\"}\\nNODE_RANK=${RANK:-\\\"0\\\"}\\n\\nDISTRIBUTED_ARGS=(\\n    --nproc_per_node $GPUS_PER_NODE\\n    --nnodes $NNODES\\n    --node_rank $NODE_RANK\\n    --master_addr $MASTER_ADDR\\n    --master_port $MASTER_PORT\\n)\\n\\n# you can setup llama2-70b maunally\\n#MODEL_ARGS=(\\n#    --model-name llama2\\n#    --num-layers 80\\n#    --hidden-size 8192\\n#    --ffn-hidden-size 28672\\n#    --num-attention-heads 64\\n#    --position-embedding-type rope\\n#    --normalization RMSNorm\\n#    --swiglu\\n#    --attention-dropout 0\\n#    --hidden-dropout 0\\n#    --disable-bias-linear\\n#    --untie-embeddings-and-output-weights\\n#    --group-query-attention\\n#    --num-query-groups 8\\n#)\\n\\n# or you can setup llama2-70b by using the following command\\nMODEL_ARGS=(\\n    --model-name llama2-70b # options: llama2-7b, llama2-13b, llama2-70b\\n)\\n\\nDATA_ARGS=(\\n    --tokenizer-type HFTokenizer\\n    --hf-tokenizer-path $TOKENIZER_PATH\\n    --data-path $DATA_PATH\\n    --split 949,50,1\\n)\\n\\nTRAINING_ARGS=(\\n    --training-phase pretrain # options: pretrain, sft\\n    --seq-length 4096\\n    --max-position-embeddings 4096\\n    --init-method-std 0.01\\n    --micro-batch-size 1\\n    --global-batch-size 1024\\n    --lr 0.0002\\n    --min-lr 1.0e-5\\n    --clip-grad 1.0\\n    --weight-decay 0.01\\n    --optimizer adam\\n    --adam-beta1 0.9\\n    --adam-beta2 0.95\\n    --adam-eps 1e-05\\n    --norm-epsilon 1e-6\\n    --train-iters 500000\\n    --lr-decay-iters 500000\\n    --lr-decay-style cosine\\n    --lr-warmup-fraction 0.002\\n    --initial-loss-scale 65536\\n    --fp16\\n    --save-interval 5000\\n    --eval-interval 1000\\n    --eval-iters 10\\n    #--ckpt-step 0\\n    #--no-load-optim\\n    #--no-load-rng\\n)\\n\\nMODEL_PARALLEL_ARGS=(\\n    --tensor-model-parallel-size 4\\n    --pipeline-model-parallel-size 4\\n    --use-distributed-optimizer\\n    --overlap-grad-reduce\\n    --overlap-param-gather\\n    --distributed-backend nccl\\n    --sequence-parallel\\n    #--tp-comm-overlap # require mpi envrionment\\n)\\n\\nLOGGING_ARGS=(\\n    --log-interval 1\\n    --tensorboard-dir ${TENSORBOARD_PATH}\\n    --log-timers-to-tensorboard\\n)\\n\\nif [ -n \\\"${WANDB_API_KEY}\\\" ]; then\\n    LOGGING_ARGS+=(\\n        --wandb-project ${WANDB_PROJECT}\\n        --wandb-exp-name ${WANDB_NAME} \\n    )\\nfi\\n\\nPYTHONPATH=$MEGATRON_PATH:$AIAK_TRAINING_PATH:$PYTHONPATH     torchrun ${DISTRIBUTED_ARGS[@]}     $AIAK_TRAINING_PATH/aiak_training_llm/train.py     ${MODEL_ARGS[@]}     ${DATA_ARGS[@]}     ${TRAINING_ARGS[@]}     ${MODEL_PARALLEL_ARGS[@]}     ${LOGGING_ARGS[@]}\\n\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":true,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi5\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi5/output/training_logs\",\"CUDA_DEVICE_MAX_CONNECTIONS\":\"1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"},\"Worker\":{\"replicas\":3,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi5\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi5/output/training_logs\",\"CUDA_DEVICE_MAX_CONNECTIONS\":\"1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":true,\"logPath\":\"/mnt/cluster/llamatest0718forxiaomi5/output/training_logs\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":true,\"isCopyJob\":true,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
              "aijob.cce.baidubce.com/timeline": "[{\"conditionType\":\"Created\",\"time\":1721269828},{\"conditionType\":\"Scheduled\",\"time\":1721269830},{\"conditionType\":\"Running\",\"time\":1721269841},{\"conditionType\":\"ManualTermination\",\"time\":1721270912}]",
              "job-manager/action": "stop",
              "job-manager/action-succeed": "stop",
              "scheduling.k8s.io/job-enable-oversell": "false",
              "tensorboard-gc": "true"
            },
            "creationTimestamp": "2024-07-18T02:30:28Z",
            "generation": 2,
            "labels": {
              "aijob.cce.baidubce.com/ai-user-id": "b5a24aa26e4d4f55bc3acf68edc4b051",
              "aijob.cce.baidubce.com/ai-user-name": "zhangmuhua",
              "aijob.cce.baidubce.com/create-from-aihcp": "true",
              "aijob.cce.baidubce.com/openapi-jobid": "pytorch-fcb2193b-60e3-4459-a23e-e97124d11c5b"
            },
            "managedFields": [
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      "f:aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": {},
                      "f:aijob.cce.baidubce.com/timeline": {}
                    }
                  },
                  "f:spec": {
                    "f:pytorchReplicaSpecs": {
                      "f:Master": {
                        "f:template": {
                          "f:spec": {
                            "f:containers": {}
                          }
                        }
                      },
                      "f:Worker": {
                        "f:template": {
                          "f:spec": {
                            "f:containers": {}
                          }
                        }
                      }
                    },
                    "f:runPolicy": {
                      "f:cleanPodPolicy": {}
                    }
                  }
                },
                "manager": "controller",
                "operation": "Update",
                "time": "2024-07-18T02:30:28Z"
              },
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      "f:aijob.cce.baidubce.com/barrier-finish": {}
                    }
                  }
                },
                "manager": "jobbarrier",
                "operation": "Update",
                "time": "2024-07-18T02:30:37Z"
              },
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      ".": {},
                      "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                      "f:aijob.cce.baidubce.com/openapi-jobid": {},
                      "f:aijob.cce.baidubce.com/pfs-id": {},
                      "f:aijob.cce.baidubce.com/raw-request": {},
                      "f:job-manager/action": {},
                      "f:scheduling.k8s.io/job-enable-oversell": {}
                    },
                    "f:labels": {
                      ".": {},
                      "f:aijob.cce.baidubce.com/ai-user-id": {},
                      "f:aijob.cce.baidubce.com/ai-user-name": {},
                      "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                      "f:aijob.cce.baidubce.com/openapi-jobid": {}
                    }
                  },
                  "f:spec": {
                    ".": {},
                    "f:pytorchReplicaSpecs": {
                      ".": {},
                      "f:Master": {
                        ".": {},
                        "f:replicas": {},
                        "f:restartPolicy": {},
                        "f:template": {
                          ".": {},
                          "f:metadata": {
                            ".": {},
                            "f:annotations": {
                              ".": {},
                              "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                              "f:aijob.cce.baidubce.com/openapi-jobid": {},
                              "f:aijob.cce.baidubce.com/pfs-id": {},
                              "f:aijob.cce.baidubce.com/raw-request": {},
                              "f:scheduling.k8s.io/job-enable-oversell": {}
                            },
                            "f:labels": {
                              ".": {},
                              "f:aijob.cce.baidubce.com/ai-user-id": {},
                              "f:aijob.cce.baidubce.com/ai-user-name": {},
                              "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                              "f:aijob.cce.baidubce.com/openapi-jobid": {}
                            }
                          },
                          "f:spec": {
                            ".": {},
                            "f:dnsPolicy": {},
                            "f:hostNetwork": {},
                            "f:schedulerName": {},
                            "f:volumes": {}
                          }
                        }
                      },
                      "f:Worker": {
                        ".": {},
                        "f:replicas": {},
                        "f:restartPolicy": {},
                        "f:template": {
                          ".": {},
                          "f:metadata": {
                            ".": {},
                            "f:annotations": {
                              ".": {},
                              "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                              "f:aijob.cce.baidubce.com/openapi-jobid": {},
                              "f:aijob.cce.baidubce.com/pfs-id": {},
                              "f:aijob.cce.baidubce.com/raw-request": {},
                              "f:scheduling.k8s.io/job-enable-oversell": {}
                            },
                            "f:labels": {
                              ".": {},
                              "f:aijob.cce.baidubce.com/ai-user-id": {},
                              "f:aijob.cce.baidubce.com/ai-user-name": {},
                              "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                              "f:aijob.cce.baidubce.com/openapi-jobid": {}
                            }
                          },
                          "f:spec": {
                            ".": {},
                            "f:dnsPolicy": {},
                            "f:hostNetwork": {},
                            "f:schedulerName": {},
                            "f:volumes": {}
                          }
                        }
                      }
                    },
                    "f:runPolicy": {
                      ".": {},
                      "f:schedulingPolicy": {
                        ".": {},
                        "f:priorityClass": {},
                        "f:queue": {}
                      }
                    }
                  }
                },
                "manager": "cce-ai-service",
                "operation": "Update",
                "time": "2024-07-18T02:48:32Z"
              },
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      "f:job-manager/action-succeed": {}
                    }
                  }
                },
                "manager": "ftagent",
                "operation": "Update",
                "time": "2024-07-18T02:48:37Z"
              },
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      "f:tensorboard-gc": {}
                    }
                  },
                  "f:status": {
                    ".": {},
                    "f:completionTime": {},
                    "f:conditions": {},
                    "f:lastReconcileTime": {},
                    "f:replicaStatuses": {
                      ".": {},
                      "f:Master": {
                        ".": {},
                        "f:active": {}
                      },
                      "f:Worker": {
                        ".": {},
                        "f:active": {},
                        "f:failed": {}
                      }
                    },
                    "f:startTime": {}
                  }
                },
                "manager": "manager",
                "operation": "Update",
                "time": "2024-07-19T02:30:55Z"
              }
            ],
            "name": "llamatest0718forxiaomi5",
            "namespace": "default",
            "resourceVersion": "2372396298",
            "uid": "16343b84-0572-459d-a9fd-a1e4cf85c1ca"
          },
          "spec": {
            "pytorchReplicaSpecs": {
              "Master": {
                "replicas": 1,
                "restartPolicy": "Never",
                "template": {
                  "metadata": {
                    "annotations": {
                      "aijob.cce.baidubce.com/fault-tolerance-enabled": "true",
                      "aijob.cce.baidubce.com/openapi-jobid": "pytorch-fcb2193b-60e3-4459-a23e-e97124d11c5b",
                      "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
                      "aijob.cce.baidubce.com/raw-request": "{\"name\":\"llamatest0718forxiaomi5\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"high\",\"oversell\":false,\"faultTolerance\":true,\"command\":\"\\n#! /bin/bash\\n\\nMEGATRON_PATH=${MEGATRON_PATH:-\\\"/workspace/AIAK-Megatron\\\"}\\nAIAK_TRAINING_PATH=${AIAK_TRAINING_PATH:-\\\"/workspace/AIAK-Training-LLM\\\"}\\n\\nDATA_PATH=${DATA_PATH:-\\\"/mnt/cluster/llama2/pile_llama_test/pile-llama_text_document\\\"}\\nTOKENIZER_PATH=${TOKENIZER_PATH:-\\\"/mnt/cluster/llama2/Llama-2-70b-hf/\\\"}\\n\\nCHECKPOINT_PATH=${CHECKPOINT_PATH:-\\\"/mnt/cluster/llama2/mcore_llama2_70b_tp4_pp4\\\"}\\n\\nTENSORBOARD_PATH=${TENSORBOARD_PATH:-\\\"/mnt/cluster/aiak-training-llm/tensorboard-log/llama2-70b-tp4pp4\\\"}\\n\\nGPUS_PER_NODE=8\\n\\n# Change for multinode config\\nMASTER_ADDR=${MASTER_ADDR:-\\\"localhost\\\"}\\nMASTER_PORT=${MASTER_PORT:-\\\"6000\\\"}\\nNNODES=${WORLD_SIZE:-\\\"1\\\"}\\nNODE_RANK=${RANK:-\\\"0\\\"}\\n\\nDISTRIBUTED_ARGS=(\\n    --nproc_per_node $GPUS_PER_NODE\\n    --nnodes $NNODES\\n    --node_rank $NODE_RANK\\n    --master_addr $MASTER_ADDR\\n    --master_port $MASTER_PORT\\n)\\n\\n# you can setup llama2-70b maunally\\n#MODEL_ARGS=(\\n#    --model-name llama2\\n#    --num-layers 80\\n#    --hidden-size 8192\\n#    --ffn-hidden-size 28672\\n#    --num-attention-heads 64\\n#    --position-embedding-type rope\\n#    --normalization RMSNorm\\n#    --swiglu\\n#    --attention-dropout 0\\n#    --hidden-dropout 0\\n#    --disable-bias-linear\\n#    --untie-embeddings-and-output-weights\\n#    --group-query-attention\\n#    --num-query-groups 8\\n#)\\n\\n# or you can setup llama2-70b by using the following command\\nMODEL_ARGS=(\\n    --model-name llama2-70b # options: llama2-7b, llama2-13b, llama2-70b\\n)\\n\\nDATA_ARGS=(\\n    --tokenizer-type HFTokenizer\\n    --hf-tokenizer-path $TOKENIZER_PATH\\n    --data-path $DATA_PATH\\n    --split 949,50,1\\n)\\n\\nTRAINING_ARGS=(\\n    --training-phase pretrain # options: pretrain, sft\\n    --seq-length 4096\\n    --max-position-embeddings 4096\\n    --init-method-std 0.01\\n    --micro-batch-size 1\\n    --global-batch-size 1024\\n    --lr 0.0002\\n    --min-lr 1.0e-5\\n    --clip-grad 1.0\\n    --weight-decay 0.01\\n    --optimizer adam\\n    --adam-beta1 0.9\\n    --adam-beta2 0.95\\n    --adam-eps 1e-05\\n    --norm-epsilon 1e-6\\n    --train-iters 500000\\n    --lr-decay-iters 500000\\n    --lr-decay-style cosine\\n    --lr-warmup-fraction 0.002\\n    --initial-loss-scale 65536\\n    --fp16\\n    --save-interval 5000\\n    --eval-interval 1000\\n    --eval-iters 10\\n    #--ckpt-step 0\\n    #--no-load-optim\\n    #--no-load-rng\\n)\\n\\nMODEL_PARALLEL_ARGS=(\\n    --tensor-model-parallel-size 4\\n    --pipeline-model-parallel-size 4\\n    --use-distributed-optimizer\\n    --overlap-grad-reduce\\n    --overlap-param-gather\\n    --distributed-backend nccl\\n    --sequence-parallel\\n    #--tp-comm-overlap # require mpi envrionment\\n)\\n\\nLOGGING_ARGS=(\\n    --log-interval 1\\n    --tensorboard-dir ${TENSORBOARD_PATH}\\n    --log-timers-to-tensorboard\\n)\\n\\nif [ -n \\\"${WANDB_API_KEY}\\\" ]; then\\n    LOGGING_ARGS+=(\\n        --wandb-project ${WANDB_PROJECT}\\n        --wandb-exp-name ${WANDB_NAME} \\n    )\\nfi\\n\\nPYTHONPATH=$MEGATRON_PATH:$AIAK_TRAINING_PATH:$PYTHONPATH     torchrun ${DISTRIBUTED_ARGS[@]}     $AIAK_TRAINING_PATH/aiak_training_llm/train.py     ${MODEL_ARGS[@]}     ${DATA_ARGS[@]}     ${TRAINING_ARGS[@]}     ${MODEL_PARALLEL_ARGS[@]}     ${LOGGING_ARGS[@]}\\n\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":true,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi5\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi5/output/training_logs\",\"CUDA_DEVICE_MAX_CONNECTIONS\":\"1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"},\"Worker\":{\"replicas\":3,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi5\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi5/output/training_logs\",\"CUDA_DEVICE_MAX_CONNECTIONS\":\"1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":true,\"logPath\":\"/mnt/cluster/llamatest0718forxiaomi5/output/training_logs\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":true,\"isCopyJob\":true,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
                      "scheduling.k8s.io/job-enable-oversell": "false"
                    },
                    "labels": {
                      "aijob.cce.baidubce.com/ai-user-id": "b5a24aa26e4d4f55bc3acf68edc4b051",
                      "aijob.cce.baidubce.com/ai-user-name": "zhangmuhua",
                      "aijob.cce.baidubce.com/create-from-aihcp": "true",
                      "aijob.cce.baidubce.com/openapi-jobid": "pytorch-fcb2193b-60e3-4459-a23e-e97124d11c5b"
                    }
                  },
                  "spec": {
                    "containers": [
                      {
                        "command": [
                          "/bin/bash",
                          "-c",
                          "\n#! /bin/bash\n\nMEGATRON_PATH=${MEGATRON_PATH:-\"/workspace/AIAK-Megatron\"}\nAIAK_TRAINING_PATH=${AIAK_TRAINING_PATH:-\"/workspace/AIAK-Training-LLM\"}\n\nDATA_PATH=${DATA_PATH:-\"/mnt/cluster/llama2/pile_llama_test/pile-llama_text_document\"}\nTOKENIZER_PATH=${TOKENIZER_PATH:-\"/mnt/cluster/llama2/Llama-2-70b-hf/\"}\n\nCHECKPOINT_PATH=${CHECKPOINT_PATH:-\"/mnt/cluster/llama2/mcore_llama2_70b_tp4_pp4\"}\n\nTENSORBOARD_PATH=${TENSORBOARD_PATH:-\"/mnt/cluster/aiak-training-llm/tensorboard-log/llama2-70b-tp4pp4\"}\n\nGPUS_PER_NODE=8\n\n# Change for multinode config\nMASTER_ADDR=${MASTER_ADDR:-\"localhost\"}\nMASTER_PORT=${MASTER_PORT:-\"6000\"}\nNNODES=${WORLD_SIZE:-\"1\"}\nNODE_RANK=${RANK:-\"0\"}\n\nDISTRIBUTED_ARGS=(\n    --nproc_per_node $GPUS_PER_NODE\n    --nnodes $NNODES\n    --node_rank $NODE_RANK\n    --master_addr $MASTER_ADDR\n    --master_port $MASTER_PORT\n)\n\n# you can setup llama2-70b maunally\n#MODEL_ARGS=(\n#    --model-name llama2\n#    --num-layers 80\n#    --hidden-size 8192\n#    --ffn-hidden-size 28672\n#    --num-attention-heads 64\n#    --position-embedding-type rope\n#    --normalization RMSNorm\n#    --swiglu\n#    --attention-dropout 0\n#    --hidden-dropout 0\n#    --disable-bias-linear\n#    --untie-embeddings-and-output-weights\n#    --group-query-attention\n#    --num-query-groups 8\n#)\n\n# or you can setup llama2-70b by using the following command\nMODEL_ARGS=(\n    --model-name llama2-70b # options: llama2-7b, llama2-13b, llama2-70b\n)\n\nDATA_ARGS=(\n    --tokenizer-type HFTokenizer\n    --hf-tokenizer-path $TOKENIZER_PATH\n    --data-path $DATA_PATH\n    --split 949,50,1\n)\n\nTRAINING_ARGS=(\n    --training-phase pretrain # options: pretrain, sft\n    --seq-length 4096\n    --max-position-embeddings 4096\n    --init-method-std 0.01\n    --micro-batch-size 1\n    --global-batch-size 1024\n    --lr 0.0002\n    --min-lr 1.0e-5\n    --clip-grad 1.0\n    --weight-decay 0.01\n    --optimizer adam\n    --adam-beta1 0.9\n    --adam-beta2 0.95\n    --adam-eps 1e-05\n    --norm-epsilon 1e-6\n    --train-iters 500000\n    --lr-decay-iters 500000\n    --lr-decay-style cosine\n    --lr-warmup-fraction 0.002\n    --initial-loss-scale 65536\n    --fp16\n    --save-interval 5000\n    --eval-interval 1000\n    --eval-iters 10\n    #--ckpt-step 0\n    #--no-load-optim\n    #--no-load-rng\n)\n\nMODEL_PARALLEL_ARGS=(\n    --tensor-model-parallel-size 4\n    --pipeline-model-parallel-size 4\n    --use-distributed-optimizer\n    --overlap-grad-reduce\n    --overlap-param-gather\n    --distributed-backend nccl\n    --sequence-parallel\n    #--tp-comm-overlap # require mpi envrionment\n)\n\nLOGGING_ARGS=(\n    --log-interval 1\n    --tensorboard-dir ${TENSORBOARD_PATH}\n    --log-timers-to-tensorboard\n)\n\nif [ -n \"${WANDB_API_KEY}\" ]; then\n    LOGGING_ARGS+=(\n        --wandb-project ${WANDB_PROJECT}\n        --wandb-exp-name ${WANDB_NAME} \n    )\nfi\n\nPYTHONPATH=$MEGATRON_PATH:$AIAK_TRAINING_PATH:$PYTHONPATH     torchrun ${DISTRIBUTED_ARGS[@]}     $AIAK_TRAINING_PATH/aiak_training_llm/train.py     ${MODEL_ARGS[@]}     ${DATA_ARGS[@]}     ${TRAINING_ARGS[@]}     ${MODEL_PARALLEL_ARGS[@]}     ${LOGGING_ARGS[@]}\n"
                        ],
                        "env": [
                          {
                            "name": "CUDA_DEVICE_MAX_CONNECTIONS",
                            "value": "1"
                          },
                          {
                            "name": "AIHC_TENSORBOARD_LOG_PATH",
                            "value": "/mnt/cluster/llamatest0718forxiaomi5/output/training_logs"
                          },
                          {
                            "name": "AIHC_JOB_NAME",
                            "value": "llamatest0718forxiaomi5"
                          },
                          {
                            "name": "NCCL_IB_DISABLE",
                            "value": "0"
                          }
                        ],
                        "image": "registry.baidubce.com/aihc-aiak/aiak-training-llm:ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release",
                        "imagePullPolicy": "Always",
                        "name": "pytorch",
                        "ports": [
                          {
                            "containerPort": 23456,
                            "name": "pytorchjob-port",
                            "protocol": "TCP"
                          }
                        ],
                        "resources": {
                          "limits": {
                            "baidu.com/a800_80g_cgpu": "8",
                            "rdma/hca": "1"
                          },
                          "requests": {
                            "baidu.com/a800_80g_cgpu": "8",
                            "rdma/hca": "1"
                          }
                        },
                        "securityContext": {
                          "capabilities": {
                            "add": [
                              "IPC_LOCK"
                            ]
                          }
                        },
                        "volumeMounts": [
                          {
                            "mountPath": "/dev/shm",
                            "name": "devshm"
                          },
                          {
                            "mountPath": "/mnt/cluster",
                            "name": "pvc-pfs"
                          }
                        ]
                      }
                    ],
                    "dnsPolicy": "ClusterFirstWithHostNet",
                    "hostNetwork": true,
                    "schedulerName": "volcano",
                    "volumes": [
                      {
                        "emptyDir": {
                          "medium": "Memory",
                          "sizeLimit": "10Gi"
                        },
                        "name": "devshm"
                      },
                      {
                        "name": "pvc-pfs",
                        "persistentVolumeClaim": {
                          "claimName": "pvc-pfs"
                        }
                      }
                    ]
                  }
                }
              },
              "Worker": {
                "replicas": 3,
                "restartPolicy": "Never",
                "template": {
                  "metadata": {
                    "annotations": {
                      "aijob.cce.baidubce.com/fault-tolerance-enabled": "true",
                      "aijob.cce.baidubce.com/openapi-jobid": "pytorch-fcb2193b-60e3-4459-a23e-e97124d11c5b",
                      "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
                      "aijob.cce.baidubce.com/raw-request": "{\"name\":\"llamatest0718forxiaomi5\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"high\",\"oversell\":false,\"faultTolerance\":true,\"command\":\"\\n#! /bin/bash\\n\\nMEGATRON_PATH=${MEGATRON_PATH:-\\\"/workspace/AIAK-Megatron\\\"}\\nAIAK_TRAINING_PATH=${AIAK_TRAINING_PATH:-\\\"/workspace/AIAK-Training-LLM\\\"}\\n\\nDATA_PATH=${DATA_PATH:-\\\"/mnt/cluster/llama2/pile_llama_test/pile-llama_text_document\\\"}\\nTOKENIZER_PATH=${TOKENIZER_PATH:-\\\"/mnt/cluster/llama2/Llama-2-70b-hf/\\\"}\\n\\nCHECKPOINT_PATH=${CHECKPOINT_PATH:-\\\"/mnt/cluster/llama2/mcore_llama2_70b_tp4_pp4\\\"}\\n\\nTENSORBOARD_PATH=${TENSORBOARD_PATH:-\\\"/mnt/cluster/aiak-training-llm/tensorboard-log/llama2-70b-tp4pp4\\\"}\\n\\nGPUS_PER_NODE=8\\n\\n# Change for multinode config\\nMASTER_ADDR=${MASTER_ADDR:-\\\"localhost\\\"}\\nMASTER_PORT=${MASTER_PORT:-\\\"6000\\\"}\\nNNODES=${WORLD_SIZE:-\\\"1\\\"}\\nNODE_RANK=${RANK:-\\\"0\\\"}\\n\\nDISTRIBUTED_ARGS=(\\n    --nproc_per_node $GPUS_PER_NODE\\n    --nnodes $NNODES\\n    --node_rank $NODE_RANK\\n    --master_addr $MASTER_ADDR\\n    --master_port $MASTER_PORT\\n)\\n\\n# you can setup llama2-70b maunally\\n#MODEL_ARGS=(\\n#    --model-name llama2\\n#    --num-layers 80\\n#    --hidden-size 8192\\n#    --ffn-hidden-size 28672\\n#    --num-attention-heads 64\\n#    --position-embedding-type rope\\n#    --normalization RMSNorm\\n#    --swiglu\\n#    --attention-dropout 0\\n#    --hidden-dropout 0\\n#    --disable-bias-linear\\n#    --untie-embeddings-and-output-weights\\n#    --group-query-attention\\n#    --num-query-groups 8\\n#)\\n\\n# or you can setup llama2-70b by using the following command\\nMODEL_ARGS=(\\n    --model-name llama2-70b # options: llama2-7b, llama2-13b, llama2-70b\\n)\\n\\nDATA_ARGS=(\\n    --tokenizer-type HFTokenizer\\n    --hf-tokenizer-path $TOKENIZER_PATH\\n    --data-path $DATA_PATH\\n    --split 949,50,1\\n)\\n\\nTRAINING_ARGS=(\\n    --training-phase pretrain # options: pretrain, sft\\n    --seq-length 4096\\n    --max-position-embeddings 4096\\n    --init-method-std 0.01\\n    --micro-batch-size 1\\n    --global-batch-size 1024\\n    --lr 0.0002\\n    --min-lr 1.0e-5\\n    --clip-grad 1.0\\n    --weight-decay 0.01\\n    --optimizer adam\\n    --adam-beta1 0.9\\n    --adam-beta2 0.95\\n    --adam-eps 1e-05\\n    --norm-epsilon 1e-6\\n    --train-iters 500000\\n    --lr-decay-iters 500000\\n    --lr-decay-style cosine\\n    --lr-warmup-fraction 0.002\\n    --initial-loss-scale 65536\\n    --fp16\\n    --save-interval 5000\\n    --eval-interval 1000\\n    --eval-iters 10\\n    #--ckpt-step 0\\n    #--no-load-optim\\n    #--no-load-rng\\n)\\n\\nMODEL_PARALLEL_ARGS=(\\n    --tensor-model-parallel-size 4\\n    --pipeline-model-parallel-size 4\\n    --use-distributed-optimizer\\n    --overlap-grad-reduce\\n    --overlap-param-gather\\n    --distributed-backend nccl\\n    --sequence-parallel\\n    #--tp-comm-overlap # require mpi envrionment\\n)\\n\\nLOGGING_ARGS=(\\n    --log-interval 1\\n    --tensorboard-dir ${TENSORBOARD_PATH}\\n    --log-timers-to-tensorboard\\n)\\n\\nif [ -n \\\"${WANDB_API_KEY}\\\" ]; then\\n    LOGGING_ARGS+=(\\n        --wandb-project ${WANDB_PROJECT}\\n        --wandb-exp-name ${WANDB_NAME} \\n    )\\nfi\\n\\nPYTHONPATH=$MEGATRON_PATH:$AIAK_TRAINING_PATH:$PYTHONPATH     torchrun ${DISTRIBUTED_ARGS[@]}     $AIAK_TRAINING_PATH/aiak_training_llm/train.py     ${MODEL_ARGS[@]}     ${DATA_ARGS[@]}     ${TRAINING_ARGS[@]}     ${MODEL_PARALLEL_ARGS[@]}     ${LOGGING_ARGS[@]}\\n\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":true,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi5\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi5/output/training_logs\",\"CUDA_DEVICE_MAX_CONNECTIONS\":\"1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"},\"Worker\":{\"replicas\":3,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi5\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi5/output/training_logs\",\"CUDA_DEVICE_MAX_CONNECTIONS\":\"1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":true,\"logPath\":\"/mnt/cluster/llamatest0718forxiaomi5/output/training_logs\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":true,\"isCopyJob\":true,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
                      "scheduling.k8s.io/job-enable-oversell": "false"
                    },
                    "labels": {
                      "aijob.cce.baidubce.com/ai-user-id": "b5a24aa26e4d4f55bc3acf68edc4b051",
                      "aijob.cce.baidubce.com/ai-user-name": "zhangmuhua",
                      "aijob.cce.baidubce.com/create-from-aihcp": "true",
                      "aijob.cce.baidubce.com/openapi-jobid": "pytorch-fcb2193b-60e3-4459-a23e-e97124d11c5b"
                    }
                  },
                  "spec": {
                    "containers": [
                      {
                        "command": [
                          "/bin/bash",
                          "-c",
                          "\n#! /bin/bash\n\nMEGATRON_PATH=${MEGATRON_PATH:-\"/workspace/AIAK-Megatron\"}\nAIAK_TRAINING_PATH=${AIAK_TRAINING_PATH:-\"/workspace/AIAK-Training-LLM\"}\n\nDATA_PATH=${DATA_PATH:-\"/mnt/cluster/llama2/pile_llama_test/pile-llama_text_document\"}\nTOKENIZER_PATH=${TOKENIZER_PATH:-\"/mnt/cluster/llama2/Llama-2-70b-hf/\"}\n\nCHECKPOINT_PATH=${CHECKPOINT_PATH:-\"/mnt/cluster/llama2/mcore_llama2_70b_tp4_pp4\"}\n\nTENSORBOARD_PATH=${TENSORBOARD_PATH:-\"/mnt/cluster/aiak-training-llm/tensorboard-log/llama2-70b-tp4pp4\"}\n\nGPUS_PER_NODE=8\n\n# Change for multinode config\nMASTER_ADDR=${MASTER_ADDR:-\"localhost\"}\nMASTER_PORT=${MASTER_PORT:-\"6000\"}\nNNODES=${WORLD_SIZE:-\"1\"}\nNODE_RANK=${RANK:-\"0\"}\n\nDISTRIBUTED_ARGS=(\n    --nproc_per_node $GPUS_PER_NODE\n    --nnodes $NNODES\n    --node_rank $NODE_RANK\n    --master_addr $MASTER_ADDR\n    --master_port $MASTER_PORT\n)\n\n# you can setup llama2-70b maunally\n#MODEL_ARGS=(\n#    --model-name llama2\n#    --num-layers 80\n#    --hidden-size 8192\n#    --ffn-hidden-size 28672\n#    --num-attention-heads 64\n#    --position-embedding-type rope\n#    --normalization RMSNorm\n#    --swiglu\n#    --attention-dropout 0\n#    --hidden-dropout 0\n#    --disable-bias-linear\n#    --untie-embeddings-and-output-weights\n#    --group-query-attention\n#    --num-query-groups 8\n#)\n\n# or you can setup llama2-70b by using the following command\nMODEL_ARGS=(\n    --model-name llama2-70b # options: llama2-7b, llama2-13b, llama2-70b\n)\n\nDATA_ARGS=(\n    --tokenizer-type HFTokenizer\n    --hf-tokenizer-path $TOKENIZER_PATH\n    --data-path $DATA_PATH\n    --split 949,50,1\n)\n\nTRAINING_ARGS=(\n    --training-phase pretrain # options: pretrain, sft\n    --seq-length 4096\n    --max-position-embeddings 4096\n    --init-method-std 0.01\n    --micro-batch-size 1\n    --global-batch-size 1024\n    --lr 0.0002\n    --min-lr 1.0e-5\n    --clip-grad 1.0\n    --weight-decay 0.01\n    --optimizer adam\n    --adam-beta1 0.9\n    --adam-beta2 0.95\n    --adam-eps 1e-05\n    --norm-epsilon 1e-6\n    --train-iters 500000\n    --lr-decay-iters 500000\n    --lr-decay-style cosine\n    --lr-warmup-fraction 0.002\n    --initial-loss-scale 65536\n    --fp16\n    --save-interval 5000\n    --eval-interval 1000\n    --eval-iters 10\n    #--ckpt-step 0\n    #--no-load-optim\n    #--no-load-rng\n)\n\nMODEL_PARALLEL_ARGS=(\n    --tensor-model-parallel-size 4\n    --pipeline-model-parallel-size 4\n    --use-distributed-optimizer\n    --overlap-grad-reduce\n    --overlap-param-gather\n    --distributed-backend nccl\n    --sequence-parallel\n    #--tp-comm-overlap # require mpi envrionment\n)\n\nLOGGING_ARGS=(\n    --log-interval 1\n    --tensorboard-dir ${TENSORBOARD_PATH}\n    --log-timers-to-tensorboard\n)\n\nif [ -n \"${WANDB_API_KEY}\" ]; then\n    LOGGING_ARGS+=(\n        --wandb-project ${WANDB_PROJECT}\n        --wandb-exp-name ${WANDB_NAME} \n    )\nfi\n\nPYTHONPATH=$MEGATRON_PATH:$AIAK_TRAINING_PATH:$PYTHONPATH     torchrun ${DISTRIBUTED_ARGS[@]}     $AIAK_TRAINING_PATH/aiak_training_llm/train.py     ${MODEL_ARGS[@]}     ${DATA_ARGS[@]}     ${TRAINING_ARGS[@]}     ${MODEL_PARALLEL_ARGS[@]}     ${LOGGING_ARGS[@]}\n"
                        ],
                        "env": [
                          {
                            "name": "NCCL_IB_DISABLE",
                            "value": "0"
                          },
                          {
                            "name": "CUDA_DEVICE_MAX_CONNECTIONS",
                            "value": "1"
                          },
                          {
                            "name": "AIHC_TENSORBOARD_LOG_PATH",
                            "value": "/mnt/cluster/llamatest0718forxiaomi5/output/training_logs"
                          },
                          {
                            "name": "AIHC_JOB_NAME",
                            "value": "llamatest0718forxiaomi5"
                          }
                        ],
                        "image": "registry.baidubce.com/aihc-aiak/aiak-training-llm:ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release",
                        "imagePullPolicy": "Always",
                        "name": "pytorch",
                        "ports": [
                          {
                            "containerPort": 23456,
                            "name": "pytorchjob-port",
                            "protocol": "TCP"
                          }
                        ],
                        "resources": {
                          "limits": {
                            "baidu.com/a800_80g_cgpu": "8",
                            "rdma/hca": "1"
                          },
                          "requests": {
                            "baidu.com/a800_80g_cgpu": "8",
                            "rdma/hca": "1"
                          }
                        },
                        "securityContext": {
                          "capabilities": {
                            "add": [
                              "IPC_LOCK"
                            ]
                          }
                        },
                        "volumeMounts": [
                          {
                            "mountPath": "/dev/shm",
                            "name": "devshm"
                          },
                          {
                            "mountPath": "/mnt/cluster",
                            "name": "pvc-pfs"
                          }
                        ]
                      }
                    ],
                    "dnsPolicy": "ClusterFirstWithHostNet",
                    "hostNetwork": true,
                    "schedulerName": "volcano",
                    "volumes": [
                      {
                        "emptyDir": {
                          "medium": "Memory",
                          "sizeLimit": "10Gi"
                        },
                        "name": "devshm"
                      },
                      {
                        "name": "pvc-pfs",
                        "persistentVolumeClaim": {
                          "claimName": "pvc-pfs"
                        }
                      }
                    ]
                  }
                }
              }
            },
            "runPolicy": {
              "cleanPodPolicy": "None",
              "schedulingPolicy": {
                "priorityClass": "high",
                "queue": "default"
              }
            }
          },
          "status": {
            "completionTime": "2024-07-18T02:48:38Z",
            "conditions": [
              {
                "lastTransitionTime": "2024-07-18T02:30:28Z",
                "lastUpdateTime": "2024-07-18T02:30:28Z",
                "message": "PyTorchJob llamatest0718forxiaomi5 is created.",
                "reason": "PyTorchJobCreated",
                "status": "True",
                "type": "Created"
              },
              {
                "lastTransitionTime": "2024-07-18T02:30:41Z",
                "lastUpdateTime": "2024-07-18T02:30:41Z",
                "message": "PyTorchJob llamatest0718forxiaomi5 is running.",
                "reason": "JobRunning",
                "status": "False",
                "type": "Running"
              },
              {
                "lastTransitionTime": "2024-07-18T02:48:32Z",
                "lastUpdateTime": "2024-07-18T02:48:32Z",
                "message": "PytorchJob default/llamatest0718forxiaomi5 is stopped",
                "reason": "PyTorchJobStopped",
                "status": "True",
                "type": "Stopped"
              },
              {
                "lastTransitionTime": "2024-07-18T02:48:38Z",
                "lastUpdateTime": "2024-07-18T02:48:38Z",
                "message": "PyTorchJob llamatest0718forxiaomi5 is failed because 1 Worker replica(s) failed.",
                "reason": "JobFailed",
                "status": "True",
                "type": "Failed"
              }
            ],
            "lastReconcileTime": "2024-07-18T02:30:28Z",
            "replicaStatuses": {
              "Master": {
                "active": 1,
                "selector": "training.kubeflow.org/job-name=llamatest0718forxiaomi5,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=master"
              },
              "Worker": {
                "active": 2,
                "failed": 1,
                "selector": "training.kubeflow.org/job-name=llamatest0718forxiaomi5,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=worker"
              }
            },
            "startTime": "2024-07-18T02:30:29Z"
          }
        },
        {
          "apiVersion": "kubeflow.org/v1",
          "kind": "PyTorchJob",
          "metadata": {
            "annotations": {
              "aijob.cce.baidubce.com/barrier-finish": "edae2b9f-0624-43ca-a8a5-2bf5322fe37f",
              "aijob.cce.baidubce.com/fault-tolerance-enabled": "true",
              "aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": "",
              "aijob.cce.baidubce.com/openapi-jobid": "pytorch-3f701207-b25e-48e7-ba06-a3d396838961",
              "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
              "aijob.cce.baidubce.com/raw-request": "{\"name\":\"llamatest0718forxiaomi6\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"high\",\"oversell\":false,\"faultTolerance\":true,\"command\":\"\\n#! /bin/bash\\n\\nMEGATRON_PATH=${MEGATRON_PATH:-\\\"/workspace/AIAK-Megatron\\\"}\\nAIAK_TRAINING_PATH=${AIAK_TRAINING_PATH:-\\\"/workspace/AIAK-Training-LLM\\\"}\\n\\nDATA_PATH=${DATA_PATH:-\\\"/mnt/cluster/llama2/pile_llama_test/pile-llama_text_document\\\"}\\nTOKENIZER_PATH=${TOKENIZER_PATH:-\\\"/mnt/cluster/llama2/Llama-2-70b-hf/\\\"}\\n\\nCHECKPOINT_PATH=${CHECKPOINT_PATH:-\\\"/mnt/cluster/llama2/mcore_llama2_70b_tp4_pp4\\\"}\\n\\nTENSORBOARD_PATH=${TENSORBOARD_PATH:-\\\"/mnt/cluster/aiak-training-llm/tensorboard-log/llama2-70b-tp4pp4\\\"}\\n\\nGPUS_PER_NODE=8\\n\\n# Change for multinode config\\nMASTER_ADDR=${MASTER_ADDR:-\\\"localhost\\\"}\\nMASTER_PORT=${MASTER_PORT:-\\\"6000\\\"}\\nNNODES=${WORLD_SIZE:-\\\"1\\\"}\\nNODE_RANK=${RANK:-\\\"0\\\"}\\n\\nDISTRIBUTED_ARGS=(\\n    --nproc_per_node $GPUS_PER_NODE\\n    --nnodes $NNODES\\n    --node_rank $NODE_RANK\\n    --master_addr $MASTER_ADDR\\n    --master_port $MASTER_PORT\\n)\\n\\n# you can setup llama2-70b maunally\\n#MODEL_ARGS=(\\n#    --model-name llama2\\n#    --num-layers 80\\n#    --hidden-size 8192\\n#    --ffn-hidden-size 28672\\n#    --num-attention-heads 64\\n#    --position-embedding-type rope\\n#    --normalization RMSNorm\\n#    --swiglu\\n#    --attention-dropout 0\\n#    --hidden-dropout 0\\n#    --disable-bias-linear\\n#    --untie-embeddings-and-output-weights\\n#    --group-query-attention\\n#    --num-query-groups 8\\n#)\\n\\n# or you can setup llama2-70b by using the following command\\nMODEL_ARGS=(\\n    --model-name llama2-70b # options: llama2-7b, llama2-13b, llama2-70b\\n)\\n\\nDATA_ARGS=(\\n    --tokenizer-type HFTokenizer\\n    --hf-tokenizer-path $TOKENIZER_PATH\\n    --data-path $DATA_PATH\\n    --split 949,50,1\\n)\\n\\nTRAINING_ARGS=(\\n    --training-phase pretrain # options: pretrain, sft\\n    --seq-length 4096\\n    --max-position-embeddings 4096\\n    --init-method-std 0.01\\n    --micro-batch-size 1\\n    --global-batch-size 128\\n    --lr 0.0002\\n    --min-lr 1.0e-5\\n    --clip-grad 1.0\\n    --weight-decay 0.01\\n    --optimizer adam\\n    --adam-beta1 0.9\\n    --adam-beta2 0.95\\n    --adam-eps 1e-05\\n    --norm-epsilon 1e-6\\n    --train-iters 500000\\n    --lr-decay-iters 500000\\n    --lr-decay-style cosine\\n    --lr-warmup-fraction 0.002\\n    --initial-loss-scale 65536\\n    --fp16\\n    --save-interval 5000\\n    --eval-interval 1000\\n    --eval-iters 10\\n    --offload-optimizer auto\\n    #--ckpt-step 0\\n    #--no-load-optim\\n    #--no-load-rng\\n)\\n\\nMODEL_PARALLEL_ARGS=(\\n    --tensor-model-parallel-size 2\\n    --pipeline-model-parallel-size 8\\n    --use-distributed-optimizer\\n    --overlap-grad-reduce\\n    --overlap-param-gather\\n    --distributed-backend nccl\\n    --sequence-parallel\\n    #--tp-comm-overlap # require mpi envrionment\\n)\\n\\nLOGGING_ARGS=(\\n    --log-interval 1\\n    --tensorboard-dir ${TENSORBOARD_PATH}\\n    --log-timers-to-tensorboard\\n)\\n\\nif [ -n \\\"${WANDB_API_KEY}\\\" ]; then\\n    LOGGING_ARGS+=(\\n        --wandb-project ${WANDB_PROJECT}\\n        --wandb-exp-name ${WANDB_NAME} \\n    )\\nfi\\n\\nPYTHONPATH=$MEGATRON_PATH:$AIAK_TRAINING_PATH:$PYTHONPATH     torchrun ${DISTRIBUTED_ARGS[@]}     $AIAK_TRAINING_PATH/aiak_training_llm/train.py     ${MODEL_ARGS[@]}     ${DATA_ARGS[@]}     ${TRAINING_ARGS[@]}     ${MODEL_PARALLEL_ARGS[@]}     ${LOGGING_ARGS[@]}\\n\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":true,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi6\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi6/output/training_logs\",\"CUDA_DEVICE_MAX_CONNECTIONS\":\"1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"},\"Worker\":{\"replicas\":3,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi6\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi6/output/training_logs\",\"CUDA_DEVICE_MAX_CONNECTIONS\":\"1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":true,\"logPath\":\"/mnt/cluster/llamatest0718forxiaomi6/output/training_logs\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":true,\"isCopyJob\":true,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
              "aijob.cce.baidubce.com/timeline": "[{\"conditionType\":\"Created\",\"time\":1721270898},{\"conditionType\":\"Scheduled\",\"time\":1721270899},{\"conditionType\":\"Running\",\"time\":1721270910},{\"conditionType\":\"ManualTermination\",\"time\":1721271258}]",
              "job-manager/action": "stop",
              "job-manager/action-succeed": "stop",
              "scheduling.k8s.io/job-enable-oversell": "false",
              "tensorboard-gc": "true"
            },
            "creationTimestamp": "2024-07-18T02:48:18Z",
            "generation": 2,
            "labels": {
              "aijob.cce.baidubce.com/ai-user-id": "b5a24aa26e4d4f55bc3acf68edc4b051",
              "aijob.cce.baidubce.com/ai-user-name": "zhangmuhua",
              "aijob.cce.baidubce.com/create-from-aihcp": "true",
              "aijob.cce.baidubce.com/openapi-jobid": "pytorch-3f701207-b25e-48e7-ba06-a3d396838961"
            },
            "managedFields": [
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      "f:aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": {},
                      "f:aijob.cce.baidubce.com/timeline": {}
                    }
                  },
                  "f:spec": {
                    "f:pytorchReplicaSpecs": {
                      "f:Master": {
                        "f:template": {
                          "f:spec": {
                            "f:containers": {}
                          }
                        }
                      },
                      "f:Worker": {
                        "f:template": {
                          "f:spec": {
                            "f:containers": {}
                          }
                        }
                      }
                    },
                    "f:runPolicy": {
                      "f:cleanPodPolicy": {}
                    }
                  }
                },
                "manager": "controller",
                "operation": "Update",
                "time": "2024-07-18T02:48:18Z"
              },
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      "f:aijob.cce.baidubce.com/barrier-finish": {}
                    }
                  }
                },
                "manager": "jobbarrier",
                "operation": "Update",
                "time": "2024-07-18T02:48:27Z"
              },
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      ".": {},
                      "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                      "f:aijob.cce.baidubce.com/openapi-jobid": {},
                      "f:aijob.cce.baidubce.com/pfs-id": {},
                      "f:aijob.cce.baidubce.com/raw-request": {},
                      "f:job-manager/action": {},
                      "f:scheduling.k8s.io/job-enable-oversell": {}
                    },
                    "f:labels": {
                      ".": {},
                      "f:aijob.cce.baidubce.com/ai-user-id": {},
                      "f:aijob.cce.baidubce.com/ai-user-name": {},
                      "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                      "f:aijob.cce.baidubce.com/openapi-jobid": {}
                    }
                  },
                  "f:spec": {
                    ".": {},
                    "f:pytorchReplicaSpecs": {
                      ".": {},
                      "f:Master": {
                        ".": {},
                        "f:replicas": {},
                        "f:restartPolicy": {},
                        "f:template": {
                          ".": {},
                          "f:metadata": {
                            ".": {},
                            "f:annotations": {
                              ".": {},
                              "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                              "f:aijob.cce.baidubce.com/openapi-jobid": {},
                              "f:aijob.cce.baidubce.com/pfs-id": {},
                              "f:aijob.cce.baidubce.com/raw-request": {},
                              "f:scheduling.k8s.io/job-enable-oversell": {}
                            },
                            "f:labels": {
                              ".": {},
                              "f:aijob.cce.baidubce.com/ai-user-id": {},
                              "f:aijob.cce.baidubce.com/ai-user-name": {},
                              "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                              "f:aijob.cce.baidubce.com/openapi-jobid": {}
                            }
                          },
                          "f:spec": {
                            ".": {},
                            "f:dnsPolicy": {},
                            "f:hostNetwork": {},
                            "f:schedulerName": {},
                            "f:volumes": {}
                          }
                        }
                      },
                      "f:Worker": {
                        ".": {},
                        "f:replicas": {},
                        "f:restartPolicy": {},
                        "f:template": {
                          ".": {},
                          "f:metadata": {
                            ".": {},
                            "f:annotations": {
                              ".": {},
                              "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                              "f:aijob.cce.baidubce.com/openapi-jobid": {},
                              "f:aijob.cce.baidubce.com/pfs-id": {},
                              "f:aijob.cce.baidubce.com/raw-request": {},
                              "f:scheduling.k8s.io/job-enable-oversell": {}
                            },
                            "f:labels": {
                              ".": {},
                              "f:aijob.cce.baidubce.com/ai-user-id": {},
                              "f:aijob.cce.baidubce.com/ai-user-name": {},
                              "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                              "f:aijob.cce.baidubce.com/openapi-jobid": {}
                            }
                          },
                          "f:spec": {
                            ".": {},
                            "f:dnsPolicy": {},
                            "f:hostNetwork": {},
                            "f:schedulerName": {},
                            "f:volumes": {}
                          }
                        }
                      }
                    },
                    "f:runPolicy": {
                      ".": {},
                      "f:schedulingPolicy": {
                        ".": {},
                        "f:priorityClass": {},
                        "f:queue": {}
                      }
                    }
                  }
                },
                "manager": "cce-ai-service",
                "operation": "Update",
                "time": "2024-07-18T02:54:18Z"
              },
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      "f:job-manager/action-succeed": {}
                    }
                  }
                },
                "manager": "ftagent",
                "operation": "Update",
                "time": "2024-07-18T02:54:23Z"
              },
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      "f:tensorboard-gc": {}
                    }
                  },
                  "f:status": {
                    ".": {},
                    "f:completionTime": {},
                    "f:conditions": {},
                    "f:lastReconcileTime": {},
                    "f:replicaStatuses": {
                      ".": {},
                      "f:Master": {
                        ".": {},
                        "f:active": {}
                      },
                      "f:Worker": {
                        ".": {},
                        "f:active": {},
                        "f:failed": {}
                      }
                    },
                    "f:startTime": {}
                  }
                },
                "manager": "manager",
                "operation": "Update",
                "time": "2024-07-19T02:48:56Z"
              }
            ],
            "name": "llamatest0718forxiaomi6",
            "namespace": "default",
            "resourceVersion": "2372410633",
            "uid": "9b140464-2b9e-4f49-9e05-ba7190c73857"
          },
          "spec": {
            "pytorchReplicaSpecs": {
              "Master": {
                "replicas": 1,
                "restartPolicy": "Never",
                "template": {
                  "metadata": {
                    "annotations": {
                      "aijob.cce.baidubce.com/fault-tolerance-enabled": "true",
                      "aijob.cce.baidubce.com/openapi-jobid": "pytorch-3f701207-b25e-48e7-ba06-a3d396838961",
                      "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
                      "aijob.cce.baidubce.com/raw-request": "{\"name\":\"llamatest0718forxiaomi6\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"high\",\"oversell\":false,\"faultTolerance\":true,\"command\":\"\\n#! /bin/bash\\n\\nMEGATRON_PATH=${MEGATRON_PATH:-\\\"/workspace/AIAK-Megatron\\\"}\\nAIAK_TRAINING_PATH=${AIAK_TRAINING_PATH:-\\\"/workspace/AIAK-Training-LLM\\\"}\\n\\nDATA_PATH=${DATA_PATH:-\\\"/mnt/cluster/llama2/pile_llama_test/pile-llama_text_document\\\"}\\nTOKENIZER_PATH=${TOKENIZER_PATH:-\\\"/mnt/cluster/llama2/Llama-2-70b-hf/\\\"}\\n\\nCHECKPOINT_PATH=${CHECKPOINT_PATH:-\\\"/mnt/cluster/llama2/mcore_llama2_70b_tp4_pp4\\\"}\\n\\nTENSORBOARD_PATH=${TENSORBOARD_PATH:-\\\"/mnt/cluster/aiak-training-llm/tensorboard-log/llama2-70b-tp4pp4\\\"}\\n\\nGPUS_PER_NODE=8\\n\\n# Change for multinode config\\nMASTER_ADDR=${MASTER_ADDR:-\\\"localhost\\\"}\\nMASTER_PORT=${MASTER_PORT:-\\\"6000\\\"}\\nNNODES=${WORLD_SIZE:-\\\"1\\\"}\\nNODE_RANK=${RANK:-\\\"0\\\"}\\n\\nDISTRIBUTED_ARGS=(\\n    --nproc_per_node $GPUS_PER_NODE\\n    --nnodes $NNODES\\n    --node_rank $NODE_RANK\\n    --master_addr $MASTER_ADDR\\n    --master_port $MASTER_PORT\\n)\\n\\n# you can setup llama2-70b maunally\\n#MODEL_ARGS=(\\n#    --model-name llama2\\n#    --num-layers 80\\n#    --hidden-size 8192\\n#    --ffn-hidden-size 28672\\n#    --num-attention-heads 64\\n#    --position-embedding-type rope\\n#    --normalization RMSNorm\\n#    --swiglu\\n#    --attention-dropout 0\\n#    --hidden-dropout 0\\n#    --disable-bias-linear\\n#    --untie-embeddings-and-output-weights\\n#    --group-query-attention\\n#    --num-query-groups 8\\n#)\\n\\n# or you can setup llama2-70b by using the following command\\nMODEL_ARGS=(\\n    --model-name llama2-70b # options: llama2-7b, llama2-13b, llama2-70b\\n)\\n\\nDATA_ARGS=(\\n    --tokenizer-type HFTokenizer\\n    --hf-tokenizer-path $TOKENIZER_PATH\\n    --data-path $DATA_PATH\\n    --split 949,50,1\\n)\\n\\nTRAINING_ARGS=(\\n    --training-phase pretrain # options: pretrain, sft\\n    --seq-length 4096\\n    --max-position-embeddings 4096\\n    --init-method-std 0.01\\n    --micro-batch-size 1\\n    --global-batch-size 128\\n    --lr 0.0002\\n    --min-lr 1.0e-5\\n    --clip-grad 1.0\\n    --weight-decay 0.01\\n    --optimizer adam\\n    --adam-beta1 0.9\\n    --adam-beta2 0.95\\n    --adam-eps 1e-05\\n    --norm-epsilon 1e-6\\n    --train-iters 500000\\n    --lr-decay-iters 500000\\n    --lr-decay-style cosine\\n    --lr-warmup-fraction 0.002\\n    --initial-loss-scale 65536\\n    --fp16\\n    --save-interval 5000\\n    --eval-interval 1000\\n    --eval-iters 10\\n    --offload-optimizer auto\\n    #--ckpt-step 0\\n    #--no-load-optim\\n    #--no-load-rng\\n)\\n\\nMODEL_PARALLEL_ARGS=(\\n    --tensor-model-parallel-size 2\\n    --pipeline-model-parallel-size 8\\n    --use-distributed-optimizer\\n    --overlap-grad-reduce\\n    --overlap-param-gather\\n    --distributed-backend nccl\\n    --sequence-parallel\\n    #--tp-comm-overlap # require mpi envrionment\\n)\\n\\nLOGGING_ARGS=(\\n    --log-interval 1\\n    --tensorboard-dir ${TENSORBOARD_PATH}\\n    --log-timers-to-tensorboard\\n)\\n\\nif [ -n \\\"${WANDB_API_KEY}\\\" ]; then\\n    LOGGING_ARGS+=(\\n        --wandb-project ${WANDB_PROJECT}\\n        --wandb-exp-name ${WANDB_NAME} \\n    )\\nfi\\n\\nPYTHONPATH=$MEGATRON_PATH:$AIAK_TRAINING_PATH:$PYTHONPATH     torchrun ${DISTRIBUTED_ARGS[@]}     $AIAK_TRAINING_PATH/aiak_training_llm/train.py     ${MODEL_ARGS[@]}     ${DATA_ARGS[@]}     ${TRAINING_ARGS[@]}     ${MODEL_PARALLEL_ARGS[@]}     ${LOGGING_ARGS[@]}\\n\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":true,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi6\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi6/output/training_logs\",\"CUDA_DEVICE_MAX_CONNECTIONS\":\"1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"},\"Worker\":{\"replicas\":3,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi6\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi6/output/training_logs\",\"CUDA_DEVICE_MAX_CONNECTIONS\":\"1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":true,\"logPath\":\"/mnt/cluster/llamatest0718forxiaomi6/output/training_logs\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":true,\"isCopyJob\":true,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
                      "scheduling.k8s.io/job-enable-oversell": "false"
                    },
                    "labels": {
                      "aijob.cce.baidubce.com/ai-user-id": "b5a24aa26e4d4f55bc3acf68edc4b051",
                      "aijob.cce.baidubce.com/ai-user-name": "zhangmuhua",
                      "aijob.cce.baidubce.com/create-from-aihcp": "true",
                      "aijob.cce.baidubce.com/openapi-jobid": "pytorch-3f701207-b25e-48e7-ba06-a3d396838961"
                    }
                  },
                  "spec": {
                    "containers": [
                      {
                        "command": [
                          "/bin/bash",
                          "-c",
                          "\n#! /bin/bash\n\nMEGATRON_PATH=${MEGATRON_PATH:-\"/workspace/AIAK-Megatron\"}\nAIAK_TRAINING_PATH=${AIAK_TRAINING_PATH:-\"/workspace/AIAK-Training-LLM\"}\n\nDATA_PATH=${DATA_PATH:-\"/mnt/cluster/llama2/pile_llama_test/pile-llama_text_document\"}\nTOKENIZER_PATH=${TOKENIZER_PATH:-\"/mnt/cluster/llama2/Llama-2-70b-hf/\"}\n\nCHECKPOINT_PATH=${CHECKPOINT_PATH:-\"/mnt/cluster/llama2/mcore_llama2_70b_tp4_pp4\"}\n\nTENSORBOARD_PATH=${TENSORBOARD_PATH:-\"/mnt/cluster/aiak-training-llm/tensorboard-log/llama2-70b-tp4pp4\"}\n\nGPUS_PER_NODE=8\n\n# Change for multinode config\nMASTER_ADDR=${MASTER_ADDR:-\"localhost\"}\nMASTER_PORT=${MASTER_PORT:-\"6000\"}\nNNODES=${WORLD_SIZE:-\"1\"}\nNODE_RANK=${RANK:-\"0\"}\n\nDISTRIBUTED_ARGS=(\n    --nproc_per_node $GPUS_PER_NODE\n    --nnodes $NNODES\n    --node_rank $NODE_RANK\n    --master_addr $MASTER_ADDR\n    --master_port $MASTER_PORT\n)\n\n# you can setup llama2-70b maunally\n#MODEL_ARGS=(\n#    --model-name llama2\n#    --num-layers 80\n#    --hidden-size 8192\n#    --ffn-hidden-size 28672\n#    --num-attention-heads 64\n#    --position-embedding-type rope\n#    --normalization RMSNorm\n#    --swiglu\n#    --attention-dropout 0\n#    --hidden-dropout 0\n#    --disable-bias-linear\n#    --untie-embeddings-and-output-weights\n#    --group-query-attention\n#    --num-query-groups 8\n#)\n\n# or you can setup llama2-70b by using the following command\nMODEL_ARGS=(\n    --model-name llama2-70b # options: llama2-7b, llama2-13b, llama2-70b\n)\n\nDATA_ARGS=(\n    --tokenizer-type HFTokenizer\n    --hf-tokenizer-path $TOKENIZER_PATH\n    --data-path $DATA_PATH\n    --split 949,50,1\n)\n\nTRAINING_ARGS=(\n    --training-phase pretrain # options: pretrain, sft\n    --seq-length 4096\n    --max-position-embeddings 4096\n    --init-method-std 0.01\n    --micro-batch-size 1\n    --global-batch-size 128\n    --lr 0.0002\n    --min-lr 1.0e-5\n    --clip-grad 1.0\n    --weight-decay 0.01\n    --optimizer adam\n    --adam-beta1 0.9\n    --adam-beta2 0.95\n    --adam-eps 1e-05\n    --norm-epsilon 1e-6\n    --train-iters 500000\n    --lr-decay-iters 500000\n    --lr-decay-style cosine\n    --lr-warmup-fraction 0.002\n    --initial-loss-scale 65536\n    --fp16\n    --save-interval 5000\n    --eval-interval 1000\n    --eval-iters 10\n    --offload-optimizer auto\n    #--ckpt-step 0\n    #--no-load-optim\n    #--no-load-rng\n)\n\nMODEL_PARALLEL_ARGS=(\n    --tensor-model-parallel-size 2\n    --pipeline-model-parallel-size 8\n    --use-distributed-optimizer\n    --overlap-grad-reduce\n    --overlap-param-gather\n    --distributed-backend nccl\n    --sequence-parallel\n    #--tp-comm-overlap # require mpi envrionment\n)\n\nLOGGING_ARGS=(\n    --log-interval 1\n    --tensorboard-dir ${TENSORBOARD_PATH}\n    --log-timers-to-tensorboard\n)\n\nif [ -n \"${WANDB_API_KEY}\" ]; then\n    LOGGING_ARGS+=(\n        --wandb-project ${WANDB_PROJECT}\n        --wandb-exp-name ${WANDB_NAME} \n    )\nfi\n\nPYTHONPATH=$MEGATRON_PATH:$AIAK_TRAINING_PATH:$PYTHONPATH     torchrun ${DISTRIBUTED_ARGS[@]}     $AIAK_TRAINING_PATH/aiak_training_llm/train.py     ${MODEL_ARGS[@]}     ${DATA_ARGS[@]}     ${TRAINING_ARGS[@]}     ${MODEL_PARALLEL_ARGS[@]}     ${LOGGING_ARGS[@]}\n"
                        ],
                        "env": [
                          {
                            "name": "NCCL_IB_DISABLE",
                            "value": "0"
                          },
                          {
                            "name": "CUDA_DEVICE_MAX_CONNECTIONS",
                            "value": "1"
                          },
                          {
                            "name": "AIHC_TENSORBOARD_LOG_PATH",
                            "value": "/mnt/cluster/llamatest0718forxiaomi6/output/training_logs"
                          },
                          {
                            "name": "AIHC_JOB_NAME",
                            "value": "llamatest0718forxiaomi6"
                          }
                        ],
                        "image": "registry.baidubce.com/aihc-aiak/aiak-training-llm:ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release",
                        "imagePullPolicy": "Always",
                        "name": "pytorch",
                        "ports": [
                          {
                            "containerPort": 23456,
                            "name": "pytorchjob-port",
                            "protocol": "TCP"
                          }
                        ],
                        "resources": {
                          "limits": {
                            "baidu.com/a800_80g_cgpu": "8",
                            "rdma/hca": "1"
                          },
                          "requests": {
                            "baidu.com/a800_80g_cgpu": "8",
                            "rdma/hca": "1"
                          }
                        },
                        "securityContext": {
                          "capabilities": {
                            "add": [
                              "IPC_LOCK"
                            ]
                          }
                        },
                        "volumeMounts": [
                          {
                            "mountPath": "/dev/shm",
                            "name": "devshm"
                          },
                          {
                            "mountPath": "/mnt/cluster",
                            "name": "pvc-pfs"
                          }
                        ]
                      }
                    ],
                    "dnsPolicy": "ClusterFirstWithHostNet",
                    "hostNetwork": true,
                    "schedulerName": "volcano",
                    "volumes": [
                      {
                        "emptyDir": {
                          "medium": "Memory",
                          "sizeLimit": "10Gi"
                        },
                        "name": "devshm"
                      },
                      {
                        "name": "pvc-pfs",
                        "persistentVolumeClaim": {
                          "claimName": "pvc-pfs"
                        }
                      }
                    ]
                  }
                }
              },
              "Worker": {
                "replicas": 3,
                "restartPolicy": "Never",
                "template": {
                  "metadata": {
                    "annotations": {
                      "aijob.cce.baidubce.com/fault-tolerance-enabled": "true",
                      "aijob.cce.baidubce.com/openapi-jobid": "pytorch-3f701207-b25e-48e7-ba06-a3d396838961",
                      "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
                      "aijob.cce.baidubce.com/raw-request": "{\"name\":\"llamatest0718forxiaomi6\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"high\",\"oversell\":false,\"faultTolerance\":true,\"command\":\"\\n#! /bin/bash\\n\\nMEGATRON_PATH=${MEGATRON_PATH:-\\\"/workspace/AIAK-Megatron\\\"}\\nAIAK_TRAINING_PATH=${AIAK_TRAINING_PATH:-\\\"/workspace/AIAK-Training-LLM\\\"}\\n\\nDATA_PATH=${DATA_PATH:-\\\"/mnt/cluster/llama2/pile_llama_test/pile-llama_text_document\\\"}\\nTOKENIZER_PATH=${TOKENIZER_PATH:-\\\"/mnt/cluster/llama2/Llama-2-70b-hf/\\\"}\\n\\nCHECKPOINT_PATH=${CHECKPOINT_PATH:-\\\"/mnt/cluster/llama2/mcore_llama2_70b_tp4_pp4\\\"}\\n\\nTENSORBOARD_PATH=${TENSORBOARD_PATH:-\\\"/mnt/cluster/aiak-training-llm/tensorboard-log/llama2-70b-tp4pp4\\\"}\\n\\nGPUS_PER_NODE=8\\n\\n# Change for multinode config\\nMASTER_ADDR=${MASTER_ADDR:-\\\"localhost\\\"}\\nMASTER_PORT=${MASTER_PORT:-\\\"6000\\\"}\\nNNODES=${WORLD_SIZE:-\\\"1\\\"}\\nNODE_RANK=${RANK:-\\\"0\\\"}\\n\\nDISTRIBUTED_ARGS=(\\n    --nproc_per_node $GPUS_PER_NODE\\n    --nnodes $NNODES\\n    --node_rank $NODE_RANK\\n    --master_addr $MASTER_ADDR\\n    --master_port $MASTER_PORT\\n)\\n\\n# you can setup llama2-70b maunally\\n#MODEL_ARGS=(\\n#    --model-name llama2\\n#    --num-layers 80\\n#    --hidden-size 8192\\n#    --ffn-hidden-size 28672\\n#    --num-attention-heads 64\\n#    --position-embedding-type rope\\n#    --normalization RMSNorm\\n#    --swiglu\\n#    --attention-dropout 0\\n#    --hidden-dropout 0\\n#    --disable-bias-linear\\n#    --untie-embeddings-and-output-weights\\n#    --group-query-attention\\n#    --num-query-groups 8\\n#)\\n\\n# or you can setup llama2-70b by using the following command\\nMODEL_ARGS=(\\n    --model-name llama2-70b # options: llama2-7b, llama2-13b, llama2-70b\\n)\\n\\nDATA_ARGS=(\\n    --tokenizer-type HFTokenizer\\n    --hf-tokenizer-path $TOKENIZER_PATH\\n    --data-path $DATA_PATH\\n    --split 949,50,1\\n)\\n\\nTRAINING_ARGS=(\\n    --training-phase pretrain # options: pretrain, sft\\n    --seq-length 4096\\n    --max-position-embeddings 4096\\n    --init-method-std 0.01\\n    --micro-batch-size 1\\n    --global-batch-size 128\\n    --lr 0.0002\\n    --min-lr 1.0e-5\\n    --clip-grad 1.0\\n    --weight-decay 0.01\\n    --optimizer adam\\n    --adam-beta1 0.9\\n    --adam-beta2 0.95\\n    --adam-eps 1e-05\\n    --norm-epsilon 1e-6\\n    --train-iters 500000\\n    --lr-decay-iters 500000\\n    --lr-decay-style cosine\\n    --lr-warmup-fraction 0.002\\n    --initial-loss-scale 65536\\n    --fp16\\n    --save-interval 5000\\n    --eval-interval 1000\\n    --eval-iters 10\\n    --offload-optimizer auto\\n    #--ckpt-step 0\\n    #--no-load-optim\\n    #--no-load-rng\\n)\\n\\nMODEL_PARALLEL_ARGS=(\\n    --tensor-model-parallel-size 2\\n    --pipeline-model-parallel-size 8\\n    --use-distributed-optimizer\\n    --overlap-grad-reduce\\n    --overlap-param-gather\\n    --distributed-backend nccl\\n    --sequence-parallel\\n    #--tp-comm-overlap # require mpi envrionment\\n)\\n\\nLOGGING_ARGS=(\\n    --log-interval 1\\n    --tensorboard-dir ${TENSORBOARD_PATH}\\n    --log-timers-to-tensorboard\\n)\\n\\nif [ -n \\\"${WANDB_API_KEY}\\\" ]; then\\n    LOGGING_ARGS+=(\\n        --wandb-project ${WANDB_PROJECT}\\n        --wandb-exp-name ${WANDB_NAME} \\n    )\\nfi\\n\\nPYTHONPATH=$MEGATRON_PATH:$AIAK_TRAINING_PATH:$PYTHONPATH     torchrun ${DISTRIBUTED_ARGS[@]}     $AIAK_TRAINING_PATH/aiak_training_llm/train.py     ${MODEL_ARGS[@]}     ${DATA_ARGS[@]}     ${TRAINING_ARGS[@]}     ${MODEL_PARALLEL_ARGS[@]}     ${LOGGING_ARGS[@]}\\n\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":true,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi6\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi6/output/training_logs\",\"CUDA_DEVICE_MAX_CONNECTIONS\":\"1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"},\"Worker\":{\"replicas\":3,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi6\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi6/output/training_logs\",\"CUDA_DEVICE_MAX_CONNECTIONS\":\"1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":true,\"logPath\":\"/mnt/cluster/llamatest0718forxiaomi6/output/training_logs\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":true,\"isCopyJob\":true,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
                      "scheduling.k8s.io/job-enable-oversell": "false"
                    },
                    "labels": {
                      "aijob.cce.baidubce.com/ai-user-id": "b5a24aa26e4d4f55bc3acf68edc4b051",
                      "aijob.cce.baidubce.com/ai-user-name": "zhangmuhua",
                      "aijob.cce.baidubce.com/create-from-aihcp": "true",
                      "aijob.cce.baidubce.com/openapi-jobid": "pytorch-3f701207-b25e-48e7-ba06-a3d396838961"
                    }
                  },
                  "spec": {
                    "containers": [
                      {
                        "command": [
                          "/bin/bash",
                          "-c",
                          "\n#! /bin/bash\n\nMEGATRON_PATH=${MEGATRON_PATH:-\"/workspace/AIAK-Megatron\"}\nAIAK_TRAINING_PATH=${AIAK_TRAINING_PATH:-\"/workspace/AIAK-Training-LLM\"}\n\nDATA_PATH=${DATA_PATH:-\"/mnt/cluster/llama2/pile_llama_test/pile-llama_text_document\"}\nTOKENIZER_PATH=${TOKENIZER_PATH:-\"/mnt/cluster/llama2/Llama-2-70b-hf/\"}\n\nCHECKPOINT_PATH=${CHECKPOINT_PATH:-\"/mnt/cluster/llama2/mcore_llama2_70b_tp4_pp4\"}\n\nTENSORBOARD_PATH=${TENSORBOARD_PATH:-\"/mnt/cluster/aiak-training-llm/tensorboard-log/llama2-70b-tp4pp4\"}\n\nGPUS_PER_NODE=8\n\n# Change for multinode config\nMASTER_ADDR=${MASTER_ADDR:-\"localhost\"}\nMASTER_PORT=${MASTER_PORT:-\"6000\"}\nNNODES=${WORLD_SIZE:-\"1\"}\nNODE_RANK=${RANK:-\"0\"}\n\nDISTRIBUTED_ARGS=(\n    --nproc_per_node $GPUS_PER_NODE\n    --nnodes $NNODES\n    --node_rank $NODE_RANK\n    --master_addr $MASTER_ADDR\n    --master_port $MASTER_PORT\n)\n\n# you can setup llama2-70b maunally\n#MODEL_ARGS=(\n#    --model-name llama2\n#    --num-layers 80\n#    --hidden-size 8192\n#    --ffn-hidden-size 28672\n#    --num-attention-heads 64\n#    --position-embedding-type rope\n#    --normalization RMSNorm\n#    --swiglu\n#    --attention-dropout 0\n#    --hidden-dropout 0\n#    --disable-bias-linear\n#    --untie-embeddings-and-output-weights\n#    --group-query-attention\n#    --num-query-groups 8\n#)\n\n# or you can setup llama2-70b by using the following command\nMODEL_ARGS=(\n    --model-name llama2-70b # options: llama2-7b, llama2-13b, llama2-70b\n)\n\nDATA_ARGS=(\n    --tokenizer-type HFTokenizer\n    --hf-tokenizer-path $TOKENIZER_PATH\n    --data-path $DATA_PATH\n    --split 949,50,1\n)\n\nTRAINING_ARGS=(\n    --training-phase pretrain # options: pretrain, sft\n    --seq-length 4096\n    --max-position-embeddings 4096\n    --init-method-std 0.01\n    --micro-batch-size 1\n    --global-batch-size 128\n    --lr 0.0002\n    --min-lr 1.0e-5\n    --clip-grad 1.0\n    --weight-decay 0.01\n    --optimizer adam\n    --adam-beta1 0.9\n    --adam-beta2 0.95\n    --adam-eps 1e-05\n    --norm-epsilon 1e-6\n    --train-iters 500000\n    --lr-decay-iters 500000\n    --lr-decay-style cosine\n    --lr-warmup-fraction 0.002\n    --initial-loss-scale 65536\n    --fp16\n    --save-interval 5000\n    --eval-interval 1000\n    --eval-iters 10\n    --offload-optimizer auto\n    #--ckpt-step 0\n    #--no-load-optim\n    #--no-load-rng\n)\n\nMODEL_PARALLEL_ARGS=(\n    --tensor-model-parallel-size 2\n    --pipeline-model-parallel-size 8\n    --use-distributed-optimizer\n    --overlap-grad-reduce\n    --overlap-param-gather\n    --distributed-backend nccl\n    --sequence-parallel\n    #--tp-comm-overlap # require mpi envrionment\n)\n\nLOGGING_ARGS=(\n    --log-interval 1\n    --tensorboard-dir ${TENSORBOARD_PATH}\n    --log-timers-to-tensorboard\n)\n\nif [ -n \"${WANDB_API_KEY}\" ]; then\n    LOGGING_ARGS+=(\n        --wandb-project ${WANDB_PROJECT}\n        --wandb-exp-name ${WANDB_NAME} \n    )\nfi\n\nPYTHONPATH=$MEGATRON_PATH:$AIAK_TRAINING_PATH:$PYTHONPATH     torchrun ${DISTRIBUTED_ARGS[@]}     $AIAK_TRAINING_PATH/aiak_training_llm/train.py     ${MODEL_ARGS[@]}     ${DATA_ARGS[@]}     ${TRAINING_ARGS[@]}     ${MODEL_PARALLEL_ARGS[@]}     ${LOGGING_ARGS[@]}\n"
                        ],
                        "env": [
                          {
                            "name": "CUDA_DEVICE_MAX_CONNECTIONS",
                            "value": "1"
                          },
                          {
                            "name": "AIHC_TENSORBOARD_LOG_PATH",
                            "value": "/mnt/cluster/llamatest0718forxiaomi6/output/training_logs"
                          },
                          {
                            "name": "AIHC_JOB_NAME",
                            "value": "llamatest0718forxiaomi6"
                          },
                          {
                            "name": "NCCL_IB_DISABLE",
                            "value": "0"
                          }
                        ],
                        "image": "registry.baidubce.com/aihc-aiak/aiak-training-llm:ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release",
                        "imagePullPolicy": "Always",
                        "name": "pytorch",
                        "ports": [
                          {
                            "containerPort": 23456,
                            "name": "pytorchjob-port",
                            "protocol": "TCP"
                          }
                        ],
                        "resources": {
                          "limits": {
                            "baidu.com/a800_80g_cgpu": "8",
                            "rdma/hca": "1"
                          },
                          "requests": {
                            "baidu.com/a800_80g_cgpu": "8",
                            "rdma/hca": "1"
                          }
                        },
                        "securityContext": {
                          "capabilities": {
                            "add": [
                              "IPC_LOCK"
                            ]
                          }
                        },
                        "volumeMounts": [
                          {
                            "mountPath": "/dev/shm",
                            "name": "devshm"
                          },
                          {
                            "mountPath": "/mnt/cluster",
                            "name": "pvc-pfs"
                          }
                        ]
                      }
                    ],
                    "dnsPolicy": "ClusterFirstWithHostNet",
                    "hostNetwork": true,
                    "schedulerName": "volcano",
                    "volumes": [
                      {
                        "emptyDir": {
                          "medium": "Memory",
                          "sizeLimit": "10Gi"
                        },
                        "name": "devshm"
                      },
                      {
                        "name": "pvc-pfs",
                        "persistentVolumeClaim": {
                          "claimName": "pvc-pfs"
                        }
                      }
                    ]
                  }
                }
              }
            },
            "runPolicy": {
              "cleanPodPolicy": "None",
              "schedulingPolicy": {
                "priorityClass": "high",
                "queue": "default"
              }
            }
          },
          "status": {
            "completionTime": "2024-07-18T02:54:25Z",
            "conditions": [
              {
                "lastTransitionTime": "2024-07-18T02:48:18Z",
                "lastUpdateTime": "2024-07-18T02:48:18Z",
                "message": "PyTorchJob llamatest0718forxiaomi6 is created.",
                "reason": "PyTorchJobCreated",
                "status": "True",
                "type": "Created"
              },
              {
                "lastTransitionTime": "2024-07-18T02:48:30Z",
                "lastUpdateTime": "2024-07-18T02:48:30Z",
                "message": "PyTorchJob llamatest0718forxiaomi6 is running.",
                "reason": "JobRunning",
                "status": "False",
                "type": "Running"
              },
              {
                "lastTransitionTime": "2024-07-18T02:54:18Z",
                "lastUpdateTime": "2024-07-18T02:54:18Z",
                "message": "PytorchJob default/llamatest0718forxiaomi6 is stopped",
                "reason": "PyTorchJobStopped",
                "status": "True",
                "type": "Stopped"
              },
              {
                "lastTransitionTime": "2024-07-18T02:54:25Z",
                "lastUpdateTime": "2024-07-18T02:54:25Z",
                "message": "PyTorchJob llamatest0718forxiaomi6 is failed because 1 Worker replica(s) failed.",
                "reason": "JobFailed",
                "status": "True",
                "type": "Failed"
              }
            ],
            "lastReconcileTime": "2024-07-18T02:48:18Z",
            "replicaStatuses": {
              "Master": {
                "active": 1,
                "selector": "training.kubeflow.org/job-name=llamatest0718forxiaomi6,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=master"
              },
              "Worker": {
                "active": 2,
                "failed": 1,
                "selector": "training.kubeflow.org/job-name=llamatest0718forxiaomi6,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=worker"
              }
            },
            "startTime": "2024-07-18T02:48:19Z"
          }
        },
        {
          "apiVersion": "kubeflow.org/v1",
          "kind": "PyTorchJob",
          "metadata": {
            "annotations": {
              "aijob.cce.baidubce.com/barrier-finish": "09d85585-87d1-4f0a-8e9c-7bb83accb9cb",
              "aijob.cce.baidubce.com/fault-tolerance-enabled": "true",
              "aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": "",
              "aijob.cce.baidubce.com/openapi-jobid": "pytorch-ee8727ec-0af3-4f80-8fa5-ed511ae8e47e",
              "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
              "aijob.cce.baidubce.com/raw-request": "{\"name\":\"llamatest0718forxiaomi7\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"high\",\"oversell\":false,\"faultTolerance\":true,\"command\":\"\\n#! /bin/bash\\n\\nMEGATRON_PATH=${MEGATRON_PATH:-\\\"/workspace/AIAK-Megatron\\\"}\\nAIAK_TRAINING_PATH=${AIAK_TRAINING_PATH:-\\\"/workspace/AIAK-Training-LLM\\\"}\\n\\nDATA_PATH=${DATA_PATH:-\\\"/mnt/cluster/llama2/pile_llama_test/pile-llama_text_document\\\"}\\nTOKENIZER_PATH=${TOKENIZER_PATH:-\\\"/mnt/cluster/llama2/Llama-2-70b-hf/\\\"}\\n\\nCHECKPOINT_PATH=${CHECKPOINT_PATH:-\\\"/mnt/cluster/llama2/mcore_llama2_70b_tp4_pp4\\\"}\\n\\nTENSORBOARD_PATH=${TENSORBOARD_PATH:-\\\"/mnt/cluster/aiak-training-llm/tensorboard-log/llama2-70b-tp4pp4\\\"}\\n\\nGPUS_PER_NODE=8\\n\\n# Change for multinode config\\nMASTER_ADDR=${MASTER_ADDR:-\\\"localhost\\\"}\\nMASTER_PORT=${MASTER_PORT:-\\\"6000\\\"}\\nNNODES=${WORLD_SIZE:-\\\"1\\\"}\\nNODE_RANK=${RANK:-\\\"0\\\"}\\n\\nDISTRIBUTED_ARGS=(\\n    --nproc_per_node $GPUS_PER_NODE\\n    --nnodes $NNODES\\n    --node_rank $NODE_RANK\\n    --master_addr $MASTER_ADDR\\n    --master_port $MASTER_PORT\\n)\\n\\n# you can setup llama2-70b maunally\\n#MODEL_ARGS=(\\n#    --model-name llama2\\n#    --num-layers 80\\n#    --hidden-size 8192\\n#    --ffn-hidden-size 28672\\n#    --num-attention-heads 64\\n#    --position-embedding-type rope\\n#    --normalization RMSNorm\\n#    --swiglu\\n#    --attention-dropout 0\\n#    --hidden-dropout 0\\n#    --disable-bias-linear\\n#    --untie-embeddings-and-output-weights\\n#    --group-query-attention\\n#    --num-query-groups 8\\n#)\\n\\n# or you can setup llama2-70b by using the following command\\nMODEL_ARGS=(\\n    --model-name llama2-70b # options: llama2-7b, llama2-13b, llama2-70b\\n)\\n\\nDATA_ARGS=(\\n    --tokenizer-type HFTokenizer\\n    --hf-tokenizer-path $TOKENIZER_PATH\\n    --data-path $DATA_PATH\\n    --split 949,50,1\\n)\\n\\nTRAINING_ARGS=(\\n    --training-phase pretrain # options: pretrain, sft\\n    --seq-length 4096\\n    --max-position-embeddings 4096\\n    --init-method-std 0.01\\n    --micro-batch-size 1\\n    --global-batch-size 128\\n    --lr 0.0002\\n    --min-lr 1.0e-5\\n    --clip-grad 1.0\\n    --weight-decay 0.01\\n    --optimizer adam\\n    --adam-beta1 0.9\\n    --adam-beta2 0.95\\n    --adam-eps 1e-05\\n    --norm-epsilon 1e-6\\n    --train-iters 500000\\n    --lr-decay-iters 500000\\n    --lr-decay-style cosine\\n    --lr-warmup-fraction 0.002\\n    --initial-loss-scale 65536\\n    --fp16\\n    --save-interval 5000\\n    --eval-interval 1000\\n    --eval-iters 10\\n    #--ckpt-step 0\\n    #--no-load-optim\\n    #--no-load-rng\\n)\\n\\nMODEL_PARALLEL_ARGS=(\\n    --tensor-model-parallel-size 4\\n    --pipeline-model-parallel-size 4\\n    --use-distributed-optimizer\\n    --overlap-grad-reduce\\n    --overlap-param-gather\\n    --distributed-backend nccl\\n    --sequence-parallel\\n    #--tp-comm-overlap # require mpi envrionment\\n)\\n\\nLOGGING_ARGS=(\\n    --log-interval 1\\n    --tensorboard-dir ${TENSORBOARD_PATH}\\n    --log-timers-to-tensorboard\\n)\\n\\nif [ -n \\\"${WANDB_API_KEY}\\\" ]; then\\n    LOGGING_ARGS+=(\\n        --wandb-project ${WANDB_PROJECT}\\n        --wandb-exp-name ${WANDB_NAME} \\n    )\\nfi\\n\\nPYTHONPATH=$MEGATRON_PATH:$AIAK_TRAINING_PATH:$PYTHONPATH     torchrun ${DISTRIBUTED_ARGS[@]}     $AIAK_TRAINING_PATH/aiak_training_llm/train.py     ${MODEL_ARGS[@]}     ${DATA_ARGS[@]}     ${TRAINING_ARGS[@]}     ${MODEL_PARALLEL_ARGS[@]}     ${LOGGING_ARGS[@]}\\n\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":true,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi7\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi7/output/training_logs\",\"CUDA_DEVICE_MAX_CONNECTIONS\":\"1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"},\"Worker\":{\"replicas\":3,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi7\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi7/output/training_logs\",\"CUDA_DEVICE_MAX_CONNECTIONS\":\"1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":true,\"logPath\":\"/mnt/cluster/llamatest0718forxiaomi7/output/training_logs\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":true,\"isCopyJob\":true,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
              "aijob.cce.baidubce.com/timeline": "[{\"conditionType\":\"Created\",\"time\":1721271251},{\"conditionType\":\"Scheduled\",\"time\":1721271252},{\"conditionType\":\"Running\",\"time\":1721271264},{\"conditionType\":\"ManualTermination\",\"time\":1721271770}]",
              "job-manager/action": "stop",
              "job-manager/action-succeed": "stop",
              "scheduling.k8s.io/job-enable-oversell": "false",
              "tensorboard-gc": "true"
            },
            "creationTimestamp": "2024-07-18T02:54:11Z",
            "generation": 2,
            "labels": {
              "aijob.cce.baidubce.com/ai-user-id": "b5a24aa26e4d4f55bc3acf68edc4b051",
              "aijob.cce.baidubce.com/ai-user-name": "zhangmuhua",
              "aijob.cce.baidubce.com/create-from-aihcp": "true",
              "aijob.cce.baidubce.com/openapi-jobid": "pytorch-ee8727ec-0af3-4f80-8fa5-ed511ae8e47e"
            },
            "managedFields": [
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      "f:aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": {},
                      "f:aijob.cce.baidubce.com/timeline": {}
                    }
                  },
                  "f:spec": {
                    "f:pytorchReplicaSpecs": {
                      "f:Master": {
                        "f:template": {
                          "f:spec": {
                            "f:containers": {}
                          }
                        }
                      },
                      "f:Worker": {
                        "f:template": {
                          "f:spec": {
                            "f:containers": {}
                          }
                        }
                      }
                    },
                    "f:runPolicy": {
                      "f:cleanPodPolicy": {}
                    }
                  }
                },
                "manager": "controller",
                "operation": "Update",
                "time": "2024-07-18T02:54:11Z"
              },
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      "f:aijob.cce.baidubce.com/barrier-finish": {}
                    }
                  }
                },
                "manager": "jobbarrier",
                "operation": "Update",
                "time": "2024-07-18T02:54:20Z"
              },
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      ".": {},
                      "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                      "f:aijob.cce.baidubce.com/openapi-jobid": {},
                      "f:aijob.cce.baidubce.com/pfs-id": {},
                      "f:aijob.cce.baidubce.com/raw-request": {},
                      "f:job-manager/action": {},
                      "f:scheduling.k8s.io/job-enable-oversell": {}
                    },
                    "f:labels": {
                      ".": {},
                      "f:aijob.cce.baidubce.com/ai-user-id": {},
                      "f:aijob.cce.baidubce.com/ai-user-name": {},
                      "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                      "f:aijob.cce.baidubce.com/openapi-jobid": {}
                    }
                  },
                  "f:spec": {
                    ".": {},
                    "f:pytorchReplicaSpecs": {
                      ".": {},
                      "f:Master": {
                        ".": {},
                        "f:replicas": {},
                        "f:restartPolicy": {},
                        "f:template": {
                          ".": {},
                          "f:metadata": {
                            ".": {},
                            "f:annotations": {
                              ".": {},
                              "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                              "f:aijob.cce.baidubce.com/openapi-jobid": {},
                              "f:aijob.cce.baidubce.com/pfs-id": {},
                              "f:aijob.cce.baidubce.com/raw-request": {},
                              "f:scheduling.k8s.io/job-enable-oversell": {}
                            },
                            "f:labels": {
                              ".": {},
                              "f:aijob.cce.baidubce.com/ai-user-id": {},
                              "f:aijob.cce.baidubce.com/ai-user-name": {},
                              "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                              "f:aijob.cce.baidubce.com/openapi-jobid": {}
                            }
                          },
                          "f:spec": {
                            ".": {},
                            "f:dnsPolicy": {},
                            "f:hostNetwork": {},
                            "f:schedulerName": {},
                            "f:volumes": {}
                          }
                        }
                      },
                      "f:Worker": {
                        ".": {},
                        "f:replicas": {},
                        "f:restartPolicy": {},
                        "f:template": {
                          ".": {},
                          "f:metadata": {
                            ".": {},
                            "f:annotations": {
                              ".": {},
                              "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                              "f:aijob.cce.baidubce.com/openapi-jobid": {},
                              "f:aijob.cce.baidubce.com/pfs-id": {},
                              "f:aijob.cce.baidubce.com/raw-request": {},
                              "f:scheduling.k8s.io/job-enable-oversell": {}
                            },
                            "f:labels": {
                              ".": {},
                              "f:aijob.cce.baidubce.com/ai-user-id": {},
                              "f:aijob.cce.baidubce.com/ai-user-name": {},
                              "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                              "f:aijob.cce.baidubce.com/openapi-jobid": {}
                            }
                          },
                          "f:spec": {
                            ".": {},
                            "f:dnsPolicy": {},
                            "f:hostNetwork": {},
                            "f:schedulerName": {},
                            "f:volumes": {}
                          }
                        }
                      }
                    },
                    "f:runPolicy": {
                      ".": {},
                      "f:schedulingPolicy": {
                        ".": {},
                        "f:priorityClass": {},
                        "f:queue": {}
                      }
                    }
                  }
                },
                "manager": "cce-ai-service",
                "operation": "Update",
                "time": "2024-07-18T03:02:50Z"
              },
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      "f:job-manager/action-succeed": {}
                    }
                  }
                },
                "manager": "ftagent",
                "operation": "Update",
                "time": "2024-07-18T03:02:55Z"
              },
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      "f:tensorboard-gc": {}
                    }
                  },
                  "f:status": {
                    ".": {},
                    "f:completionTime": {},
                    "f:conditions": {},
                    "f:lastReconcileTime": {},
                    "f:replicaStatuses": {
                      ".": {},
                      "f:Master": {
                        ".": {},
                        "f:failed": {}
                      },
                      "f:Worker": {
                        ".": {},
                        "f:active": {}
                      }
                    },
                    "f:startTime": {}
                  }
                },
                "manager": "manager",
                "operation": "Update",
                "time": "2024-07-19T02:54:56Z"
              }
            ],
            "name": "llamatest0718forxiaomi7",
            "namespace": "default",
            "resourceVersion": "2372416037",
            "uid": "23b6eaf3-423c-48de-800e-3fe709057ba3"
          },
          "spec": {
            "pytorchReplicaSpecs": {
              "Master": {
                "replicas": 1,
                "restartPolicy": "Never",
                "template": {
                  "metadata": {
                    "annotations": {
                      "aijob.cce.baidubce.com/fault-tolerance-enabled": "true",
                      "aijob.cce.baidubce.com/openapi-jobid": "pytorch-ee8727ec-0af3-4f80-8fa5-ed511ae8e47e",
                      "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
                      "aijob.cce.baidubce.com/raw-request": "{\"name\":\"llamatest0718forxiaomi7\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"high\",\"oversell\":false,\"faultTolerance\":true,\"command\":\"\\n#! /bin/bash\\n\\nMEGATRON_PATH=${MEGATRON_PATH:-\\\"/workspace/AIAK-Megatron\\\"}\\nAIAK_TRAINING_PATH=${AIAK_TRAINING_PATH:-\\\"/workspace/AIAK-Training-LLM\\\"}\\n\\nDATA_PATH=${DATA_PATH:-\\\"/mnt/cluster/llama2/pile_llama_test/pile-llama_text_document\\\"}\\nTOKENIZER_PATH=${TOKENIZER_PATH:-\\\"/mnt/cluster/llama2/Llama-2-70b-hf/\\\"}\\n\\nCHECKPOINT_PATH=${CHECKPOINT_PATH:-\\\"/mnt/cluster/llama2/mcore_llama2_70b_tp4_pp4\\\"}\\n\\nTENSORBOARD_PATH=${TENSORBOARD_PATH:-\\\"/mnt/cluster/aiak-training-llm/tensorboard-log/llama2-70b-tp4pp4\\\"}\\n\\nGPUS_PER_NODE=8\\n\\n# Change for multinode config\\nMASTER_ADDR=${MASTER_ADDR:-\\\"localhost\\\"}\\nMASTER_PORT=${MASTER_PORT:-\\\"6000\\\"}\\nNNODES=${WORLD_SIZE:-\\\"1\\\"}\\nNODE_RANK=${RANK:-\\\"0\\\"}\\n\\nDISTRIBUTED_ARGS=(\\n    --nproc_per_node $GPUS_PER_NODE\\n    --nnodes $NNODES\\n    --node_rank $NODE_RANK\\n    --master_addr $MASTER_ADDR\\n    --master_port $MASTER_PORT\\n)\\n\\n# you can setup llama2-70b maunally\\n#MODEL_ARGS=(\\n#    --model-name llama2\\n#    --num-layers 80\\n#    --hidden-size 8192\\n#    --ffn-hidden-size 28672\\n#    --num-attention-heads 64\\n#    --position-embedding-type rope\\n#    --normalization RMSNorm\\n#    --swiglu\\n#    --attention-dropout 0\\n#    --hidden-dropout 0\\n#    --disable-bias-linear\\n#    --untie-embeddings-and-output-weights\\n#    --group-query-attention\\n#    --num-query-groups 8\\n#)\\n\\n# or you can setup llama2-70b by using the following command\\nMODEL_ARGS=(\\n    --model-name llama2-70b # options: llama2-7b, llama2-13b, llama2-70b\\n)\\n\\nDATA_ARGS=(\\n    --tokenizer-type HFTokenizer\\n    --hf-tokenizer-path $TOKENIZER_PATH\\n    --data-path $DATA_PATH\\n    --split 949,50,1\\n)\\n\\nTRAINING_ARGS=(\\n    --training-phase pretrain # options: pretrain, sft\\n    --seq-length 4096\\n    --max-position-embeddings 4096\\n    --init-method-std 0.01\\n    --micro-batch-size 1\\n    --global-batch-size 128\\n    --lr 0.0002\\n    --min-lr 1.0e-5\\n    --clip-grad 1.0\\n    --weight-decay 0.01\\n    --optimizer adam\\n    --adam-beta1 0.9\\n    --adam-beta2 0.95\\n    --adam-eps 1e-05\\n    --norm-epsilon 1e-6\\n    --train-iters 500000\\n    --lr-decay-iters 500000\\n    --lr-decay-style cosine\\n    --lr-warmup-fraction 0.002\\n    --initial-loss-scale 65536\\n    --fp16\\n    --save-interval 5000\\n    --eval-interval 1000\\n    --eval-iters 10\\n    #--ckpt-step 0\\n    #--no-load-optim\\n    #--no-load-rng\\n)\\n\\nMODEL_PARALLEL_ARGS=(\\n    --tensor-model-parallel-size 4\\n    --pipeline-model-parallel-size 4\\n    --use-distributed-optimizer\\n    --overlap-grad-reduce\\n    --overlap-param-gather\\n    --distributed-backend nccl\\n    --sequence-parallel\\n    #--tp-comm-overlap # require mpi envrionment\\n)\\n\\nLOGGING_ARGS=(\\n    --log-interval 1\\n    --tensorboard-dir ${TENSORBOARD_PATH}\\n    --log-timers-to-tensorboard\\n)\\n\\nif [ -n \\\"${WANDB_API_KEY}\\\" ]; then\\n    LOGGING_ARGS+=(\\n        --wandb-project ${WANDB_PROJECT}\\n        --wandb-exp-name ${WANDB_NAME} \\n    )\\nfi\\n\\nPYTHONPATH=$MEGATRON_PATH:$AIAK_TRAINING_PATH:$PYTHONPATH     torchrun ${DISTRIBUTED_ARGS[@]}     $AIAK_TRAINING_PATH/aiak_training_llm/train.py     ${MODEL_ARGS[@]}     ${DATA_ARGS[@]}     ${TRAINING_ARGS[@]}     ${MODEL_PARALLEL_ARGS[@]}     ${LOGGING_ARGS[@]}\\n\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":true,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi7\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi7/output/training_logs\",\"CUDA_DEVICE_MAX_CONNECTIONS\":\"1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"},\"Worker\":{\"replicas\":3,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi7\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi7/output/training_logs\",\"CUDA_DEVICE_MAX_CONNECTIONS\":\"1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":true,\"logPath\":\"/mnt/cluster/llamatest0718forxiaomi7/output/training_logs\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":true,\"isCopyJob\":true,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
                      "scheduling.k8s.io/job-enable-oversell": "false"
                    },
                    "labels": {
                      "aijob.cce.baidubce.com/ai-user-id": "b5a24aa26e4d4f55bc3acf68edc4b051",
                      "aijob.cce.baidubce.com/ai-user-name": "zhangmuhua",
                      "aijob.cce.baidubce.com/create-from-aihcp": "true",
                      "aijob.cce.baidubce.com/openapi-jobid": "pytorch-ee8727ec-0af3-4f80-8fa5-ed511ae8e47e"
                    }
                  },
                  "spec": {
                    "containers": [
                      {
                        "command": [
                          "/bin/bash",
                          "-c",
                          "\n#! /bin/bash\n\nMEGATRON_PATH=${MEGATRON_PATH:-\"/workspace/AIAK-Megatron\"}\nAIAK_TRAINING_PATH=${AIAK_TRAINING_PATH:-\"/workspace/AIAK-Training-LLM\"}\n\nDATA_PATH=${DATA_PATH:-\"/mnt/cluster/llama2/pile_llama_test/pile-llama_text_document\"}\nTOKENIZER_PATH=${TOKENIZER_PATH:-\"/mnt/cluster/llama2/Llama-2-70b-hf/\"}\n\nCHECKPOINT_PATH=${CHECKPOINT_PATH:-\"/mnt/cluster/llama2/mcore_llama2_70b_tp4_pp4\"}\n\nTENSORBOARD_PATH=${TENSORBOARD_PATH:-\"/mnt/cluster/aiak-training-llm/tensorboard-log/llama2-70b-tp4pp4\"}\n\nGPUS_PER_NODE=8\n\n# Change for multinode config\nMASTER_ADDR=${MASTER_ADDR:-\"localhost\"}\nMASTER_PORT=${MASTER_PORT:-\"6000\"}\nNNODES=${WORLD_SIZE:-\"1\"}\nNODE_RANK=${RANK:-\"0\"}\n\nDISTRIBUTED_ARGS=(\n    --nproc_per_node $GPUS_PER_NODE\n    --nnodes $NNODES\n    --node_rank $NODE_RANK\n    --master_addr $MASTER_ADDR\n    --master_port $MASTER_PORT\n)\n\n# you can setup llama2-70b maunally\n#MODEL_ARGS=(\n#    --model-name llama2\n#    --num-layers 80\n#    --hidden-size 8192\n#    --ffn-hidden-size 28672\n#    --num-attention-heads 64\n#    --position-embedding-type rope\n#    --normalization RMSNorm\n#    --swiglu\n#    --attention-dropout 0\n#    --hidden-dropout 0\n#    --disable-bias-linear\n#    --untie-embeddings-and-output-weights\n#    --group-query-attention\n#    --num-query-groups 8\n#)\n\n# or you can setup llama2-70b by using the following command\nMODEL_ARGS=(\n    --model-name llama2-70b # options: llama2-7b, llama2-13b, llama2-70b\n)\n\nDATA_ARGS=(\n    --tokenizer-type HFTokenizer\n    --hf-tokenizer-path $TOKENIZER_PATH\n    --data-path $DATA_PATH\n    --split 949,50,1\n)\n\nTRAINING_ARGS=(\n    --training-phase pretrain # options: pretrain, sft\n    --seq-length 4096\n    --max-position-embeddings 4096\n    --init-method-std 0.01\n    --micro-batch-size 1\n    --global-batch-size 128\n    --lr 0.0002\n    --min-lr 1.0e-5\n    --clip-grad 1.0\n    --weight-decay 0.01\n    --optimizer adam\n    --adam-beta1 0.9\n    --adam-beta2 0.95\n    --adam-eps 1e-05\n    --norm-epsilon 1e-6\n    --train-iters 500000\n    --lr-decay-iters 500000\n    --lr-decay-style cosine\n    --lr-warmup-fraction 0.002\n    --initial-loss-scale 65536\n    --fp16\n    --save-interval 5000\n    --eval-interval 1000\n    --eval-iters 10\n    #--ckpt-step 0\n    #--no-load-optim\n    #--no-load-rng\n)\n\nMODEL_PARALLEL_ARGS=(\n    --tensor-model-parallel-size 4\n    --pipeline-model-parallel-size 4\n    --use-distributed-optimizer\n    --overlap-grad-reduce\n    --overlap-param-gather\n    --distributed-backend nccl\n    --sequence-parallel\n    #--tp-comm-overlap # require mpi envrionment\n)\n\nLOGGING_ARGS=(\n    --log-interval 1\n    --tensorboard-dir ${TENSORBOARD_PATH}\n    --log-timers-to-tensorboard\n)\n\nif [ -n \"${WANDB_API_KEY}\" ]; then\n    LOGGING_ARGS+=(\n        --wandb-project ${WANDB_PROJECT}\n        --wandb-exp-name ${WANDB_NAME} \n    )\nfi\n\nPYTHONPATH=$MEGATRON_PATH:$AIAK_TRAINING_PATH:$PYTHONPATH     torchrun ${DISTRIBUTED_ARGS[@]}     $AIAK_TRAINING_PATH/aiak_training_llm/train.py     ${MODEL_ARGS[@]}     ${DATA_ARGS[@]}     ${TRAINING_ARGS[@]}     ${MODEL_PARALLEL_ARGS[@]}     ${LOGGING_ARGS[@]}\n"
                        ],
                        "env": [
                          {
                            "name": "CUDA_DEVICE_MAX_CONNECTIONS",
                            "value": "1"
                          },
                          {
                            "name": "AIHC_TENSORBOARD_LOG_PATH",
                            "value": "/mnt/cluster/llamatest0718forxiaomi7/output/training_logs"
                          },
                          {
                            "name": "AIHC_JOB_NAME",
                            "value": "llamatest0718forxiaomi7"
                          },
                          {
                            "name": "NCCL_IB_DISABLE",
                            "value": "0"
                          }
                        ],
                        "image": "registry.baidubce.com/aihc-aiak/aiak-training-llm:ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release",
                        "imagePullPolicy": "Always",
                        "name": "pytorch",
                        "ports": [
                          {
                            "containerPort": 23456,
                            "name": "pytorchjob-port",
                            "protocol": "TCP"
                          }
                        ],
                        "resources": {
                          "limits": {
                            "baidu.com/a800_80g_cgpu": "8",
                            "rdma/hca": "1"
                          },
                          "requests": {
                            "baidu.com/a800_80g_cgpu": "8",
                            "rdma/hca": "1"
                          }
                        },
                        "securityContext": {
                          "capabilities": {
                            "add": [
                              "IPC_LOCK"
                            ]
                          }
                        },
                        "volumeMounts": [
                          {
                            "mountPath": "/dev/shm",
                            "name": "devshm"
                          },
                          {
                            "mountPath": "/mnt/cluster",
                            "name": "pvc-pfs"
                          }
                        ]
                      }
                    ],
                    "dnsPolicy": "ClusterFirstWithHostNet",
                    "hostNetwork": true,
                    "schedulerName": "volcano",
                    "volumes": [
                      {
                        "emptyDir": {
                          "medium": "Memory",
                          "sizeLimit": "10Gi"
                        },
                        "name": "devshm"
                      },
                      {
                        "name": "pvc-pfs",
                        "persistentVolumeClaim": {
                          "claimName": "pvc-pfs"
                        }
                      }
                    ]
                  }
                }
              },
              "Worker": {
                "replicas": 3,
                "restartPolicy": "Never",
                "template": {
                  "metadata": {
                    "annotations": {
                      "aijob.cce.baidubce.com/fault-tolerance-enabled": "true",
                      "aijob.cce.baidubce.com/openapi-jobid": "pytorch-ee8727ec-0af3-4f80-8fa5-ed511ae8e47e",
                      "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
                      "aijob.cce.baidubce.com/raw-request": "{\"name\":\"llamatest0718forxiaomi7\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"high\",\"oversell\":false,\"faultTolerance\":true,\"command\":\"\\n#! /bin/bash\\n\\nMEGATRON_PATH=${MEGATRON_PATH:-\\\"/workspace/AIAK-Megatron\\\"}\\nAIAK_TRAINING_PATH=${AIAK_TRAINING_PATH:-\\\"/workspace/AIAK-Training-LLM\\\"}\\n\\nDATA_PATH=${DATA_PATH:-\\\"/mnt/cluster/llama2/pile_llama_test/pile-llama_text_document\\\"}\\nTOKENIZER_PATH=${TOKENIZER_PATH:-\\\"/mnt/cluster/llama2/Llama-2-70b-hf/\\\"}\\n\\nCHECKPOINT_PATH=${CHECKPOINT_PATH:-\\\"/mnt/cluster/llama2/mcore_llama2_70b_tp4_pp4\\\"}\\n\\nTENSORBOARD_PATH=${TENSORBOARD_PATH:-\\\"/mnt/cluster/aiak-training-llm/tensorboard-log/llama2-70b-tp4pp4\\\"}\\n\\nGPUS_PER_NODE=8\\n\\n# Change for multinode config\\nMASTER_ADDR=${MASTER_ADDR:-\\\"localhost\\\"}\\nMASTER_PORT=${MASTER_PORT:-\\\"6000\\\"}\\nNNODES=${WORLD_SIZE:-\\\"1\\\"}\\nNODE_RANK=${RANK:-\\\"0\\\"}\\n\\nDISTRIBUTED_ARGS=(\\n    --nproc_per_node $GPUS_PER_NODE\\n    --nnodes $NNODES\\n    --node_rank $NODE_RANK\\n    --master_addr $MASTER_ADDR\\n    --master_port $MASTER_PORT\\n)\\n\\n# you can setup llama2-70b maunally\\n#MODEL_ARGS=(\\n#    --model-name llama2\\n#    --num-layers 80\\n#    --hidden-size 8192\\n#    --ffn-hidden-size 28672\\n#    --num-attention-heads 64\\n#    --position-embedding-type rope\\n#    --normalization RMSNorm\\n#    --swiglu\\n#    --attention-dropout 0\\n#    --hidden-dropout 0\\n#    --disable-bias-linear\\n#    --untie-embeddings-and-output-weights\\n#    --group-query-attention\\n#    --num-query-groups 8\\n#)\\n\\n# or you can setup llama2-70b by using the following command\\nMODEL_ARGS=(\\n    --model-name llama2-70b # options: llama2-7b, llama2-13b, llama2-70b\\n)\\n\\nDATA_ARGS=(\\n    --tokenizer-type HFTokenizer\\n    --hf-tokenizer-path $TOKENIZER_PATH\\n    --data-path $DATA_PATH\\n    --split 949,50,1\\n)\\n\\nTRAINING_ARGS=(\\n    --training-phase pretrain # options: pretrain, sft\\n    --seq-length 4096\\n    --max-position-embeddings 4096\\n    --init-method-std 0.01\\n    --micro-batch-size 1\\n    --global-batch-size 128\\n    --lr 0.0002\\n    --min-lr 1.0e-5\\n    --clip-grad 1.0\\n    --weight-decay 0.01\\n    --optimizer adam\\n    --adam-beta1 0.9\\n    --adam-beta2 0.95\\n    --adam-eps 1e-05\\n    --norm-epsilon 1e-6\\n    --train-iters 500000\\n    --lr-decay-iters 500000\\n    --lr-decay-style cosine\\n    --lr-warmup-fraction 0.002\\n    --initial-loss-scale 65536\\n    --fp16\\n    --save-interval 5000\\n    --eval-interval 1000\\n    --eval-iters 10\\n    #--ckpt-step 0\\n    #--no-load-optim\\n    #--no-load-rng\\n)\\n\\nMODEL_PARALLEL_ARGS=(\\n    --tensor-model-parallel-size 4\\n    --pipeline-model-parallel-size 4\\n    --use-distributed-optimizer\\n    --overlap-grad-reduce\\n    --overlap-param-gather\\n    --distributed-backend nccl\\n    --sequence-parallel\\n    #--tp-comm-overlap # require mpi envrionment\\n)\\n\\nLOGGING_ARGS=(\\n    --log-interval 1\\n    --tensorboard-dir ${TENSORBOARD_PATH}\\n    --log-timers-to-tensorboard\\n)\\n\\nif [ -n \\\"${WANDB_API_KEY}\\\" ]; then\\n    LOGGING_ARGS+=(\\n        --wandb-project ${WANDB_PROJECT}\\n        --wandb-exp-name ${WANDB_NAME} \\n    )\\nfi\\n\\nPYTHONPATH=$MEGATRON_PATH:$AIAK_TRAINING_PATH:$PYTHONPATH     torchrun ${DISTRIBUTED_ARGS[@]}     $AIAK_TRAINING_PATH/aiak_training_llm/train.py     ${MODEL_ARGS[@]}     ${DATA_ARGS[@]}     ${TRAINING_ARGS[@]}     ${MODEL_PARALLEL_ARGS[@]}     ${LOGGING_ARGS[@]}\\n\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":true,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi7\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi7/output/training_logs\",\"CUDA_DEVICE_MAX_CONNECTIONS\":\"1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"},\"Worker\":{\"replicas\":3,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi7\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi7/output/training_logs\",\"CUDA_DEVICE_MAX_CONNECTIONS\":\"1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":true,\"logPath\":\"/mnt/cluster/llamatest0718forxiaomi7/output/training_logs\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":true,\"isCopyJob\":true,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
                      "scheduling.k8s.io/job-enable-oversell": "false"
                    },
                    "labels": {
                      "aijob.cce.baidubce.com/ai-user-id": "b5a24aa26e4d4f55bc3acf68edc4b051",
                      "aijob.cce.baidubce.com/ai-user-name": "zhangmuhua",
                      "aijob.cce.baidubce.com/create-from-aihcp": "true",
                      "aijob.cce.baidubce.com/openapi-jobid": "pytorch-ee8727ec-0af3-4f80-8fa5-ed511ae8e47e"
                    }
                  },
                  "spec": {
                    "containers": [
                      {
                        "command": [
                          "/bin/bash",
                          "-c",
                          "\n#! /bin/bash\n\nMEGATRON_PATH=${MEGATRON_PATH:-\"/workspace/AIAK-Megatron\"}\nAIAK_TRAINING_PATH=${AIAK_TRAINING_PATH:-\"/workspace/AIAK-Training-LLM\"}\n\nDATA_PATH=${DATA_PATH:-\"/mnt/cluster/llama2/pile_llama_test/pile-llama_text_document\"}\nTOKENIZER_PATH=${TOKENIZER_PATH:-\"/mnt/cluster/llama2/Llama-2-70b-hf/\"}\n\nCHECKPOINT_PATH=${CHECKPOINT_PATH:-\"/mnt/cluster/llama2/mcore_llama2_70b_tp4_pp4\"}\n\nTENSORBOARD_PATH=${TENSORBOARD_PATH:-\"/mnt/cluster/aiak-training-llm/tensorboard-log/llama2-70b-tp4pp4\"}\n\nGPUS_PER_NODE=8\n\n# Change for multinode config\nMASTER_ADDR=${MASTER_ADDR:-\"localhost\"}\nMASTER_PORT=${MASTER_PORT:-\"6000\"}\nNNODES=${WORLD_SIZE:-\"1\"}\nNODE_RANK=${RANK:-\"0\"}\n\nDISTRIBUTED_ARGS=(\n    --nproc_per_node $GPUS_PER_NODE\n    --nnodes $NNODES\n    --node_rank $NODE_RANK\n    --master_addr $MASTER_ADDR\n    --master_port $MASTER_PORT\n)\n\n# you can setup llama2-70b maunally\n#MODEL_ARGS=(\n#    --model-name llama2\n#    --num-layers 80\n#    --hidden-size 8192\n#    --ffn-hidden-size 28672\n#    --num-attention-heads 64\n#    --position-embedding-type rope\n#    --normalization RMSNorm\n#    --swiglu\n#    --attention-dropout 0\n#    --hidden-dropout 0\n#    --disable-bias-linear\n#    --untie-embeddings-and-output-weights\n#    --group-query-attention\n#    --num-query-groups 8\n#)\n\n# or you can setup llama2-70b by using the following command\nMODEL_ARGS=(\n    --model-name llama2-70b # options: llama2-7b, llama2-13b, llama2-70b\n)\n\nDATA_ARGS=(\n    --tokenizer-type HFTokenizer\n    --hf-tokenizer-path $TOKENIZER_PATH\n    --data-path $DATA_PATH\n    --split 949,50,1\n)\n\nTRAINING_ARGS=(\n    --training-phase pretrain # options: pretrain, sft\n    --seq-length 4096\n    --max-position-embeddings 4096\n    --init-method-std 0.01\n    --micro-batch-size 1\n    --global-batch-size 128\n    --lr 0.0002\n    --min-lr 1.0e-5\n    --clip-grad 1.0\n    --weight-decay 0.01\n    --optimizer adam\n    --adam-beta1 0.9\n    --adam-beta2 0.95\n    --adam-eps 1e-05\n    --norm-epsilon 1e-6\n    --train-iters 500000\n    --lr-decay-iters 500000\n    --lr-decay-style cosine\n    --lr-warmup-fraction 0.002\n    --initial-loss-scale 65536\n    --fp16\n    --save-interval 5000\n    --eval-interval 1000\n    --eval-iters 10\n    #--ckpt-step 0\n    #--no-load-optim\n    #--no-load-rng\n)\n\nMODEL_PARALLEL_ARGS=(\n    --tensor-model-parallel-size 4\n    --pipeline-model-parallel-size 4\n    --use-distributed-optimizer\n    --overlap-grad-reduce\n    --overlap-param-gather\n    --distributed-backend nccl\n    --sequence-parallel\n    #--tp-comm-overlap # require mpi envrionment\n)\n\nLOGGING_ARGS=(\n    --log-interval 1\n    --tensorboard-dir ${TENSORBOARD_PATH}\n    --log-timers-to-tensorboard\n)\n\nif [ -n \"${WANDB_API_KEY}\" ]; then\n    LOGGING_ARGS+=(\n        --wandb-project ${WANDB_PROJECT}\n        --wandb-exp-name ${WANDB_NAME} \n    )\nfi\n\nPYTHONPATH=$MEGATRON_PATH:$AIAK_TRAINING_PATH:$PYTHONPATH     torchrun ${DISTRIBUTED_ARGS[@]}     $AIAK_TRAINING_PATH/aiak_training_llm/train.py     ${MODEL_ARGS[@]}     ${DATA_ARGS[@]}     ${TRAINING_ARGS[@]}     ${MODEL_PARALLEL_ARGS[@]}     ${LOGGING_ARGS[@]}\n"
                        ],
                        "env": [
                          {
                            "name": "CUDA_DEVICE_MAX_CONNECTIONS",
                            "value": "1"
                          },
                          {
                            "name": "AIHC_TENSORBOARD_LOG_PATH",
                            "value": "/mnt/cluster/llamatest0718forxiaomi7/output/training_logs"
                          },
                          {
                            "name": "AIHC_JOB_NAME",
                            "value": "llamatest0718forxiaomi7"
                          },
                          {
                            "name": "NCCL_IB_DISABLE",
                            "value": "0"
                          }
                        ],
                        "image": "registry.baidubce.com/aihc-aiak/aiak-training-llm:ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release",
                        "imagePullPolicy": "Always",
                        "name": "pytorch",
                        "ports": [
                          {
                            "containerPort": 23456,
                            "name": "pytorchjob-port",
                            "protocol": "TCP"
                          }
                        ],
                        "resources": {
                          "limits": {
                            "baidu.com/a800_80g_cgpu": "8",
                            "rdma/hca": "1"
                          },
                          "requests": {
                            "baidu.com/a800_80g_cgpu": "8",
                            "rdma/hca": "1"
                          }
                        },
                        "securityContext": {
                          "capabilities": {
                            "add": [
                              "IPC_LOCK"
                            ]
                          }
                        },
                        "volumeMounts": [
                          {
                            "mountPath": "/dev/shm",
                            "name": "devshm"
                          },
                          {
                            "mountPath": "/mnt/cluster",
                            "name": "pvc-pfs"
                          }
                        ]
                      }
                    ],
                    "dnsPolicy": "ClusterFirstWithHostNet",
                    "hostNetwork": true,
                    "schedulerName": "volcano",
                    "volumes": [
                      {
                        "emptyDir": {
                          "medium": "Memory",
                          "sizeLimit": "10Gi"
                        },
                        "name": "devshm"
                      },
                      {
                        "name": "pvc-pfs",
                        "persistentVolumeClaim": {
                          "claimName": "pvc-pfs"
                        }
                      }
                    ]
                  }
                }
              }
            },
            "runPolicy": {
              "cleanPodPolicy": "None",
              "schedulingPolicy": {
                "priorityClass": "high",
                "queue": "default"
              }
            }
          },
          "status": {
            "completionTime": "2024-07-18T03:02:54Z",
            "conditions": [
              {
                "lastTransitionTime": "2024-07-18T02:54:11Z",
                "lastUpdateTime": "2024-07-18T02:54:11Z",
                "message": "PyTorchJob llamatest0718forxiaomi7 is created.",
                "reason": "PyTorchJobCreated",
                "status": "True",
                "type": "Created"
              },
              {
                "lastTransitionTime": "2024-07-18T02:54:24Z",
                "lastUpdateTime": "2024-07-18T02:54:24Z",
                "message": "PyTorchJob llamatest0718forxiaomi7 is running.",
                "reason": "JobRunning",
                "status": "False",
                "type": "Running"
              },
              {
                "lastTransitionTime": "2024-07-18T03:02:50Z",
                "lastUpdateTime": "2024-07-18T03:02:50Z",
                "message": "PytorchJob default/llamatest0718forxiaomi7 is stopped",
                "reason": "PyTorchJobStopped",
                "status": "True",
                "type": "Stopped"
              },
              {
                "lastTransitionTime": "2024-07-18T03:02:54Z",
                "lastUpdateTime": "2024-07-18T03:02:54Z",
                "message": "PyTorchJob llamatest0718forxiaomi7 is failed because 1 Master replica(s) failed.",
                "reason": "JobFailed",
                "status": "True",
                "type": "Failed"
              }
            ],
            "lastReconcileTime": "2024-07-18T02:54:11Z",
            "replicaStatuses": {
              "Master": {
                "failed": 1,
                "selector": "training.kubeflow.org/job-name=llamatest0718forxiaomi7,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=master"
              },
              "Worker": {
                "active": 3,
                "selector": "training.kubeflow.org/job-name=llamatest0718forxiaomi7,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=worker"
              }
            },
            "startTime": "2024-07-18T02:54:11Z"
          }
        },
        {
          "apiVersion": "kubeflow.org/v1",
          "kind": "PyTorchJob",
          "metadata": {
            "annotations": {
              "aijob.cce.baidubce.com/barrier-finish": "8b92a18c-0c8d-40aa-b27a-6f6129729c34",
              "aijob.cce.baidubce.com/fault-tolerance-enabled": "true",
              "aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": "",
              "aijob.cce.baidubce.com/openapi-jobid": "pytorch-be7cbb30-0a0a-471b-b6ff-e0825477ada6",
              "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
              "aijob.cce.baidubce.com/raw-request": "{\"name\":\"llamatest0718forxiaomi8\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"high\",\"oversell\":false,\"faultTolerance\":true,\"command\":\"\\n#! /bin/bash\\n\\nMEGATRON_PATH=${MEGATRON_PATH:-\\\"/workspace/AIAK-Megatron\\\"}\\nAIAK_TRAINING_PATH=${AIAK_TRAINING_PATH:-\\\"/workspace/AIAK-Training-LLM\\\"}\\n\\nDATA_PATH=${DATA_PATH:-\\\"/mnt/cluster/llama2/pile_llama_test/pile-llama_text_document\\\"}\\nTOKENIZER_PATH=${TOKENIZER_PATH:-\\\"/mnt/cluster/llama2/Llama-2-70b-hf/\\\"}\\n\\nCHECKPOINT_PATH=${CHECKPOINT_PATH:-\\\"/mnt/cluster/llama2/mcore_llama2_70b_tp4_pp4\\\"}\\n\\nTENSORBOARD_PATH=${TENSORBOARD_PATH:-\\\"/mnt/cluster/aiak-training-llm/tensorboard-log/llama2-70b-tp4pp4\\\"}\\n\\nGPUS_PER_NODE=8\\n\\n# Change for multinode config\\nMASTER_ADDR=${MASTER_ADDR:-\\\"localhost\\\"}\\nMASTER_PORT=${MASTER_PORT:-\\\"6000\\\"}\\nNNODES=${WORLD_SIZE:-\\\"1\\\"}\\nNODE_RANK=${RANK:-\\\"0\\\"}\\n\\nDISTRIBUTED_ARGS=(\\n    --nproc_per_node $GPUS_PER_NODE\\n    --nnodes $NNODES\\n    --node_rank $NODE_RANK\\n    --master_addr $MASTER_ADDR\\n    --master_port $MASTER_PORT\\n)\\n\\n# you can setup llama2-70b maunally\\n#MODEL_ARGS=(\\n#    --model-name llama2\\n#    --num-layers 80\\n#    --hidden-size 8192\\n#    --ffn-hidden-size 28672\\n#    --num-attention-heads 64\\n#    --position-embedding-type rope\\n#    --normalization RMSNorm\\n#    --swiglu\\n#    --attention-dropout 0\\n#    --hidden-dropout 0\\n#    --disable-bias-linear\\n#    --untie-embeddings-and-output-weights\\n#    --group-query-attention\\n#    --num-query-groups 8\\n#)\\n\\n# or you can setup llama2-70b by using the following command\\nMODEL_ARGS=(\\n    --model-name llama2-70b # options: llama2-7b, llama2-13b, llama2-70b\\n)\\n\\nDATA_ARGS=(\\n    --tokenizer-type HFTokenizer\\n    --hf-tokenizer-path $TOKENIZER_PATH\\n    --data-path $DATA_PATH\\n    --split 949,50,1\\n)\\n\\nTRAINING_ARGS=(\\n    --training-phase pretrain # options: pretrain, sft\\n    --seq-length 4096\\n    --max-position-embeddings 4096\\n    --init-method-std 0.01\\n    --micro-batch-size 1\\n    --global-batch-size 1024\\n    --lr 0.0002\\n    --min-lr 1.0e-5\\n    --clip-grad 1.0\\n    --weight-decay 0.01\\n    --optimizer adam\\n    --adam-beta1 0.9\\n    --adam-beta2 0.95\\n    --adam-eps 1e-05\\n    --norm-epsilon 1e-6\\n    --train-iters 500000\\n    --lr-decay-iters 500000\\n    --lr-decay-style cosine\\n    --lr-warmup-fraction 0.002\\n    --initial-loss-scale 256\\n    --fp16\\n    --save-interval 5000\\n    --eval-interval 1000\\n    --eval-iters 10\\n    #--ckpt-step 0\\n    #--no-load-optim\\n    #--no-load-rng\\n)\\n\\nMODEL_PARALLEL_ARGS=(\\n    --tensor-model-parallel-size 4\\n    --pipeline-model-parallel-size 4\\n    --use-distributed-optimizer\\n    --overlap-grad-reduce\\n    --overlap-param-gather\\n    --distributed-backend nccl\\n    --sequence-parallel\\n    #--tp-comm-overlap # require mpi envrionment\\n)\\n\\nLOGGING_ARGS=(\\n    --log-interval 1\\n    --tensorboard-dir ${TENSORBOARD_PATH}\\n    --log-timers-to-tensorboard\\n)\\n\\nif [ -n \\\"${WANDB_API_KEY}\\\" ]; then\\n    LOGGING_ARGS+=(\\n        --wandb-project ${WANDB_PROJECT}\\n        --wandb-exp-name ${WANDB_NAME} \\n    )\\nfi\\n\\nPYTHONPATH=$MEGATRON_PATH:$AIAK_TRAINING_PATH:$PYTHONPATH     torchrun ${DISTRIBUTED_ARGS[@]}     $AIAK_TRAINING_PATH/aiak_training_llm/train.py     ${MODEL_ARGS[@]}     ${DATA_ARGS[@]}     ${TRAINING_ARGS[@]}     ${MODEL_PARALLEL_ARGS[@]}     ${LOGGING_ARGS[@]}\\n\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":true,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi8\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi8/output/training_logs\",\"CUDA_DEVICE_MAX_CONNECTIONS\":\"1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"},\"Worker\":{\"replicas\":3,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi8\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi8/output/training_logs\",\"CUDA_DEVICE_MAX_CONNECTIONS\":\"1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":true,\"logPath\":\"/mnt/cluster/llamatest0718forxiaomi8/output/training_logs\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":true,\"isCopyJob\":true,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
              "aijob.cce.baidubce.com/timeline": "[{\"conditionType\":\"Created\",\"time\":1721271762},{\"conditionType\":\"Scheduled\",\"time\":1721271763},{\"conditionType\":\"Running\",\"time\":1721271774},{\"conditionType\":\"ManualTermination\",\"time\":1721291996}]",
              "job-manager/action": "stop",
              "job-manager/action-succeed": "stop",
              "scheduling.k8s.io/job-enable-oversell": "false",
              "tensorboard-gc": "true"
            },
            "creationTimestamp": "2024-07-18T03:02:42Z",
            "generation": 2,
            "labels": {
              "aijob.cce.baidubce.com/ai-user-id": "b5a24aa26e4d4f55bc3acf68edc4b051",
              "aijob.cce.baidubce.com/ai-user-name": "zhangmuhua",
              "aijob.cce.baidubce.com/create-from-aihcp": "true",
              "aijob.cce.baidubce.com/openapi-jobid": "pytorch-be7cbb30-0a0a-471b-b6ff-e0825477ada6"
            },
            "managedFields": [
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      "f:aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": {},
                      "f:aijob.cce.baidubce.com/timeline": {}
                    }
                  },
                  "f:spec": {
                    "f:pytorchReplicaSpecs": {
                      "f:Master": {
                        "f:template": {
                          "f:spec": {
                            "f:containers": {}
                          }
                        }
                      },
                      "f:Worker": {
                        "f:template": {
                          "f:spec": {
                            "f:containers": {}
                          }
                        }
                      }
                    },
                    "f:runPolicy": {
                      "f:cleanPodPolicy": {}
                    }
                  }
                },
                "manager": "controller",
                "operation": "Update",
                "time": "2024-07-18T03:02:42Z"
              },
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      "f:aijob.cce.baidubce.com/barrier-finish": {}
                    }
                  }
                },
                "manager": "jobbarrier",
                "operation": "Update",
                "time": "2024-07-18T03:02:51Z"
              },
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      ".": {},
                      "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                      "f:aijob.cce.baidubce.com/openapi-jobid": {},
                      "f:aijob.cce.baidubce.com/pfs-id": {},
                      "f:aijob.cce.baidubce.com/raw-request": {},
                      "f:job-manager/action": {},
                      "f:scheduling.k8s.io/job-enable-oversell": {}
                    },
                    "f:labels": {
                      ".": {},
                      "f:aijob.cce.baidubce.com/ai-user-id": {},
                      "f:aijob.cce.baidubce.com/ai-user-name": {},
                      "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                      "f:aijob.cce.baidubce.com/openapi-jobid": {}
                    }
                  },
                  "f:spec": {
                    ".": {},
                    "f:pytorchReplicaSpecs": {
                      ".": {},
                      "f:Master": {
                        ".": {},
                        "f:replicas": {},
                        "f:restartPolicy": {},
                        "f:template": {
                          ".": {},
                          "f:metadata": {
                            ".": {},
                            "f:annotations": {
                              ".": {},
                              "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                              "f:aijob.cce.baidubce.com/openapi-jobid": {},
                              "f:aijob.cce.baidubce.com/pfs-id": {},
                              "f:aijob.cce.baidubce.com/raw-request": {},
                              "f:scheduling.k8s.io/job-enable-oversell": {}
                            },
                            "f:labels": {
                              ".": {},
                              "f:aijob.cce.baidubce.com/ai-user-id": {},
                              "f:aijob.cce.baidubce.com/ai-user-name": {},
                              "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                              "f:aijob.cce.baidubce.com/openapi-jobid": {}
                            }
                          },
                          "f:spec": {
                            ".": {},
                            "f:dnsPolicy": {},
                            "f:hostNetwork": {},
                            "f:schedulerName": {},
                            "f:volumes": {}
                          }
                        }
                      },
                      "f:Worker": {
                        ".": {},
                        "f:replicas": {},
                        "f:restartPolicy": {},
                        "f:template": {
                          ".": {},
                          "f:metadata": {
                            ".": {},
                            "f:annotations": {
                              ".": {},
                              "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                              "f:aijob.cce.baidubce.com/openapi-jobid": {},
                              "f:aijob.cce.baidubce.com/pfs-id": {},
                              "f:aijob.cce.baidubce.com/raw-request": {},
                              "f:scheduling.k8s.io/job-enable-oversell": {}
                            },
                            "f:labels": {
                              ".": {},
                              "f:aijob.cce.baidubce.com/ai-user-id": {},
                              "f:aijob.cce.baidubce.com/ai-user-name": {},
                              "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                              "f:aijob.cce.baidubce.com/openapi-jobid": {}
                            }
                          },
                          "f:spec": {
                            ".": {},
                            "f:dnsPolicy": {},
                            "f:hostNetwork": {},
                            "f:schedulerName": {},
                            "f:volumes": {}
                          }
                        }
                      }
                    },
                    "f:runPolicy": {
                      ".": {},
                      "f:schedulingPolicy": {
                        ".": {},
                        "f:priorityClass": {},
                        "f:queue": {}
                      }
                    }
                  }
                },
                "manager": "cce-ai-service",
                "operation": "Update",
                "time": "2024-07-18T08:39:56Z"
              },
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      "f:job-manager/action-succeed": {}
                    }
                  }
                },
                "manager": "ftagent",
                "operation": "Update",
                "time": "2024-07-18T08:40:03Z"
              },
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      "f:tensorboard-gc": {}
                    }
                  },
                  "f:status": {
                    ".": {},
                    "f:completionTime": {},
                    "f:conditions": {},
                    "f:lastReconcileTime": {},
                    "f:replicaStatuses": {
                      ".": {},
                      "f:Master": {
                        ".": {},
                        "f:active": {}
                      },
                      "f:Worker": {
                        ".": {},
                        "f:active": {},
                        "f:failed": {}
                      }
                    },
                    "f:startTime": {}
                  }
                },
                "manager": "manager",
                "operation": "Update",
                "time": "2024-07-19T03:02:56Z"
              }
            ],
            "name": "llamatest0718forxiaomi8",
            "namespace": "default",
            "resourceVersion": "2372422590",
            "uid": "11240b44-0997-4805-b6e7-21b594c2fbcb"
          },
          "spec": {
            "pytorchReplicaSpecs": {
              "Master": {
                "replicas": 1,
                "restartPolicy": "Never",
                "template": {
                  "metadata": {
                    "annotations": {
                      "aijob.cce.baidubce.com/fault-tolerance-enabled": "true",
                      "aijob.cce.baidubce.com/openapi-jobid": "pytorch-be7cbb30-0a0a-471b-b6ff-e0825477ada6",
                      "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
                      "aijob.cce.baidubce.com/raw-request": "{\"name\":\"llamatest0718forxiaomi8\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"high\",\"oversell\":false,\"faultTolerance\":true,\"command\":\"\\n#! /bin/bash\\n\\nMEGATRON_PATH=${MEGATRON_PATH:-\\\"/workspace/AIAK-Megatron\\\"}\\nAIAK_TRAINING_PATH=${AIAK_TRAINING_PATH:-\\\"/workspace/AIAK-Training-LLM\\\"}\\n\\nDATA_PATH=${DATA_PATH:-\\\"/mnt/cluster/llama2/pile_llama_test/pile-llama_text_document\\\"}\\nTOKENIZER_PATH=${TOKENIZER_PATH:-\\\"/mnt/cluster/llama2/Llama-2-70b-hf/\\\"}\\n\\nCHECKPOINT_PATH=${CHECKPOINT_PATH:-\\\"/mnt/cluster/llama2/mcore_llama2_70b_tp4_pp4\\\"}\\n\\nTENSORBOARD_PATH=${TENSORBOARD_PATH:-\\\"/mnt/cluster/aiak-training-llm/tensorboard-log/llama2-70b-tp4pp4\\\"}\\n\\nGPUS_PER_NODE=8\\n\\n# Change for multinode config\\nMASTER_ADDR=${MASTER_ADDR:-\\\"localhost\\\"}\\nMASTER_PORT=${MASTER_PORT:-\\\"6000\\\"}\\nNNODES=${WORLD_SIZE:-\\\"1\\\"}\\nNODE_RANK=${RANK:-\\\"0\\\"}\\n\\nDISTRIBUTED_ARGS=(\\n    --nproc_per_node $GPUS_PER_NODE\\n    --nnodes $NNODES\\n    --node_rank $NODE_RANK\\n    --master_addr $MASTER_ADDR\\n    --master_port $MASTER_PORT\\n)\\n\\n# you can setup llama2-70b maunally\\n#MODEL_ARGS=(\\n#    --model-name llama2\\n#    --num-layers 80\\n#    --hidden-size 8192\\n#    --ffn-hidden-size 28672\\n#    --num-attention-heads 64\\n#    --position-embedding-type rope\\n#    --normalization RMSNorm\\n#    --swiglu\\n#    --attention-dropout 0\\n#    --hidden-dropout 0\\n#    --disable-bias-linear\\n#    --untie-embeddings-and-output-weights\\n#    --group-query-attention\\n#    --num-query-groups 8\\n#)\\n\\n# or you can setup llama2-70b by using the following command\\nMODEL_ARGS=(\\n    --model-name llama2-70b # options: llama2-7b, llama2-13b, llama2-70b\\n)\\n\\nDATA_ARGS=(\\n    --tokenizer-type HFTokenizer\\n    --hf-tokenizer-path $TOKENIZER_PATH\\n    --data-path $DATA_PATH\\n    --split 949,50,1\\n)\\n\\nTRAINING_ARGS=(\\n    --training-phase pretrain # options: pretrain, sft\\n    --seq-length 4096\\n    --max-position-embeddings 4096\\n    --init-method-std 0.01\\n    --micro-batch-size 1\\n    --global-batch-size 1024\\n    --lr 0.0002\\n    --min-lr 1.0e-5\\n    --clip-grad 1.0\\n    --weight-decay 0.01\\n    --optimizer adam\\n    --adam-beta1 0.9\\n    --adam-beta2 0.95\\n    --adam-eps 1e-05\\n    --norm-epsilon 1e-6\\n    --train-iters 500000\\n    --lr-decay-iters 500000\\n    --lr-decay-style cosine\\n    --lr-warmup-fraction 0.002\\n    --initial-loss-scale 256\\n    --fp16\\n    --save-interval 5000\\n    --eval-interval 1000\\n    --eval-iters 10\\n    #--ckpt-step 0\\n    #--no-load-optim\\n    #--no-load-rng\\n)\\n\\nMODEL_PARALLEL_ARGS=(\\n    --tensor-model-parallel-size 4\\n    --pipeline-model-parallel-size 4\\n    --use-distributed-optimizer\\n    --overlap-grad-reduce\\n    --overlap-param-gather\\n    --distributed-backend nccl\\n    --sequence-parallel\\n    #--tp-comm-overlap # require mpi envrionment\\n)\\n\\nLOGGING_ARGS=(\\n    --log-interval 1\\n    --tensorboard-dir ${TENSORBOARD_PATH}\\n    --log-timers-to-tensorboard\\n)\\n\\nif [ -n \\\"${WANDB_API_KEY}\\\" ]; then\\n    LOGGING_ARGS+=(\\n        --wandb-project ${WANDB_PROJECT}\\n        --wandb-exp-name ${WANDB_NAME} \\n    )\\nfi\\n\\nPYTHONPATH=$MEGATRON_PATH:$AIAK_TRAINING_PATH:$PYTHONPATH     torchrun ${DISTRIBUTED_ARGS[@]}     $AIAK_TRAINING_PATH/aiak_training_llm/train.py     ${MODEL_ARGS[@]}     ${DATA_ARGS[@]}     ${TRAINING_ARGS[@]}     ${MODEL_PARALLEL_ARGS[@]}     ${LOGGING_ARGS[@]}\\n\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":true,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi8\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi8/output/training_logs\",\"CUDA_DEVICE_MAX_CONNECTIONS\":\"1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"},\"Worker\":{\"replicas\":3,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi8\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi8/output/training_logs\",\"CUDA_DEVICE_MAX_CONNECTIONS\":\"1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":true,\"logPath\":\"/mnt/cluster/llamatest0718forxiaomi8/output/training_logs\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":true,\"isCopyJob\":true,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
                      "scheduling.k8s.io/job-enable-oversell": "false"
                    },
                    "labels": {
                      "aijob.cce.baidubce.com/ai-user-id": "b5a24aa26e4d4f55bc3acf68edc4b051",
                      "aijob.cce.baidubce.com/ai-user-name": "zhangmuhua",
                      "aijob.cce.baidubce.com/create-from-aihcp": "true",
                      "aijob.cce.baidubce.com/openapi-jobid": "pytorch-be7cbb30-0a0a-471b-b6ff-e0825477ada6"
                    }
                  },
                  "spec": {
                    "containers": [
                      {
                        "command": [
                          "/bin/bash",
                          "-c",
                          "\n#! /bin/bash\n\nMEGATRON_PATH=${MEGATRON_PATH:-\"/workspace/AIAK-Megatron\"}\nAIAK_TRAINING_PATH=${AIAK_TRAINING_PATH:-\"/workspace/AIAK-Training-LLM\"}\n\nDATA_PATH=${DATA_PATH:-\"/mnt/cluster/llama2/pile_llama_test/pile-llama_text_document\"}\nTOKENIZER_PATH=${TOKENIZER_PATH:-\"/mnt/cluster/llama2/Llama-2-70b-hf/\"}\n\nCHECKPOINT_PATH=${CHECKPOINT_PATH:-\"/mnt/cluster/llama2/mcore_llama2_70b_tp4_pp4\"}\n\nTENSORBOARD_PATH=${TENSORBOARD_PATH:-\"/mnt/cluster/aiak-training-llm/tensorboard-log/llama2-70b-tp4pp4\"}\n\nGPUS_PER_NODE=8\n\n# Change for multinode config\nMASTER_ADDR=${MASTER_ADDR:-\"localhost\"}\nMASTER_PORT=${MASTER_PORT:-\"6000\"}\nNNODES=${WORLD_SIZE:-\"1\"}\nNODE_RANK=${RANK:-\"0\"}\n\nDISTRIBUTED_ARGS=(\n    --nproc_per_node $GPUS_PER_NODE\n    --nnodes $NNODES\n    --node_rank $NODE_RANK\n    --master_addr $MASTER_ADDR\n    --master_port $MASTER_PORT\n)\n\n# you can setup llama2-70b maunally\n#MODEL_ARGS=(\n#    --model-name llama2\n#    --num-layers 80\n#    --hidden-size 8192\n#    --ffn-hidden-size 28672\n#    --num-attention-heads 64\n#    --position-embedding-type rope\n#    --normalization RMSNorm\n#    --swiglu\n#    --attention-dropout 0\n#    --hidden-dropout 0\n#    --disable-bias-linear\n#    --untie-embeddings-and-output-weights\n#    --group-query-attention\n#    --num-query-groups 8\n#)\n\n# or you can setup llama2-70b by using the following command\nMODEL_ARGS=(\n    --model-name llama2-70b # options: llama2-7b, llama2-13b, llama2-70b\n)\n\nDATA_ARGS=(\n    --tokenizer-type HFTokenizer\n    --hf-tokenizer-path $TOKENIZER_PATH\n    --data-path $DATA_PATH\n    --split 949,50,1\n)\n\nTRAINING_ARGS=(\n    --training-phase pretrain # options: pretrain, sft\n    --seq-length 4096\n    --max-position-embeddings 4096\n    --init-method-std 0.01\n    --micro-batch-size 1\n    --global-batch-size 1024\n    --lr 0.0002\n    --min-lr 1.0e-5\n    --clip-grad 1.0\n    --weight-decay 0.01\n    --optimizer adam\n    --adam-beta1 0.9\n    --adam-beta2 0.95\n    --adam-eps 1e-05\n    --norm-epsilon 1e-6\n    --train-iters 500000\n    --lr-decay-iters 500000\n    --lr-decay-style cosine\n    --lr-warmup-fraction 0.002\n    --initial-loss-scale 256\n    --fp16\n    --save-interval 5000\n    --eval-interval 1000\n    --eval-iters 10\n    #--ckpt-step 0\n    #--no-load-optim\n    #--no-load-rng\n)\n\nMODEL_PARALLEL_ARGS=(\n    --tensor-model-parallel-size 4\n    --pipeline-model-parallel-size 4\n    --use-distributed-optimizer\n    --overlap-grad-reduce\n    --overlap-param-gather\n    --distributed-backend nccl\n    --sequence-parallel\n    #--tp-comm-overlap # require mpi envrionment\n)\n\nLOGGING_ARGS=(\n    --log-interval 1\n    --tensorboard-dir ${TENSORBOARD_PATH}\n    --log-timers-to-tensorboard\n)\n\nif [ -n \"${WANDB_API_KEY}\" ]; then\n    LOGGING_ARGS+=(\n        --wandb-project ${WANDB_PROJECT}\n        --wandb-exp-name ${WANDB_NAME} \n    )\nfi\n\nPYTHONPATH=$MEGATRON_PATH:$AIAK_TRAINING_PATH:$PYTHONPATH     torchrun ${DISTRIBUTED_ARGS[@]}     $AIAK_TRAINING_PATH/aiak_training_llm/train.py     ${MODEL_ARGS[@]}     ${DATA_ARGS[@]}     ${TRAINING_ARGS[@]}     ${MODEL_PARALLEL_ARGS[@]}     ${LOGGING_ARGS[@]}\n"
                        ],
                        "env": [
                          {
                            "name": "CUDA_DEVICE_MAX_CONNECTIONS",
                            "value": "1"
                          },
                          {
                            "name": "AIHC_TENSORBOARD_LOG_PATH",
                            "value": "/mnt/cluster/llamatest0718forxiaomi8/output/training_logs"
                          },
                          {
                            "name": "AIHC_JOB_NAME",
                            "value": "llamatest0718forxiaomi8"
                          },
                          {
                            "name": "NCCL_IB_DISABLE",
                            "value": "0"
                          }
                        ],
                        "image": "registry.baidubce.com/aihc-aiak/aiak-training-llm:ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release",
                        "imagePullPolicy": "Always",
                        "name": "pytorch",
                        "ports": [
                          {
                            "containerPort": 23456,
                            "name": "pytorchjob-port",
                            "protocol": "TCP"
                          }
                        ],
                        "resources": {
                          "limits": {
                            "baidu.com/a800_80g_cgpu": "8",
                            "rdma/hca": "1"
                          },
                          "requests": {
                            "baidu.com/a800_80g_cgpu": "8",
                            "rdma/hca": "1"
                          }
                        },
                        "securityContext": {
                          "capabilities": {
                            "add": [
                              "IPC_LOCK"
                            ]
                          }
                        },
                        "volumeMounts": [
                          {
                            "mountPath": "/dev/shm",
                            "name": "devshm"
                          },
                          {
                            "mountPath": "/mnt/cluster",
                            "name": "pvc-pfs"
                          }
                        ]
                      }
                    ],
                    "dnsPolicy": "ClusterFirstWithHostNet",
                    "hostNetwork": true,
                    "schedulerName": "volcano",
                    "volumes": [
                      {
                        "emptyDir": {
                          "medium": "Memory",
                          "sizeLimit": "10Gi"
                        },
                        "name": "devshm"
                      },
                      {
                        "name": "pvc-pfs",
                        "persistentVolumeClaim": {
                          "claimName": "pvc-pfs"
                        }
                      }
                    ]
                  }
                }
              },
              "Worker": {
                "replicas": 3,
                "restartPolicy": "Never",
                "template": {
                  "metadata": {
                    "annotations": {
                      "aijob.cce.baidubce.com/fault-tolerance-enabled": "true",
                      "aijob.cce.baidubce.com/openapi-jobid": "pytorch-be7cbb30-0a0a-471b-b6ff-e0825477ada6",
                      "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
                      "aijob.cce.baidubce.com/raw-request": "{\"name\":\"llamatest0718forxiaomi8\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"high\",\"oversell\":false,\"faultTolerance\":true,\"command\":\"\\n#! /bin/bash\\n\\nMEGATRON_PATH=${MEGATRON_PATH:-\\\"/workspace/AIAK-Megatron\\\"}\\nAIAK_TRAINING_PATH=${AIAK_TRAINING_PATH:-\\\"/workspace/AIAK-Training-LLM\\\"}\\n\\nDATA_PATH=${DATA_PATH:-\\\"/mnt/cluster/llama2/pile_llama_test/pile-llama_text_document\\\"}\\nTOKENIZER_PATH=${TOKENIZER_PATH:-\\\"/mnt/cluster/llama2/Llama-2-70b-hf/\\\"}\\n\\nCHECKPOINT_PATH=${CHECKPOINT_PATH:-\\\"/mnt/cluster/llama2/mcore_llama2_70b_tp4_pp4\\\"}\\n\\nTENSORBOARD_PATH=${TENSORBOARD_PATH:-\\\"/mnt/cluster/aiak-training-llm/tensorboard-log/llama2-70b-tp4pp4\\\"}\\n\\nGPUS_PER_NODE=8\\n\\n# Change for multinode config\\nMASTER_ADDR=${MASTER_ADDR:-\\\"localhost\\\"}\\nMASTER_PORT=${MASTER_PORT:-\\\"6000\\\"}\\nNNODES=${WORLD_SIZE:-\\\"1\\\"}\\nNODE_RANK=${RANK:-\\\"0\\\"}\\n\\nDISTRIBUTED_ARGS=(\\n    --nproc_per_node $GPUS_PER_NODE\\n    --nnodes $NNODES\\n    --node_rank $NODE_RANK\\n    --master_addr $MASTER_ADDR\\n    --master_port $MASTER_PORT\\n)\\n\\n# you can setup llama2-70b maunally\\n#MODEL_ARGS=(\\n#    --model-name llama2\\n#    --num-layers 80\\n#    --hidden-size 8192\\n#    --ffn-hidden-size 28672\\n#    --num-attention-heads 64\\n#    --position-embedding-type rope\\n#    --normalization RMSNorm\\n#    --swiglu\\n#    --attention-dropout 0\\n#    --hidden-dropout 0\\n#    --disable-bias-linear\\n#    --untie-embeddings-and-output-weights\\n#    --group-query-attention\\n#    --num-query-groups 8\\n#)\\n\\n# or you can setup llama2-70b by using the following command\\nMODEL_ARGS=(\\n    --model-name llama2-70b # options: llama2-7b, llama2-13b, llama2-70b\\n)\\n\\nDATA_ARGS=(\\n    --tokenizer-type HFTokenizer\\n    --hf-tokenizer-path $TOKENIZER_PATH\\n    --data-path $DATA_PATH\\n    --split 949,50,1\\n)\\n\\nTRAINING_ARGS=(\\n    --training-phase pretrain # options: pretrain, sft\\n    --seq-length 4096\\n    --max-position-embeddings 4096\\n    --init-method-std 0.01\\n    --micro-batch-size 1\\n    --global-batch-size 1024\\n    --lr 0.0002\\n    --min-lr 1.0e-5\\n    --clip-grad 1.0\\n    --weight-decay 0.01\\n    --optimizer adam\\n    --adam-beta1 0.9\\n    --adam-beta2 0.95\\n    --adam-eps 1e-05\\n    --norm-epsilon 1e-6\\n    --train-iters 500000\\n    --lr-decay-iters 500000\\n    --lr-decay-style cosine\\n    --lr-warmup-fraction 0.002\\n    --initial-loss-scale 256\\n    --fp16\\n    --save-interval 5000\\n    --eval-interval 1000\\n    --eval-iters 10\\n    #--ckpt-step 0\\n    #--no-load-optim\\n    #--no-load-rng\\n)\\n\\nMODEL_PARALLEL_ARGS=(\\n    --tensor-model-parallel-size 4\\n    --pipeline-model-parallel-size 4\\n    --use-distributed-optimizer\\n    --overlap-grad-reduce\\n    --overlap-param-gather\\n    --distributed-backend nccl\\n    --sequence-parallel\\n    #--tp-comm-overlap # require mpi envrionment\\n)\\n\\nLOGGING_ARGS=(\\n    --log-interval 1\\n    --tensorboard-dir ${TENSORBOARD_PATH}\\n    --log-timers-to-tensorboard\\n)\\n\\nif [ -n \\\"${WANDB_API_KEY}\\\" ]; then\\n    LOGGING_ARGS+=(\\n        --wandb-project ${WANDB_PROJECT}\\n        --wandb-exp-name ${WANDB_NAME} \\n    )\\nfi\\n\\nPYTHONPATH=$MEGATRON_PATH:$AIAK_TRAINING_PATH:$PYTHONPATH     torchrun ${DISTRIBUTED_ARGS[@]}     $AIAK_TRAINING_PATH/aiak_training_llm/train.py     ${MODEL_ARGS[@]}     ${DATA_ARGS[@]}     ${TRAINING_ARGS[@]}     ${MODEL_PARALLEL_ARGS[@]}     ${LOGGING_ARGS[@]}\\n\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":true,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi8\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi8/output/training_logs\",\"CUDA_DEVICE_MAX_CONNECTIONS\":\"1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"},\"Worker\":{\"replicas\":3,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi8\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi8/output/training_logs\",\"CUDA_DEVICE_MAX_CONNECTIONS\":\"1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":true,\"logPath\":\"/mnt/cluster/llamatest0718forxiaomi8/output/training_logs\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":true,\"isCopyJob\":true,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
                      "scheduling.k8s.io/job-enable-oversell": "false"
                    },
                    "labels": {
                      "aijob.cce.baidubce.com/ai-user-id": "b5a24aa26e4d4f55bc3acf68edc4b051",
                      "aijob.cce.baidubce.com/ai-user-name": "zhangmuhua",
                      "aijob.cce.baidubce.com/create-from-aihcp": "true",
                      "aijob.cce.baidubce.com/openapi-jobid": "pytorch-be7cbb30-0a0a-471b-b6ff-e0825477ada6"
                    }
                  },
                  "spec": {
                    "containers": [
                      {
                        "command": [
                          "/bin/bash",
                          "-c",
                          "\n#! /bin/bash\n\nMEGATRON_PATH=${MEGATRON_PATH:-\"/workspace/AIAK-Megatron\"}\nAIAK_TRAINING_PATH=${AIAK_TRAINING_PATH:-\"/workspace/AIAK-Training-LLM\"}\n\nDATA_PATH=${DATA_PATH:-\"/mnt/cluster/llama2/pile_llama_test/pile-llama_text_document\"}\nTOKENIZER_PATH=${TOKENIZER_PATH:-\"/mnt/cluster/llama2/Llama-2-70b-hf/\"}\n\nCHECKPOINT_PATH=${CHECKPOINT_PATH:-\"/mnt/cluster/llama2/mcore_llama2_70b_tp4_pp4\"}\n\nTENSORBOARD_PATH=${TENSORBOARD_PATH:-\"/mnt/cluster/aiak-training-llm/tensorboard-log/llama2-70b-tp4pp4\"}\n\nGPUS_PER_NODE=8\n\n# Change for multinode config\nMASTER_ADDR=${MASTER_ADDR:-\"localhost\"}\nMASTER_PORT=${MASTER_PORT:-\"6000\"}\nNNODES=${WORLD_SIZE:-\"1\"}\nNODE_RANK=${RANK:-\"0\"}\n\nDISTRIBUTED_ARGS=(\n    --nproc_per_node $GPUS_PER_NODE\n    --nnodes $NNODES\n    --node_rank $NODE_RANK\n    --master_addr $MASTER_ADDR\n    --master_port $MASTER_PORT\n)\n\n# you can setup llama2-70b maunally\n#MODEL_ARGS=(\n#    --model-name llama2\n#    --num-layers 80\n#    --hidden-size 8192\n#    --ffn-hidden-size 28672\n#    --num-attention-heads 64\n#    --position-embedding-type rope\n#    --normalization RMSNorm\n#    --swiglu\n#    --attention-dropout 0\n#    --hidden-dropout 0\n#    --disable-bias-linear\n#    --untie-embeddings-and-output-weights\n#    --group-query-attention\n#    --num-query-groups 8\n#)\n\n# or you can setup llama2-70b by using the following command\nMODEL_ARGS=(\n    --model-name llama2-70b # options: llama2-7b, llama2-13b, llama2-70b\n)\n\nDATA_ARGS=(\n    --tokenizer-type HFTokenizer\n    --hf-tokenizer-path $TOKENIZER_PATH\n    --data-path $DATA_PATH\n    --split 949,50,1\n)\n\nTRAINING_ARGS=(\n    --training-phase pretrain # options: pretrain, sft\n    --seq-length 4096\n    --max-position-embeddings 4096\n    --init-method-std 0.01\n    --micro-batch-size 1\n    --global-batch-size 1024\n    --lr 0.0002\n    --min-lr 1.0e-5\n    --clip-grad 1.0\n    --weight-decay 0.01\n    --optimizer adam\n    --adam-beta1 0.9\n    --adam-beta2 0.95\n    --adam-eps 1e-05\n    --norm-epsilon 1e-6\n    --train-iters 500000\n    --lr-decay-iters 500000\n    --lr-decay-style cosine\n    --lr-warmup-fraction 0.002\n    --initial-loss-scale 256\n    --fp16\n    --save-interval 5000\n    --eval-interval 1000\n    --eval-iters 10\n    #--ckpt-step 0\n    #--no-load-optim\n    #--no-load-rng\n)\n\nMODEL_PARALLEL_ARGS=(\n    --tensor-model-parallel-size 4\n    --pipeline-model-parallel-size 4\n    --use-distributed-optimizer\n    --overlap-grad-reduce\n    --overlap-param-gather\n    --distributed-backend nccl\n    --sequence-parallel\n    #--tp-comm-overlap # require mpi envrionment\n)\n\nLOGGING_ARGS=(\n    --log-interval 1\n    --tensorboard-dir ${TENSORBOARD_PATH}\n    --log-timers-to-tensorboard\n)\n\nif [ -n \"${WANDB_API_KEY}\" ]; then\n    LOGGING_ARGS+=(\n        --wandb-project ${WANDB_PROJECT}\n        --wandb-exp-name ${WANDB_NAME} \n    )\nfi\n\nPYTHONPATH=$MEGATRON_PATH:$AIAK_TRAINING_PATH:$PYTHONPATH     torchrun ${DISTRIBUTED_ARGS[@]}     $AIAK_TRAINING_PATH/aiak_training_llm/train.py     ${MODEL_ARGS[@]}     ${DATA_ARGS[@]}     ${TRAINING_ARGS[@]}     ${MODEL_PARALLEL_ARGS[@]}     ${LOGGING_ARGS[@]}\n"
                        ],
                        "env": [
                          {
                            "name": "NCCL_IB_DISABLE",
                            "value": "0"
                          },
                          {
                            "name": "CUDA_DEVICE_MAX_CONNECTIONS",
                            "value": "1"
                          },
                          {
                            "name": "AIHC_TENSORBOARD_LOG_PATH",
                            "value": "/mnt/cluster/llamatest0718forxiaomi8/output/training_logs"
                          },
                          {
                            "name": "AIHC_JOB_NAME",
                            "value": "llamatest0718forxiaomi8"
                          }
                        ],
                        "image": "registry.baidubce.com/aihc-aiak/aiak-training-llm:ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release",
                        "imagePullPolicy": "Always",
                        "name": "pytorch",
                        "ports": [
                          {
                            "containerPort": 23456,
                            "name": "pytorchjob-port",
                            "protocol": "TCP"
                          }
                        ],
                        "resources": {
                          "limits": {
                            "baidu.com/a800_80g_cgpu": "8",
                            "rdma/hca": "1"
                          },
                          "requests": {
                            "baidu.com/a800_80g_cgpu": "8",
                            "rdma/hca": "1"
                          }
                        },
                        "securityContext": {
                          "capabilities": {
                            "add": [
                              "IPC_LOCK"
                            ]
                          }
                        },
                        "volumeMounts": [
                          {
                            "mountPath": "/dev/shm",
                            "name": "devshm"
                          },
                          {
                            "mountPath": "/mnt/cluster",
                            "name": "pvc-pfs"
                          }
                        ]
                      }
                    ],
                    "dnsPolicy": "ClusterFirstWithHostNet",
                    "hostNetwork": true,
                    "schedulerName": "volcano",
                    "volumes": [
                      {
                        "emptyDir": {
                          "medium": "Memory",
                          "sizeLimit": "10Gi"
                        },
                        "name": "devshm"
                      },
                      {
                        "name": "pvc-pfs",
                        "persistentVolumeClaim": {
                          "claimName": "pvc-pfs"
                        }
                      }
                    ]
                  }
                }
              }
            },
            "runPolicy": {
              "cleanPodPolicy": "None",
              "schedulingPolicy": {
                "priorityClass": "high",
                "queue": "default"
              }
            }
          },
          "status": {
            "completionTime": "2024-07-18T08:40:08Z",
            "conditions": [
              {
                "lastTransitionTime": "2024-07-18T03:02:42Z",
                "lastUpdateTime": "2024-07-18T03:02:42Z",
                "message": "PyTorchJob llamatest0718forxiaomi8 is created.",
                "reason": "PyTorchJobCreated",
                "status": "True",
                "type": "Created"
              },
              {
                "lastTransitionTime": "2024-07-18T03:02:54Z",
                "lastUpdateTime": "2024-07-18T03:02:54Z",
                "message": "PyTorchJob llamatest0718forxiaomi8 is running.",
                "reason": "JobRunning",
                "status": "False",
                "type": "Running"
              },
              {
                "lastTransitionTime": "2024-07-18T08:39:56Z",
                "lastUpdateTime": "2024-07-18T08:39:56Z",
                "message": "PytorchJob default/llamatest0718forxiaomi8 is stopped",
                "reason": "PyTorchJobStopped",
                "status": "True",
                "type": "Stopped"
              },
              {
                "lastTransitionTime": "2024-07-18T08:40:08Z",
                "lastUpdateTime": "2024-07-18T08:40:08Z",
                "message": "PyTorchJob llamatest0718forxiaomi8 is failed because 1 Worker replica(s) failed.",
                "reason": "JobFailed",
                "status": "True",
                "type": "Failed"
              }
            ],
            "lastReconcileTime": "2024-07-18T03:02:42Z",
            "replicaStatuses": {
              "Master": {
                "active": 1,
                "selector": "training.kubeflow.org/job-name=llamatest0718forxiaomi8,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=master"
              },
              "Worker": {
                "active": 2,
                "failed": 1,
                "selector": "training.kubeflow.org/job-name=llamatest0718forxiaomi8,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=worker"
              }
            },
            "startTime": "2024-07-18T03:02:43Z"
          }
        },
        {
          "apiVersion": "kubeflow.org/v1",
          "kind": "PyTorchJob",
          "metadata": {
            "annotations": {
              "aijob.cce.baidubce.com/barrier-finish": "2dc24e3c-baa2-42cd-bbc9-705e8178aab4",
              "aijob.cce.baidubce.com/fault-tolerance-enabled": "true",
              "aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": "",
              "aijob.cce.baidubce.com/openapi-jobid": "pytorch-6ae32368-97b5-4e0d-9d78-1dcab6fd0361",
              "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
              "aijob.cce.baidubce.com/raw-request": "{\"name\":\"llamatest0718forxiaomi9\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"high\",\"oversell\":false,\"faultTolerance\":true,\"command\":\"\\n#! /bin/bash\\n\\nMEGATRON_PATH=${MEGATRON_PATH:-\\\"/workspace/AIAK-Megatron\\\"}\\nAIAK_TRAINING_PATH=${AIAK_TRAINING_PATH:-\\\"/workspace/AIAK-Training-LLM\\\"}\\n\\nDATA_PATH=${DATA_PATH:-\\\"/mnt/cluster/llama2/pile_llama_test/pile-llama_text_document\\\"}\\nTOKENIZER_PATH=${TOKENIZER_PATH:-\\\"/mnt/cluster/llama2/Llama-2-70b-hf/\\\"}\\n\\nCHECKPOINT_PATH=${CHECKPOINT_PATH:-\\\"/mnt/cluster/llama2/mcore_llama2_70b_tp4_pp4\\\"}\\n\\nTENSORBOARD_PATH=${TENSORBOARD_PATH:-\\\"/mnt/cluster/aiak-training-llm/tensorboard-log/llama2-70b-tp4pp4\\\"}\\n\\nGPUS_PER_NODE=8\\n\\n# Change for multinode config\\nMASTER_ADDR=${MASTER_ADDR:-\\\"localhost\\\"}\\nMASTER_PORT=${MASTER_PORT:-\\\"6000\\\"}\\nNNODES=${WORLD_SIZE:-\\\"1\\\"}\\nNODE_RANK=${RANK:-\\\"0\\\"}\\n\\nDISTRIBUTED_ARGS=(\\n    --nproc_per_node $GPUS_PER_NODE\\n    --nnodes $NNODES\\n    --node_rank $NODE_RANK\\n    --master_addr $MASTER_ADDR\\n    --master_port $MASTER_PORT\\n)\\n\\n# you can setup llama2-70b maunally\\n#MODEL_ARGS=(\\n#    --model-name llama2\\n#    --num-layers 80\\n#    --hidden-size 8192\\n#    --ffn-hidden-size 28672\\n#    --num-attention-heads 64\\n#    --position-embedding-type rope\\n#    --normalization RMSNorm\\n#    --swiglu\\n#    --attention-dropout 0\\n#    --hidden-dropout 0\\n#    --disable-bias-linear\\n#    --untie-embeddings-and-output-weights\\n#    --group-query-attention\\n#    --num-query-groups 8\\n#)\\n\\n# or you can setup llama2-70b by using the following command\\nMODEL_ARGS=(\\n    --model-name llama2-70b # options: llama2-7b, llama2-13b, llama2-70b\\n)\\n\\nDATA_ARGS=(\\n    --tokenizer-type HFTokenizer\\n    --hf-tokenizer-path $TOKENIZER_PATH\\n    --data-path $DATA_PATH\\n    --split 949,50,1\\n)\\n\\nTRAINING_ARGS=(\\n    --training-phase pretrain # options: pretrain, sft\\n    --seq-length 4096\\n    --max-position-embeddings 4096\\n    --init-method-std 0.01\\n    --micro-batch-size 1\\n    --global-batch-size 1024\\n    --lr 0.0002\\n    --min-lr 1.0e-5\\n    --clip-grad 1.0\\n    --weight-decay 0.01\\n    --optimizer adam\\n    --adam-beta1 0.9\\n    --adam-beta2 0.95\\n    --adam-eps 1e-05\\n    --norm-epsilon 1e-6\\n    --train-iters 500000\\n    --lr-decay-iters 500000\\n    --lr-decay-style cosine\\n    --lr-warmup-fraction 0.002\\n    --initial-loss-scale 16\\n    --fp16\\n    --save-interval 5000\\n    --eval-interval 1000\\n    --eval-iters 10\\n    #--ckpt-step 0\\n    #--no-load-optim\\n    #--no-load-rng\\n)\\n\\nMODEL_PARALLEL_ARGS=(\\n    --tensor-model-parallel-size 4\\n    --pipeline-model-parallel-size 4\\n    --use-distributed-optimizer\\n    --overlap-grad-reduce\\n    --overlap-param-gather\\n    --distributed-backend nccl\\n    --sequence-parallel\\n    #--tp-comm-overlap # require mpi envrionment\\n)\\n\\nLOGGING_ARGS=(\\n    --log-interval 1\\n    --tensorboard-dir ${TENSORBOARD_PATH}\\n    --log-timers-to-tensorboard\\n)\\n\\nif [ -n \\\"${WANDB_API_KEY}\\\" ]; then\\n    LOGGING_ARGS+=(\\n        --wandb-project ${WANDB_PROJECT}\\n        --wandb-exp-name ${WANDB_NAME} \\n    )\\nfi\\n\\nPYTHONPATH=$MEGATRON_PATH:$AIAK_TRAINING_PATH:$PYTHONPATH     torchrun ${DISTRIBUTED_ARGS[@]}     $AIAK_TRAINING_PATH/aiak_training_llm/train.py     ${MODEL_ARGS[@]}     ${DATA_ARGS[@]}     ${TRAINING_ARGS[@]}     ${MODEL_PARALLEL_ARGS[@]}     ${LOGGING_ARGS[@]}\\n\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":true,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi9\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi9/output/training_logs\",\"CUDA_DEVICE_MAX_CONNECTIONS\":\"1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"},\"Worker\":{\"replicas\":3,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi9\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi9/output/training_logs\",\"CUDA_DEVICE_MAX_CONNECTIONS\":\"1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":true,\"logPath\":\"/mnt/cluster/llamatest0718forxiaomi9/output/training_logs\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":true,\"isCopyJob\":true,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
              "aijob.cce.baidubce.com/timeline": "[{\"conditionType\":\"Created\",\"time\":1721291978},{\"conditionType\":\"Scheduled\",\"time\":1721292009},{\"conditionType\":\"Running\",\"time\":1721292052},{\"conditionType\":\"ManualTermination\",\"time\":1721387985}]",
              "job-manager/action": "stop",
              "job-manager/action-succeed": "stop",
              "scheduling.k8s.io/job-enable-oversell": "false",
              "tensorboard-gc": "true"
            },
            "creationTimestamp": "2024-07-18T08:39:38Z",
            "generation": 2,
            "labels": {
              "aijob.cce.baidubce.com/ai-user-id": "dd0cc6ebcaa04da5af73af3448ffb35d",
              "aijob.cce.baidubce.com/ai-user-name": "wangzhuyun",
              "aijob.cce.baidubce.com/create-from-aihcp": "true",
              "aijob.cce.baidubce.com/openapi-jobid": "pytorch-6ae32368-97b5-4e0d-9d78-1dcab6fd0361"
            },
            "managedFields": [
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      "f:aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": {},
                      "f:aijob.cce.baidubce.com/timeline": {}
                    }
                  },
                  "f:spec": {
                    "f:pytorchReplicaSpecs": {
                      "f:Master": {
                        "f:template": {
                          "f:spec": {
                            "f:containers": {}
                          }
                        }
                      },
                      "f:Worker": {
                        "f:template": {
                          "f:spec": {
                            "f:containers": {}
                          }
                        }
                      }
                    },
                    "f:runPolicy": {
                      "f:cleanPodPolicy": {}
                    }
                  }
                },
                "manager": "controller",
                "operation": "Update",
                "time": "2024-07-18T08:39:38Z"
              },
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      "f:aijob.cce.baidubce.com/barrier-finish": {}
                    }
                  }
                },
                "manager": "jobbarrier",
                "operation": "Update",
                "time": "2024-07-18T08:40:48Z"
              },
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      ".": {},
                      "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                      "f:aijob.cce.baidubce.com/openapi-jobid": {},
                      "f:aijob.cce.baidubce.com/pfs-id": {},
                      "f:aijob.cce.baidubce.com/raw-request": {},
                      "f:job-manager/action": {},
                      "f:scheduling.k8s.io/job-enable-oversell": {}
                    },
                    "f:labels": {
                      ".": {},
                      "f:aijob.cce.baidubce.com/ai-user-id": {},
                      "f:aijob.cce.baidubce.com/ai-user-name": {},
                      "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                      "f:aijob.cce.baidubce.com/openapi-jobid": {}
                    }
                  },
                  "f:spec": {
                    ".": {},
                    "f:pytorchReplicaSpecs": {
                      ".": {},
                      "f:Master": {
                        ".": {},
                        "f:replicas": {},
                        "f:restartPolicy": {},
                        "f:template": {
                          ".": {},
                          "f:metadata": {
                            ".": {},
                            "f:annotations": {
                              ".": {},
                              "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                              "f:aijob.cce.baidubce.com/openapi-jobid": {},
                              "f:aijob.cce.baidubce.com/pfs-id": {},
                              "f:aijob.cce.baidubce.com/raw-request": {},
                              "f:scheduling.k8s.io/job-enable-oversell": {}
                            },
                            "f:labels": {
                              ".": {},
                              "f:aijob.cce.baidubce.com/ai-user-id": {},
                              "f:aijob.cce.baidubce.com/ai-user-name": {},
                              "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                              "f:aijob.cce.baidubce.com/openapi-jobid": {}
                            }
                          },
                          "f:spec": {
                            ".": {},
                            "f:dnsPolicy": {},
                            "f:hostNetwork": {},
                            "f:schedulerName": {},
                            "f:volumes": {}
                          }
                        }
                      },
                      "f:Worker": {
                        ".": {},
                        "f:replicas": {},
                        "f:restartPolicy": {},
                        "f:template": {
                          ".": {},
                          "f:metadata": {
                            ".": {},
                            "f:annotations": {
                              ".": {},
                              "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                              "f:aijob.cce.baidubce.com/openapi-jobid": {},
                              "f:aijob.cce.baidubce.com/pfs-id": {},
                              "f:aijob.cce.baidubce.com/raw-request": {},
                              "f:scheduling.k8s.io/job-enable-oversell": {}
                            },
                            "f:labels": {
                              ".": {},
                              "f:aijob.cce.baidubce.com/ai-user-id": {},
                              "f:aijob.cce.baidubce.com/ai-user-name": {},
                              "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                              "f:aijob.cce.baidubce.com/openapi-jobid": {}
                            }
                          },
                          "f:spec": {
                            ".": {},
                            "f:dnsPolicy": {},
                            "f:hostNetwork": {},
                            "f:schedulerName": {},
                            "f:volumes": {}
                          }
                        }
                      }
                    },
                    "f:runPolicy": {
                      ".": {},
                      "f:schedulingPolicy": {
                        ".": {},
                        "f:priorityClass": {},
                        "f:queue": {}
                      }
                    }
                  }
                },
                "manager": "cce-ai-service",
                "operation": "Update",
                "time": "2024-07-19T11:19:45Z"
              },
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      "f:job-manager/action-succeed": {}
                    }
                  }
                },
                "manager": "ftagent",
                "operation": "Update",
                "time": "2024-07-19T11:19:51Z"
              },
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      "f:tensorboard-gc": {}
                    }
                  },
                  "f:status": {
                    ".": {},
                    "f:completionTime": {},
                    "f:conditions": {},
                    "f:lastReconcileTime": {},
                    "f:replicaStatuses": {
                      ".": {},
                      "f:Master": {
                        ".": {},
                        "f:active": {}
                      },
                      "f:Worker": {
                        ".": {},
                        "f:active": {},
                        "f:failed": {}
                      }
                    },
                    "f:startTime": {}
                  }
                },
                "manager": "manager",
                "operation": "Update",
                "time": "2024-07-19T11:19:57Z"
              }
            ],
            "name": "llamatest0718forxiaomi9",
            "namespace": "default",
            "resourceVersion": "2372827685",
            "uid": "1d954d68-56f0-4537-82b7-9d1ea765ca5f"
          },
          "spec": {
            "pytorchReplicaSpecs": {
              "Master": {
                "replicas": 1,
                "restartPolicy": "Never",
                "template": {
                  "metadata": {
                    "annotations": {
                      "aijob.cce.baidubce.com/fault-tolerance-enabled": "true",
                      "aijob.cce.baidubce.com/openapi-jobid": "pytorch-6ae32368-97b5-4e0d-9d78-1dcab6fd0361",
                      "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
                      "aijob.cce.baidubce.com/raw-request": "{\"name\":\"llamatest0718forxiaomi9\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"high\",\"oversell\":false,\"faultTolerance\":true,\"command\":\"\\n#! /bin/bash\\n\\nMEGATRON_PATH=${MEGATRON_PATH:-\\\"/workspace/AIAK-Megatron\\\"}\\nAIAK_TRAINING_PATH=${AIAK_TRAINING_PATH:-\\\"/workspace/AIAK-Training-LLM\\\"}\\n\\nDATA_PATH=${DATA_PATH:-\\\"/mnt/cluster/llama2/pile_llama_test/pile-llama_text_document\\\"}\\nTOKENIZER_PATH=${TOKENIZER_PATH:-\\\"/mnt/cluster/llama2/Llama-2-70b-hf/\\\"}\\n\\nCHECKPOINT_PATH=${CHECKPOINT_PATH:-\\\"/mnt/cluster/llama2/mcore_llama2_70b_tp4_pp4\\\"}\\n\\nTENSORBOARD_PATH=${TENSORBOARD_PATH:-\\\"/mnt/cluster/aiak-training-llm/tensorboard-log/llama2-70b-tp4pp4\\\"}\\n\\nGPUS_PER_NODE=8\\n\\n# Change for multinode config\\nMASTER_ADDR=${MASTER_ADDR:-\\\"localhost\\\"}\\nMASTER_PORT=${MASTER_PORT:-\\\"6000\\\"}\\nNNODES=${WORLD_SIZE:-\\\"1\\\"}\\nNODE_RANK=${RANK:-\\\"0\\\"}\\n\\nDISTRIBUTED_ARGS=(\\n    --nproc_per_node $GPUS_PER_NODE\\n    --nnodes $NNODES\\n    --node_rank $NODE_RANK\\n    --master_addr $MASTER_ADDR\\n    --master_port $MASTER_PORT\\n)\\n\\n# you can setup llama2-70b maunally\\n#MODEL_ARGS=(\\n#    --model-name llama2\\n#    --num-layers 80\\n#    --hidden-size 8192\\n#    --ffn-hidden-size 28672\\n#    --num-attention-heads 64\\n#    --position-embedding-type rope\\n#    --normalization RMSNorm\\n#    --swiglu\\n#    --attention-dropout 0\\n#    --hidden-dropout 0\\n#    --disable-bias-linear\\n#    --untie-embeddings-and-output-weights\\n#    --group-query-attention\\n#    --num-query-groups 8\\n#)\\n\\n# or you can setup llama2-70b by using the following command\\nMODEL_ARGS=(\\n    --model-name llama2-70b # options: llama2-7b, llama2-13b, llama2-70b\\n)\\n\\nDATA_ARGS=(\\n    --tokenizer-type HFTokenizer\\n    --hf-tokenizer-path $TOKENIZER_PATH\\n    --data-path $DATA_PATH\\n    --split 949,50,1\\n)\\n\\nTRAINING_ARGS=(\\n    --training-phase pretrain # options: pretrain, sft\\n    --seq-length 4096\\n    --max-position-embeddings 4096\\n    --init-method-std 0.01\\n    --micro-batch-size 1\\n    --global-batch-size 1024\\n    --lr 0.0002\\n    --min-lr 1.0e-5\\n    --clip-grad 1.0\\n    --weight-decay 0.01\\n    --optimizer adam\\n    --adam-beta1 0.9\\n    --adam-beta2 0.95\\n    --adam-eps 1e-05\\n    --norm-epsilon 1e-6\\n    --train-iters 500000\\n    --lr-decay-iters 500000\\n    --lr-decay-style cosine\\n    --lr-warmup-fraction 0.002\\n    --initial-loss-scale 16\\n    --fp16\\n    --save-interval 5000\\n    --eval-interval 1000\\n    --eval-iters 10\\n    #--ckpt-step 0\\n    #--no-load-optim\\n    #--no-load-rng\\n)\\n\\nMODEL_PARALLEL_ARGS=(\\n    --tensor-model-parallel-size 4\\n    --pipeline-model-parallel-size 4\\n    --use-distributed-optimizer\\n    --overlap-grad-reduce\\n    --overlap-param-gather\\n    --distributed-backend nccl\\n    --sequence-parallel\\n    #--tp-comm-overlap # require mpi envrionment\\n)\\n\\nLOGGING_ARGS=(\\n    --log-interval 1\\n    --tensorboard-dir ${TENSORBOARD_PATH}\\n    --log-timers-to-tensorboard\\n)\\n\\nif [ -n \\\"${WANDB_API_KEY}\\\" ]; then\\n    LOGGING_ARGS+=(\\n        --wandb-project ${WANDB_PROJECT}\\n        --wandb-exp-name ${WANDB_NAME} \\n    )\\nfi\\n\\nPYTHONPATH=$MEGATRON_PATH:$AIAK_TRAINING_PATH:$PYTHONPATH     torchrun ${DISTRIBUTED_ARGS[@]}     $AIAK_TRAINING_PATH/aiak_training_llm/train.py     ${MODEL_ARGS[@]}     ${DATA_ARGS[@]}     ${TRAINING_ARGS[@]}     ${MODEL_PARALLEL_ARGS[@]}     ${LOGGING_ARGS[@]}\\n\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":true,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi9\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi9/output/training_logs\",\"CUDA_DEVICE_MAX_CONNECTIONS\":\"1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"},\"Worker\":{\"replicas\":3,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi9\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi9/output/training_logs\",\"CUDA_DEVICE_MAX_CONNECTIONS\":\"1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":true,\"logPath\":\"/mnt/cluster/llamatest0718forxiaomi9/output/training_logs\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":true,\"isCopyJob\":true,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
                      "scheduling.k8s.io/job-enable-oversell": "false"
                    },
                    "labels": {
                      "aijob.cce.baidubce.com/ai-user-id": "dd0cc6ebcaa04da5af73af3448ffb35d",
                      "aijob.cce.baidubce.com/ai-user-name": "wangzhuyun",
                      "aijob.cce.baidubce.com/create-from-aihcp": "true",
                      "aijob.cce.baidubce.com/openapi-jobid": "pytorch-6ae32368-97b5-4e0d-9d78-1dcab6fd0361"
                    }
                  },
                  "spec": {
                    "containers": [
                      {
                        "command": [
                          "/bin/bash",
                          "-c",
                          "\n#! /bin/bash\n\nMEGATRON_PATH=${MEGATRON_PATH:-\"/workspace/AIAK-Megatron\"}\nAIAK_TRAINING_PATH=${AIAK_TRAINING_PATH:-\"/workspace/AIAK-Training-LLM\"}\n\nDATA_PATH=${DATA_PATH:-\"/mnt/cluster/llama2/pile_llama_test/pile-llama_text_document\"}\nTOKENIZER_PATH=${TOKENIZER_PATH:-\"/mnt/cluster/llama2/Llama-2-70b-hf/\"}\n\nCHECKPOINT_PATH=${CHECKPOINT_PATH:-\"/mnt/cluster/llama2/mcore_llama2_70b_tp4_pp4\"}\n\nTENSORBOARD_PATH=${TENSORBOARD_PATH:-\"/mnt/cluster/aiak-training-llm/tensorboard-log/llama2-70b-tp4pp4\"}\n\nGPUS_PER_NODE=8\n\n# Change for multinode config\nMASTER_ADDR=${MASTER_ADDR:-\"localhost\"}\nMASTER_PORT=${MASTER_PORT:-\"6000\"}\nNNODES=${WORLD_SIZE:-\"1\"}\nNODE_RANK=${RANK:-\"0\"}\n\nDISTRIBUTED_ARGS=(\n    --nproc_per_node $GPUS_PER_NODE\n    --nnodes $NNODES\n    --node_rank $NODE_RANK\n    --master_addr $MASTER_ADDR\n    --master_port $MASTER_PORT\n)\n\n# you can setup llama2-70b maunally\n#MODEL_ARGS=(\n#    --model-name llama2\n#    --num-layers 80\n#    --hidden-size 8192\n#    --ffn-hidden-size 28672\n#    --num-attention-heads 64\n#    --position-embedding-type rope\n#    --normalization RMSNorm\n#    --swiglu\n#    --attention-dropout 0\n#    --hidden-dropout 0\n#    --disable-bias-linear\n#    --untie-embeddings-and-output-weights\n#    --group-query-attention\n#    --num-query-groups 8\n#)\n\n# or you can setup llama2-70b by using the following command\nMODEL_ARGS=(\n    --model-name llama2-70b # options: llama2-7b, llama2-13b, llama2-70b\n)\n\nDATA_ARGS=(\n    --tokenizer-type HFTokenizer\n    --hf-tokenizer-path $TOKENIZER_PATH\n    --data-path $DATA_PATH\n    --split 949,50,1\n)\n\nTRAINING_ARGS=(\n    --training-phase pretrain # options: pretrain, sft\n    --seq-length 4096\n    --max-position-embeddings 4096\n    --init-method-std 0.01\n    --micro-batch-size 1\n    --global-batch-size 1024\n    --lr 0.0002\n    --min-lr 1.0e-5\n    --clip-grad 1.0\n    --weight-decay 0.01\n    --optimizer adam\n    --adam-beta1 0.9\n    --adam-beta2 0.95\n    --adam-eps 1e-05\n    --norm-epsilon 1e-6\n    --train-iters 500000\n    --lr-decay-iters 500000\n    --lr-decay-style cosine\n    --lr-warmup-fraction 0.002\n    --initial-loss-scale 16\n    --fp16\n    --save-interval 5000\n    --eval-interval 1000\n    --eval-iters 10\n    #--ckpt-step 0\n    #--no-load-optim\n    #--no-load-rng\n)\n\nMODEL_PARALLEL_ARGS=(\n    --tensor-model-parallel-size 4\n    --pipeline-model-parallel-size 4\n    --use-distributed-optimizer\n    --overlap-grad-reduce\n    --overlap-param-gather\n    --distributed-backend nccl\n    --sequence-parallel\n    #--tp-comm-overlap # require mpi envrionment\n)\n\nLOGGING_ARGS=(\n    --log-interval 1\n    --tensorboard-dir ${TENSORBOARD_PATH}\n    --log-timers-to-tensorboard\n)\n\nif [ -n \"${WANDB_API_KEY}\" ]; then\n    LOGGING_ARGS+=(\n        --wandb-project ${WANDB_PROJECT}\n        --wandb-exp-name ${WANDB_NAME} \n    )\nfi\n\nPYTHONPATH=$MEGATRON_PATH:$AIAK_TRAINING_PATH:$PYTHONPATH     torchrun ${DISTRIBUTED_ARGS[@]}     $AIAK_TRAINING_PATH/aiak_training_llm/train.py     ${MODEL_ARGS[@]}     ${DATA_ARGS[@]}     ${TRAINING_ARGS[@]}     ${MODEL_PARALLEL_ARGS[@]}     ${LOGGING_ARGS[@]}\n"
                        ],
                        "env": [
                          {
                            "name": "CUDA_DEVICE_MAX_CONNECTIONS",
                            "value": "1"
                          },
                          {
                            "name": "AIHC_TENSORBOARD_LOG_PATH",
                            "value": "/mnt/cluster/llamatest0718forxiaomi9/output/training_logs"
                          },
                          {
                            "name": "AIHC_JOB_NAME",
                            "value": "llamatest0718forxiaomi9"
                          },
                          {
                            "name": "NCCL_IB_DISABLE",
                            "value": "0"
                          }
                        ],
                        "image": "registry.baidubce.com/aihc-aiak/aiak-training-llm:ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release",
                        "imagePullPolicy": "Always",
                        "name": "pytorch",
                        "ports": [
                          {
                            "containerPort": 23456,
                            "name": "pytorchjob-port",
                            "protocol": "TCP"
                          }
                        ],
                        "resources": {
                          "limits": {
                            "baidu.com/a800_80g_cgpu": "8",
                            "rdma/hca": "1"
                          },
                          "requests": {
                            "baidu.com/a800_80g_cgpu": "8",
                            "rdma/hca": "1"
                          }
                        },
                        "securityContext": {
                          "capabilities": {
                            "add": [
                              "IPC_LOCK"
                            ]
                          }
                        },
                        "volumeMounts": [
                          {
                            "mountPath": "/dev/shm",
                            "name": "devshm"
                          },
                          {
                            "mountPath": "/mnt/cluster",
                            "name": "pvc-pfs"
                          }
                        ]
                      }
                    ],
                    "dnsPolicy": "ClusterFirstWithHostNet",
                    "hostNetwork": true,
                    "schedulerName": "volcano",
                    "volumes": [
                      {
                        "emptyDir": {
                          "medium": "Memory",
                          "sizeLimit": "10Gi"
                        },
                        "name": "devshm"
                      },
                      {
                        "name": "pvc-pfs",
                        "persistentVolumeClaim": {
                          "claimName": "pvc-pfs"
                        }
                      }
                    ]
                  }
                }
              },
              "Worker": {
                "replicas": 3,
                "restartPolicy": "Never",
                "template": {
                  "metadata": {
                    "annotations": {
                      "aijob.cce.baidubce.com/fault-tolerance-enabled": "true",
                      "aijob.cce.baidubce.com/openapi-jobid": "pytorch-6ae32368-97b5-4e0d-9d78-1dcab6fd0361",
                      "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
                      "aijob.cce.baidubce.com/raw-request": "{\"name\":\"llamatest0718forxiaomi9\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"high\",\"oversell\":false,\"faultTolerance\":true,\"command\":\"\\n#! /bin/bash\\n\\nMEGATRON_PATH=${MEGATRON_PATH:-\\\"/workspace/AIAK-Megatron\\\"}\\nAIAK_TRAINING_PATH=${AIAK_TRAINING_PATH:-\\\"/workspace/AIAK-Training-LLM\\\"}\\n\\nDATA_PATH=${DATA_PATH:-\\\"/mnt/cluster/llama2/pile_llama_test/pile-llama_text_document\\\"}\\nTOKENIZER_PATH=${TOKENIZER_PATH:-\\\"/mnt/cluster/llama2/Llama-2-70b-hf/\\\"}\\n\\nCHECKPOINT_PATH=${CHECKPOINT_PATH:-\\\"/mnt/cluster/llama2/mcore_llama2_70b_tp4_pp4\\\"}\\n\\nTENSORBOARD_PATH=${TENSORBOARD_PATH:-\\\"/mnt/cluster/aiak-training-llm/tensorboard-log/llama2-70b-tp4pp4\\\"}\\n\\nGPUS_PER_NODE=8\\n\\n# Change for multinode config\\nMASTER_ADDR=${MASTER_ADDR:-\\\"localhost\\\"}\\nMASTER_PORT=${MASTER_PORT:-\\\"6000\\\"}\\nNNODES=${WORLD_SIZE:-\\\"1\\\"}\\nNODE_RANK=${RANK:-\\\"0\\\"}\\n\\nDISTRIBUTED_ARGS=(\\n    --nproc_per_node $GPUS_PER_NODE\\n    --nnodes $NNODES\\n    --node_rank $NODE_RANK\\n    --master_addr $MASTER_ADDR\\n    --master_port $MASTER_PORT\\n)\\n\\n# you can setup llama2-70b maunally\\n#MODEL_ARGS=(\\n#    --model-name llama2\\n#    --num-layers 80\\n#    --hidden-size 8192\\n#    --ffn-hidden-size 28672\\n#    --num-attention-heads 64\\n#    --position-embedding-type rope\\n#    --normalization RMSNorm\\n#    --swiglu\\n#    --attention-dropout 0\\n#    --hidden-dropout 0\\n#    --disable-bias-linear\\n#    --untie-embeddings-and-output-weights\\n#    --group-query-attention\\n#    --num-query-groups 8\\n#)\\n\\n# or you can setup llama2-70b by using the following command\\nMODEL_ARGS=(\\n    --model-name llama2-70b # options: llama2-7b, llama2-13b, llama2-70b\\n)\\n\\nDATA_ARGS=(\\n    --tokenizer-type HFTokenizer\\n    --hf-tokenizer-path $TOKENIZER_PATH\\n    --data-path $DATA_PATH\\n    --split 949,50,1\\n)\\n\\nTRAINING_ARGS=(\\n    --training-phase pretrain # options: pretrain, sft\\n    --seq-length 4096\\n    --max-position-embeddings 4096\\n    --init-method-std 0.01\\n    --micro-batch-size 1\\n    --global-batch-size 1024\\n    --lr 0.0002\\n    --min-lr 1.0e-5\\n    --clip-grad 1.0\\n    --weight-decay 0.01\\n    --optimizer adam\\n    --adam-beta1 0.9\\n    --adam-beta2 0.95\\n    --adam-eps 1e-05\\n    --norm-epsilon 1e-6\\n    --train-iters 500000\\n    --lr-decay-iters 500000\\n    --lr-decay-style cosine\\n    --lr-warmup-fraction 0.002\\n    --initial-loss-scale 16\\n    --fp16\\n    --save-interval 5000\\n    --eval-interval 1000\\n    --eval-iters 10\\n    #--ckpt-step 0\\n    #--no-load-optim\\n    #--no-load-rng\\n)\\n\\nMODEL_PARALLEL_ARGS=(\\n    --tensor-model-parallel-size 4\\n    --pipeline-model-parallel-size 4\\n    --use-distributed-optimizer\\n    --overlap-grad-reduce\\n    --overlap-param-gather\\n    --distributed-backend nccl\\n    --sequence-parallel\\n    #--tp-comm-overlap # require mpi envrionment\\n)\\n\\nLOGGING_ARGS=(\\n    --log-interval 1\\n    --tensorboard-dir ${TENSORBOARD_PATH}\\n    --log-timers-to-tensorboard\\n)\\n\\nif [ -n \\\"${WANDB_API_KEY}\\\" ]; then\\n    LOGGING_ARGS+=(\\n        --wandb-project ${WANDB_PROJECT}\\n        --wandb-exp-name ${WANDB_NAME} \\n    )\\nfi\\n\\nPYTHONPATH=$MEGATRON_PATH:$AIAK_TRAINING_PATH:$PYTHONPATH     torchrun ${DISTRIBUTED_ARGS[@]}     $AIAK_TRAINING_PATH/aiak_training_llm/train.py     ${MODEL_ARGS[@]}     ${DATA_ARGS[@]}     ${TRAINING_ARGS[@]}     ${MODEL_PARALLEL_ARGS[@]}     ${LOGGING_ARGS[@]}\\n\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":true,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi9\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi9/output/training_logs\",\"CUDA_DEVICE_MAX_CONNECTIONS\":\"1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"},\"Worker\":{\"replicas\":3,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm\",\"tag\":\"ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"llamatest0718forxiaomi9\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/llamatest0718forxiaomi9/output/training_logs\",\"CUDA_DEVICE_MAX_CONNECTIONS\":\"1\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":true,\"logPath\":\"/mnt/cluster/llamatest0718forxiaomi9/output/training_logs\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":true,\"isCopyJob\":true,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
                      "scheduling.k8s.io/job-enable-oversell": "false"
                    },
                    "labels": {
                      "aijob.cce.baidubce.com/ai-user-id": "dd0cc6ebcaa04da5af73af3448ffb35d",
                      "aijob.cce.baidubce.com/ai-user-name": "wangzhuyun",
                      "aijob.cce.baidubce.com/create-from-aihcp": "true",
                      "aijob.cce.baidubce.com/openapi-jobid": "pytorch-6ae32368-97b5-4e0d-9d78-1dcab6fd0361"
                    }
                  },
                  "spec": {
                    "containers": [
                      {
                        "command": [
                          "/bin/bash",
                          "-c",
                          "\n#! /bin/bash\n\nMEGATRON_PATH=${MEGATRON_PATH:-\"/workspace/AIAK-Megatron\"}\nAIAK_TRAINING_PATH=${AIAK_TRAINING_PATH:-\"/workspace/AIAK-Training-LLM\"}\n\nDATA_PATH=${DATA_PATH:-\"/mnt/cluster/llama2/pile_llama_test/pile-llama_text_document\"}\nTOKENIZER_PATH=${TOKENIZER_PATH:-\"/mnt/cluster/llama2/Llama-2-70b-hf/\"}\n\nCHECKPOINT_PATH=${CHECKPOINT_PATH:-\"/mnt/cluster/llama2/mcore_llama2_70b_tp4_pp4\"}\n\nTENSORBOARD_PATH=${TENSORBOARD_PATH:-\"/mnt/cluster/aiak-training-llm/tensorboard-log/llama2-70b-tp4pp4\"}\n\nGPUS_PER_NODE=8\n\n# Change for multinode config\nMASTER_ADDR=${MASTER_ADDR:-\"localhost\"}\nMASTER_PORT=${MASTER_PORT:-\"6000\"}\nNNODES=${WORLD_SIZE:-\"1\"}\nNODE_RANK=${RANK:-\"0\"}\n\nDISTRIBUTED_ARGS=(\n    --nproc_per_node $GPUS_PER_NODE\n    --nnodes $NNODES\n    --node_rank $NODE_RANK\n    --master_addr $MASTER_ADDR\n    --master_port $MASTER_PORT\n)\n\n# you can setup llama2-70b maunally\n#MODEL_ARGS=(\n#    --model-name llama2\n#    --num-layers 80\n#    --hidden-size 8192\n#    --ffn-hidden-size 28672\n#    --num-attention-heads 64\n#    --position-embedding-type rope\n#    --normalization RMSNorm\n#    --swiglu\n#    --attention-dropout 0\n#    --hidden-dropout 0\n#    --disable-bias-linear\n#    --untie-embeddings-and-output-weights\n#    --group-query-attention\n#    --num-query-groups 8\n#)\n\n# or you can setup llama2-70b by using the following command\nMODEL_ARGS=(\n    --model-name llama2-70b # options: llama2-7b, llama2-13b, llama2-70b\n)\n\nDATA_ARGS=(\n    --tokenizer-type HFTokenizer\n    --hf-tokenizer-path $TOKENIZER_PATH\n    --data-path $DATA_PATH\n    --split 949,50,1\n)\n\nTRAINING_ARGS=(\n    --training-phase pretrain # options: pretrain, sft\n    --seq-length 4096\n    --max-position-embeddings 4096\n    --init-method-std 0.01\n    --micro-batch-size 1\n    --global-batch-size 1024\n    --lr 0.0002\n    --min-lr 1.0e-5\n    --clip-grad 1.0\n    --weight-decay 0.01\n    --optimizer adam\n    --adam-beta1 0.9\n    --adam-beta2 0.95\n    --adam-eps 1e-05\n    --norm-epsilon 1e-6\n    --train-iters 500000\n    --lr-decay-iters 500000\n    --lr-decay-style cosine\n    --lr-warmup-fraction 0.002\n    --initial-loss-scale 16\n    --fp16\n    --save-interval 5000\n    --eval-interval 1000\n    --eval-iters 10\n    #--ckpt-step 0\n    #--no-load-optim\n    #--no-load-rng\n)\n\nMODEL_PARALLEL_ARGS=(\n    --tensor-model-parallel-size 4\n    --pipeline-model-parallel-size 4\n    --use-distributed-optimizer\n    --overlap-grad-reduce\n    --overlap-param-gather\n    --distributed-backend nccl\n    --sequence-parallel\n    #--tp-comm-overlap # require mpi envrionment\n)\n\nLOGGING_ARGS=(\n    --log-interval 1\n    --tensorboard-dir ${TENSORBOARD_PATH}\n    --log-timers-to-tensorboard\n)\n\nif [ -n \"${WANDB_API_KEY}\" ]; then\n    LOGGING_ARGS+=(\n        --wandb-project ${WANDB_PROJECT}\n        --wandb-exp-name ${WANDB_NAME} \n    )\nfi\n\nPYTHONPATH=$MEGATRON_PATH:$AIAK_TRAINING_PATH:$PYTHONPATH     torchrun ${DISTRIBUTED_ARGS[@]}     $AIAK_TRAINING_PATH/aiak_training_llm/train.py     ${MODEL_ARGS[@]}     ${DATA_ARGS[@]}     ${TRAINING_ARGS[@]}     ${MODEL_PARALLEL_ARGS[@]}     ${LOGGING_ARGS[@]}\n"
                        ],
                        "env": [
                          {
                            "name": "AIHC_TENSORBOARD_LOG_PATH",
                            "value": "/mnt/cluster/llamatest0718forxiaomi9/output/training_logs"
                          },
                          {
                            "name": "AIHC_JOB_NAME",
                            "value": "llamatest0718forxiaomi9"
                          },
                          {
                            "name": "NCCL_IB_DISABLE",
                            "value": "0"
                          },
                          {
                            "name": "CUDA_DEVICE_MAX_CONNECTIONS",
                            "value": "1"
                          }
                        ],
                        "image": "registry.baidubce.com/aihc-aiak/aiak-training-llm:ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release",
                        "imagePullPolicy": "Always",
                        "name": "pytorch",
                        "ports": [
                          {
                            "containerPort": 23456,
                            "name": "pytorchjob-port",
                            "protocol": "TCP"
                          }
                        ],
                        "resources": {
                          "limits": {
                            "baidu.com/a800_80g_cgpu": "8",
                            "rdma/hca": "1"
                          },
                          "requests": {
                            "baidu.com/a800_80g_cgpu": "8",
                            "rdma/hca": "1"
                          }
                        },
                        "securityContext": {
                          "capabilities": {
                            "add": [
                              "IPC_LOCK"
                            ]
                          }
                        },
                        "volumeMounts": [
                          {
                            "mountPath": "/dev/shm",
                            "name": "devshm"
                          },
                          {
                            "mountPath": "/mnt/cluster",
                            "name": "pvc-pfs"
                          }
                        ]
                      }
                    ],
                    "dnsPolicy": "ClusterFirstWithHostNet",
                    "hostNetwork": true,
                    "schedulerName": "volcano",
                    "volumes": [
                      {
                        "emptyDir": {
                          "medium": "Memory",
                          "sizeLimit": "10Gi"
                        },
                        "name": "devshm"
                      },
                      {
                        "name": "pvc-pfs",
                        "persistentVolumeClaim": {
                          "claimName": "pvc-pfs"
                        }
                      }
                    ]
                  }
                }
              }
            },
            "runPolicy": {
              "cleanPodPolicy": "None",
              "schedulingPolicy": {
                "priorityClass": "high",
                "queue": "default"
              }
            }
          },
          "status": {
            "completionTime": "2024-07-19T11:19:57Z",
            "conditions": [
              {
                "lastTransitionTime": "2024-07-18T08:39:38Z",
                "lastUpdateTime": "2024-07-18T08:39:38Z",
                "message": "PyTorchJob llamatest0718forxiaomi9 is created.",
                "reason": "PyTorchJobCreated",
                "status": "True",
                "type": "Created"
              },
              {
                "lastTransitionTime": "2024-07-18T08:40:52Z",
                "lastUpdateTime": "2024-07-18T08:40:52Z",
                "message": "PyTorchJob llamatest0718forxiaomi9 is running.",
                "reason": "JobRunning",
                "status": "False",
                "type": "Running"
              },
              {
                "lastTransitionTime": "2024-07-19T11:19:45Z",
                "lastUpdateTime": "2024-07-19T11:19:45Z",
                "message": "PytorchJob default/llamatest0718forxiaomi9 is stopped",
                "reason": "PyTorchJobStopped",
                "status": "True",
                "type": "Stopped"
              },
              {
                "lastTransitionTime": "2024-07-19T11:19:57Z",
                "lastUpdateTime": "2024-07-19T11:19:57Z",
                "message": "PyTorchJob llamatest0718forxiaomi9 is failed because 1 Worker replica(s) failed.",
                "reason": "JobFailed",
                "status": "True",
                "type": "Failed"
              }
            ],
            "lastReconcileTime": "2024-07-18T08:39:38Z",
            "replicaStatuses": {
              "Master": {
                "active": 1,
                "selector": "training.kubeflow.org/job-name=llamatest0718forxiaomi9,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=master"
              },
              "Worker": {
                "active": 2,
                "failed": 1,
                "selector": "training.kubeflow.org/job-name=llamatest0718forxiaomi9,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=worker"
              }
            },
            "startTime": "2024-07-18T08:39:39Z"
          }
        },
        {
          "apiVersion": "kubeflow.org/v1",
          "kind": "PyTorchJob",
          "metadata": {
            "annotations": {
              "aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": "",
              "aijob.cce.baidubce.com/timeline": "[{\"conditionType\":\"Created\",\"time\":1721028726},{\"conditionType\":\"Scheduled\",\"time\":1721028727},{\"conditionType\":\"Running\",\"time\":1721028737},{\"conditionType\":\"Failed\",\"time\":1721272510}]",
              "kubectl.kubernetes.io/last-applied-configuration": "{\"apiVersion\":\"kubeflow.org/v1\",\"kind\":\"PyTorchJob\",\"metadata\":{\"annotations\":{},\"name\":\"pangbo-12h-modelcompass-eval\",\"namespace\":\"default\"},\"spec\":{\"pytorchReplicaSpecs\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"template\":{\"metadata\":null,\"spec\":{\"containers\":[{\"command\":[\"bash\",\"-c\",\"sleep 4d\",\"/workspace/launch.sh\"],\"env\":[{\"name\":\"CUDA_DEVICE_MAX_CONNECTIONS\",\"value\":\"1\"},{\"name\":\"NCCL_DEBUG\",\"value\":\"INFO\"},{\"name\":\"NCCL_IB_DISABLE\",\"value\":\"0\"},{\"name\":\"MASTER\",\"value\":\"1\"}],\"image\":\"registry.baidubce.com/cce-ai-native/aiak-algo:0.1\",\"imagePullPolicy\":\"Always\",\"name\":\"pytorch\",\"resources\":{\"limits\":{\"nvidia.com/gpu\":8,\"rdma/hca\":1}},\"securityContext\":{\"capabilities\":{\"add\":[\"IPC_LOCK\"]}},\"volumeMounts\":[{\"mountPath\":\"/dev/shm\",\"name\":\"cache-volume\"},{\"mountPath\":\"/workspace/launch.sh\",\"name\":\"config-volume\",\"subPath\":\"launch.sh\"},{\"mountPath\":\"/mnt/cluster\",\"name\":\"data\"}]}],\"schedulerName\":\"volcano\",\"volumes\":[{\"emptyDir\":{\"medium\":\"Memory\"},\"name\":\"cache-volume\"},{\"configMap\":{\"name\":\"pangbo-12h-modelcompass-eval\"},\"name\":\"config-volume\"},{\"name\":\"data\",\"persistentVolumeClaim\":{\"claimName\":\"pvc-pfs\"}}]}}}}}}\n"
            },
            "creationTimestamp": "2024-07-15T07:32:06Z",
            "generation": 2,
            "managedFields": [
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      "f:aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": {},
                      "f:aijob.cce.baidubce.com/timeline": {}
                    }
                  },
                  "f:spec": {
                    "f:pytorchReplicaSpecs": {
                      "f:Master": {
                        "f:template": {
                          "f:metadata": {},
                          "f:spec": {
                            "f:containers": {}
                          }
                        }
                      }
                    },
                    "f:runPolicy": {
                      ".": {},
                      "f:cleanPodPolicy": {}
                    }
                  }
                },
                "manager": "controller",
                "operation": "Update",
                "time": "2024-07-15T07:32:06Z"
              },
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      ".": {},
                      "f:kubectl.kubernetes.io/last-applied-configuration": {}
                    }
                  },
                  "f:spec": {
                    ".": {},
                    "f:pytorchReplicaSpecs": {
                      ".": {},
                      "f:Master": {
                        ".": {},
                        "f:replicas": {},
                        "f:restartPolicy": {},
                        "f:template": {
                          ".": {},
                          "f:spec": {
                            ".": {},
                            "f:schedulerName": {},
                            "f:volumes": {}
                          }
                        }
                      }
                    }
                  }
                },
                "manager": "kubectl-client-side-apply",
                "operation": "Update",
                "time": "2024-07-15T07:32:06Z"
              },
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:status": {
                    ".": {},
                    "f:completionTime": {},
                    "f:conditions": {},
                    "f:lastReconcileTime": {},
                    "f:replicaStatuses": {
                      ".": {},
                      "f:Master": {
                        ".": {},
                        "f:failed": {},
                        "f:selector": {}
                      }
                    },
                    "f:startTime": {}
                  }
                },
                "manager": "manager",
                "operation": "Update",
                "time": "2024-07-18T03:15:10Z"
              }
            ],
            "name": "pangbo-12h-modelcompass-eval",
            "namespace": "default",
            "resourceVersion": "2371234821",
            "uid": "fec5fdd4-ffcd-46cc-832a-913ec1717de8"
          },
          "spec": {
            "pytorchReplicaSpecs": {
              "Master": {
                "replicas": 1,
                "restartPolicy": "Never",
                "template": {
                  "metadata": {},
                  "spec": {
                    "containers": [
                      {
                        "command": [
                          "bash",
                          "-c",
                          "sleep 4d",
                          "/workspace/launch.sh"
                        ],
                        "env": [
                          {
                            "name": "CUDA_DEVICE_MAX_CONNECTIONS",
                            "value": "1"
                          },
                          {
                            "name": "NCCL_DEBUG",
                            "value": "INFO"
                          },
                          {
                            "name": "NCCL_IB_DISABLE",
                            "value": "0"
                          },
                          {
                            "name": "MASTER",
                            "value": "1"
                          }
                        ],
                        "image": "registry.baidubce.com/cce-ai-native/aiak-algo:0.1",
                        "imagePullPolicy": "Always",
                        "name": "pytorch",
                        "ports": [
                          {
                            "containerPort": 23456,
                            "name": "pytorchjob-port",
                            "protocol": "TCP"
                          }
                        ],
                        "resources": {
                          "limits": {
                            "nvidia.com/gpu": "8",
                            "rdma/hca": "1"
                          }
                        },
                        "securityContext": {
                          "capabilities": {
                            "add": [
                              "IPC_LOCK"
                            ]
                          }
                        },
                        "volumeMounts": [
                          {
                            "mountPath": "/dev/shm",
                            "name": "cache-volume"
                          },
                          {
                            "mountPath": "/workspace/launch.sh",
                            "name": "config-volume",
                            "subPath": "launch.sh"
                          },
                          {
                            "mountPath": "/mnt/cluster",
                            "name": "data"
                          }
                        ]
                      }
                    ],
                    "schedulerName": "volcano",
                    "volumes": [
                      {
                        "emptyDir": {
                          "medium": "Memory"
                        },
                        "name": "cache-volume"
                      },
                      {
                        "configMap": {
                          "name": "pangbo-12h-modelcompass-eval"
                        },
                        "name": "config-volume"
                      },
                      {
                        "name": "data",
                        "persistentVolumeClaim": {
                          "claimName": "pvc-pfs"
                        }
                      }
                    ]
                  }
                }
              }
            },
            "runPolicy": {
              "cleanPodPolicy": "None"
            }
          },
          "status": {
            "completionTime": "2024-07-18T03:15:10Z",
            "conditions": [
              {
                "lastTransitionTime": "2024-07-15T07:32:06Z",
                "lastUpdateTime": "2024-07-15T07:32:06Z",
                "message": "PyTorchJob pangbo-12h-modelcompass-eval is created.",
                "reason": "PyTorchJobCreated",
                "status": "True",
                "type": "Created"
              },
              {
                "lastTransitionTime": "2024-07-15T07:32:17Z",
                "lastUpdateTime": "2024-07-15T07:32:17Z",
                "message": "PyTorchJob pangbo-12h-modelcompass-eval is running.",
                "reason": "JobRunning",
                "status": "False",
                "type": "Running"
              },
              {
                "lastTransitionTime": "2024-07-18T03:15:10Z",
                "lastUpdateTime": "2024-07-18T03:15:10Z",
                "message": "PyTorchJob pangbo-12h-modelcompass-eval is failed because 1 Master replica(s) failed.",
                "reason": "JobFailed",
                "status": "True",
                "type": "Failed"
              }
            ],
            "lastReconcileTime": "2024-07-15T07:32:06Z",
            "replicaStatuses": {
              "Master": {
                "failed": 1,
                "selector": "training.kubeflow.org/job-name=pangbo-12h-modelcompass-eval,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=master"
              }
            },
            "startTime": "2024-07-15T07:32:07Z"
          }
        },
        {
          "apiVersion": "kubeflow.org/v1",
          "kind": "PyTorchJob",
          "metadata": {
            "annotations": {
              "aijob.cce.baidubce.com/fault-tolerance-enabled": "true",
              "aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": "",
              "aijob.cce.baidubce.com/timeline": "[{\"conditionType\":\"Created\",\"time\":1721655040}]",
              "kubectl.kubernetes.io/last-applied-configuration": "{\"apiVersion\":\"kubeflow.org/v1\",\"kind\":\"PyTorchJob\",\"metadata\":{\"annotations\":{},\"name\":\"pangbo-48h-megatron-llama3-longcontext-pre\",\"namespace\":\"default\"},\"spec\":{\"pytorchReplicaSpecs\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"template\":{\"metadata\":null,\"spec\":{\"containers\":[{\"command\":[\"bash\",\"/workspace/launch.sh\"],\"env\":[{\"name\":\"CUDA_DEVICE_MAX_CONNECTIONS\",\"value\":\"1\"},{\"name\":\"NCCL_DEBUG\",\"value\":\"INFO\"},{\"name\":\"NCCL_IB_DISABLE\",\"value\":\"0\"},{\"name\":\"MASTER\",\"value\":\"1\"}],\"image\":\"registry.baidubce.com/hac-aiacc/aiak-training-llm:ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_dev_20240718_204220\",\"imagePullPolicy\":\"Always\",\"name\":\"pytorch\",\"resources\":{\"limits\":{\"nvidia.com/gpu\":8,\"rdma/hca\":1}},\"securityContext\":{\"capabilities\":{\"add\":[\"IPC_LOCK\"]}},\"volumeMounts\":[{\"mountPath\":\"/dev/shm\",\"name\":\"cache-volume\"},{\"mountPath\":\"/workspace/launch.sh\",\"name\":\"config-volume\",\"subPath\":\"launch.sh\"},{\"mountPath\":\"/mnt/cluster\",\"name\":\"data\"}]}],\"schedulerName\":\"volcano\",\"volumes\":[{\"emptyDir\":{\"medium\":\"Memory\"},\"name\":\"cache-volume\"},{\"configMap\":{\"name\":\"pangbo-48h-megatron-llama3-longcontext-pre\"},\"name\":\"config-volume\"},{\"name\":\"data\",\"persistentVolumeClaim\":{\"claimName\":\"pvc-pfs\"}}]}}},\"Worker\":{\"replicas\":3,\"restartPolicy\":\"Never\",\"template\":{\"spec\":{\"containers\":[{\"command\":[\"bash\",\"/workspace/launch.sh\"],\"env\":[{\"name\":\"CUDA_DEVICE_MAX_CONNECTIONS\",\"value\":\"1\"},{\"name\":\"NCCL_DEBUG\",\"value\":\"INFO\"},{\"name\":\"NCCL_IB_DISABLE\",\"value\":\"0\"}],\"image\":\"registry.baidubce.com/hac-aiacc/aiak-training-llm:ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_dev_20240718_204220\",\"imagePullPolicy\":\"Always\",\"name\":\"pytorch\",\"resources\":{\"limits\":{\"nvidia.com/gpu\":8,\"rdma/hca\":1}},\"securityContext\":{\"capabilities\":{\"add\":[\"IPC_LOCK\"]}},\"volumeMounts\":[{\"mountPath\":\"/dev/shm\",\"name\":\"cache-volume\"},{\"mountPath\":\"/workspace/launch.sh\",\"name\":\"config-volume\",\"subPath\":\"launch.sh\"},{\"mountPath\":\"/mnt/cluster\",\"name\":\"data\"}]}],\"schedulerName\":\"volcano\",\"volumes\":[{\"emptyDir\":{\"medium\":\"Memory\"},\"name\":\"cache-volume\"},{\"configMap\":{\"name\":\"pangbo-48h-megatron-llama3-longcontext-pre\"},\"name\":\"config-volume\"},{\"name\":\"data\",\"persistentVolumeClaim\":{\"claimName\":\"pvc-pfs\"}}]}}}}}}\n"
            },
            "creationTimestamp": "2024-07-22T13:30:40Z",
            "generation": 2,
            "managedFields": [
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      "f:aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": {},
                      "f:aijob.cce.baidubce.com/timeline": {}
                    }
                  }
                },
                "manager": "controller",
                "operation": "Update",
                "time": "2024-07-22T13:30:40Z"
              },
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      ".": {},
                      "f:kubectl.kubernetes.io/last-applied-configuration": {}
                    }
                  },
                  "f:spec": {
                    ".": {},
                    "f:pytorchReplicaSpecs": {
                      ".": {},
                      "f:Master": {
                        ".": {},
                        "f:replicas": {},
                        "f:restartPolicy": {},
                        "f:template": {
                          ".": {},
                          "f:spec": {
                            ".": {},
                            "f:schedulerName": {},
                            "f:volumes": {}
                          }
                        }
                      },
                      "f:Worker": {
                        ".": {},
                        "f:replicas": {},
                        "f:restartPolicy": {},
                        "f:template": {
                          ".": {},
                          "f:spec": {
                            ".": {},
                            "f:schedulerName": {},
                            "f:volumes": {}
                          }
                        }
                      }
                    }
                  }
                },
                "manager": "kubectl-client-side-apply",
                "operation": "Update",
                "time": "2024-07-22T13:30:40Z"
              },
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {}
                    }
                  },
                  "f:spec": {
                    "f:pytorchReplicaSpecs": {
                      "f:Master": {
                        "f:template": {
                          "f:metadata": {},
                          "f:spec": {
                            "f:containers": {}
                          }
                        }
                      },
                      "f:Worker": {
                        "f:template": {
                          "f:metadata": {},
                          "f:spec": {
                            "f:containers": {}
                          }
                        }
                      }
                    },
                    "f:runPolicy": {
                      ".": {},
                      "f:cleanPodPolicy": {}
                    }
                  },
                  "f:status": {
                    ".": {},
                    "f:conditions": {},
                    "f:lastReconcileTime": {},
                    "f:replicaStatuses": {
                      ".": {},
                      "f:Master": {
                        ".": {},
                        "f:selector": {}
                      },
                      "f:Worker": {
                        ".": {},
                        "f:selector": {}
                      }
                    },
                    "f:startTime": {}
                  }
                },
                "manager": "manager",
                "operation": "Update",
                "time": "2024-07-22T13:30:41Z"
              }
            ],
            "name": "pangbo-48h-megatron-llama3-longcontext-pre",
            "namespace": "default",
            "resourceVersion": "2376331138",
            "uid": "6f074d4f-0e40-4539-9db0-39805a24f55a"
          },
          "spec": {
            "pytorchReplicaSpecs": {
              "Master": {
                "replicas": 1,
                "restartPolicy": "Never",
                "template": {
                  "metadata": {},
                  "spec": {
                    "containers": [
                      {
                        "command": [
                          "bash",
                          "/workspace/launch.sh"
                        ],
                        "env": [
                          {
                            "name": "CUDA_DEVICE_MAX_CONNECTIONS",
                            "value": "1"
                          },
                          {
                            "name": "NCCL_DEBUG",
                            "value": "INFO"
                          },
                          {
                            "name": "NCCL_IB_DISABLE",
                            "value": "0"
                          },
                          {
                            "name": "MASTER",
                            "value": "1"
                          }
                        ],
                        "image": "registry.baidubce.com/hac-aiacc/aiak-training-llm:ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_dev_20240718_204220",
                        "imagePullPolicy": "Always",
                        "name": "pytorch",
                        "ports": [
                          {
                            "containerPort": 23456,
                            "name": "pytorchjob-port",
                            "protocol": "TCP"
                          }
                        ],
                        "resources": {
                          "limits": {
                            "nvidia.com/gpu": "8",
                            "rdma/hca": "1"
                          }
                        },
                        "securityContext": {
                          "capabilities": {
                            "add": [
                              "IPC_LOCK"
                            ]
                          }
                        },
                        "volumeMounts": [
                          {
                            "mountPath": "/dev/shm",
                            "name": "cache-volume"
                          },
                          {
                            "mountPath": "/workspace/launch.sh",
                            "name": "config-volume",
                            "subPath": "launch.sh"
                          },
                          {
                            "mountPath": "/mnt/cluster",
                            "name": "data"
                          }
                        ]
                      }
                    ],
                    "schedulerName": "volcano",
                    "volumes": [
                      {
                        "emptyDir": {
                          "medium": "Memory"
                        },
                        "name": "cache-volume"
                      },
                      {
                        "configMap": {
                          "name": "pangbo-48h-megatron-llama3-longcontext-pre"
                        },
                        "name": "config-volume"
                      },
                      {
                        "name": "data",
                        "persistentVolumeClaim": {
                          "claimName": "pvc-pfs"
                        }
                      }
                    ]
                  }
                }
              },
              "Worker": {
                "replicas": 3,
                "restartPolicy": "Never",
                "template": {
                  "metadata": {},
                  "spec": {
                    "containers": [
                      {
                        "command": [
                          "bash",
                          "/workspace/launch.sh"
                        ],
                        "env": [
                          {
                            "name": "CUDA_DEVICE_MAX_CONNECTIONS",
                            "value": "1"
                          },
                          {
                            "name": "NCCL_DEBUG",
                            "value": "INFO"
                          },
                          {
                            "name": "NCCL_IB_DISABLE",
                            "value": "0"
                          }
                        ],
                        "image": "registry.baidubce.com/hac-aiacc/aiak-training-llm:ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_dev_20240718_204220",
                        "imagePullPolicy": "Always",
                        "name": "pytorch",
                        "ports": [
                          {
                            "containerPort": 23456,
                            "name": "pytorchjob-port",
                            "protocol": "TCP"
                          }
                        ],
                        "resources": {
                          "limits": {
                            "nvidia.com/gpu": "8",
                            "rdma/hca": "1"
                          }
                        },
                        "securityContext": {
                          "capabilities": {
                            "add": [
                              "IPC_LOCK"
                            ]
                          }
                        },
                        "volumeMounts": [
                          {
                            "mountPath": "/dev/shm",
                            "name": "cache-volume"
                          },
                          {
                            "mountPath": "/workspace/launch.sh",
                            "name": "config-volume",
                            "subPath": "launch.sh"
                          },
                          {
                            "mountPath": "/mnt/cluster",
                            "name": "data"
                          }
                        ]
                      }
                    ],
                    "schedulerName": "volcano",
                    "volumes": [
                      {
                        "emptyDir": {
                          "medium": "Memory"
                        },
                        "name": "cache-volume"
                      },
                      {
                        "configMap": {
                          "name": "pangbo-48h-megatron-llama3-longcontext-pre"
                        },
                        "name": "config-volume"
                      },
                      {
                        "name": "data",
                        "persistentVolumeClaim": {
                          "claimName": "pvc-pfs"
                        }
                      }
                    ]
                  }
                }
              }
            },
            "runPolicy": {
              "cleanPodPolicy": "None"
            }
          },
          "status": {
            "conditions": [
              {
                "lastTransitionTime": "2024-07-22T13:30:40Z",
                "lastUpdateTime": "2024-07-22T13:30:40Z",
                "message": "PyTorchJob pangbo-48h-megatron-llama3-longcontext-pre is created.",
                "reason": "PyTorchJobCreated",
                "status": "True",
                "type": "Created"
              }
            ],
            "lastReconcileTime": "2024-07-22T13:30:41Z",
            "replicaStatuses": {
              "Master": {
                "selector": "training.kubeflow.org/job-name=pangbo-48h-megatron-llama3-longcontext-pre,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=master"
              },
              "Worker": {
                "selector": "training.kubeflow.org/job-name=pangbo-48h-megatron-llama3-longcontext-pre,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=worker"
              }
            },
            "startTime": "2024-07-22T13:30:41Z"
          }
        },
        {
          "apiVersion": "kubeflow.org/v1",
          "kind": "PyTorchJob",
          "metadata": {
            "annotations": {
              "aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": "",
              "aijob.cce.baidubce.com/timeline": "[{\"conditionType\":\"Created\",\"time\":1721371809},{\"conditionType\":\"Scheduled\",\"time\":1721371811},{\"conditionType\":\"Running\",\"time\":1721371823}]",
              "kubectl.kubernetes.io/last-applied-configuration": "{\"apiVersion\":\"kubeflow.org/v1\",\"kind\":\"PyTorchJob\",\"metadata\":{\"annotations\":{},\"name\":\"pangbo-modelcompass-longcontext\",\"namespace\":\"default\"},\"spec\":{\"pytorchReplicaSpecs\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"template\":{\"metadata\":null,\"spec\":{\"containers\":[{\"command\":[\"bash\",\"-c\",\"sleep infinity\",\"/workspace/launch.sh\"],\"env\":[{\"name\":\"CUDA_DEVICE_MAX_CONNECTIONS\",\"value\":\"1\"},{\"name\":\"NCCL_DEBUG\",\"value\":\"INFO\"},{\"name\":\"NCCL_IB_DISABLE\",\"value\":\"0\"},{\"name\":\"MASTER\",\"value\":\"1\"}],\"image\":\"registry.baidubce.com/cce-ai-native/aiak-algo:0.1\",\"imagePullPolicy\":\"Always\",\"name\":\"pytorch\",\"resources\":{\"limits\":{\"nvidia.com/gpu\":8,\"rdma/hca\":1}},\"securityContext\":{\"capabilities\":{\"add\":[\"IPC_LOCK\"]}},\"volumeMounts\":[{\"mountPath\":\"/dev/shm\",\"name\":\"cache-volume\"},{\"mountPath\":\"/workspace/launch.sh\",\"name\":\"config-volume\",\"subPath\":\"launch.sh\"},{\"mountPath\":\"/mnt/cluster\",\"name\":\"data\"}]}],\"schedulerName\":\"volcano\",\"volumes\":[{\"emptyDir\":{\"medium\":\"Memory\"},\"name\":\"cache-volume\"},{\"configMap\":{\"name\":\"pangbo-modelcompass-longcontext\"},\"name\":\"config-volume\"},{\"name\":\"data\",\"persistentVolumeClaim\":{\"claimName\":\"pvc-pfs\"}}]}}}}}}\n"
            },
            "creationTimestamp": "2024-07-19T06:50:09Z",
            "generation": 2,
            "managedFields": [
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      "f:aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": {},
                      "f:aijob.cce.baidubce.com/timeline": {}
                    }
                  },
                  "f:spec": {
                    "f:pytorchReplicaSpecs": {
                      "f:Master": {
                        "f:template": {
                          "f:metadata": {},
                          "f:spec": {
                            "f:containers": {}
                          }
                        }
                      }
                    },
                    "f:runPolicy": {
                      ".": {},
                      "f:cleanPodPolicy": {}
                    }
                  }
                },
                "manager": "controller",
                "operation": "Update",
                "time": "2024-07-19T06:50:09Z"
              },
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      ".": {},
                      "f:kubectl.kubernetes.io/last-applied-configuration": {}
                    }
                  },
                  "f:spec": {
                    ".": {},
                    "f:pytorchReplicaSpecs": {
                      ".": {},
                      "f:Master": {
                        ".": {},
                        "f:replicas": {},
                        "f:restartPolicy": {},
                        "f:template": {
                          ".": {},
                          "f:spec": {
                            ".": {},
                            "f:schedulerName": {},
                            "f:volumes": {}
                          }
                        }
                      }
                    }
                  }
                },
                "manager": "kubectl-client-side-apply",
                "operation": "Update",
                "time": "2024-07-19T06:50:09Z"
              },
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:status": {
                    ".": {},
                    "f:conditions": {},
                    "f:lastReconcileTime": {},
                    "f:replicaStatuses": {
                      ".": {},
                      "f:Master": {
                        ".": {},
                        "f:active": {},
                        "f:selector": {}
                      }
                    },
                    "f:startTime": {}
                  }
                },
                "manager": "manager",
                "operation": "Update",
                "time": "2024-07-19T06:50:23Z"
              }
            ],
            "name": "pangbo-modelcompass-longcontext",
            "namespace": "default",
            "resourceVersion": "2372606547",
            "uid": "b8698c07-ca1e-4dd7-bb61-029dbcd4d754"
          },
          "spec": {
            "pytorchReplicaSpecs": {
              "Master": {
                "replicas": 1,
                "restartPolicy": "Never",
                "template": {
                  "metadata": {},
                  "spec": {
                    "containers": [
                      {
                        "command": [
                          "bash",
                          "-c",
                          "sleep infinity",
                          "/workspace/launch.sh"
                        ],
                        "env": [
                          {
                            "name": "CUDA_DEVICE_MAX_CONNECTIONS",
                            "value": "1"
                          },
                          {
                            "name": "NCCL_DEBUG",
                            "value": "INFO"
                          },
                          {
                            "name": "NCCL_IB_DISABLE",
                            "value": "0"
                          },
                          {
                            "name": "MASTER",
                            "value": "1"
                          }
                        ],
                        "image": "registry.baidubce.com/cce-ai-native/aiak-algo:0.1",
                        "imagePullPolicy": "Always",
                        "name": "pytorch",
                        "ports": [
                          {
                            "containerPort": 23456,
                            "name": "pytorchjob-port",
                            "protocol": "TCP"
                          }
                        ],
                        "resources": {
                          "limits": {
                            "nvidia.com/gpu": "8",
                            "rdma/hca": "1"
                          }
                        },
                        "securityContext": {
                          "capabilities": {
                            "add": [
                              "IPC_LOCK"
                            ]
                          }
                        },
                        "volumeMounts": [
                          {
                            "mountPath": "/dev/shm",
                            "name": "cache-volume"
                          },
                          {
                            "mountPath": "/workspace/launch.sh",
                            "name": "config-volume",
                            "subPath": "launch.sh"
                          },
                          {
                            "mountPath": "/mnt/cluster",
                            "name": "data"
                          }
                        ]
                      }
                    ],
                    "schedulerName": "volcano",
                    "volumes": [
                      {
                        "emptyDir": {
                          "medium": "Memory"
                        },
                        "name": "cache-volume"
                      },
                      {
                        "configMap": {
                          "name": "pangbo-modelcompass-longcontext"
                        },
                        "name": "config-volume"
                      },
                      {
                        "name": "data",
                        "persistentVolumeClaim": {
                          "claimName": "pvc-pfs"
                        }
                      }
                    ]
                  }
                }
              }
            },
            "runPolicy": {
              "cleanPodPolicy": "None"
            }
          },
          "status": {
            "conditions": [
              {
                "lastTransitionTime": "2024-07-19T06:50:09Z",
                "lastUpdateTime": "2024-07-19T06:50:09Z",
                "message": "PyTorchJob pangbo-modelcompass-longcontext is created.",
                "reason": "PyTorchJobCreated",
                "status": "True",
                "type": "Created"
              },
              {
                "lastTransitionTime": "2024-07-19T06:50:23Z",
                "lastUpdateTime": "2024-07-19T06:50:23Z",
                "message": "PyTorchJob pangbo-modelcompass-longcontext is running.",
                "reason": "JobRunning",
                "status": "True",
                "type": "Running"
              }
            ],
            "lastReconcileTime": "2024-07-19T06:50:09Z",
            "replicaStatuses": {
              "Master": {
                "active": 1,
                "selector": "training.kubeflow.org/job-name=pangbo-modelcompass-longcontext,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=master"
              }
            },
            "startTime": "2024-07-19T06:50:10Z"
          }
        },
        {
          "apiVersion": "kubeflow.org/v1",
          "kind": "PyTorchJob",
          "metadata": {
            "annotations": {
              "aijob.cce.baidubce.com/barrier-finish": "55a7279d-e844-4868-9f72-766bf94d7fd1",
              "aijob.cce.baidubce.com/fault-tolerance-enabled": "false",
              "aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": "",
              "aijob.cce.baidubce.com/openapi-jobid": "pytorch-bcdbd3fe-46d7-4caf-a587-93aa8c501a3f",
              "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
              "aijob.cce.baidubce.com/raw-request": "{\"name\":\"pengxiangyu-48hours-deepseek3\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"high\",\"oversell\":false,\"faultTolerance\":false,\"command\":\"sleep 100000000\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":true,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/hac-aiacc/pxy_megatron\",\"tag\":\"20240722\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"pengxiangyu-48hours-deepseek3\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"},\"Worker\":{\"replicas\":7,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/hac-aiacc/pxy_megatron\",\"tag\":\"20240722\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"pengxiangyu-48hours-deepseek3\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":false,\"logPath\":\"\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":true,\"isCopyJob\":true,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
              "aijob.cce.baidubce.com/timeline": "[{\"conditionType\":\"Created\",\"time\":1721640261},{\"conditionType\":\"Scheduled\",\"time\":1721640451},{\"conditionType\":\"Running\",\"time\":1721640803}]",
              "scheduling.k8s.io/job-enable-oversell": "false"
            },
            "creationTimestamp": "2024-07-22T09:24:21Z",
            "generation": 2,
            "labels": {
              "aijob.cce.baidubce.com/ai-user-id": "b54a2f2a03dc4237b19f5df1b1b6e252",
              "aijob.cce.baidubce.com/ai-user-name": "pengxiangyu",
              "aijob.cce.baidubce.com/create-from-aihcp": "true",
              "aijob.cce.baidubce.com/openapi-jobid": "pytorch-bcdbd3fe-46d7-4caf-a587-93aa8c501a3f"
            },
            "managedFields": [
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      ".": {},
                      "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                      "f:aijob.cce.baidubce.com/openapi-jobid": {},
                      "f:aijob.cce.baidubce.com/pfs-id": {},
                      "f:aijob.cce.baidubce.com/raw-request": {},
                      "f:scheduling.k8s.io/job-enable-oversell": {}
                    },
                    "f:labels": {
                      ".": {},
                      "f:aijob.cce.baidubce.com/ai-user-id": {},
                      "f:aijob.cce.baidubce.com/ai-user-name": {},
                      "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                      "f:aijob.cce.baidubce.com/openapi-jobid": {}
                    }
                  },
                  "f:spec": {
                    ".": {},
                    "f:pytorchReplicaSpecs": {
                      ".": {},
                      "f:Master": {
                        ".": {},
                        "f:replicas": {},
                        "f:restartPolicy": {},
                        "f:template": {
                          ".": {},
                          "f:metadata": {
                            ".": {},
                            "f:annotations": {
                              ".": {},
                              "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                              "f:aijob.cce.baidubce.com/openapi-jobid": {},
                              "f:aijob.cce.baidubce.com/pfs-id": {},
                              "f:aijob.cce.baidubce.com/raw-request": {},
                              "f:scheduling.k8s.io/job-enable-oversell": {}
                            },
                            "f:labels": {
                              ".": {},
                              "f:aijob.cce.baidubce.com/ai-user-id": {},
                              "f:aijob.cce.baidubce.com/ai-user-name": {},
                              "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                              "f:aijob.cce.baidubce.com/openapi-jobid": {}
                            }
                          },
                          "f:spec": {
                            ".": {},
                            "f:dnsPolicy": {},
                            "f:hostNetwork": {},
                            "f:schedulerName": {},
                            "f:volumes": {}
                          }
                        }
                      },
                      "f:Worker": {
                        ".": {},
                        "f:replicas": {},
                        "f:restartPolicy": {},
                        "f:template": {
                          ".": {},
                          "f:metadata": {
                            ".": {},
                            "f:annotations": {
                              ".": {},
                              "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                              "f:aijob.cce.baidubce.com/openapi-jobid": {},
                              "f:aijob.cce.baidubce.com/pfs-id": {},
                              "f:aijob.cce.baidubce.com/raw-request": {},
                              "f:scheduling.k8s.io/job-enable-oversell": {}
                            },
                            "f:labels": {
                              ".": {},
                              "f:aijob.cce.baidubce.com/ai-user-id": {},
                              "f:aijob.cce.baidubce.com/ai-user-name": {},
                              "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                              "f:aijob.cce.baidubce.com/openapi-jobid": {}
                            }
                          },
                          "f:spec": {
                            ".": {},
                            "f:dnsPolicy": {},
                            "f:hostNetwork": {},
                            "f:schedulerName": {},
                            "f:volumes": {}
                          }
                        }
                      }
                    },
                    "f:runPolicy": {
                      ".": {},
                      "f:schedulingPolicy": {
                        ".": {},
                        "f:priorityClass": {},
                        "f:queue": {}
                      }
                    }
                  }
                },
                "manager": "cce-ai-service",
                "operation": "Update",
                "time": "2024-07-22T09:24:21Z"
              },
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      "f:aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": {},
                      "f:aijob.cce.baidubce.com/timeline": {}
                    }
                  },
                  "f:spec": {
                    "f:pytorchReplicaSpecs": {
                      "f:Master": {
                        "f:template": {
                          "f:spec": {
                            "f:containers": {}
                          }
                        }
                      },
                      "f:Worker": {
                        "f:template": {
                          "f:spec": {
                            "f:containers": {}
                          }
                        }
                      }
                    },
                    "f:runPolicy": {
                      "f:cleanPodPolicy": {}
                    }
                  }
                },
                "manager": "controller",
                "operation": "Update",
                "time": "2024-07-22T09:24:21Z"
              },
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      "f:aijob.cce.baidubce.com/barrier-finish": {}
                    }
                  }
                },
                "manager": "jobbarrier",
                "operation": "Update",
                "time": "2024-07-22T09:33:20Z"
              },
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:status": {
                    ".": {},
                    "f:conditions": {},
                    "f:lastReconcileTime": {},
                    "f:replicaStatuses": {
                      ".": {},
                      "f:Master": {
                        ".": {},
                        "f:active": {},
                        "f:selector": {}
                      },
                      "f:Worker": {
                        ".": {},
                        "f:active": {},
                        "f:selector": {}
                      }
                    },
                    "f:startTime": {}
                  }
                },
                "manager": "manager",
                "operation": "Update",
                "time": "2024-07-22T09:33:27Z"
              }
            ],
            "name": "pengxiangyu-48hours-deepseek3",
            "namespace": "default",
            "resourceVersion": "2376142069",
            "uid": "2c2d004e-987d-4518-9ec2-3a0bafaccaf9"
          },
          "spec": {
            "pytorchReplicaSpecs": {
              "Master": {
                "replicas": 1,
                "restartPolicy": "Never",
                "template": {
                  "metadata": {
                    "annotations": {
                      "aijob.cce.baidubce.com/fault-tolerance-enabled": "false",
                      "aijob.cce.baidubce.com/openapi-jobid": "pytorch-bcdbd3fe-46d7-4caf-a587-93aa8c501a3f",
                      "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
                      "aijob.cce.baidubce.com/raw-request": "{\"name\":\"pengxiangyu-48hours-deepseek3\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"high\",\"oversell\":false,\"faultTolerance\":false,\"command\":\"sleep 100000000\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":true,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/hac-aiacc/pxy_megatron\",\"tag\":\"20240722\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"pengxiangyu-48hours-deepseek3\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"},\"Worker\":{\"replicas\":7,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/hac-aiacc/pxy_megatron\",\"tag\":\"20240722\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"pengxiangyu-48hours-deepseek3\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":false,\"logPath\":\"\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":true,\"isCopyJob\":true,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
                      "scheduling.k8s.io/job-enable-oversell": "false"
                    },
                    "labels": {
                      "aijob.cce.baidubce.com/ai-user-id": "b54a2f2a03dc4237b19f5df1b1b6e252",
                      "aijob.cce.baidubce.com/ai-user-name": "pengxiangyu",
                      "aijob.cce.baidubce.com/create-from-aihcp": "true",
                      "aijob.cce.baidubce.com/openapi-jobid": "pytorch-bcdbd3fe-46d7-4caf-a587-93aa8c501a3f"
                    }
                  },
                  "spec": {
                    "containers": [
                      {
                        "command": [
                          "/bin/bash",
                          "-c",
                          "sleep 100000000"
                        ],
                        "env": [
                          {
                            "name": "AIHC_JOB_NAME",
                            "value": "pengxiangyu-48hours-deepseek3"
                          },
                          {
                            "name": "NCCL_IB_DISABLE",
                            "value": "0"
                          }
                        ],
                        "image": "registry.baidubce.com/hac-aiacc/pxy_megatron:20240722",
                        "imagePullPolicy": "Always",
                        "name": "pytorch",
                        "ports": [
                          {
                            "containerPort": 23456,
                            "name": "pytorchjob-port",
                            "protocol": "TCP"
                          }
                        ],
                        "resources": {
                          "limits": {
                            "baidu.com/a800_80g_cgpu": "8",
                            "rdma/hca": "1"
                          },
                          "requests": {
                            "baidu.com/a800_80g_cgpu": "8",
                            "rdma/hca": "1"
                          }
                        },
                        "securityContext": {
                          "capabilities": {
                            "add": [
                              "IPC_LOCK"
                            ]
                          }
                        },
                        "volumeMounts": [
                          {
                            "mountPath": "/dev/shm",
                            "name": "devshm"
                          },
                          {
                            "mountPath": "/mnt/cluster",
                            "name": "pvc-pfs"
                          }
                        ]
                      }
                    ],
                    "dnsPolicy": "ClusterFirstWithHostNet",
                    "hostNetwork": true,
                    "schedulerName": "volcano",
                    "volumes": [
                      {
                        "emptyDir": {
                          "medium": "Memory",
                          "sizeLimit": "10Gi"
                        },
                        "name": "devshm"
                      },
                      {
                        "name": "pvc-pfs",
                        "persistentVolumeClaim": {
                          "claimName": "pvc-pfs"
                        }
                      }
                    ]
                  }
                }
              },
              "Worker": {
                "replicas": 7,
                "restartPolicy": "Never",
                "template": {
                  "metadata": {
                    "annotations": {
                      "aijob.cce.baidubce.com/fault-tolerance-enabled": "false",
                      "aijob.cce.baidubce.com/openapi-jobid": "pytorch-bcdbd3fe-46d7-4caf-a587-93aa8c501a3f",
                      "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
                      "aijob.cce.baidubce.com/raw-request": "{\"name\":\"pengxiangyu-48hours-deepseek3\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"high\",\"oversell\":false,\"faultTolerance\":false,\"command\":\"sleep 100000000\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":true,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/hac-aiacc/pxy_megatron\",\"tag\":\"20240722\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"pengxiangyu-48hours-deepseek3\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"},\"Worker\":{\"replicas\":7,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/hac-aiacc/pxy_megatron\",\"tag\":\"20240722\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"pengxiangyu-48hours-deepseek3\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":false,\"logPath\":\"\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":true,\"isCopyJob\":true,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
                      "scheduling.k8s.io/job-enable-oversell": "false"
                    },
                    "labels": {
                      "aijob.cce.baidubce.com/ai-user-id": "b54a2f2a03dc4237b19f5df1b1b6e252",
                      "aijob.cce.baidubce.com/ai-user-name": "pengxiangyu",
                      "aijob.cce.baidubce.com/create-from-aihcp": "true",
                      "aijob.cce.baidubce.com/openapi-jobid": "pytorch-bcdbd3fe-46d7-4caf-a587-93aa8c501a3f"
                    }
                  },
                  "spec": {
                    "containers": [
                      {
                        "command": [
                          "/bin/bash",
                          "-c",
                          "sleep 100000000"
                        ],
                        "env": [
                          {
                            "name": "AIHC_JOB_NAME",
                            "value": "pengxiangyu-48hours-deepseek3"
                          },
                          {
                            "name": "NCCL_IB_DISABLE",
                            "value": "0"
                          }
                        ],
                        "image": "registry.baidubce.com/hac-aiacc/pxy_megatron:20240722",
                        "imagePullPolicy": "Always",
                        "name": "pytorch",
                        "ports": [
                          {
                            "containerPort": 23456,
                            "name": "pytorchjob-port",
                            "protocol": "TCP"
                          }
                        ],
                        "resources": {
                          "limits": {
                            "baidu.com/a800_80g_cgpu": "8",
                            "rdma/hca": "1"
                          },
                          "requests": {
                            "baidu.com/a800_80g_cgpu": "8",
                            "rdma/hca": "1"
                          }
                        },
                        "securityContext": {
                          "capabilities": {
                            "add": [
                              "IPC_LOCK"
                            ]
                          }
                        },
                        "volumeMounts": [
                          {
                            "mountPath": "/dev/shm",
                            "name": "devshm"
                          },
                          {
                            "mountPath": "/mnt/cluster",
                            "name": "pvc-pfs"
                          }
                        ]
                      }
                    ],
                    "dnsPolicy": "ClusterFirstWithHostNet",
                    "hostNetwork": true,
                    "schedulerName": "volcano",
                    "volumes": [
                      {
                        "emptyDir": {
                          "medium": "Memory",
                          "sizeLimit": "10Gi"
                        },
                        "name": "devshm"
                      },
                      {
                        "name": "pvc-pfs",
                        "persistentVolumeClaim": {
                          "claimName": "pvc-pfs"
                        }
                      }
                    ]
                  }
                }
              }
            },
            "runPolicy": {
              "cleanPodPolicy": "None",
              "schedulingPolicy": {
                "priorityClass": "high",
                "queue": "default"
              }
            }
          },
          "status": {
            "conditions": [
              {
                "lastTransitionTime": "2024-07-22T09:24:21Z",
                "lastUpdateTime": "2024-07-22T09:24:21Z",
                "message": "PyTorchJob pengxiangyu-48hours-deepseek3 is created.",
                "reason": "PyTorchJobCreated",
                "status": "True",
                "type": "Created"
              },
              {
                "lastTransitionTime": "2024-07-22T09:33:23Z",
                "lastUpdateTime": "2024-07-22T09:33:23Z",
                "message": "PyTorchJob pengxiangyu-48hours-deepseek3 is running.",
                "reason": "JobRunning",
                "status": "True",
                "type": "Running"
              }
            ],
            "lastReconcileTime": "2024-07-22T09:26:42Z",
            "replicaStatuses": {
              "Master": {
                "active": 1,
                "selector": "training.kubeflow.org/job-name=pengxiangyu-48hours-deepseek3,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=master"
              },
              "Worker": {
                "active": 7,
                "selector": "training.kubeflow.org/job-name=pengxiangyu-48hours-deepseek3,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=worker"
              }
            },
            "startTime": "2024-07-22T09:27:31Z"
          }
        },
        {
          "apiVersion": "kubeflow.org/v1",
          "kind": "PyTorchJob",
          "metadata": {
            "annotations": {
              "aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": "",
              "aijob.cce.baidubce.com/timeline": "[{\"conditionType\":\"Created\",\"time\":1721116231},{\"conditionType\":\"Scheduled\",\"time\":1721116233},{\"conditionType\":\"Running\",\"time\":1721116579},{\"conditionType\":\"Failed\",\"time\":1721187332}]",
              "kubectl.kubernetes.io/last-applied-configuration": "{\"apiVersion\":\"kubeflow.org/v1\",\"kind\":\"PyTorchJob\",\"metadata\":{\"annotations\":{},\"name\":\"robin4-task-for-8gpu\",\"namespace\":\"default\"},\"spec\":{\"pytorchReplicaSpecs\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"template\":{\"metadata\":null,\"spec\":{\"containers\":[{\"command\":[\"bash\",\"/workspace/Megatron-LM/examples/launch.sh\"],\"env\":[{\"name\":\"CUDA_DEVICE_MAX_CONNECTIONS\",\"value\":\"1\"},{\"name\":\"NCCL_DEBUG\",\"value\":\"INFO\"},{\"name\":\"NCCL_IB_DISABLE\",\"value\":\"0\"},{\"name\":\"MASTER\",\"value\":\"1\"}],\"image\":\"registry.baidubce.com/cce-ai-native/aiak-megatron:ubuntu22.04-cu12.2-torch2.1.0-py310_v1.2.4.2\",\"imagePullPolicy\":\"Always\",\"name\":\"pytorch\",\"resources\":{\"limits\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1}},\"securityContext\":{\"capabilities\":{\"add\":[\"IPC_LOCK\"]}},\"volumeMounts\":[{\"mountPath\":\"/dev/shm\",\"name\":\"cache-volume\"},{\"mountPath\":\"/tmp\",\"name\":\"tmp-volume\"},{\"mountPath\":\"/workspace/Megatron-LM/examples/launch.sh\",\"name\":\"config-volume\",\"subPath\":\"launch.sh\"},{\"mountPath\":\"/mnt/cluster\",\"name\":\"data\"}]}],\"schedulerName\":\"volcano\",\"volumes\":[{\"emptyDir\":{\"medium\":\"Memory\"},\"name\":\"cache-volume\"},{\"emptyDir\":{\"medium\":\"Memory\"},\"name\":\"tmp-volume\"},{\"configMap\":{\"name\":\"robin4-task-for-8gpu\"},\"name\":\"config-volume\"},{\"name\":\"data\",\"persistentVolumeClaim\":{\"claimName\":\"pvc-pfs\"}}]}}}}}}\n"
            },
            "creationTimestamp": "2024-07-16T07:50:31Z",
            "generation": 2,
            "managedFields": [
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      ".": {},
                      "f:kubectl.kubernetes.io/last-applied-configuration": {}
                    }
                  },
                  "f:spec": {
                    ".": {},
                    "f:pytorchReplicaSpecs": {
                      ".": {},
                      "f:Master": {
                        ".": {},
                        "f:replicas": {},
                        "f:restartPolicy": {},
                        "f:template": {
                          ".": {},
                          "f:spec": {
                            ".": {},
                            "f:schedulerName": {},
                            "f:volumes": {}
                          }
                        }
                      }
                    }
                  }
                },
                "manager": "kubectl-client-side-apply",
                "operation": "Update",
                "time": "2024-07-16T07:50:31Z"
              },
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      "f:aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": {},
                      "f:aijob.cce.baidubce.com/timeline": {}
                    }
                  },
                  "f:spec": {
                    "f:pytorchReplicaSpecs": {
                      "f:Master": {
                        "f:template": {
                          "f:metadata": {},
                          "f:spec": {
                            "f:containers": {}
                          }
                        }
                      }
                    },
                    "f:runPolicy": {
                      ".": {},
                      "f:cleanPodPolicy": {}
                    }
                  }
                },
                "manager": "controller",
                "operation": "Update",
                "time": "2024-07-16T07:50:32Z"
              },
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:status": {
                    ".": {},
                    "f:completionTime": {},
                    "f:conditions": {},
                    "f:lastReconcileTime": {},
                    "f:replicaStatuses": {
                      ".": {},
                      "f:Master": {
                        ".": {},
                        "f:failed": {},
                        "f:selector": {}
                      }
                    },
                    "f:startTime": {}
                  }
                },
                "manager": "manager",
                "operation": "Update",
                "time": "2024-07-17T03:35:32Z"
              }
            ],
            "name": "robin4-task-for-8gpu",
            "namespace": "default",
            "resourceVersion": "2369998659",
            "uid": "938bee1a-1877-42e9-be00-da9d8f682f03"
          },
          "spec": {
            "pytorchReplicaSpecs": {
              "Master": {
                "replicas": 1,
                "restartPolicy": "Never",
                "template": {
                  "metadata": {},
                  "spec": {
                    "containers": [
                      {
                        "command": [
                          "bash",
                          "/workspace/Megatron-LM/examples/launch.sh"
                        ],
                        "env": [
                          {
                            "name": "CUDA_DEVICE_MAX_CONNECTIONS",
                            "value": "1"
                          },
                          {
                            "name": "NCCL_DEBUG",
                            "value": "INFO"
                          },
                          {
                            "name": "NCCL_IB_DISABLE",
                            "value": "0"
                          },
                          {
                            "name": "MASTER",
                            "value": "1"
                          }
                        ],
                        "image": "registry.baidubce.com/cce-ai-native/aiak-megatron:ubuntu22.04-cu12.2-torch2.1.0-py310_v1.2.4.2",
                        "imagePullPolicy": "Always",
                        "name": "pytorch",
                        "ports": [
                          {
                            "containerPort": 23456,
                            "name": "pytorchjob-port",
                            "protocol": "TCP"
                          }
                        ],
                        "resources": {
                          "limits": {
                            "baidu.com/a800_80g_cgpu": "8",
                            "rdma/hca": "1"
                          }
                        },
                        "securityContext": {
                          "capabilities": {
                            "add": [
                              "IPC_LOCK"
                            ]
                          }
                        },
                        "volumeMounts": [
                          {
                            "mountPath": "/dev/shm",
                            "name": "cache-volume"
                          },
                          {
                            "mountPath": "/tmp",
                            "name": "tmp-volume"
                          },
                          {
                            "mountPath": "/workspace/Megatron-LM/examples/launch.sh",
                            "name": "config-volume",
                            "subPath": "launch.sh"
                          },
                          {
                            "mountPath": "/mnt/cluster",
                            "name": "data"
                          }
                        ]
                      }
                    ],
                    "schedulerName": "volcano",
                    "volumes": [
                      {
                        "emptyDir": {
                          "medium": "Memory"
                        },
                        "name": "cache-volume"
                      },
                      {
                        "emptyDir": {
                          "medium": "Memory"
                        },
                        "name": "tmp-volume"
                      },
                      {
                        "configMap": {
                          "name": "robin4-task-for-8gpu"
                        },
                        "name": "config-volume"
                      },
                      {
                        "name": "data",
                        "persistentVolumeClaim": {
                          "claimName": "pvc-pfs"
                        }
                      }
                    ]
                  }
                }
              }
            },
            "runPolicy": {
              "cleanPodPolicy": "None"
            }
          },
          "status": {
            "completionTime": "2024-07-17T03:35:32Z",
            "conditions": [
              {
                "lastTransitionTime": "2024-07-16T07:50:31Z",
                "lastUpdateTime": "2024-07-16T07:50:31Z",
                "message": "PyTorchJob robin4-task-for-8gpu is created.",
                "reason": "PyTorchJobCreated",
                "status": "True",
                "type": "Created"
              },
              {
                "lastTransitionTime": "2024-07-16T07:56:19Z",
                "lastUpdateTime": "2024-07-16T07:56:19Z",
                "message": "PyTorchJob robin4-task-for-8gpu is running.",
                "reason": "JobRunning",
                "status": "False",
                "type": "Running"
              },
              {
                "lastTransitionTime": "2024-07-17T03:35:32Z",
                "lastUpdateTime": "2024-07-17T03:35:32Z",
                "message": "PyTorchJob robin4-task-for-8gpu is failed because 1 Master replica(s) failed.",
                "reason": "JobFailed",
                "status": "True",
                "type": "Failed"
              }
            ],
            "lastReconcileTime": "2024-07-16T07:50:32Z",
            "replicaStatuses": {
              "Master": {
                "failed": 1,
                "selector": "training.kubeflow.org/job-name=robin4-task-for-8gpu,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=master"
              }
            },
            "startTime": "2024-07-16T07:50:32Z"
          }
        },
        {
          "apiVersion": "kubeflow.org/v1",
          "kind": "PyTorchJob",
          "metadata": {
            "annotations": {
              "aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": "",
              "aijob.cce.baidubce.com/timeline": "[{\"conditionType\":\"Created\",\"time\":1721287168},{\"conditionType\":\"Scheduled\",\"time\":1721290353},{\"conditionType\":\"Running\",\"time\":1721290368},{\"conditionType\":\"Failed\",\"time\":1721614767}]",
              "job-manager/action-succeed": "stop",
              "kubectl.kubernetes.io/last-applied-configuration": "{\"apiVersion\":\"kubeflow.org/v1\",\"kind\":\"PyTorchJob\",\"metadata\":{\"annotations\":{},\"name\":\"robin5-task-for-8gpu\",\"namespace\":\"default\"},\"spec\":{\"pytorchReplicaSpecs\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"template\":{\"metadata\":null,\"spec\":{\"containers\":[{\"command\":[\"bash\",\"/workspace/Megatron-LM/examples/launch.sh\"],\"env\":[{\"name\":\"CUDA_DEVICE_MAX_CONNECTIONS\",\"value\":\"1\"},{\"name\":\"NCCL_DEBUG\",\"value\":\"INFO\"},{\"name\":\"NCCL_IB_DISABLE\",\"value\":\"0\"},{\"name\":\"MASTER\",\"value\":\"1\"}],\"image\":\"registry.baidubce.com/cce-ai-native/aiak-megatron:ubuntu22.04-cu12.2-torch2.1.0-py310_v1.2.4.2\",\"imagePullPolicy\":\"Always\",\"name\":\"pytorch\",\"resources\":{\"limits\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1}},\"securityContext\":{\"capabilities\":{\"add\":[\"IPC_LOCK\"]}},\"volumeMounts\":[{\"mountPath\":\"/dev/shm\",\"name\":\"cache-volume\"},{\"mountPath\":\"/tmp\",\"name\":\"tmp-volume\"},{\"mountPath\":\"/workspace/Megatron-LM/examples/launch.sh\",\"name\":\"config-volume\",\"subPath\":\"launch.sh\"},{\"mountPath\":\"/mnt/cluster\",\"name\":\"data\"}]}],\"schedulerName\":\"volcano\",\"volumes\":[{\"emptyDir\":{\"medium\":\"Memory\"},\"name\":\"cache-volume\"},{\"emptyDir\":{\"medium\":\"Memory\"},\"name\":\"tmp-volume\"},{\"configMap\":{\"name\":\"robin5-task-for-8gpu\"},\"name\":\"config-volume\"},{\"name\":\"data\",\"persistentVolumeClaim\":{\"claimName\":\"pvc-pfs\"}}]}}}}}}\n"
            },
            "creationTimestamp": "2024-07-18T07:19:28Z",
            "generation": 2,
            "managedFields": [
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      "f:aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": {},
                      "f:aijob.cce.baidubce.com/timeline": {}
                    }
                  },
                  "f:spec": {
                    "f:pytorchReplicaSpecs": {
                      "f:Master": {
                        "f:template": {
                          "f:metadata": {},
                          "f:spec": {
                            "f:containers": {}
                          }
                        }
                      }
                    },
                    "f:runPolicy": {
                      ".": {},
                      "f:cleanPodPolicy": {}
                    }
                  }
                },
                "manager": "controller",
                "operation": "Update",
                "time": "2024-07-18T07:19:28Z"
              },
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      ".": {},
                      "f:kubectl.kubernetes.io/last-applied-configuration": {}
                    }
                  },
                  "f:spec": {
                    ".": {},
                    "f:pytorchReplicaSpecs": {
                      ".": {},
                      "f:Master": {
                        ".": {},
                        "f:replicas": {},
                        "f:restartPolicy": {},
                        "f:template": {
                          ".": {},
                          "f:spec": {
                            ".": {},
                            "f:schedulerName": {},
                            "f:volumes": {}
                          }
                        }
                      }
                    }
                  }
                },
                "manager": "kubectl-client-side-apply",
                "operation": "Update",
                "time": "2024-07-18T07:19:28Z"
              },
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:status": {
                    ".": {},
                    "f:completionTime": {},
                    "f:conditions": {},
                    "f:lastReconcileTime": {},
                    "f:replicaStatuses": {
                      ".": {},
                      "f:Master": {
                        ".": {},
                        "f:failed": {},
                        "f:selector": {}
                      }
                    },
                    "f:startTime": {}
                  }
                },
                "manager": "manager",
                "operation": "Update",
                "time": "2024-07-22T02:19:27Z"
              },
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      "f:job-manager/action-succeed": {}
                    }
                  }
                },
                "manager": "ftagent",
                "operation": "Update",
                "time": "2024-07-22T02:19:34Z"
              }
            ],
            "name": "robin5-task-for-8gpu",
            "namespace": "default",
            "resourceVersion": "2375788011",
            "uid": "44eff632-1f0d-4042-8f0d-42be75e5543c"
          },
          "spec": {
            "pytorchReplicaSpecs": {
              "Master": {
                "replicas": 1,
                "restartPolicy": "Never",
                "template": {
                  "metadata": {},
                  "spec": {
                    "containers": [
                      {
                        "command": [
                          "bash",
                          "/workspace/Megatron-LM/examples/launch.sh"
                        ],
                        "env": [
                          {
                            "name": "CUDA_DEVICE_MAX_CONNECTIONS",
                            "value": "1"
                          },
                          {
                            "name": "NCCL_DEBUG",
                            "value": "INFO"
                          },
                          {
                            "name": "NCCL_IB_DISABLE",
                            "value": "0"
                          },
                          {
                            "name": "MASTER",
                            "value": "1"
                          }
                        ],
                        "image": "registry.baidubce.com/cce-ai-native/aiak-megatron:ubuntu22.04-cu12.2-torch2.1.0-py310_v1.2.4.2",
                        "imagePullPolicy": "Always",
                        "name": "pytorch",
                        "ports": [
                          {
                            "containerPort": 23456,
                            "name": "pytorchjob-port",
                            "protocol": "TCP"
                          }
                        ],
                        "resources": {
                          "limits": {
                            "baidu.com/a800_80g_cgpu": "8",
                            "rdma/hca": "1"
                          }
                        },
                        "securityContext": {
                          "capabilities": {
                            "add": [
                              "IPC_LOCK"
                            ]
                          }
                        },
                        "volumeMounts": [
                          {
                            "mountPath": "/dev/shm",
                            "name": "cache-volume"
                          },
                          {
                            "mountPath": "/tmp",
                            "name": "tmp-volume"
                          },
                          {
                            "mountPath": "/workspace/Megatron-LM/examples/launch.sh",
                            "name": "config-volume",
                            "subPath": "launch.sh"
                          },
                          {
                            "mountPath": "/mnt/cluster",
                            "name": "data"
                          }
                        ]
                      }
                    ],
                    "schedulerName": "volcano",
                    "volumes": [
                      {
                        "emptyDir": {
                          "medium": "Memory"
                        },
                        "name": "cache-volume"
                      },
                      {
                        "emptyDir": {
                          "medium": "Memory"
                        },
                        "name": "tmp-volume"
                      },
                      {
                        "configMap": {
                          "name": "robin5-task-for-8gpu"
                        },
                        "name": "config-volume"
                      },
                      {
                        "name": "data",
                        "persistentVolumeClaim": {
                          "claimName": "pvc-pfs"
                        }
                      }
                    ]
                  }
                }
              }
            },
            "runPolicy": {
              "cleanPodPolicy": "None"
            }
          },
          "status": {
            "completionTime": "2024-07-22T02:19:27Z",
            "conditions": [
              {
                "lastTransitionTime": "2024-07-18T07:19:28Z",
                "lastUpdateTime": "2024-07-18T07:19:28Z",
                "message": "PyTorchJob robin5-task-for-8gpu is created.",
                "reason": "PyTorchJobCreated",
                "status": "True",
                "type": "Created"
              },
              {
                "lastTransitionTime": "2024-07-18T08:12:48Z",
                "lastUpdateTime": "2024-07-18T08:12:48Z",
                "message": "PyTorchJob robin5-task-for-8gpu is running.",
                "reason": "JobRunning",
                "status": "False",
                "type": "Running"
              },
              {
                "lastTransitionTime": "2024-07-22T02:19:27Z",
                "lastUpdateTime": "2024-07-22T02:19:27Z",
                "message": "PyTorchJob robin5-task-for-8gpu is failed because 1 Master replica(s) failed.",
                "reason": "JobFailed",
                "status": "True",
                "type": "Failed"
              }
            ],
            "lastReconcileTime": "2024-07-18T07:23:50Z",
            "replicaStatuses": {
              "Master": {
                "failed": 1,
                "selector": "training.kubeflow.org/job-name=robin5-task-for-8gpu,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=master"
              }
            },
            "startTime": "2024-07-18T07:24:01Z"
          }
        },
        {
          "apiVersion": "kubeflow.org/v1",
          "kind": "PyTorchJob",
          "metadata": {
            "annotations": {
              "aijob.cce.baidubce.com/fault-tolerance-enabled": "true",
              "aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": "",
              "aijob.cce.baidubce.com/openapi-jobid": "pytorch-2dd06763-040a-41ee-bb76-5f222085f746",
              "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
              "aijob.cce.baidubce.com/raw-request": "{\"name\":\"test-pfs\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"normal\",\"oversell\":false,\"faultTolerance\":true,\"command\":\"sleep 36000\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/pfs\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":false,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihcp-public/pytorch\",\"tag\":\"22.08-py3\",\"resource\":{\"baidu.com/a800_80g_cgpu\":1,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"test-pfs\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":false,\"logPath\":\"\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":false,\"isCopyJob\":false,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
              "aijob.cce.baidubce.com/timeline": "[{\"conditionType\":\"Created\",\"time\":1721376494},{\"conditionType\":\"Scheduled\",\"time\":1721376496},{\"conditionType\":\"Running\",\"time\":1721376743},{\"conditionType\":\"Succeeded\",\"time\":1721412750}]",
              "scheduling.k8s.io/job-enable-oversell": "false"
            },
            "creationTimestamp": "2024-07-19T08:08:14Z",
            "generation": 2,
            "labels": {
              "aijob.cce.baidubce.com/ai-user-id": "60e7857753284b0e8da9689beead6615",
              "aijob.cce.baidubce.com/ai-user-name": "zhangwenjing01",
              "aijob.cce.baidubce.com/create-from-aihcp": "true",
              "aijob.cce.baidubce.com/openapi-jobid": "pytorch-2dd06763-040a-41ee-bb76-5f222085f746"
            },
            "managedFields": [
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      ".": {},
                      "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                      "f:aijob.cce.baidubce.com/openapi-jobid": {},
                      "f:aijob.cce.baidubce.com/pfs-id": {},
                      "f:aijob.cce.baidubce.com/raw-request": {},
                      "f:scheduling.k8s.io/job-enable-oversell": {}
                    },
                    "f:labels": {
                      ".": {},
                      "f:aijob.cce.baidubce.com/ai-user-id": {},
                      "f:aijob.cce.baidubce.com/ai-user-name": {},
                      "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                      "f:aijob.cce.baidubce.com/openapi-jobid": {}
                    }
                  },
                  "f:spec": {
                    ".": {},
                    "f:pytorchReplicaSpecs": {
                      ".": {},
                      "f:Master": {
                        ".": {},
                        "f:replicas": {},
                        "f:restartPolicy": {},
                        "f:template": {
                          ".": {},
                          "f:metadata": {
                            ".": {},
                            "f:annotations": {
                              ".": {},
                              "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                              "f:aijob.cce.baidubce.com/openapi-jobid": {},
                              "f:aijob.cce.baidubce.com/pfs-id": {},
                              "f:aijob.cce.baidubce.com/raw-request": {},
                              "f:scheduling.k8s.io/job-enable-oversell": {}
                            },
                            "f:labels": {
                              ".": {},
                              "f:aijob.cce.baidubce.com/ai-user-id": {},
                              "f:aijob.cce.baidubce.com/ai-user-name": {},
                              "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                              "f:aijob.cce.baidubce.com/openapi-jobid": {}
                            }
                          },
                          "f:spec": {
                            ".": {},
                            "f:schedulerName": {},
                            "f:volumes": {}
                          }
                        }
                      }
                    },
                    "f:runPolicy": {
                      ".": {},
                      "f:schedulingPolicy": {
                        ".": {},
                        "f:priorityClass": {},
                        "f:queue": {}
                      }
                    }
                  }
                },
                "manager": "cce-ai-service",
                "operation": "Update",
                "time": "2024-07-19T08:08:14Z"
              },
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      "f:aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": {},
                      "f:aijob.cce.baidubce.com/timeline": {}
                    }
                  },
                  "f:spec": {
                    "f:pytorchReplicaSpecs": {
                      "f:Master": {
                        "f:template": {
                          "f:spec": {
                            "f:containers": {}
                          }
                        }
                      }
                    },
                    "f:runPolicy": {
                      "f:cleanPodPolicy": {}
                    }
                  }
                },
                "manager": "controller",
                "operation": "Update",
                "time": "2024-07-19T08:08:14Z"
              },
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:status": {
                    ".": {},
                    "f:completionTime": {},
                    "f:conditions": {},
                    "f:lastReconcileTime": {},
                    "f:replicaStatuses": {
                      ".": {},
                      "f:Master": {
                        ".": {},
                        "f:selector": {},
                        "f:succeeded": {}
                      }
                    },
                    "f:startTime": {}
                  }
                },
                "manager": "manager",
                "operation": "Update",
                "time": "2024-07-19T18:12:30Z"
              }
            ],
            "name": "test-pfs",
            "namespace": "default",
            "resourceVersion": "2373153106",
            "uid": "07cb89c2-4fe7-4a74-ad4e-fe59c3bb207d"
          },
          "spec": {
            "pytorchReplicaSpecs": {
              "Master": {
                "replicas": 1,
                "restartPolicy": "Never",
                "template": {
                  "metadata": {
                    "annotations": {
                      "aijob.cce.baidubce.com/fault-tolerance-enabled": "true",
                      "aijob.cce.baidubce.com/openapi-jobid": "pytorch-2dd06763-040a-41ee-bb76-5f222085f746",
                      "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
                      "aijob.cce.baidubce.com/raw-request": "{\"name\":\"test-pfs\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"normal\",\"oversell\":false,\"faultTolerance\":true,\"command\":\"sleep 36000\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/pfs\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":false,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihcp-public/pytorch\",\"tag\":\"22.08-py3\",\"resource\":{\"baidu.com/a800_80g_cgpu\":1,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"test-pfs\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":false,\"logPath\":\"\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":false,\"isCopyJob\":false,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
                      "scheduling.k8s.io/job-enable-oversell": "false"
                    },
                    "labels": {
                      "aijob.cce.baidubce.com/ai-user-id": "60e7857753284b0e8da9689beead6615",
                      "aijob.cce.baidubce.com/ai-user-name": "zhangwenjing01",
                      "aijob.cce.baidubce.com/create-from-aihcp": "true",
                      "aijob.cce.baidubce.com/openapi-jobid": "pytorch-2dd06763-040a-41ee-bb76-5f222085f746"
                    }
                  },
                  "spec": {
                    "containers": [
                      {
                        "command": [
                          "/bin/bash",
                          "-c",
                          "sleep 36000"
                        ],
                        "env": [
                          {
                            "name": "AIHC_JOB_NAME",
                            "value": "test-pfs"
                          },
                          {
                            "name": "NCCL_IB_DISABLE",
                            "value": "0"
                          }
                        ],
                        "image": "registry.baidubce.com/aihcp-public/pytorch:22.08-py3",
                        "imagePullPolicy": "Always",
                        "name": "pytorch",
                        "ports": [
                          {
                            "containerPort": 23456,
                            "name": "pytorchjob-port",
                            "protocol": "TCP"
                          }
                        ],
                        "resources": {
                          "limits": {
                            "baidu.com/a800_80g_cgpu": "1",
                            "rdma/hca": "1"
                          },
                          "requests": {
                            "baidu.com/a800_80g_cgpu": "1",
                            "rdma/hca": "1"
                          }
                        },
                        "securityContext": {
                          "capabilities": {
                            "add": [
                              "IPC_LOCK"
                            ]
                          }
                        },
                        "volumeMounts": [
                          {
                            "mountPath": "/dev/shm",
                            "name": "devshm"
                          },
                          {
                            "mountPath": "/mnt/pfs",
                            "name": "pvc-pfs"
                          }
                        ]
                      }
                    ],
                    "schedulerName": "volcano",
                    "volumes": [
                      {
                        "emptyDir": {
                          "medium": "Memory",
                          "sizeLimit": "10Gi"
                        },
                        "name": "devshm"
                      },
                      {
                        "name": "pvc-pfs",
                        "persistentVolumeClaim": {
                          "claimName": "pvc-pfs"
                        }
                      }
                    ]
                  }
                }
              }
            },
            "runPolicy": {
              "cleanPodPolicy": "None",
              "schedulingPolicy": {
                "priorityClass": "normal",
                "queue": "default"
              }
            }
          },
          "status": {
            "completionTime": "2024-07-19T18:12:30Z",
            "conditions": [
              {
                "lastTransitionTime": "2024-07-19T08:08:14Z",
                "lastUpdateTime": "2024-07-19T08:08:14Z",
                "message": "PyTorchJob test-pfs is created.",
                "reason": "PyTorchJobCreated",
                "status": "True",
                "type": "Created"
              },
              {
                "lastTransitionTime": "2024-07-19T08:12:23Z",
                "lastUpdateTime": "2024-07-19T08:12:23Z",
                "message": "PyTorchJob test-pfs is running.",
                "reason": "JobRunning",
                "status": "False",
                "type": "Running"
              },
              {
                "lastTransitionTime": "2024-07-19T18:12:30Z",
                "lastUpdateTime": "2024-07-19T18:12:30Z",
                "message": "PyTorchJob test-pfs is successfully completed.",
                "reason": "JobSucceeded",
                "status": "True",
                "type": "Succeeded"
              }
            ],
            "lastReconcileTime": "2024-07-19T08:08:14Z",
            "replicaStatuses": {
              "Master": {
                "selector": "training.kubeflow.org/job-name=test-pfs,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=master",
                "succeeded": 1
              }
            },
            "startTime": "2024-07-19T08:08:15Z"
          }
        },
        {
          "apiVersion": "kubeflow.org/v1",
          "kind": "PyTorchJob",
          "metadata": {
            "annotations": {
              "aijob.cce.baidubce.com/fault-tolerance-enabled": "true",
              "aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": "",
              "aijob.cce.baidubce.com/internal-fault-tolerance-time": "2024-07-15T07:23:58.72041018Z",
              "aijob.cce.baidubce.com/openapi-jobid": "pytorch-0d2baffc-5ac5-40ff-98be-56b4f25eb192",
              "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
              "aijob.cce.baidubce.com/raw-request": "{\"name\":\"testlxq-1\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"normal\",\"oversell\":false,\"faultTolerance\":true,\"command\":\"sleep-inf\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":false,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihcp-public/pytorch\",\"tag\":\"22.08-py3\",\"resource\":{\"baidu.com/a800_80g_cgpu\":1,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"testlxq-1\",\"LOG_COLLECTION\":\"true\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":false,\"logPath\":\"\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":false,\"isCopyJob\":true,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
              "aijob.cce.baidubce.com/timeline": "[{\"conditionType\":\"Created\",\"time\":1721027977},{\"conditionType\":\"Scheduled\",\"time\":1721027979},{\"conditionType\":\"Running\",\"time\":1721028208},{\"conditionType\":\"Abnormal\",\"time\":1721028238},{\"conditionType\":\"Failed\",\"time\":1721028843}]",
              "scheduling.k8s.io/job-enable-oversell": "false"
            },
            "creationTimestamp": "2024-07-15T07:19:37Z",
            "generation": 3,
            "labels": {
              "aijob.cce.baidubce.com/ai-user-id": "d2871024f2904725b16e04b75914d9ca",
              "aijob.cce.baidubce.com/ai-user-name": "xingyushan",
              "aijob.cce.baidubce.com/create-from-aihcp": "true",
              "aijob.cce.baidubce.com/openapi-jobid": "pytorch-0d2baffc-5ac5-40ff-98be-56b4f25eb192"
            },
            "managedFields": [
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      ".": {},
                      "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                      "f:aijob.cce.baidubce.com/openapi-jobid": {},
                      "f:aijob.cce.baidubce.com/pfs-id": {},
                      "f:aijob.cce.baidubce.com/raw-request": {},
                      "f:scheduling.k8s.io/job-enable-oversell": {}
                    },
                    "f:labels": {
                      ".": {},
                      "f:aijob.cce.baidubce.com/ai-user-id": {},
                      "f:aijob.cce.baidubce.com/ai-user-name": {},
                      "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                      "f:aijob.cce.baidubce.com/openapi-jobid": {}
                    }
                  },
                  "f:spec": {
                    ".": {},
                    "f:pytorchReplicaSpecs": {
                      ".": {},
                      "f:Master": {
                        ".": {},
                        "f:replicas": {},
                        "f:restartPolicy": {},
                        "f:template": {
                          ".": {},
                          "f:metadata": {
                            ".": {},
                            "f:annotations": {
                              ".": {},
                              "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                              "f:aijob.cce.baidubce.com/openapi-jobid": {},
                              "f:aijob.cce.baidubce.com/pfs-id": {},
                              "f:aijob.cce.baidubce.com/raw-request": {},
                              "f:scheduling.k8s.io/job-enable-oversell": {}
                            },
                            "f:labels": {
                              ".": {},
                              "f:aijob.cce.baidubce.com/ai-user-id": {},
                              "f:aijob.cce.baidubce.com/ai-user-name": {},
                              "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                              "f:aijob.cce.baidubce.com/openapi-jobid": {}
                            }
                          },
                          "f:spec": {
                            ".": {},
                            "f:schedulerName": {}
                          }
                        }
                      }
                    },
                    "f:runPolicy": {
                      ".": {},
                      "f:schedulingPolicy": {
                        ".": {},
                        "f:priorityClass": {},
                        "f:queue": {}
                      }
                    }
                  }
                },
                "manager": "cce-ai-service",
                "operation": "Update",
                "time": "2024-07-15T07:19:37Z"
              },
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      "f:aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": {},
                      "f:aijob.cce.baidubce.com/timeline": {}
                    }
                  },
                  "f:spec": {
                    "f:runPolicy": {
                      "f:cleanPodPolicy": {}
                    }
                  }
                },
                "manager": "controller",
                "operation": "Update",
                "time": "2024-07-15T07:19:37Z"
              },
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      "f:aijob.cce.baidubce.com/internal-fault-tolerance-time": {}
                    }
                  },
                  "f:spec": {
                    "f:pytorchReplicaSpecs": {
                      "f:Master": {
                        "f:template": {
                          "f:metadata": {
                            "f:annotations": {
                              "f:prometheus.io/path": {},
                              "f:prometheus.io/port": {},
                              "f:prometheus.io/scrape": {}
                            }
                          },
                          "f:spec": {
                            "f:containers": {},
                            "f:serviceAccountName": {},
                            "f:shareProcessNamespace": {},
                            "f:volumes": {}
                          }
                        }
                      }
                    }
                  },
                  "f:status": {
                    ".": {},
                    "f:completionTime": {},
                    "f:conditions": {},
                    "f:lastReconcileTime": {},
                    "f:replicaStatuses": {
                      ".": {},
                      "f:Master": {
                        ".": {},
                        "f:failed": {},
                        "f:selector": {}
                      }
                    },
                    "f:startTime": {}
                  }
                },
                "manager": "manager",
                "operation": "Update",
                "time": "2024-07-15T07:34:03Z"
              }
            ],
            "name": "testlxq-1",
            "namespace": "default",
            "resourceVersion": "2367492714",
            "uid": "f235bcb8-431b-421c-96a5-0a520cc110c8"
          },
          "spec": {
            "pytorchReplicaSpecs": {
              "Master": {
                "replicas": 1,
                "restartPolicy": "Never",
                "template": {
                  "metadata": {
                    "annotations": {
                      "aijob.cce.baidubce.com/fault-tolerance-enabled": "true",
                      "aijob.cce.baidubce.com/openapi-jobid": "pytorch-0d2baffc-5ac5-40ff-98be-56b4f25eb192",
                      "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
                      "aijob.cce.baidubce.com/raw-request": "{\"name\":\"testlxq-1\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"normal\",\"oversell\":false,\"faultTolerance\":true,\"command\":\"sleep-inf\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":false,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihcp-public/pytorch\",\"tag\":\"22.08-py3\",\"resource\":{\"baidu.com/a800_80g_cgpu\":1,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"testlxq-1\",\"LOG_COLLECTION\":\"true\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":false,\"logPath\":\"\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":false,\"isCopyJob\":true,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
                      "prometheus.io/path": "/metrics",
                      "prometheus.io/port": "9101",
                      "prometheus.io/scrape": "true",
                      "scheduling.k8s.io/job-enable-oversell": "false"
                    },
                    "labels": {
                      "aijob.cce.baidubce.com/ai-user-id": "d2871024f2904725b16e04b75914d9ca",
                      "aijob.cce.baidubce.com/ai-user-name": "xingyushan",
                      "aijob.cce.baidubce.com/create-from-aihcp": "true",
                      "aijob.cce.baidubce.com/openapi-jobid": "pytorch-0d2baffc-5ac5-40ff-98be-56b4f25eb192"
                    }
                  },
                  "spec": {
                    "containers": [
                      {
                        "command": [
                          "/bin/bash",
                          "-c",
                          "sleep-inf"
                        ],
                        "env": [
                          {
                            "name": "LOG_COLLECTION",
                            "value": "true"
                          },
                          {
                            "name": "AIHC_JOB_NAME",
                            "value": "testlxq-1"
                          },
                          {
                            "name": "NCCL_IB_DISABLE",
                            "value": "0"
                          },
                          {
                            "name": "BCCL_BUS_BW_CALCULATE_MODE",
                            "value": "Agg"
                          },
                          {
                            "name": "BCCL_PROFILING_FILE",
                            "value": "/var/bccl/logs/busbw.cal.%h.%p"
                          }
                        ],
                        "image": "registry.baidubce.com/aihcp-public/pytorch:22.08-py3",
                        "imagePullPolicy": "Always",
                        "name": "pytorch",
                        "ports": [
                          {
                            "containerPort": 23456,
                            "name": "pytorchjob-port",
                            "protocol": "TCP"
                          }
                        ],
                        "resources": {
                          "limits": {
                            "baidu.com/a800_80g_cgpu": "1",
                            "rdma/hca": "1"
                          },
                          "requests": {
                            "baidu.com/a800_80g_cgpu": "1",
                            "rdma/hca": "1"
                          }
                        },
                        "securityContext": {
                          "capabilities": {
                            "add": [
                              "IPC_LOCK"
                            ]
                          }
                        },
                        "volumeMounts": [
                          {
                            "mountPath": "/dev/shm",
                            "name": "devshm"
                          },
                          {
                            "mountPath": "/mnt/cluster",
                            "name": "pvc-pfs"
                          },
                          {
                            "mountPath": "/var/bccl/logs",
                            "name": "bccl-logs-volume"
                          }
                        ]
                      },
                      {
                        "env": [
                          {
                            "name": "POD_NAME",
                            "valueFrom": {
                              "fieldRef": {
                                "apiVersion": "v1",
                                "fieldPath": "metadata.name"
                              }
                            }
                          },
                          {
                            "name": "POD_UID",
                            "valueFrom": {
                              "fieldRef": {
                                "apiVersion": "v1",
                                "fieldPath": "metadata.uid"
                              }
                            }
                          },
                          {
                            "name": "POD_NAMESPACE",
                            "valueFrom": {
                              "fieldRef": {
                                "apiVersion": "v1",
                                "fieldPath": "metadata.namespace"
                              }
                            }
                          },
                          {
                            "name": "NODE_NAME",
                            "valueFrom": {
                              "fieldRef": {
                                "apiVersion": "v1",
                                "fieldPath": "spec.nodeName"
                              }
                            }
                          },
                          {
                            "name": "JOB_NAME",
                            "value": "testlxq-1"
                          },
                          {
                            "name": "NODE_IP",
                            "valueFrom": {
                              "fieldRef": {
                                "apiVersion": "v1",
                                "fieldPath": "status.hostIP"
                              }
                            }
                          },
                          {
                            "name": "ENABLE_ELASTIC",
                            "value": "9"
                          },
                          {
                            "name": "GPUS_PER_NODE",
                            "value": "1"
                          },
                          {
                            "name": "BCCL_LOG_DIR",
                            "value": "/var/bccl/logs"
                          },
                          {
                            "name": "EXPORTER_PORT",
                            "value": "9101"
                          },
                          {
                            "name": "EXPORTER_INTERVAL",
                            "value": "60"
                          },
                          {
                            "name": "EXPORTER_PATH",
                            "value": "/metrics"
                          },
                          {
                            "name": "BCCL_BUS_BW_CALCULATE_MODE",
                            "value": "Agg"
                          },
                          {
                            "name": "BCCL_PROFILING_FILE",
                            "value": "/var/bccl/logs/busbw.cal.%h.%p"
                          }
                        ],
                        "image": "registry.baidubce.com/cce-plugin-dev/ftagent:v1.6-20240713172215",
                        "imagePullPolicy": "Always",
                        "name": "ftagent",
                        "ports": [
                          {
                            "containerPort": 9101,
                            "name": "exporter",
                            "protocol": "TCP"
                          }
                        ],
                        "resources": {},
                        "securityContext": {
                          "capabilities": {
                            "add": [
                              "IPC_LOCK"
                            ]
                          }
                        },
                        "volumeMounts": [
                          {
                            "mountPath": "/var/log/pods",
                            "name": "pod-log-volume"
                          },
                          {
                            "mountPath": "/home/cce",
                            "name": "container-log-volume"
                          },
                          {
                            "mountPath": "/var/bccl/logs",
                            "name": "bccl-logs-volume"
                          }
                        ]
                      }
                    ],
                    "schedulerName": "volcano",
                    "serviceAccountName": "ftagent-sa",
                    "shareProcessNamespace": true,
                    "volumes": [
                      {
                        "emptyDir": {
                          "medium": "Memory",
                          "sizeLimit": "10Gi"
                        },
                        "name": "devshm"
                      },
                      {
                        "name": "pvc-pfs",
                        "persistentVolumeClaim": {
                          "claimName": "pvc-pfs"
                        }
                      },
                      {
                        "emptyDir": {},
                        "name": "bccl-logs-volume"
                      },
                      {
                        "hostPath": {
                          "path": "/var/log/pods",
                          "type": "DirectoryOrCreate"
                        },
                        "name": "pod-log-volume"
                      },
                      {
                        "hostPath": {
                          "path": "/home/cce",
                          "type": "DirectoryOrCreate"
                        },
                        "name": "container-log-volume"
                      }
                    ]
                  }
                }
              }
            },
            "runPolicy": {
              "cleanPodPolicy": "None",
              "schedulingPolicy": {
                "priorityClass": "normal",
                "queue": "default"
              }
            }
          },
          "status": {
            "completionTime": "2024-07-15T07:34:03Z",
            "conditions": [
              {
                "lastTransitionTime": "2024-07-15T07:19:37Z",
                "lastUpdateTime": "2024-07-15T07:19:37Z",
                "message": "PyTorchJob testlxq-1 is created.",
                "reason": "PyTorchJobCreated",
                "status": "True",
                "type": "Created"
              },
              {
                "lastTransitionTime": "2024-07-15T07:23:28Z",
                "lastUpdateTime": "2024-07-15T07:23:28Z",
                "message": "PyTorchJob testlxq-1 is running.",
                "reason": "JobRunning",
                "status": "False",
                "type": "Running"
              },
              {
                "lastTransitionTime": "2024-07-15T07:34:03Z",
                "lastUpdateTime": "2024-07-15T07:34:03Z",
                "message": "PyTorchJob testlxq-1 is failed because 1 Master replica(s) failed.",
                "reason": "JobFailed",
                "status": "True",
                "type": "Failed"
              }
            ],
            "lastReconcileTime": "2024-07-15T07:19:37Z",
            "replicaStatuses": {
              "Master": {
                "failed": 1,
                "selector": "training.kubeflow.org/job-name=testlxq-1,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=master"
              }
            },
            "startTime": "2024-07-15T07:19:38Z"
          }
        },
        {
          "apiVersion": "kubeflow.org/v1",
          "kind": "PyTorchJob",
          "metadata": {
            "annotations": {
              "aijob.cce.baidubce.com/barrier-finish": "9ca2c9b5-f186-4fb9-bdf1-44c4c700365e",
              "aijob.cce.baidubce.com/fault-tolerance-enabled": "true",
              "aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": "",
              "aijob.cce.baidubce.com/timeline": "[{\"conditionType\":\"Created\",\"time\":1721668050},{\"conditionType\":\"Scheduled\",\"time\":1721668052},{\"conditionType\":\"Running\",\"time\":1721668246}]",
              "kubectl.kubernetes.io/last-applied-configuration": "{\"apiVersion\":\"kubeflow.org/v1\",\"kind\":\"PyTorchJob\",\"metadata\":{\"annotations\":{},\"name\":\"wangzhuyun-accelerate-open-sora-plan\",\"namespace\":\"default\"},\"spec\":{\"pytorchReplicaSpecs\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"template\":{\"metadata\":null,\"spec\":{\"containers\":[{\"command\":[\"bash\",\"/workspace/Open-Sora-Plan/launch.sh\"],\"env\":[{\"name\":\"CUDA_DEVICE_MAX_CONNECTIONS\",\"value\":\"1\"},{\"name\":\"NCCL_DEBUG\",\"value\":\"INFO\"},{\"name\":\"NCCL_IB_DISABLE\",\"value\":\"0\"},{\"name\":\"MASTER\",\"value\":\"1\"}],\"image\":\"registry.baidubce.com/cce-ai-native/open_sora_plan:v1.1.0\",\"imagePullPolicy\":\"Always\",\"name\":\"pytorch\",\"resources\":{\"limits\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1}},\"securityContext\":{\"capabilities\":{\"add\":[\"IPC_LOCK\"]}},\"volumeMounts\":[{\"mountPath\":\"/dev/shm\",\"name\":\"cache-volume\"},{\"mountPath\":\"/workspace/Open-Sora-Plan/launch.sh\",\"name\":\"config-volume\",\"subPath\":\"launch.sh\"},{\"mountPath\":\"/remote-home1\",\"name\":\"data\"}]}],\"dnsPolicy\":\"ClusterFirstWithHostNet\",\"hostNetwork\":true,\"schedulerName\":\"volcano\",\"tolerations\":[{\"operator\":\"Exists\"}],\"volumes\":[{\"emptyDir\":{\"medium\":\"Memory\"},\"name\":\"cache-volume\"},{\"configMap\":{\"name\":\"launch-cm-open-sora-plan\"},\"name\":\"config-volume\"},{\"name\":\"data\",\"persistentVolumeClaim\":{\"claimName\":\"pvc-pfs\"}}]}}},\"Worker\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"template\":{\"metadata\":null,\"spec\":{\"containers\":[{\"command\":[\"bash\",\"/workspace/Open-Sora-Plan/launch.sh\"],\"env\":[{\"name\":\"CUDA_DEVICE_MAX_CONNECTIONS\",\"value\":\"1\"},{\"name\":\"NCCL_DEBUG\",\"value\":\"INFO\"},{\"name\":\"NCCL_IB_DISABLE\",\"value\":\"0\"}],\"image\":\"registry.baidubce.com/cce-ai-native/open_sora_plan:v1.1.0\",\"imagePullPolicy\":\"Always\",\"name\":\"pytorch\",\"resources\":{\"limits\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1}},\"securityContext\":{\"capabilities\":{\"add\":[\"IPC_LOCK\"]}},\"volumeMounts\":[{\"mountPath\":\"/dev/shm\",\"name\":\"cache-volume\"},{\"mountPath\":\"/workspace/Open-Sora-Plan/launch.sh\",\"name\":\"config-volume\",\"subPath\":\"launch.sh\"},{\"mountPath\":\"/remote-home1\",\"name\":\"data\"}]}],\"dnsPolicy\":\"ClusterFirstWithHostNet\",\"hostNetwork\":true,\"schedulerName\":\"volcano\",\"tolerations\":[{\"operator\":\"Exists\"}],\"volumes\":[{\"emptyDir\":{\"medium\":\"Memory\"},\"name\":\"cache-volume\"},{\"configMap\":{\"name\":\"launch-cm-open-sora-plan\"},\"name\":\"config-volume\"},{\"name\":\"data\",\"persistentVolumeClaim\":{\"claimName\":\"pvc-pfs\"}}]}}}}}}\n"
            },
            "creationTimestamp": "2024-07-22T17:07:30Z",
            "generation": 2,
            "managedFields": [
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      "f:aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": {},
                      "f:aijob.cce.baidubce.com/timeline": {}
                    }
                  }
                },
                "manager": "controller",
                "operation": "Update",
                "time": "2024-07-22T17:07:30Z"
              },
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      ".": {},
                      "f:kubectl.kubernetes.io/last-applied-configuration": {}
                    }
                  },
                  "f:spec": {
                    ".": {},
                    "f:pytorchReplicaSpecs": {
                      ".": {},
                      "f:Master": {
                        ".": {},
                        "f:replicas": {},
                        "f:restartPolicy": {},
                        "f:template": {
                          ".": {},
                          "f:spec": {
                            ".": {},
                            "f:dnsPolicy": {},
                            "f:hostNetwork": {},
                            "f:schedulerName": {},
                            "f:tolerations": {},
                            "f:volumes": {}
                          }
                        }
                      },
                      "f:Worker": {
                        ".": {},
                        "f:replicas": {},
                        "f:restartPolicy": {},
                        "f:template": {
                          ".": {},
                          "f:spec": {
                            ".": {},
                            "f:dnsPolicy": {},
                            "f:hostNetwork": {},
                            "f:schedulerName": {},
                            "f:tolerations": {},
                            "f:volumes": {}
                          }
                        }
                      }
                    }
                  }
                },
                "manager": "kubectl-client-side-apply",
                "operation": "Update",
                "time": "2024-07-22T17:07:30Z"
              },
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      "f:aijob.cce.baidubce.com/barrier-finish": {}
                    }
                  }
                },
                "manager": "jobbarrier",
                "operation": "Update",
                "time": "2024-07-22T17:10:42Z"
              },
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {}
                    }
                  },
                  "f:spec": {
                    "f:pytorchReplicaSpecs": {
                      "f:Master": {
                        "f:template": {
                          "f:metadata": {},
                          "f:spec": {
                            "f:containers": {}
                          }
                        }
                      },
                      "f:Worker": {
                        "f:template": {
                          "f:metadata": {},
                          "f:spec": {
                            "f:containers": {}
                          }
                        }
                      }
                    },
                    "f:runPolicy": {
                      ".": {},
                      "f:cleanPodPolicy": {}
                    }
                  },
                  "f:status": {
                    ".": {},
                    "f:conditions": {},
                    "f:lastReconcileTime": {},
                    "f:replicaStatuses": {
                      ".": {},
                      "f:Master": {
                        ".": {},
                        "f:active": {},
                        "f:selector": {}
                      },
                      "f:Worker": {
                        ".": {},
                        "f:active": {},
                        "f:selector": {}
                      }
                    },
                    "f:startTime": {}
                  }
                },
                "manager": "manager",
                "operation": "Update",
                "time": "2024-07-22T17:10:51Z"
              }
            ],
            "name": "wangzhuyun-accelerate-open-sora-plan",
            "namespace": "default",
            "resourceVersion": "2376578060",
            "uid": "7b721fc4-9bc9-4206-a741-84439f7ea51b"
          },
          "spec": {
            "pytorchReplicaSpecs": {
              "Master": {
                "replicas": 1,
                "restartPolicy": "Never",
                "template": {
                  "metadata": {},
                  "spec": {
                    "containers": [
                      {
                        "command": [
                          "bash",
                          "/workspace/Open-Sora-Plan/launch.sh"
                        ],
                        "env": [
                          {
                            "name": "CUDA_DEVICE_MAX_CONNECTIONS",
                            "value": "1"
                          },
                          {
                            "name": "NCCL_DEBUG",
                            "value": "INFO"
                          },
                          {
                            "name": "NCCL_IB_DISABLE",
                            "value": "0"
                          },
                          {
                            "name": "MASTER",
                            "value": "1"
                          }
                        ],
                        "image": "registry.baidubce.com/cce-ai-native/open_sora_plan:v1.1.0",
                        "imagePullPolicy": "Always",
                        "name": "pytorch",
                        "ports": [
                          {
                            "containerPort": 23456,
                            "name": "pytorchjob-port",
                            "protocol": "TCP"
                          }
                        ],
                        "resources": {
                          "limits": {
                            "baidu.com/a800_80g_cgpu": "8",
                            "rdma/hca": "1"
                          }
                        },
                        "securityContext": {
                          "capabilities": {
                            "add": [
                              "IPC_LOCK"
                            ]
                          }
                        },
                        "volumeMounts": [
                          {
                            "mountPath": "/dev/shm",
                            "name": "cache-volume"
                          },
                          {
                            "mountPath": "/workspace/Open-Sora-Plan/launch.sh",
                            "name": "config-volume",
                            "subPath": "launch.sh"
                          },
                          {
                            "mountPath": "/remote-home1",
                            "name": "data"
                          }
                        ]
                      }
                    ],
                    "dnsPolicy": "ClusterFirstWithHostNet",
                    "hostNetwork": true,
                    "schedulerName": "volcano",
                    "tolerations": [
                      {
                        "operator": "Exists"
                      }
                    ],
                    "volumes": [
                      {
                        "emptyDir": {
                          "medium": "Memory"
                        },
                        "name": "cache-volume"
                      },
                      {
                        "configMap": {
                          "name": "launch-cm-open-sora-plan"
                        },
                        "name": "config-volume"
                      },
                      {
                        "name": "data",
                        "persistentVolumeClaim": {
                          "claimName": "pvc-pfs"
                        }
                      }
                    ]
                  }
                }
              },
              "Worker": {
                "replicas": 1,
                "restartPolicy": "Never",
                "template": {
                  "metadata": {},
                  "spec": {
                    "containers": [
                      {
                        "command": [
                          "bash",
                          "/workspace/Open-Sora-Plan/launch.sh"
                        ],
                        "env": [
                          {
                            "name": "CUDA_DEVICE_MAX_CONNECTIONS",
                            "value": "1"
                          },
                          {
                            "name": "NCCL_DEBUG",
                            "value": "INFO"
                          },
                          {
                            "name": "NCCL_IB_DISABLE",
                            "value": "0"
                          }
                        ],
                        "image": "registry.baidubce.com/cce-ai-native/open_sora_plan:v1.1.0",
                        "imagePullPolicy": "Always",
                        "name": "pytorch",
                        "ports": [
                          {
                            "containerPort": 23456,
                            "name": "pytorchjob-port",
                            "protocol": "TCP"
                          }
                        ],
                        "resources": {
                          "limits": {
                            "baidu.com/a800_80g_cgpu": "8",
                            "rdma/hca": "1"
                          }
                        },
                        "securityContext": {
                          "capabilities": {
                            "add": [
                              "IPC_LOCK"
                            ]
                          }
                        },
                        "volumeMounts": [
                          {
                            "mountPath": "/dev/shm",
                            "name": "cache-volume"
                          },
                          {
                            "mountPath": "/workspace/Open-Sora-Plan/launch.sh",
                            "name": "config-volume",
                            "subPath": "launch.sh"
                          },
                          {
                            "mountPath": "/remote-home1",
                            "name": "data"
                          }
                        ]
                      }
                    ],
                    "dnsPolicy": "ClusterFirstWithHostNet",
                    "hostNetwork": true,
                    "schedulerName": "volcano",
                    "tolerations": [
                      {
                        "operator": "Exists"
                      }
                    ],
                    "volumes": [
                      {
                        "emptyDir": {
                          "medium": "Memory"
                        },
                        "name": "cache-volume"
                      },
                      {
                        "configMap": {
                          "name": "launch-cm-open-sora-plan"
                        },
                        "name": "config-volume"
                      },
                      {
                        "name": "data",
                        "persistentVolumeClaim": {
                          "claimName": "pvc-pfs"
                        }
                      }
                    ]
                  }
                }
              }
            },
            "runPolicy": {
              "cleanPodPolicy": "None"
            }
          },
          "status": {
            "conditions": [
              {
                "lastTransitionTime": "2024-07-22T17:07:30Z",
                "lastUpdateTime": "2024-07-22T17:07:30Z",
                "message": "PyTorchJob wangzhuyun-accelerate-open-sora-plan is created.",
                "reason": "PyTorchJobCreated",
                "status": "True",
                "type": "Created"
              },
              {
                "lastTransitionTime": "2024-07-22T17:10:46Z",
                "lastUpdateTime": "2024-07-22T17:10:46Z",
                "message": "PyTorchJob wangzhuyun-accelerate-open-sora-plan is running.",
                "reason": "JobRunning",
                "status": "True",
                "type": "Running"
              }
            ],
            "lastReconcileTime": "2024-07-22T17:07:30Z",
            "replicaStatuses": {
              "Master": {
                "active": 1,
                "selector": "training.kubeflow.org/job-name=wangzhuyun-accelerate-open-sora-plan,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=master"
              },
              "Worker": {
                "active": 1,
                "selector": "training.kubeflow.org/job-name=wangzhuyun-accelerate-open-sora-plan,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=worker"
              }
            },
            "startTime": "2024-07-22T17:07:31Z"
          }
        },
        {
          "apiVersion": "kubeflow.org/v1",
          "kind": "PyTorchJob",
          "metadata": {
            "annotations": {
              "aijob.cce.baidubce.com/barrier-finish": "72c47958-95fe-4174-86ce-0ae3e8eba4f5",
              "aijob.cce.baidubce.com/fault-tolerance-enabled": "false",
              "aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": "",
              "aijob.cce.baidubce.com/openapi-jobid": "pytorch-b3c9ce0b-1e76-427d-a2d7-eea086048d3d",
              "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
              "aijob.cce.baidubce.com/raw-request": "{\"name\":\"whx-llama-test-3\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"normal\",\"oversell\":false,\"faultTolerance\":false,\"command\":\"/bin/bash -c\\n#! /bin/bash\\n#rm /workspace/llama/pile_llama_test/*_indexmap*\\n#rm -rf /workspace/llama/pile_llama_test/pile_test_jsonl/\\nROOT_DIR=/workspace/Megatron-LM/examples\\n# 数据集及CHECKPOINT的PATH可按需替换成用户自定义路径\\nDATA_PATH=/mnt/cluster/llama/pile_llama_test/pile-llama_text_document\\nTOKENIZER_PATH=/mnt/cluster/llama/tokenizer/tokenizer.model\\nTENSORBOARD_PATH=/workspace\\n\\nMOUNT_PATH=/mnt/cluster\\nPATH_RESOURCE=/workspace/llama\\n\\n\\n# Ensure the mount path exists\\nmkdir -p ${MOUNT_PATH}\\necho \\\"Contents of MOUNT_PATH before copy:\\\"\\nls -l ${MOUNT_PATH}\\n\\n# Copy data to the mount path\\ncp -r ${PATH_RESOURCE} ${MOUNT_PATH} || { echo \\\"Failed to copy PATH_RESOURCE\\\"; exit 1; }\\n\\necho \\\"Contents of MOUNT_PATH after copy:\\\"\\nls -l ${MOUNT_PATH}\\n\\n\\nGPUS_PER_NODE=8\\n\\nDISTRIBUTED_ARGS=\\\"--nproc_per_node ${GPUS_PER_NODE} --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $MASTER_ADDR --master_port $MASTER_PORT\\\"\\nLLAMA2_7B_ARGS=\\\"--tensor-model-parallel-size 1 \\\\\\n--pipeline-model-parallel-size 2 \\\\\\n--num-layers 32 \\\\\\n--hidden-size 4096 \\\\\\n--ffn-hidden-size 11008 \\\\\\n--num-attention-heads 32 \\\\\\n--micro-batch-size 1 \\\\\\n--global-batch-size 16 \\\\\\n--seq-length 512 \\\\\\n--max-position-embeddings 4096 \\\\\\n--lr 0.0003 \\\\\\n--min-lr 1.0e-5 \\\\\\n--clip-grad 1.0 \\\\\\n--weight-decay 1e-2 \\\\\\n--optimizer adam \\\\\\n--adam-beta1 0.9 \\\\\\n--adam-beta2 0.95 \\\\\\n--adam-eps 1e-05 \\\\\\n--train-iters 5000 \\\\\\n--lr-decay-iters 320000 \\\\\\n--lr-decay-style cosine \\\\\\n--lr-warmup-fraction .01 \\\\\\n--no-async-tensor-model-parallel-allreduce \\\\\\n--tokenizer-type LLaMASentencePieceTokenizer \\\\\\n--tokenizer-model $TOKENIZER_PATH \\\\\\n--activation-func swiglu \\\\\\n--use-rotary-position-embeddings \\\\\\n--rmsnorm-epsilon 1e-5 \\\\\\n--no-position-embedding \\\\\\n--disable-bias-linear \\\\\\n--attention-dropout 0 \\\\\\n--hidden-dropout 0 \\\\\\n--embedding-dropout 0 \\\\\\n--use-distributed-optimizer \\\\\\n--untie-embeddings-and-output-weights \\\\\\n--initial-loss-scale 16 \\\\\\n--sequence-parallel \\\\\\n--fused-rmsnorm \\\\\\n--fp16\\\"\\n\\nOUTPUT_ARGS=\\\"--log-interval 1 \\\\\\n --save-interval 50000 \\\\\\n --eval-interval 1000 \\\\\\n --eval-iters 10\\\"\\n\\nOTHER_ARGS=\\\"--data-path $DATA_PATH \\\\\\n--data-impl mmap \\\\\\n--split 949,50,1 \\\\\\n--tensorboard-dir ${TENSORBOARD_PATH} \\\\\\n--distributed-backend nccl\\\"\\n\\nPYTHONPATH=\\\"$ROOT_DIR/..\\\":\\\"$ROOT_DIR/../megatron/fused_kernels\\\":$PYTHONPATH \\\\\\npython -m torch.distributed.launch $DISTRIBUTED_ARGS \\\\\\n$ROOT_DIR/../pretrain_llama.py \\\\\\n$LLAMA2_7B_ARGS \\\\\\n$OUTPUT_ARGS \\\\\\n$OTHER_ARGS\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":true,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-megatron\",\"tag\":\"ubuntu20.04-cu11.8-torch1.14.0-py38-bccl1.2.3.1_v1.2.7.5_release-test3\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"whx-llama-test-3\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/whx-llama-test-3/output/training_logs\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"},\"Worker\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-megatron\",\"tag\":\"ubuntu20.04-cu11.8-torch1.14.0-py38-bccl1.2.3.1_v1.2.7.5_release-test3\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"whx-llama-test-3\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/whx-llama-test-3/output/training_logs\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":true,\"logPath\":\"/mnt/cluster/whx-llama-test-3/output/training_logs\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":true,\"isCopyJob\":true,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
              "aijob.cce.baidubce.com/timeline": "[{\"conditionType\":\"Created\",\"time\":1721374704},{\"conditionType\":\"Scheduled\",\"time\":1721374706},{\"conditionType\":\"Running\",\"time\":1721375168},{\"conditionType\":\"Succeeded\",\"time\":1721376909}]",
              "scheduling.k8s.io/job-enable-oversell": "false",
              "tensorboard-gc": "true"
            },
            "creationTimestamp": "2024-07-19T07:38:24Z",
            "generation": 2,
            "labels": {
              "aijob.cce.baidubce.com/ai-user-id": "44b2ef4fe15a45a7ab5b1227ae50a261",
              "aijob.cce.baidubce.com/ai-user-name": "wanghouxi",
              "aijob.cce.baidubce.com/create-from-aihcp": "true",
              "aijob.cce.baidubce.com/openapi-jobid": "pytorch-b3c9ce0b-1e76-427d-a2d7-eea086048d3d"
            },
            "managedFields": [
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      ".": {},
                      "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                      "f:aijob.cce.baidubce.com/openapi-jobid": {},
                      "f:aijob.cce.baidubce.com/pfs-id": {},
                      "f:aijob.cce.baidubce.com/raw-request": {},
                      "f:scheduling.k8s.io/job-enable-oversell": {}
                    },
                    "f:labels": {
                      ".": {},
                      "f:aijob.cce.baidubce.com/ai-user-id": {},
                      "f:aijob.cce.baidubce.com/ai-user-name": {},
                      "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                      "f:aijob.cce.baidubce.com/openapi-jobid": {}
                    }
                  },
                  "f:spec": {
                    ".": {},
                    "f:pytorchReplicaSpecs": {
                      ".": {},
                      "f:Master": {
                        ".": {},
                        "f:replicas": {},
                        "f:restartPolicy": {},
                        "f:template": {
                          ".": {},
                          "f:metadata": {
                            ".": {},
                            "f:annotations": {
                              ".": {},
                              "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                              "f:aijob.cce.baidubce.com/openapi-jobid": {},
                              "f:aijob.cce.baidubce.com/pfs-id": {},
                              "f:aijob.cce.baidubce.com/raw-request": {},
                              "f:scheduling.k8s.io/job-enable-oversell": {}
                            },
                            "f:labels": {
                              ".": {},
                              "f:aijob.cce.baidubce.com/ai-user-id": {},
                              "f:aijob.cce.baidubce.com/ai-user-name": {},
                              "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                              "f:aijob.cce.baidubce.com/openapi-jobid": {}
                            }
                          },
                          "f:spec": {
                            ".": {},
                            "f:dnsPolicy": {},
                            "f:hostNetwork": {},
                            "f:schedulerName": {},
                            "f:volumes": {}
                          }
                        }
                      },
                      "f:Worker": {
                        ".": {},
                        "f:replicas": {},
                        "f:restartPolicy": {},
                        "f:template": {
                          ".": {},
                          "f:metadata": {
                            ".": {},
                            "f:annotations": {
                              ".": {},
                              "f:aijob.cce.baidubce.com/fault-tolerance-enabled": {},
                              "f:aijob.cce.baidubce.com/openapi-jobid": {},
                              "f:aijob.cce.baidubce.com/pfs-id": {},
                              "f:aijob.cce.baidubce.com/raw-request": {},
                              "f:scheduling.k8s.io/job-enable-oversell": {}
                            },
                            "f:labels": {
                              ".": {},
                              "f:aijob.cce.baidubce.com/ai-user-id": {},
                              "f:aijob.cce.baidubce.com/ai-user-name": {},
                              "f:aijob.cce.baidubce.com/create-from-aihcp": {},
                              "f:aijob.cce.baidubce.com/openapi-jobid": {}
                            }
                          },
                          "f:spec": {
                            ".": {},
                            "f:dnsPolicy": {},
                            "f:hostNetwork": {},
                            "f:schedulerName": {},
                            "f:volumes": {}
                          }
                        }
                      }
                    },
                    "f:runPolicy": {
                      ".": {},
                      "f:schedulingPolicy": {
                        ".": {},
                        "f:priorityClass": {},
                        "f:queue": {}
                      }
                    }
                  }
                },
                "manager": "cce-ai-service",
                "operation": "Update",
                "time": "2024-07-19T07:38:24Z"
              },
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      "f:aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": {},
                      "f:aijob.cce.baidubce.com/timeline": {}
                    }
                  },
                  "f:spec": {
                    "f:pytorchReplicaSpecs": {
                      "f:Master": {
                        "f:template": {
                          "f:spec": {
                            "f:containers": {}
                          }
                        }
                      },
                      "f:Worker": {
                        "f:template": {
                          "f:spec": {
                            "f:containers": {}
                          }
                        }
                      }
                    },
                    "f:runPolicy": {
                      "f:cleanPodPolicy": {}
                    }
                  }
                },
                "manager": "controller",
                "operation": "Update",
                "time": "2024-07-19T07:38:24Z"
              },
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      "f:aijob.cce.baidubce.com/barrier-finish": {}
                    }
                  }
                },
                "manager": "jobbarrier",
                "operation": "Update",
                "time": "2024-07-19T07:46:03Z"
              },
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      "f:tensorboard-gc": {}
                    }
                  },
                  "f:status": {
                    ".": {},
                    "f:completionTime": {},
                    "f:conditions": {},
                    "f:lastReconcileTime": {},
                    "f:replicaStatuses": {
                      ".": {},
                      "f:Master": {
                        ".": {},
                        "f:selector": {},
                        "f:succeeded": {}
                      },
                      "f:Worker": {
                        ".": {},
                        "f:selector": {},
                        "f:succeeded": {}
                      }
                    },
                    "f:startTime": {}
                  }
                },
                "manager": "manager",
                "operation": "Update",
                "time": "2024-07-20T07:39:10Z"
              }
            ],
            "name": "whx-llama-test-3",
            "namespace": "default",
            "resourceVersion": "2373784196",
            "uid": "83b2ed94-afe8-40ba-ae91-fc3fe563748d"
          },
          "spec": {
            "pytorchReplicaSpecs": {
              "Master": {
                "replicas": 1,
                "restartPolicy": "Never",
                "template": {
                  "metadata": {
                    "annotations": {
                      "aijob.cce.baidubce.com/fault-tolerance-enabled": "false",
                      "aijob.cce.baidubce.com/openapi-jobid": "pytorch-b3c9ce0b-1e76-427d-a2d7-eea086048d3d",
                      "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
                      "aijob.cce.baidubce.com/raw-request": "{\"name\":\"whx-llama-test-3\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"normal\",\"oversell\":false,\"faultTolerance\":false,\"command\":\"/bin/bash -c\\n#! /bin/bash\\n#rm /workspace/llama/pile_llama_test/*_indexmap*\\n#rm -rf /workspace/llama/pile_llama_test/pile_test_jsonl/\\nROOT_DIR=/workspace/Megatron-LM/examples\\n# 数据集及CHECKPOINT的PATH可按需替换成用户自定义路径\\nDATA_PATH=/mnt/cluster/llama/pile_llama_test/pile-llama_text_document\\nTOKENIZER_PATH=/mnt/cluster/llama/tokenizer/tokenizer.model\\nTENSORBOARD_PATH=/workspace\\n\\nMOUNT_PATH=/mnt/cluster\\nPATH_RESOURCE=/workspace/llama\\n\\n\\n# Ensure the mount path exists\\nmkdir -p ${MOUNT_PATH}\\necho \\\"Contents of MOUNT_PATH before copy:\\\"\\nls -l ${MOUNT_PATH}\\n\\n# Copy data to the mount path\\ncp -r ${PATH_RESOURCE} ${MOUNT_PATH} || { echo \\\"Failed to copy PATH_RESOURCE\\\"; exit 1; }\\n\\necho \\\"Contents of MOUNT_PATH after copy:\\\"\\nls -l ${MOUNT_PATH}\\n\\n\\nGPUS_PER_NODE=8\\n\\nDISTRIBUTED_ARGS=\\\"--nproc_per_node ${GPUS_PER_NODE} --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $MASTER_ADDR --master_port $MASTER_PORT\\\"\\nLLAMA2_7B_ARGS=\\\"--tensor-model-parallel-size 1 \\\\\\n--pipeline-model-parallel-size 2 \\\\\\n--num-layers 32 \\\\\\n--hidden-size 4096 \\\\\\n--ffn-hidden-size 11008 \\\\\\n--num-attention-heads 32 \\\\\\n--micro-batch-size 1 \\\\\\n--global-batch-size 16 \\\\\\n--seq-length 512 \\\\\\n--max-position-embeddings 4096 \\\\\\n--lr 0.0003 \\\\\\n--min-lr 1.0e-5 \\\\\\n--clip-grad 1.0 \\\\\\n--weight-decay 1e-2 \\\\\\n--optimizer adam \\\\\\n--adam-beta1 0.9 \\\\\\n--adam-beta2 0.95 \\\\\\n--adam-eps 1e-05 \\\\\\n--train-iters 5000 \\\\\\n--lr-decay-iters 320000 \\\\\\n--lr-decay-style cosine \\\\\\n--lr-warmup-fraction .01 \\\\\\n--no-async-tensor-model-parallel-allreduce \\\\\\n--tokenizer-type LLaMASentencePieceTokenizer \\\\\\n--tokenizer-model $TOKENIZER_PATH \\\\\\n--activation-func swiglu \\\\\\n--use-rotary-position-embeddings \\\\\\n--rmsnorm-epsilon 1e-5 \\\\\\n--no-position-embedding \\\\\\n--disable-bias-linear \\\\\\n--attention-dropout 0 \\\\\\n--hidden-dropout 0 \\\\\\n--embedding-dropout 0 \\\\\\n--use-distributed-optimizer \\\\\\n--untie-embeddings-and-output-weights \\\\\\n--initial-loss-scale 16 \\\\\\n--sequence-parallel \\\\\\n--fused-rmsnorm \\\\\\n--fp16\\\"\\n\\nOUTPUT_ARGS=\\\"--log-interval 1 \\\\\\n --save-interval 50000 \\\\\\n --eval-interval 1000 \\\\\\n --eval-iters 10\\\"\\n\\nOTHER_ARGS=\\\"--data-path $DATA_PATH \\\\\\n--data-impl mmap \\\\\\n--split 949,50,1 \\\\\\n--tensorboard-dir ${TENSORBOARD_PATH} \\\\\\n--distributed-backend nccl\\\"\\n\\nPYTHONPATH=\\\"$ROOT_DIR/..\\\":\\\"$ROOT_DIR/../megatron/fused_kernels\\\":$PYTHONPATH \\\\\\npython -m torch.distributed.launch $DISTRIBUTED_ARGS \\\\\\n$ROOT_DIR/../pretrain_llama.py \\\\\\n$LLAMA2_7B_ARGS \\\\\\n$OUTPUT_ARGS \\\\\\n$OTHER_ARGS\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":true,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-megatron\",\"tag\":\"ubuntu20.04-cu11.8-torch1.14.0-py38-bccl1.2.3.1_v1.2.7.5_release-test3\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"whx-llama-test-3\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/whx-llama-test-3/output/training_logs\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"},\"Worker\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-megatron\",\"tag\":\"ubuntu20.04-cu11.8-torch1.14.0-py38-bccl1.2.3.1_v1.2.7.5_release-test3\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"whx-llama-test-3\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/whx-llama-test-3/output/training_logs\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":true,\"logPath\":\"/mnt/cluster/whx-llama-test-3/output/training_logs\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":true,\"isCopyJob\":true,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
                      "scheduling.k8s.io/job-enable-oversell": "false"
                    },
                    "labels": {
                      "aijob.cce.baidubce.com/ai-user-id": "44b2ef4fe15a45a7ab5b1227ae50a261",
                      "aijob.cce.baidubce.com/ai-user-name": "wanghouxi",
                      "aijob.cce.baidubce.com/create-from-aihcp": "true",
                      "aijob.cce.baidubce.com/openapi-jobid": "pytorch-b3c9ce0b-1e76-427d-a2d7-eea086048d3d"
                    }
                  },
                  "spec": {
                    "containers": [
                      {
                        "command": [
                          "/bin/bash",
                          "-c",
                          "/bin/bash -c\n#! /bin/bash\n#rm /workspace/llama/pile_llama_test/*_indexmap*\n#rm -rf /workspace/llama/pile_llama_test/pile_test_jsonl/\nROOT_DIR=/workspace/Megatron-LM/examples\n# 数据集及CHECKPOINT的PATH可按需替换成用户自定义路径\nDATA_PATH=/mnt/cluster/llama/pile_llama_test/pile-llama_text_document\nTOKENIZER_PATH=/mnt/cluster/llama/tokenizer/tokenizer.model\nTENSORBOARD_PATH=/workspace\n\nMOUNT_PATH=/mnt/cluster\nPATH_RESOURCE=/workspace/llama\n\n\n# Ensure the mount path exists\nmkdir -p ${MOUNT_PATH}\necho \"Contents of MOUNT_PATH before copy:\"\nls -l ${MOUNT_PATH}\n\n# Copy data to the mount path\ncp -r ${PATH_RESOURCE} ${MOUNT_PATH} || { echo \"Failed to copy PATH_RESOURCE\"; exit 1; }\n\necho \"Contents of MOUNT_PATH after copy:\"\nls -l ${MOUNT_PATH}\n\n\nGPUS_PER_NODE=8\n\nDISTRIBUTED_ARGS=\"--nproc_per_node ${GPUS_PER_NODE} --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $MASTER_ADDR --master_port $MASTER_PORT\"\nLLAMA2_7B_ARGS=\"--tensor-model-parallel-size 1 \\\n--pipeline-model-parallel-size 2 \\\n--num-layers 32 \\\n--hidden-size 4096 \\\n--ffn-hidden-size 11008 \\\n--num-attention-heads 32 \\\n--micro-batch-size 1 \\\n--global-batch-size 16 \\\n--seq-length 512 \\\n--max-position-embeddings 4096 \\\n--lr 0.0003 \\\n--min-lr 1.0e-5 \\\n--clip-grad 1.0 \\\n--weight-decay 1e-2 \\\n--optimizer adam \\\n--adam-beta1 0.9 \\\n--adam-beta2 0.95 \\\n--adam-eps 1e-05 \\\n--train-iters 5000 \\\n--lr-decay-iters 320000 \\\n--lr-decay-style cosine \\\n--lr-warmup-fraction .01 \\\n--no-async-tensor-model-parallel-allreduce \\\n--tokenizer-type LLaMASentencePieceTokenizer \\\n--tokenizer-model $TOKENIZER_PATH \\\n--activation-func swiglu \\\n--use-rotary-position-embeddings \\\n--rmsnorm-epsilon 1e-5 \\\n--no-position-embedding \\\n--disable-bias-linear \\\n--attention-dropout 0 \\\n--hidden-dropout 0 \\\n--embedding-dropout 0 \\\n--use-distributed-optimizer \\\n--untie-embeddings-and-output-weights \\\n--initial-loss-scale 16 \\\n--sequence-parallel \\\n--fused-rmsnorm \\\n--fp16\"\n\nOUTPUT_ARGS=\"--log-interval 1 \\\n --save-interval 50000 \\\n --eval-interval 1000 \\\n --eval-iters 10\"\n\nOTHER_ARGS=\"--data-path $DATA_PATH \\\n--data-impl mmap \\\n--split 949,50,1 \\\n--tensorboard-dir ${TENSORBOARD_PATH} \\\n--distributed-backend nccl\"\n\nPYTHONPATH=\"$ROOT_DIR/..\":\"$ROOT_DIR/../megatron/fused_kernels\":$PYTHONPATH \\\npython -m torch.distributed.launch $DISTRIBUTED_ARGS \\\n$ROOT_DIR/../pretrain_llama.py \\\n$LLAMA2_7B_ARGS \\\n$OUTPUT_ARGS \\\n$OTHER_ARGS"
                        ],
                        "env": [
                          {
                            "name": "AIHC_TENSORBOARD_LOG_PATH",
                            "value": "/mnt/cluster/whx-llama-test-3/output/training_logs"
                          },
                          {
                            "name": "AIHC_JOB_NAME",
                            "value": "whx-llama-test-3"
                          },
                          {
                            "name": "NCCL_IB_DISABLE",
                            "value": "0"
                          }
                        ],
                        "image": "registry.baidubce.com/aihc-aiak/aiak-megatron:ubuntu20.04-cu11.8-torch1.14.0-py38-bccl1.2.3.1_v1.2.7.5_release-test3",
                        "imagePullPolicy": "Always",
                        "name": "pytorch",
                        "ports": [
                          {
                            "containerPort": 23456,
                            "name": "pytorchjob-port",
                            "protocol": "TCP"
                          }
                        ],
                        "resources": {
                          "limits": {
                            "baidu.com/a800_80g_cgpu": "8",
                            "rdma/hca": "1"
                          },
                          "requests": {
                            "baidu.com/a800_80g_cgpu": "8",
                            "rdma/hca": "1"
                          }
                        },
                        "securityContext": {
                          "capabilities": {
                            "add": [
                              "IPC_LOCK"
                            ]
                          }
                        },
                        "volumeMounts": [
                          {
                            "mountPath": "/dev/shm",
                            "name": "devshm"
                          },
                          {
                            "mountPath": "/mnt/cluster",
                            "name": "pvc-pfs"
                          }
                        ]
                      }
                    ],
                    "dnsPolicy": "ClusterFirstWithHostNet",
                    "hostNetwork": true,
                    "schedulerName": "volcano",
                    "volumes": [
                      {
                        "emptyDir": {
                          "medium": "Memory",
                          "sizeLimit": "10Gi"
                        },
                        "name": "devshm"
                      },
                      {
                        "name": "pvc-pfs",
                        "persistentVolumeClaim": {
                          "claimName": "pvc-pfs"
                        }
                      }
                    ]
                  }
                }
              },
              "Worker": {
                "replicas": 1,
                "restartPolicy": "Never",
                "template": {
                  "metadata": {
                    "annotations": {
                      "aijob.cce.baidubce.com/fault-tolerance-enabled": "false",
                      "aijob.cce.baidubce.com/openapi-jobid": "pytorch-b3c9ce0b-1e76-427d-a2d7-eea086048d3d",
                      "aijob.cce.baidubce.com/pfs-id": "pfs-oYQuh4",
                      "aijob.cce.baidubce.com/raw-request": "{\"name\":\"whx-llama-test-3\",\"namespace\":\"\",\"queue\":\"default\",\"priority\":\"normal\",\"oversell\":false,\"faultTolerance\":false,\"command\":\"/bin/bash -c\\n#! /bin/bash\\n#rm /workspace/llama/pile_llama_test/*_indexmap*\\n#rm -rf /workspace/llama/pile_llama_test/pile_test_jsonl/\\nROOT_DIR=/workspace/Megatron-LM/examples\\n# 数据集及CHECKPOINT的PATH可按需替换成用户自定义路径\\nDATA_PATH=/mnt/cluster/llama/pile_llama_test/pile-llama_text_document\\nTOKENIZER_PATH=/mnt/cluster/llama/tokenizer/tokenizer.model\\nTENSORBOARD_PATH=/workspace\\n\\nMOUNT_PATH=/mnt/cluster\\nPATH_RESOURCE=/workspace/llama\\n\\n\\n# Ensure the mount path exists\\nmkdir -p ${MOUNT_PATH}\\necho \\\"Contents of MOUNT_PATH before copy:\\\"\\nls -l ${MOUNT_PATH}\\n\\n# Copy data to the mount path\\ncp -r ${PATH_RESOURCE} ${MOUNT_PATH} || { echo \\\"Failed to copy PATH_RESOURCE\\\"; exit 1; }\\n\\necho \\\"Contents of MOUNT_PATH after copy:\\\"\\nls -l ${MOUNT_PATH}\\n\\n\\nGPUS_PER_NODE=8\\n\\nDISTRIBUTED_ARGS=\\\"--nproc_per_node ${GPUS_PER_NODE} --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $MASTER_ADDR --master_port $MASTER_PORT\\\"\\nLLAMA2_7B_ARGS=\\\"--tensor-model-parallel-size 1 \\\\\\n--pipeline-model-parallel-size 2 \\\\\\n--num-layers 32 \\\\\\n--hidden-size 4096 \\\\\\n--ffn-hidden-size 11008 \\\\\\n--num-attention-heads 32 \\\\\\n--micro-batch-size 1 \\\\\\n--global-batch-size 16 \\\\\\n--seq-length 512 \\\\\\n--max-position-embeddings 4096 \\\\\\n--lr 0.0003 \\\\\\n--min-lr 1.0e-5 \\\\\\n--clip-grad 1.0 \\\\\\n--weight-decay 1e-2 \\\\\\n--optimizer adam \\\\\\n--adam-beta1 0.9 \\\\\\n--adam-beta2 0.95 \\\\\\n--adam-eps 1e-05 \\\\\\n--train-iters 5000 \\\\\\n--lr-decay-iters 320000 \\\\\\n--lr-decay-style cosine \\\\\\n--lr-warmup-fraction .01 \\\\\\n--no-async-tensor-model-parallel-allreduce \\\\\\n--tokenizer-type LLaMASentencePieceTokenizer \\\\\\n--tokenizer-model $TOKENIZER_PATH \\\\\\n--activation-func swiglu \\\\\\n--use-rotary-position-embeddings \\\\\\n--rmsnorm-epsilon 1e-5 \\\\\\n--no-position-embedding \\\\\\n--disable-bias-linear \\\\\\n--attention-dropout 0 \\\\\\n--hidden-dropout 0 \\\\\\n--embedding-dropout 0 \\\\\\n--use-distributed-optimizer \\\\\\n--untie-embeddings-and-output-weights \\\\\\n--initial-loss-scale 16 \\\\\\n--sequence-parallel \\\\\\n--fused-rmsnorm \\\\\\n--fp16\\\"\\n\\nOUTPUT_ARGS=\\\"--log-interval 1 \\\\\\n --save-interval 50000 \\\\\\n --eval-interval 1000 \\\\\\n --eval-iters 10\\\"\\n\\nOTHER_ARGS=\\\"--data-path $DATA_PATH \\\\\\n--data-impl mmap \\\\\\n--split 949,50,1 \\\\\\n--tensorboard-dir ${TENSORBOARD_PATH} \\\\\\n--distributed-backend nccl\\\"\\n\\nPYTHONPATH=\\\"$ROOT_DIR/..\\\":\\\"$ROOT_DIR/../megatron/fused_kernels\\\":$PYTHONPATH \\\\\\npython -m torch.distributed.launch $DISTRIBUTED_ARGS \\\\\\n$ROOT_DIR/../pretrain_llama.py \\\\\\n$LLAMA2_7B_ARGS \\\\\\n$OUTPUT_ARGS \\\\\\n$OTHER_ARGS\",\"datasource\":[{\"type\":\"emptydir\",\"name\":\"devshm\",\"pvc\":\"\",\"mountPath\":\"/dev/shm\",\"options\":{\"sizeLimit\":10,\"medium\":\"Memory\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}},{\"type\":\"\",\"name\":\"\",\"pvc\":\"pvc-pfs\",\"mountPath\":\"/mnt/cluster\",\"options\":{\"sizeLimit\":0,\"medium\":\"\",\"hostPath\":\"\",\"hostPathType\":\"\",\"readOnly\":false}}],\"jobFramework\":\"pytorch\",\"jobDistributed\":true,\"jobSpec\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-megatron\",\"tag\":\"ubuntu20.04-cu11.8-torch1.14.0-py38-bccl1.2.3.1_v1.2.7.5_release-test3\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"whx-llama-test-3\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/whx-llama-test-3/output/training_logs\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"},\"Worker\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"image\":\"registry.baidubce.com/aihc-aiak/aiak-megatron\",\"tag\":\"ubuntu20.04-cu11.8-torch1.14.0-py38-bccl1.2.3.1_v1.2.7.5_release-test3\",\"resource\":{\"baidu.com/a800_80g_cgpu\":8,\"rdma/hca\":1},\"env\":{\"AIHC_JOB_NAME\":\"whx-llama-test-3\",\"AIHC_TENSORBOARD_LOG_PATH\":\"/mnt/cluster/whx-llama-test-3/output/training_logs\",\"NCCL_IB_DISABLE\":\"0\"},\"command\":\"\",\"args\":\"\",\"postStart\":\"\",\"preStop\":\"\"}},\"imagePullSecrets\":null,\"imagePullSecretUsername\":\"\",\"imagePullSecretPassword\":\"\",\"tensorboard\":{\"enable\":true,\"logPath\":\"/mnt/cluster/whx-llama-test-3/output/training_logs\",\"serviceType\":\"LoadBalancer\"},\"labels\":{\"aijob.cce.baidubce.com/create-from-aihcp\":\"true\"},\"annotations\":null,\"nodeSelector\":null,\"autoCreatePVC\":true,\"hostNetwork\":true,\"isCopyJob\":true,\"sourceJobName\":\"\",\"workloadType\":\"PytorchJob\",\"pfsId\":\"pfs-oYQuh4\"}",
                      "scheduling.k8s.io/job-enable-oversell": "false"
                    },
                    "labels": {
                      "aijob.cce.baidubce.com/ai-user-id": "44b2ef4fe15a45a7ab5b1227ae50a261",
                      "aijob.cce.baidubce.com/ai-user-name": "wanghouxi",
                      "aijob.cce.baidubce.com/create-from-aihcp": "true",
                      "aijob.cce.baidubce.com/openapi-jobid": "pytorch-b3c9ce0b-1e76-427d-a2d7-eea086048d3d"
                    }
                  },
                  "spec": {
                    "containers": [
                      {
                        "command": [
                          "/bin/bash",
                          "-c",
                          "/bin/bash -c\n#! /bin/bash\n#rm /workspace/llama/pile_llama_test/*_indexmap*\n#rm -rf /workspace/llama/pile_llama_test/pile_test_jsonl/\nROOT_DIR=/workspace/Megatron-LM/examples\n# 数据集及CHECKPOINT的PATH可按需替换成用户自定义路径\nDATA_PATH=/mnt/cluster/llama/pile_llama_test/pile-llama_text_document\nTOKENIZER_PATH=/mnt/cluster/llama/tokenizer/tokenizer.model\nTENSORBOARD_PATH=/workspace\n\nMOUNT_PATH=/mnt/cluster\nPATH_RESOURCE=/workspace/llama\n\n\n# Ensure the mount path exists\nmkdir -p ${MOUNT_PATH}\necho \"Contents of MOUNT_PATH before copy:\"\nls -l ${MOUNT_PATH}\n\n# Copy data to the mount path\ncp -r ${PATH_RESOURCE} ${MOUNT_PATH} || { echo \"Failed to copy PATH_RESOURCE\"; exit 1; }\n\necho \"Contents of MOUNT_PATH after copy:\"\nls -l ${MOUNT_PATH}\n\n\nGPUS_PER_NODE=8\n\nDISTRIBUTED_ARGS=\"--nproc_per_node ${GPUS_PER_NODE} --nnodes $WORLD_SIZE --node_rank $RANK --master_addr $MASTER_ADDR --master_port $MASTER_PORT\"\nLLAMA2_7B_ARGS=\"--tensor-model-parallel-size 1 \\\n--pipeline-model-parallel-size 2 \\\n--num-layers 32 \\\n--hidden-size 4096 \\\n--ffn-hidden-size 11008 \\\n--num-attention-heads 32 \\\n--micro-batch-size 1 \\\n--global-batch-size 16 \\\n--seq-length 512 \\\n--max-position-embeddings 4096 \\\n--lr 0.0003 \\\n--min-lr 1.0e-5 \\\n--clip-grad 1.0 \\\n--weight-decay 1e-2 \\\n--optimizer adam \\\n--adam-beta1 0.9 \\\n--adam-beta2 0.95 \\\n--adam-eps 1e-05 \\\n--train-iters 5000 \\\n--lr-decay-iters 320000 \\\n--lr-decay-style cosine \\\n--lr-warmup-fraction .01 \\\n--no-async-tensor-model-parallel-allreduce \\\n--tokenizer-type LLaMASentencePieceTokenizer \\\n--tokenizer-model $TOKENIZER_PATH \\\n--activation-func swiglu \\\n--use-rotary-position-embeddings \\\n--rmsnorm-epsilon 1e-5 \\\n--no-position-embedding \\\n--disable-bias-linear \\\n--attention-dropout 0 \\\n--hidden-dropout 0 \\\n--embedding-dropout 0 \\\n--use-distributed-optimizer \\\n--untie-embeddings-and-output-weights \\\n--initial-loss-scale 16 \\\n--sequence-parallel \\\n--fused-rmsnorm \\\n--fp16\"\n\nOUTPUT_ARGS=\"--log-interval 1 \\\n --save-interval 50000 \\\n --eval-interval 1000 \\\n --eval-iters 10\"\n\nOTHER_ARGS=\"--data-path $DATA_PATH \\\n--data-impl mmap \\\n--split 949,50,1 \\\n--tensorboard-dir ${TENSORBOARD_PATH} \\\n--distributed-backend nccl\"\n\nPYTHONPATH=\"$ROOT_DIR/..\":\"$ROOT_DIR/../megatron/fused_kernels\":$PYTHONPATH \\\npython -m torch.distributed.launch $DISTRIBUTED_ARGS \\\n$ROOT_DIR/../pretrain_llama.py \\\n$LLAMA2_7B_ARGS \\\n$OUTPUT_ARGS \\\n$OTHER_ARGS"
                        ],
                        "env": [
                          {
                            "name": "AIHC_TENSORBOARD_LOG_PATH",
                            "value": "/mnt/cluster/whx-llama-test-3/output/training_logs"
                          },
                          {
                            "name": "AIHC_JOB_NAME",
                            "value": "whx-llama-test-3"
                          },
                          {
                            "name": "NCCL_IB_DISABLE",
                            "value": "0"
                          }
                        ],
                        "image": "registry.baidubce.com/aihc-aiak/aiak-megatron:ubuntu20.04-cu11.8-torch1.14.0-py38-bccl1.2.3.1_v1.2.7.5_release-test3",
                        "imagePullPolicy": "Always",
                        "name": "pytorch",
                        "ports": [
                          {
                            "containerPort": 23456,
                            "name": "pytorchjob-port",
                            "protocol": "TCP"
                          }
                        ],
                        "resources": {
                          "limits": {
                            "baidu.com/a800_80g_cgpu": "8",
                            "rdma/hca": "1"
                          },
                          "requests": {
                            "baidu.com/a800_80g_cgpu": "8",
                            "rdma/hca": "1"
                          }
                        },
                        "securityContext": {
                          "capabilities": {
                            "add": [
                              "IPC_LOCK"
                            ]
                          }
                        },
                        "volumeMounts": [
                          {
                            "mountPath": "/dev/shm",
                            "name": "devshm"
                          },
                          {
                            "mountPath": "/mnt/cluster",
                            "name": "pvc-pfs"
                          }
                        ]
                      }
                    ],
                    "dnsPolicy": "ClusterFirstWithHostNet",
                    "hostNetwork": true,
                    "schedulerName": "volcano",
                    "volumes": [
                      {
                        "emptyDir": {
                          "medium": "Memory",
                          "sizeLimit": "10Gi"
                        },
                        "name": "devshm"
                      },
                      {
                        "name": "pvc-pfs",
                        "persistentVolumeClaim": {
                          "claimName": "pvc-pfs"
                        }
                      }
                    ]
                  }
                }
              }
            },
            "runPolicy": {
              "cleanPodPolicy": "None",
              "schedulingPolicy": {
                "priorityClass": "normal",
                "queue": "default"
              }
            }
          },
          "status": {
            "completionTime": "2024-07-19T08:15:09Z",
            "conditions": [
              {
                "lastTransitionTime": "2024-07-19T07:38:24Z",
                "lastUpdateTime": "2024-07-19T07:38:24Z",
                "message": "PyTorchJob whx-llama-test-3 is created.",
                "reason": "PyTorchJobCreated",
                "status": "True",
                "type": "Created"
              },
              {
                "lastTransitionTime": "2024-07-19T07:46:08Z",
                "lastUpdateTime": "2024-07-19T07:46:08Z",
                "message": "PyTorchJob whx-llama-test-3 is running.",
                "reason": "JobRunning",
                "status": "False",
                "type": "Running"
              },
              {
                "lastTransitionTime": "2024-07-19T08:15:09Z",
                "lastUpdateTime": "2024-07-19T08:15:09Z",
                "message": "PyTorchJob whx-llama-test-3 is successfully completed.",
                "reason": "JobSucceeded",
                "status": "True",
                "type": "Succeeded"
              }
            ],
            "lastReconcileTime": "2024-07-19T07:38:24Z",
            "replicaStatuses": {
              "Master": {
                "selector": "training.kubeflow.org/job-name=whx-llama-test-3,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=master",
                "succeeded": 1
              },
              "Worker": {
                "selector": "training.kubeflow.org/job-name=whx-llama-test-3,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=worker",
                "succeeded": 1
              }
            },
            "startTime": "2024-07-19T07:38:25Z"
          }
        },
        {
          "apiVersion": "kubeflow.org/v1",
          "kind": "PyTorchJob",
          "metadata": {
            "annotations": {
              "aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": "",
              "aijob.cce.baidubce.com/timeline": "[{\"conditionType\":\"Created\",\"time\":1721375616},{\"conditionType\":\"Scheduled\",\"time\":1721375618},{\"conditionType\":\"Running\",\"time\":1721375628}]",
              "kubectl.kubernetes.io/last-applied-configuration": "{\"apiVersion\":\"kubeflow.org/v1\",\"kind\":\"PyTorchJob\",\"metadata\":{\"annotations\":{},\"name\":\"xiaojunjie-aiak-sora\",\"namespace\":\"default\"},\"spec\":{\"pytorchReplicaSpecs\":{\"Master\":{\"replicas\":1,\"restartPolicy\":\"Never\",\"template\":{\"metadata\":null,\"spec\":{\"containers\":[{\"command\":[\"bash\",\"-c\",\"sleep 100d\"],\"env\":[{\"name\":\"CUDA_DEVICE_MAX_CONNECTIONS\",\"value\":\"1\"},{\"name\":\"NCCL_DEBUG\",\"value\":\"INFO\"},{\"name\":\"NCCL_IB_DISABLE\",\"value\":\"0\"},{\"name\":\"MASTER\",\"value\":\"1\"}],\"image\":\"registry.baidubce.com/aihc-aiak/aiak-training-llm:ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\"imagePullPolicy\":\"Always\",\"name\":\"pytorch\",\"resources\":{\"limits\":{\"nvidia.com/gpu\":8,\"rdma/hca\":1}},\"securityContext\":{\"capabilities\":{\"add\":[\"IPC_LOCK\"]}},\"volumeMounts\":[{\"mountPath\":\"/dev/shm\",\"name\":\"cache-volume\"},{\"mountPath\":\"/workspace\",\"name\":\"data\",\"subPath\":\"xiaojunjie\"},{\"mountPath\":\"/mnt/pfs\",\"name\":\"data\"}]}],\"schedulerName\":\"volcano\",\"volumes\":[{\"emptyDir\":{\"medium\":\"Memory\"},\"name\":\"cache-volume\"},{\"name\":\"data\",\"persistentVolumeClaim\":{\"claimName\":\"pvc-pfs\"}}]}}}}}}\n"
            },
            "creationTimestamp": "2024-07-19T07:53:36Z",
            "generation": 2,
            "managedFields": [
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      "f:aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": {},
                      "f:aijob.cce.baidubce.com/timeline": {}
                    }
                  },
                  "f:spec": {
                    "f:pytorchReplicaSpecs": {
                      "f:Master": {
                        "f:template": {
                          "f:metadata": {},
                          "f:spec": {
                            "f:containers": {}
                          }
                        }
                      }
                    },
                    "f:runPolicy": {
                      ".": {},
                      "f:cleanPodPolicy": {}
                    }
                  }
                },
                "manager": "controller",
                "operation": "Update",
                "time": "2024-07-19T07:53:36Z"
              },
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      ".": {},
                      "f:kubectl.kubernetes.io/last-applied-configuration": {}
                    }
                  },
                  "f:spec": {
                    ".": {},
                    "f:pytorchReplicaSpecs": {
                      ".": {},
                      "f:Master": {
                        ".": {},
                        "f:replicas": {},
                        "f:restartPolicy": {},
                        "f:template": {
                          ".": {},
                          "f:spec": {
                            ".": {},
                            "f:schedulerName": {},
                            "f:volumes": {}
                          }
                        }
                      }
                    }
                  }
                },
                "manager": "kubectl-client-side-apply",
                "operation": "Update",
                "time": "2024-07-19T07:53:36Z"
              },
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:status": {
                    ".": {},
                    "f:conditions": {},
                    "f:lastReconcileTime": {},
                    "f:replicaStatuses": {
                      ".": {},
                      "f:Master": {
                        ".": {},
                        "f:active": {},
                        "f:selector": {}
                      }
                    },
                    "f:startTime": {}
                  }
                },
                "manager": "manager",
                "operation": "Update",
                "time": "2024-07-19T07:53:48Z"
              }
            ],
            "name": "xiaojunjie-aiak-sora",
            "namespace": "default",
            "resourceVersion": "2372657445",
            "uid": "c78234b2-3b17-483d-8ed0-3bbd7bdd0d7d"
          },
          "spec": {
            "pytorchReplicaSpecs": {
              "Master": {
                "replicas": 1,
                "restartPolicy": "Never",
                "template": {
                  "metadata": {},
                  "spec": {
                    "containers": [
                      {
                        "command": [
                          "bash",
                          "-c",
                          "sleep 100d"
                        ],
                        "env": [
                          {
                            "name": "CUDA_DEVICE_MAX_CONNECTIONS",
                            "value": "1"
                          },
                          {
                            "name": "NCCL_DEBUG",
                            "value": "INFO"
                          },
                          {
                            "name": "NCCL_IB_DISABLE",
                            "value": "0"
                          },
                          {
                            "name": "MASTER",
                            "value": "1"
                          }
                        ],
                        "image": "registry.baidubce.com/aihc-aiak/aiak-training-llm:ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release",
                        "imagePullPolicy": "Always",
                        "name": "pytorch",
                        "ports": [
                          {
                            "containerPort": 23456,
                            "name": "pytorchjob-port",
                            "protocol": "TCP"
                          }
                        ],
                        "resources": {
                          "limits": {
                            "nvidia.com/gpu": "8",
                            "rdma/hca": "1"
                          }
                        },
                        "securityContext": {
                          "capabilities": {
                            "add": [
                              "IPC_LOCK"
                            ]
                          }
                        },
                        "volumeMounts": [
                          {
                            "mountPath": "/dev/shm",
                            "name": "cache-volume"
                          },
                          {
                            "mountPath": "/workspace",
                            "name": "data",
                            "subPath": "xiaojunjie"
                          },
                          {
                            "mountPath": "/mnt/pfs",
                            "name": "data"
                          }
                        ]
                      }
                    ],
                    "schedulerName": "volcano",
                    "volumes": [
                      {
                        "emptyDir": {
                          "medium": "Memory"
                        },
                        "name": "cache-volume"
                      },
                      {
                        "name": "data",
                        "persistentVolumeClaim": {
                          "claimName": "pvc-pfs"
                        }
                      }
                    ]
                  }
                }
              }
            },
            "runPolicy": {
              "cleanPodPolicy": "None"
            }
          },
          "status": {
            "conditions": [
              {
                "lastTransitionTime": "2024-07-19T07:53:36Z",
                "lastUpdateTime": "2024-07-19T07:53:36Z",
                "message": "PyTorchJob xiaojunjie-aiak-sora is created.",
                "reason": "PyTorchJobCreated",
                "status": "True",
                "type": "Created"
              },
              {
                "lastTransitionTime": "2024-07-19T07:53:48Z",
                "lastUpdateTime": "2024-07-19T07:53:48Z",
                "message": "PyTorchJob xiaojunjie-aiak-sora is running.",
                "reason": "JobRunning",
                "status": "True",
                "type": "Running"
              }
            ],
            "lastReconcileTime": "2024-07-19T07:53:36Z",
            "replicaStatuses": {
              "Master": {
                "active": 1,
                "selector": "training.kubeflow.org/job-name=xiaojunjie-aiak-sora,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=master"
              }
            },
            "startTime": "2024-07-19T07:53:37Z"
          }
        },
        {
          "apiVersion": "kubeflow.org/v1",
          "kind": "PyTorchJob",
          "metadata": {
            "annotations": {
              "aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": "",
              "aijob.cce.baidubce.com/timeline": "[{\"conditionType\":\"Created\",\"time\":1721628143},{\"conditionType\":\"Scheduled\",\"time\":1721628145},{\"conditionType\":\"Running\",\"time\":1721628159}]"
            },
            "creationTimestamp": "2024-07-22T06:02:23Z",
            "generation": 2,
            "managedFields": [
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:metadata": {
                    "f:annotations": {
                      ".": {},
                      "f:aijob.cce.baidubce.com/internal-fault-tolerance-count-mark": {},
                      "f:aijob.cce.baidubce.com/timeline": {}
                    }
                  },
                  "f:spec": {
                    "f:pytorchReplicaSpecs": {
                      "f:Master": {
                        "f:template": {
                          "f:metadata": {},
                          "f:spec": {
                            "f:containers": {}
                          }
                        }
                      }
                    },
                    "f:runPolicy": {
                      ".": {},
                      "f:cleanPodPolicy": {}
                    }
                  }
                },
                "manager": "controller",
                "operation": "Update",
                "time": "2024-07-22T06:02:23Z"
              },
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:spec": {
                    ".": {},
                    "f:pytorchReplicaSpecs": {
                      ".": {},
                      "f:Master": {
                        ".": {},
                        "f:replicas": {},
                        "f:restartPolicy": {},
                        "f:template": {
                          ".": {},
                          "f:spec": {
                            ".": {},
                            "f:schedulerName": {},
                            "f:volumes": {}
                          }
                        }
                      }
                    }
                  }
                },
                "manager": "kubectl-create",
                "operation": "Update",
                "time": "2024-07-22T06:02:23Z"
              },
              {
                "apiVersion": "kubeflow.org/v1",
                "fieldsType": "FieldsV1",
                "fieldsV1": {
                  "f:status": {
                    ".": {},
                    "f:conditions": {},
                    "f:lastReconcileTime": {},
                    "f:replicaStatuses": {
                      ".": {},
                      "f:Master": {
                        ".": {},
                        "f:active": {},
                        "f:selector": {}
                      }
                    },
                    "f:startTime": {}
                  }
                },
                "manager": "manager",
                "operation": "Update",
                "time": "2024-07-22T06:02:39Z"
              }
            ],
            "name": "zhanghenghua-llama-factory-qwen14-predict",
            "namespace": "default",
            "resourceVersion": "2375968038",
            "uid": "b299db41-984d-44d3-8aff-349793775437"
          },
          "spec": {
            "pytorchReplicaSpecs": {
              "Master": {
                "replicas": 1,
                "restartPolicy": "Never",
                "template": {
                  "metadata": {},
                  "spec": {
                    "containers": [
                      {
                        "command": [
                          "bash",
                          "-c",
                          "sleep infinity"
                        ],
                        "env": [
                          {
                            "name": "CUDA_DEVICE_MAX_CONNECTIONS",
                            "value": "1"
                          },
                          {
                            "name": "NCCL_DEBUG",
                            "value": "INFO"
                          },
                          {
                            "name": "NCCL_IB_DISABLE",
                            "value": "0"
                          },
                          {
                            "name": "MASTER",
                            "value": "1"
                          }
                        ],
                        "image": "registry.baidubce.com/hac-aiacc/llama-factory:ubuntu22.04-cu12.3-torch2.2.0-py310-deepspeed0.14.4-v0.8.3",
                        "imagePullPolicy": "Always",
                        "name": "pytorch",
                        "ports": [
                          {
                            "containerPort": 23456,
                            "name": "pytorchjob-port",
                            "protocol": "TCP"
                          }
                        ],
                        "resources": {
                          "limits": {
                            "ephemeral-storage": "191680782Ki",
                            "nvidia.com/gpu": "8",
                            "rdma/hca": "1"
                          }
                        },
                        "securityContext": {
                          "capabilities": {
                            "add": [
                              "IPC_LOCK"
                            ]
                          }
                        },
                        "volumeMounts": [
                          {
                            "mountPath": "/dev/shm",
                            "name": "cache-volume"
                          },
                          {
                            "mountPath": "/workspace/LLaMA-Factory/launch.sh",
                            "name": "config-volume",
                            "subPath": "launch.sh"
                          },
                          {
                            "mountPath": "/mnt/cluster",
                            "name": "data"
                          }
                        ]
                      }
                    ],
                    "schedulerName": "volcano",
                    "volumes": [
                      {
                        "emptyDir": {
                          "medium": "Memory"
                        },
                        "name": "cache-volume"
                      },
                      {
                        "configMap": {
                          "name": "launch-llama-factory-qwen14-predict"
                        },
                        "name": "config-volume"
                      },
                      {
                        "name": "data",
                        "persistentVolumeClaim": {
                          "claimName": "pvc-pfs"
                        }
                      }
                    ]
                  }
                }
              }
            },
            "runPolicy": {
              "cleanPodPolicy": "None"
            }
          },
          "status": {
            "conditions": [
              {
                "lastTransitionTime": "2024-07-22T06:02:23Z",
                "lastUpdateTime": "2024-07-22T06:02:23Z",
                "message": "PyTorchJob zhanghenghua-llama-factory-qwen14-predict is created.",
                "reason": "PyTorchJobCreated",
                "status": "True",
                "type": "Created"
              },
              {
                "lastTransitionTime": "2024-07-22T06:02:39Z",
                "lastUpdateTime": "2024-07-22T06:02:39Z",
                "message": "PyTorchJob zhanghenghua-llama-factory-qwen14-predict is running.",
                "reason": "JobRunning",
                "status": "True",
                "type": "Running"
              }
            ],
            "lastReconcileTime": "2024-07-22T06:02:23Z",
            "replicaStatuses": {
              "Master": {
                "active": 1,
                "selector": "training.kubeflow.org/job-name=zhanghenghua-llama-factory-qwen14-predict,training.kubeflow.org/operator-name=pytorchjob-controller,training.kubeflow.org/replica-type=master"
              }
            },
            "startTime": "2024-07-22T06:02:24Z"
          }
        }
      ],
      "kind": "PyTorchJobList",
      "metadata": {
        "continue": "",
        "resourceVersion": "2377135837"
      }
    }
  }